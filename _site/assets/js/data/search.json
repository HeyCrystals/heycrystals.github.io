[
  
  {
    "title": "用好大模型?这5种实用的Prompt框架你一定要看看!",
    "url": "/posts/use-prompt-framework/",
    "categories": "大模型",
    "tags": "",
    "date": "2023-10-15 00:00:00 +0800",
    





    
    "snippet": "前言大模型正为我们带来前所未有的技术革新，而用好大模型也是有一定技巧的。本文主要分享5种实用的Prompt对话提示框架，结合自己的实际需求，让你能够灵活使用大模型!1.RTF框架RTF(Role-Task-Format)框架是一个非常简单通用的Prompt提示框架，我们和任意大模型对话场景下都可以使用该规范进行改进输出  R-Role(角色)：指定大模型担当固定角色(程序员、数据分析师、讲解...",
    "content": "前言大模型正为我们带来前所未有的技术革新，而用好大模型也是有一定技巧的。本文主要分享5种实用的Prompt对话提示框架，结合自己的实际需求，让你能够灵活使用大模型!1.RTF框架RTF(Role-Task-Format)框架是一个非常简单通用的Prompt提示框架，我们和任意大模型对话场景下都可以使用该规范进行改进输出  R-Role(角色)：指定大模型担当固定角色(程序员、数据分析师、讲解员、记者等等)  T-Task(任务): 任务，告诉大模型需要为我们做的事情  F-Format(格式)：大模型最终结果的返回格式(比如：表格、Markdown、英文等等)主要优点：  简单、方便  指定Role角色，可以让大模型在当前的角色范围内回答知识，这在一些特定的领域中非常有效  指定Role角色也能让工程上检索知识能够确定边界范围，配合元数据所发挥的威力会更强  如果结合RAG知识内容检索，那么上下文回答的内容会让用户感觉更加是顺畅示例1: 给出一份Python语言的学习清单  Role：指定大模型角色为Python布道师  Task：Python语言的学习从基础到进阶清单列表  Format： 以表格的形式返回在实际工作的任务中，我通过优化Prompt工程，对于我们的产品改善，对于回答的内容改善也非常明显！  在我司给宁波天一阁开发的AI讲解产品中，我们提供和大模型对话的RAG产品，将天一阁的相关知识导入到系统，借助大模型进行讲解回答对比以下两个Prompt的区别：原Prompt：基于以下已知信息，简洁和专业的来回答天一阁相关的的问题。如果无法从中得到答案，请说 \"根据已知信息无法回答该问题\" 或 \"没有提供足够的相关信息\"，不允许在答案中添加编造成分，答案请使用中文。问题:{}已知内容:{}改进后的Prompt：你是宁波天一阁的历史研究员，基于以下已知信息，简洁和专业的来回答天一阁相关的的问题。如果无法从中得到答案，请根据根据实际回答，不要臆测内容，否则请说 \"根据已知信息无法回答该问题\" 或 \"没有提供足够的相关信息\"，不允许在答案中添加编造成分，答案请使用中文。问题:{}已知内容:{}改进后，大模型回答更加拟人化，如下图：2.思考链模式通过这种模式来逐步改善大模型的推理能力，非常适合一些复杂的任务处理。例如：  分析型或者逻辑推理型的任务  决策  解决问题(比如程序员根据错误日志找Bug)而要使用这种模式，只需要在末尾添加”让我们逐步思考”即可。3. RISEN框架  R-Role:大模型扮演的角色  I-Instructions: 指示命令，和Task-任务差不多  S-Steps: 步骤  E-End Goal: 最终目标  N-Narrowing(Constraints): 缩小范围(约束条件)，和RTF框架中的Format有异曲同工之妙，一个是格式的约束，而这里的约束可以是任意方面，比如回答的内容(特定领域)、字数限制等等方面该框架主要适合：  撰写具有特定约束的任务(例如博客文章)  有明确指导方针的任务（例如商业计划）示例：4.RODES框架  R-Role: 角色  O - Objective: 目标  D - Details: 详细的细节  E - Examples: 示例  S - Sense Check: 感官检查示例：5.密度链模式密度链模式Prompt是Salesforce、麻省理工学院和哥伦比亚大学的研究人员推出的一种新提示，它非常的高效,使用递归来创建越来越好的输出的提示，与普通提示生成的 GPT-4 摘要相比，它生成的摘要更加密集且更适合人们理解。  这种模式在RAG工程中非常实用，想想看你的客户上传的文档知识库(PDF/WORD)都是长篇的步骤性的文档,而在RAG召回送给大模型的Context上下文又受限于大模型的Token限制,为了更好的回答用户提问的问题，对于上传的知识库做密度链模式的摘要总结，然后索引整个文章内容召回是非常有必要的，最终能够非常精准的回答用户的问题。适合：  总结  改进您最喜欢的提示  通过递归生成可用的长格式内容密度链模式的Prompt如下：文章: {ARTICLE}您将为上述文章生成越来越简洁、实体密集的摘要。重复以下2个步骤5次：- 步骤1:从文章中识别出先前生成的摘要中缺少的 1-3 个信息实体（以“;”分隔）。- 步骤2:写一个新的、长度相同的、更密集的摘要，其中涵盖先前摘要中的每个实体和细节以及缺失的内容实体。缺少的实体是:- **相关的:**与主要故事相关，- **具体的:**描述具体而简洁（5个字或更少），- **新颖的:**不在之前的摘要中- **务实的:**存在于文章中- **任何地方:** 位于文章中的任何位置**指南:**- 第一个摘要应该较长（4-5句，约80个词），但非常不具体，除了标记为缺失的实体外，几乎没有包含其他信息。使用过度冗长的语言和填充词（例如，“本文讨论”）以达到约80个词。- 让每个词都有意义：重新撰写前一个摘要以改善流畅性，并为额外的实体腾出空间。- 利用融合、压缩和删除诸如“文章讨论”的无信息短语，腾出空间。- 摘要应变得非常密集而简洁，但又是自包含的，例如，不需要阅读文章就能容易理解。- 缺失的实体可以出现在新摘要的任何位置。- 永远不要删除前一个摘要中的实体。如果无法腾出空间，就添加更少的新实体。请记住，对于每个摘要都使用相同数量的词。以JSON格式回答。JSON应该是一个字典列表（长度为5），其中键是“Missing_Entities”和“Denser_Summary”。关于密度链模式的Prompt论文可以参考：https://arxiv.org/pdf/2309.04269.pdf或者微信公众号回复”cod”获取文件总结Prompt对话提示框架在大模型领域中是非常重要的一环,不管你是在直接使用大模型，还是在做RAG领域的产品开发,Prompt的重要程度都是无可替代的。希望大家能根据本文列出的这5种Prompt框架进行举一反三，多多实践～~对于Prompt工程技术细节，可以阅读员外的这两篇文章:  一文讲清楚实用Prompt工程  高级prompt工程讲解"
  },
  
  {
    "title": "实战0-1,Java开发者也能看懂的大模型应用RAG开发实践",
    "url": "/posts/rag-inaction-java/",
    "categories": "大模型, Java",
    "tags": "",
    "date": "2023-10-12 00:00:00 +0800",
    





    
    "snippet": "前言在前几天的文章中，我分享说在RAG领域，很多都是工程上的实践，做AI大模型应用的开发其实Java也能写，那么本文就一个Java开发者的立场，构建实现一个最基础的大模型应用系统。而大模型应用系统其实在目前阶段，可能应用最广的还是RAG领域，因此，本文也是通过在RAG领域的基础架构下，来实现应用的开发，主要需求点：让大模型理解文本(知识库)内容，基于知识库范围内的内容进行回答对话而基于知识库...",
    "content": "前言在前几天的文章中，我分享说在RAG领域，很多都是工程上的实践，做AI大模型应用的开发其实Java也能写，那么本文就一个Java开发者的立场，构建实现一个最基础的大模型应用系统。而大模型应用系统其实在目前阶段，可能应用最广的还是RAG领域，因此，本文也是通过在RAG领域的基础架构下，来实现应用的开发，主要需求点：让大模型理解文本(知识库)内容，基于知识库范围内的内容进行回答对话而基于知识库的回答会帮助我们解决哪些问题呢？  ✅ 节省大模型训练成本：我们知道ChatGPT的知识内容停留在2021年，最新的知识它并不知道，而检索增强生成则可以解决大模型无法快速学习的问题，训练大模型代价是非常昂贵的，不仅仅只是金钱，还包括时间，随着模型的参数大小成本成正相关。  ✅ 让大模型更聪明：很多企业内部的私有数据大模型并没有学习，而通过RAG的方式可以让大模型在知识库范围的领域进行回答，避免胡说八道，基于底层大模型的基座，可以让我们的应用系统看上去更加的聪明。在本文中，你将学习到：  ✅ RAG工程的基本处理框架流程(基于Java)  ✅ 向量数据库的基础使用及了解技术栈考虑到作者也是Java开发者，因此本文所选择的技术栈以及中间件也是Java人员都耳熟能详的，主要技术栈如下：1、开发框架：Spring Boot、Spring Shell(命令行对话)Java开发者对于Spring Boot的生态应该是非常熟悉的，而选择Spring Shell工具包主要是为了演示命令行的交互问答效果，和本次的技术无太大关系，算是一个最小雏形的产品交互体验。2、HTTP组件：OkHTTP、OkHTTP-SSE此次我们选择的大模型是以智谱AI开放的ChatGLM系列为主，因此我们需要HTTP组件和商业大模型的API进行接口的对接，当然开发者如果有足够的条件，也是可以在本地部署开源大模型并且开放API接口进行调试的，这个并不冲突，本文只是为了方便演示效果，所以使用了智谱的大模型API接口，而智谱AI注册后，默认提供了一个18元的免费Token消费额度，因此接口的API-Key只需要注册一个即可快速获取。3、工具包：Hutool非常好用的一个基础工具包组件，封装了很多工具类方法，包含字符、文件、时间、集合等等本文会使用到Hutool包的文本读取和切割方法。4、向量数据库：ElasticSearch向量数据库是RAG应用程序的基础中间件，所有的文本Embedding向量都需要存储在向量数据库中间件中进行召回计算，当然在Java领域并没有类似Python中numpy这类本地化工具组件包，即可快速实现矩阵计算等需求(PS:最近Java21的发布中，不仅仅只是虚拟线程等新特性，提供的向量API相信在未来AI领域，Java也会有一席之地的)，所以选择了独立部署的中间件。本文选择ElasticSearch可能对于Java开发人员也是比较熟悉的一个组件，毕竟ES在Java领域用途还是非常广的，只是可能很多开发者并不知道ElasticSearch居然还有存储向量数据的功能？对于向量数据库中间件的选择，目前市面上有非常多的向量数据库，包括：Milvus、Qdrant、Postgres(pgvector)、Chroma 等等，Java开发者可以在熟悉当前流程后，根据自己的实际需求，选择符合企业生产环境的向量数据库。5、LLM大模型：ChatGLM-Std为了演示方便，本文直接使用开放API接口的商业大模型，智谱AI提供的ChatGLM-StdRAG工程的基本处理流程在RAG检索增强生成领域中，最简单的核心处理流程架构图如下：  该架构图图是一个非常简单的流程图，在RAG领域中其实有非常多的处理细节，当我们深入了解后就会知道  我们后续根据该图来进行Java编码实现。在RAG应用工程领域，其实整个程序的处理包含两部分：  问答：对用户提问的问题通过向量Embedding模型处理，然后通过查询向量数据库(ElasticSearch)进行相似度计算获取和用户问题最相似的知识库段落内容，获取成功后，构建Prompt，最终发送给大模型获取最终的答案。  数据处理：数据的处理是将用户私有的数据进行提取，包括各种结构化及非结构化数据(例如PDF/Word/Text等等)，提取文本数据后进行分割处理，最终通过向量Embedding模型将这些分割后的段落进行向量化，最终向量数据存储在基础设施向量数据库组件中，以供后续的问答流程使用。从图中我们可以知道，在我们所需要的大模型处于什么位置，以及它的作用，主要是两个模型的应用：  向量Embedding模型：对我们本地知识的向量表征处理，将文本内容转化为便于计算机理解的向量表示  LLM问答大模型：大模型负责将我们通过语义召回的段落+用户的问题结合，构建的Prompt送给大模型以获取最终的答案，问答大模型在这里充当的角色是理解我们送给他的内容，然后进行精准回答Java编码实践我们理解了基础的架构流程，接下来就是编码实现了环境准备Java：JDK 1.8ElasticSearch：7.16.1对于ElasticSearch的安装，可以通过docker-compose在本地快速部署一个编写docker-compose.yml配置文件，当前部署目录建data文件夹挂载数据目录version: \"3\"services:  elasticsearch:    image: elasticsearch:7.16.1    ports:      - \"9200:9200\"      - \"9300:9300\"    environment:      node.name: es      cluster.name: elasticsearch      discovery.type: single-node        ES_JAVA_OPTS: -Xms4096m -Xmx4096m    volumes:      - ./data:/usr/share/elasticsearch/data    deploy:      resources:        limits:          cpus: \"4\"          memory: 5G        reservations:          cpus: \"1\"          memory: 2G    restart: always启动Es：docker-compose up -d应用初体验先来看整个程序的应用效果，通过Spring Shell环境下，程序启动后，如下图所示：程序启动后，在命令行终端，我们可以看到一个可交互的命令行，此时，我们可以通过add和chat两个命令完成图1中的整个流程先使用add命令加载文档，在data目录下分别存储了001.txt、002.txt两个文件，通过命令加载向量处理，如下图：当日志显示保存向量成功后，此时，我们即可以通过chat命令进行对话了，我们先来看看002.txt的文本主要说了什么内容？  data目录下的文本，开发者在调试时可以自己随意添加,网上随便找的文章都可以文章内容是一篇非常具有代表性的时政人物介绍新闻，那么我们就根据该文章的内容进行问答！问题1:苏州2022年全市的GDP是多少?问题2:吉林省宣传部部长现在是谁？通过第一个问题，你是否可以发现问题呢？，如果你问ChatGPT一样的问题，它能准确回答吗？以下是ChatGPT的回答通过对比ChatGPT，开发者应该能看到一个基础的对比效果，主要体现：  我们都知道ChatGPT大模型的内容日期截止到2021年，之后世界发生了什么，它并不知道，同类的GPT大模型也会出现一样的问题，因为训练大模型的代价是非常昂贵的，不可能按周、月，甚至是年的频率去更新大模型。  基于现有的知识回答内容(RAG)，能够有效的避免大模型胡说八道,而且回答的更精准技术实现进行问答体验后，我们来看具体的Java代码实现。新建Spring Boot项目，工程目录如下：GitHub：https://github.com/xiaoymin/LlmInAction/tree/master/llm_chat_java_hello从上文的RAG流程图中，我们知道了主要分两个步骤来实现，分别是数据的向量处理和问答由于是通过Spring Shell进行实现，因此这里我也分开，主要实现了两个Command命令：  add：在data目录下，为了演示需要，存放了两个txt内容，可以通过add file名称来实现文档的向量化流程加载处理，数据的处理开发者在实际的生产过程中可以通过定时任务、MQ消息等方式进行异步处理。  chat：通过命令chat 问题即可在Spring Shell的命令行终端进行对话，可以问data目录下相关的问题为了方便后续的处理，程序启动时即会自动构建向量数据库的索引集合，代码如下：/**     * 初始化向量数据库index     * @param collectionName 名称     * @param dim 维度     */    public boolean initCollection(String collectionName,int dim){        log.info(\"collection:{}\", collectionName);        // 查看向量索引是否存在，此方法为固定默认索引字段        IndexOperations indexOperations = elasticsearchRestTemplate.indexOps(IndexCoordinates.of(collectionName));        if (!indexOperations.exists()) {            // 索引不存在，直接创建            log.info(\"index not exists,create\");            //创建es的结构，简化处理            Document document = Document.from(this.elasticMapping(dim));            // 创建            indexOperations.create(new HashMap&lt;&gt;(), document);            return true;        }        return true;    }Es中的Index的Mapping结构如下：开发者需要注意vector字段，字段类型时dense_vector,并且指定向量维度为1024  向量维度的长度指定是和最终向量Embedding模型息息相关的，不同的模型有不同的维度，比如ChatGPT的向量模型维度是1536，百度文心一言也有368的，因此根据实际情况进行选择。  而这里因为我们选择的是智谱AI的向量模型，该模型返回的维度为1024，那么我们在向量数据库的维度就设置为1024首先是add命令实现文档的向量化过程处理，代码如下：@Slf4j@AllArgsConstructor@ShellComponentpublic class AddTxtCommand {    final TxtChunk txtChunk;    final VectorStorage vectorStorage;    final ZhipuAI zhipuAI;    @ShellMethod(value = \"add local txt data\")    public String add(String doc){        log.info(\"start add doc.\");        // 加载        List&lt;ChunkResult&gt; chunkResults= txtChunk.chunk(doc);        // embedding        List&lt;EmbeddingResult&gt; embeddingResults=zhipuAI.embedding(chunkResults);        // store vector        String collection= vectorStorage.getCollectionName();        vectorStorage.store(collection,embeddingResults);        log.info(\"finished\");        return \"finished docId:{}\"+doc;    }}我们完全按照图1RAG的流程架构图进行代码的变现，主要的步骤：1、加载指定的文档，并且将文档内容进行分割处理(按固定size大小进行分割处理)，得到分割集合chunkResults，代码如下：@Slf4j@Component@AllArgsConstructorpublic class TxtChunk {    public List&lt;ChunkResult&gt; chunk(String docId){        String path=\"data/\"+docId+\".txt\";        log.info(\"start chunk---&gt; docId:{},path:{}\",docId,path);        // 读取data目录下的文件流        ClassPathResource classPathResource=new ClassPathResource(path);        try {            // 读取为文本            String txt=IoUtil.read(classPathResource.getInputStream(), StandardCharsets.UTF_8);            //按固定字数分割,256            String[] lines=StrUtil.split(txt,256);            log.info(\"chunk size:{}\", ArrayUtil.length(lines));            List&lt;ChunkResult&gt; results=new ArrayList&lt;&gt;();            //此处给每个文档一个固定的chunkId            AtomicInteger atomicInteger=new AtomicInteger(0);            for (String line:lines){                ChunkResult chunkResult=new ChunkResult();                chunkResult.setDocId(docId);                chunkResult.setContent(line);                chunkResult.setChunkId(atomicInteger.incrementAndGet());                results.add(chunkResult);            }            return results;        } catch (IOException e) {            log.error(e.getMessage());        }        return new ArrayList&lt;&gt;();    }}2、将分块的集合通过智谱AI提供的向量Embedding模型进行向量化处理，代码实现如下：/**     * 批量     * @param chunkResults 批量文本     * @return 向量     */    public List&lt;EmbeddingResult&gt; embedding(List&lt;ChunkResult&gt; chunkResults){        log.info(\"start embedding,size:{}\",CollectionUtil.size(chunkResults));        if (CollectionUtil.isEmpty(chunkResults)){            return new ArrayList&lt;&gt;();        }        List&lt;EmbeddingResult&gt; embeddingResults=new ArrayList&lt;&gt;();        for (ChunkResult chunkResult:chunkResults){            //分别处理            embeddingResults.add(this.embedding(chunkResult));        }        return embeddingResults;    }    public EmbeddingResult embedding(ChunkResult chunkResult){       //获取智谱AI的开发Key        String apiKey= this.getApiKey();        // 初始化http客户端        OkHttpClient.Builder builder = new OkHttpClient.Builder()                .connectTimeout(20000, TimeUnit.MILLISECONDS)                .readTimeout(20000, TimeUnit.MILLISECONDS)                .writeTimeout(20000, TimeUnit.MILLISECONDS)                .addInterceptor(new ZhipuHeaderInterceptor(apiKey));        OkHttpClient okHttpClient = builder.build();        EmbeddingResult embedRequest=new EmbeddingResult();        embedRequest.setPrompt(chunkResult.getContent());        embedRequest.setRequestId(Objects.toString(chunkResult.getChunkId()));        // 智谱embedding模型接口        Request request = new Request.Builder()                .url(\"https://open.bigmodel.cn/api/paas/v3/model-api/text_embedding/invoke\")                .post(RequestBody.create(MediaType.parse(ContentType.JSON.getValue()), GSON.toJson(embedRequest)))                .build();        try {            Response response= okHttpClient.newCall(request).execute();            String result=response.body().string();            ZhipuResult zhipuResult= GSON.fromJson(result, ZhipuResult.class);            EmbeddingResult ret= zhipuResult.getData();            ret.setPrompt(embedRequest.getPrompt());            ret.setRequestId(embedRequest.getRequestId());            return  ret;        } catch (IOException e) {            throw new RuntimeException(e);        }    }3、向量处理成功后，我们即可将向量数据存储在向量数据库中间件(ElasticSearch)中,调用vectorStorage.store处理，代码如下：public void store(String collectionName,List&lt;EmbeddingResult&gt; embeddingResults){        //保存向量        log.info(\"save vector,collection:{},size:{}\",collectionName, CollectionUtil.size(embeddingResults));        List&lt;IndexQuery&gt; results = new ArrayList&lt;&gt;();        for (EmbeddingResult embeddingResult : embeddingResults) {            ElasticVectorData ele = new ElasticVectorData();            ele.setVector(embeddingResult.getEmbedding());            ele.setChunkId(embeddingResult.getRequestId());            ele.setContent(embeddingResult.getPrompt());            results.add(new IndexQueryBuilder().withObject(ele).build());        }        // 构建数据包        List&lt;IndexedObjectInformation&gt; bulkedResult = elasticsearchRestTemplate.bulkIndex(results, IndexCoordinates.of(collectionName));        int size = CollectionUtil.size(bulkedResult);        log.info(\"保存向量成功-size:{}\", size);    }至此，整个文本数据的Embedding处理就完成了。数据处理完成后，接下来我们需要实现问答chat命令,来看代码实现：@AllArgsConstructor@Slf4j@ShellComponentpublic class ChatCommand {    final VectorStorage vectorStorage;    final ZhipuAI zhipuAI;    @ShellMethod(value = \"chat with files\")    public String chat(String question){        if (StrUtil.isBlank(question)){            return \"You must send a question\";        }        //句子转向量        double[] vector=zhipuAI.sentence(question);        // 向量召回        String collection= vectorStorage.getCollectionName();        String vectorData=vectorStorage.retrieval(collection,vector);        if (StrUtil.isBlank(vectorData)){            return \"No Answer!\";        }        // 构建Prompt        String prompt= LLMUtils.buildPrompt(question,vectorData);        zhipuAI.chat(prompt);        // 大模型对话        //return \"you question:{}\"+question+\"finished.\";        return StrUtil.EMPTY;    }}Chat命令主要包含的步骤如下：1、将用户的问句首先通过向量Embedding模型转化得到一个多维的浮点型向量数组，代码如下：/**     * 获取句子的向量     * @param sentence 句子     * @return 向量     */    public double[] sentence(String sentence){        ChunkResult chunkResult=new ChunkResult();        chunkResult.setContent(sentence);        chunkResult.setChunkId(RandomUtil.randomInt());        EmbeddingResult embeddingResult=this.embedding(chunkResult);        return embeddingResult.getEmbedding();    }2、根据向量数据查询向量数据库召回相似的段落内容，vectorStorage.retrieval方法代码如下：public String retrieval(String collectionName,double[] vector){        // Build the script,查询向量        Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();        params.put(\"query_vector\", vector);        // 计算cos值+1，避免出现负数的情况，得到结果后，实际score值在减1再计算        Script script = new Script(ScriptType.INLINE, Script.DEFAULT_SCRIPT_LANG, \"cosineSimilarity(params.query_vector, 'vector')+1\", params);        ScriptScoreQueryBuilder scriptScoreQueryBuilder = new ScriptScoreQueryBuilder(QueryBuilders.boolQuery(), script);        // 构建请求        NativeSearchQuery nativeSearchQuery = new NativeSearchQueryBuilder()                .withQuery(scriptScoreQueryBuilder)                .withPageable(Pageable.ofSize(3)).build();        SearchHits&lt;ElasticVectorData&gt; dataSearchHits = this.elasticsearchRestTemplate.search(nativeSearchQuery, ElasticVectorData.class, IndexCoordinates.of(collectionName));        //log.info(\"检索成功，size:{}\", dataSearchHits.getTotalHits());        List&lt;SearchHit&lt;ElasticVectorData&gt;&gt; data = dataSearchHits.getSearchHits();        List&lt;String&gt; results = new LinkedList&lt;&gt;();        for (SearchHit&lt;ElasticVectorData&gt; ele : data) {            results.add(ele.getContent().getContent());        }        return CollectionUtil.join(results,\"\");    }这里主要利用了ElasticSearch提供的cosineSimilarity余弦相似性函数，计算向量得到相似度的分值，分值会在区间[0,1]之间，如果无限趋近于1那么代表用户输入的句子和之前我们存储在向量中的句子是非常相似的，越相似代表我们找到了语义相近的文档内容，可以作为最终构建大模型Prompt的基础内容。  向量矩阵的计算除了余弦相似性，还有IP点积、欧几里得距离等等，根据实际情况选择不同的算法实现。3、向量召回Top3得到相似的语义文本内容后，我们就可以构建Prompt了，并且发送给大模型，Prompt如下：public static String buildPrompt(String question,String context){        return \"请利用如下上下文的信息回答问题：\" + \"\\n\" +                question + \"\\n\" +                \"上下文信息如下：\" + \"\\n\" +                context + \"\\n\" +                \"如果上下文信息中没有帮助,则不允许胡乱回答！\";    }而在构建Prompt时，我们可以遵循一个最简单的框架范式,RTF框架(Role-Task-Format)：  R-Role：指定GPT大模型担任特定的角色  T-Task：任务,需要大模型做的事情  F-Format：大模型返回的内容格式(常规情况下可以忽略)4、最后是调用大模型，实现sse流式调用输出，代码如下： public void chat(String prompt){        try {            OkHttpClient.Builder builder = new OkHttpClient.Builder()                    .connectTimeout(20000, TimeUnit.MILLISECONDS)                    .readTimeout(20000, TimeUnit.MILLISECONDS)                    .writeTimeout(20000, TimeUnit.MILLISECONDS)                    .addInterceptor(new ZhipuHeaderInterceptor(this.getApiKey()));            OkHttpClient okHttpClient = builder.build();            ZhipuChatCompletion zhipuChatCompletion=new ZhipuChatCompletion();            zhipuChatCompletion.addPrompt(prompt);            // 采样温度，控制输出的随机性，必须为正数            // 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定            zhipuChatCompletion.setTemperature(0.7f);            zhipuChatCompletion.setTop_p(0.7f);            EventSource.Factory factory = EventSources.createFactory(okHttpClient);            ObjectMapper mapper = new ObjectMapper();            String requestBody = mapper.writeValueAsString(zhipuChatCompletion);            Request request = new Request.Builder()                    .url(\"https://open.bigmodel.cn/api/paas/v3/model-api/chatglm_std/sse-invoke\")                    .post(RequestBody.create(MediaType.parse(ContentType.JSON.getValue()), requestBody))                    .build();            CountDownLatch countDownLatch=new CountDownLatch(1);            // 创建事件,控制台输出            EventSource eventSource = factory.newEventSource(request, new ConsoleEventSourceListener(countDownLatch));            countDownLatch.await();        } catch (Exception e) {            log.error(\"llm-chat异常：{}\", e.getMessage());        }    }SSE流式的调用我们使用了okhttp-sse组件提供的功能快速实现。好了，整个工程层面的Java代码实现就已经全部完成了。最后以上就是本片分享的全部内容了，通过Java开发语言，实现一个最小可用级别的RAG大模型应用！相信你看完本文后，也能够对AI大模型应用的开发有一个基本的了解。如果你也在关注大模型、RAG检索增强生成技术，欢迎关注我，一起探索学习、成长～！附录本文代码Github：https://github.com/xiaoymin/LlmInAction智谱AI：https://open.bigmodel.cn/"
  },
  
  {
    "title": "全面进击AI大模型、RAG领域",
    "url": "/posts/llm-start/",
    "categories": "大模型",
    "tags": "RAG实战, RAG, 大模型实战, LLM",
    "date": "2023-10-10 00:00:00 +0800",
    





    
    "snippet": "写在前面首先，非常感谢关注Knife4j项目的朋友，该公众号应该是今年开始，对于开源项目Knife4j的更新都在此公众号进行了第一时间的发布更新，包括该项目的迭代、想法、实践等等内容，包括最近Knife4j的付费产品Knife4jInsight的推出，虽然更新的不是很频繁，但对于还是要给自己一直坚持的事情做输出点赞的(感动了自己😹)。对于写公众号而言，对于文章的发表，如果有人持续关注的话，会...",
    "content": "写在前面首先，非常感谢关注Knife4j项目的朋友，该公众号应该是今年开始，对于开源项目Knife4j的更新都在此公众号进行了第一时间的发布更新，包括该项目的迭代、想法、实践等等内容，包括最近Knife4j的付费产品Knife4jInsight的推出，虽然更新的不是很频繁，但对于还是要给自己一直坚持的事情做输出点赞的(感动了自己😹)。对于写公众号而言，对于文章的发表，如果有人持续关注的话，会是一种正向的鼓励～！而现在，考虑到我实际工作中的内容，目前工作核心是在做大模型RAG(检索增强生成)方面的开发工作，主要还是以Java技术栈进行产品的功能迭代开发，Python语言则更多的偏向底层大模型方面，包括大模型(LLM)的训练、微调、数据标注、向量Embedding等领域，工程上，业务产品测的逻辑实现、编排，接口开发等等功能还是以Java语言实现为主，并非使用当下最火的LangChain、LlaMaIndex等Python框架，我在昨天看一本书《Java开发之道》里面提到，开发者在实际开发过程中，在产品或项目开发周期结束后，需要善于总结自己的工作内容，我觉得以Blog或者视频的形式进行输出最好，这样才能更快速的成长。我回想起这么多年的工作，对于一个领域，不管是技术层面，或者是业务层面，似乎一直是缺少总结性的输出的，或者说做的都不是太深入。在早些时候，我和我的老大哥员外说，这么多年做的东西不管是产品、还是项目，都不太能拿的出手，而随着时间越久，这种深深的挫败感就从内心油然而生，每每想起，都自感恼火😫。主要原因还是我们做的东西都太表面了，在技术层面，我们很多技术都是浮于表面，并没有做持续深度的精进，产品层面，一个像样的产品是经过千锤百炼的打磨的，细扣每一个细节，把同类竞品比下去，也许产品上面一个看似不起眼的优点，都能把同类的竞品给比下去，而要做到产品上的优势体现，技术人员的投入是成正相关的。项目就更不用说了，交钥匙工程(内部代号，意指项目做完就验收了，至于使用如何，功能好不好用从来没care过，业主也不care)的项目做的已经数都数不过来了。而最近我和我的老伙计员外已经一头扎进了AI大模型、RAG(Retrieval Augmented Generation-检索增强生成)这个赛道，每天讨论的都是大模型、RAG等相关内容，然后产品的技术栈开发又是Java为主，Python为辅，在Java语言这个领域开发AI应用，好像目前在RAG这个领域并没有相关的技术文档、博客输出，基本80%都是Python，我在看了LangChain、LlaMaIndex等Python框架处理开发大模型应用(主要是RAG)时，除了在本地加载大模型外，很多其实都是工程方面的知识，并非一定要使用Python语言来进行开发，而我最近实际工作中又在做这个，因此，希望能够通过以Java+Python两种语言的形式，通过学习大模型、RAG等新型领域的知识,甚至是学习Python语言，将自己学到的内容以及一些工作中的实践通过文章的方式进行输出分享，更多的还是会将内容应用的实际的产品中，也希望在这个领域做一个深耕，不管是技术上还是业务领域，大模型这一波，我觉得每一个开发者都应该持续保持关注。在AI大模型、RAG这个赛道，我们要做的事情：      技术：深挖AI大模型、RAG领域的技术细节(应用工程领域)，从思想、代码、架构等领域都需要花120%的投入，知其所以然！          ☑️ 考虑到我并非搞算法的人员，底层的大模型算法等内容，我觉得对于我自己的要求而言，做到知道、了解即可，甚至有必要的话，搞一张4090(太贵了，还没舍得买)的卡跑跑预训练的模型也是有必要的！      ☑️ RAG领域在工程层面的知识所涉及的面也是足够广的，对于做应用开发者而言，也并非一朝一夕就能全盘了解其中的细节，需要做的就是两字：“深耕”      ☑️ 技术层面有时候是需要较真一下的，解决关键的核心技术问题是对竞对产品的致命打击            产品：坚持价值输出导向,倾听客户的意见,坚决反对交钥匙工程          ☑️ 技术上输出最终都会落地到实际应用产品的开发上，而产品需要坚持的事情则是要尊重用户，技术测则需要尊重产品      ☑️ 价值输出导向是永恒的真理，客户付费买单，最终看中的也是这个产品所带来的价值，或者说能够给客户带来收益(赚钱才是硬道理)      ☑️ 做顺势而为的事情，而大模型这一波技术浪潮，我觉得做这方面相关的内容或者产品技术探索，就是顺势了      🆕 新名称这个公众号之前都是以Swagger/OpenAPI/Knife4j等领域相关的名称，因为一直在维护开源项目Knife4j，主要还是和接口相关的，就一直用了这些名称！思来想去，公众号的性质也是个人性质，以后更多的还是以个人的一些想法、工作实践等内容为主进行输出，就干脆换回之前一直用的网络昵称名称吧：八一菜刀  🆕 名称含义(该公众号之前注册时也是用的这个名称，相当于恢复出厂设置了)  八一：字面意思一致  菜刀：作者故乡来自湖南省桑植县，贺龙元帅故乡，贺老总两把菜刀闹革命是旗帜，以此纪念，同时也有时刻思念故乡之意！✍️ 要写一些什么呢？目前看来，主要两个方面：  开源：开源项目Knife4j并没有停更，所以和这个项目相关的内容、资讯等，也会同步发布在这个公众号里面，这个项目作者有精力的情况下还是会持续更新下去的。  RAG：以学习者的心态，学习大模型领域相关的技术，特别是RAG领域，这块领域我觉得哪怕你不是一个算法人员，而仅仅只是一个普通的开发者(Java/Python/.Net等)，是可以触控可及的，而我的工作中目前正在做这类产品的开发迭代，不管是学习或者工作中，必然会碰到很多棘手的问题，那么就会将自己的思考以及实践总结分享出来。结合我最近的工作内容，我总结了一部分的大纲内容(后面随着学习的深入可能会扩展更多)，如下图：在技术层面，我愿称这方面的技术合集为”大模型应用工程技术“。为什么这么说呢？主要几个方面：  主要还是基于应用层面的技术围绕展开，而底层的大模型训练、数据标注、基于预训练模型的微调(Fine-turn)等领域，我觉得那是专业算法人员干的事情，比如基于企业的私有数据调整开源预训练大模型的权重，通过SFT手段进行微调，或者从0到1基于数据语料构建一个全新的垂直领域的Embedding模型，这已经属于更便底层的领域了，相信很多和我一样的Java开发人员其实像接触到这方面的知识，哪怕是学习都是很吃力的，就做到了解和知道吧，看个人兴趣。  而RAG领域的知识点，更多的是偏工程应用技术，包括数据的处理、存储、逻辑编排等等对于非算法领域的人员，对于业务开发人员来说我们是擅长的，虽然也是和AI大模型挂钩，但LLM作为底层的基础设施，我们更多的是使用大模型的能力，在大模型基础之上，构建上层的应用烟囱，所以作为开发人员，是可以尝试去学习、了解的，我认为是触手可及的。而在”大模型应用工程技术“，我初步列了一个大纲(后面随着学习的深入可能会扩展更多)目前包含的几个方面：  向量Embedding：在RAG领域中，将多模态数据(文本、图像、视频、音频等数据)进行向量Embedding的嵌入转化，通过向量计算召回Top k，可以解决很多实际生产中的问题，比如：文本相似度计算、以图搜图、以文搜图等等，这方面都会涉及到向量的知识。  LLM语言模型：LLM大模型(Large Language Model)作为基础设施，是上层应用的基石，但是在应用领域中，对大模型的了解也是很有必要的，包括Prompt的构建优化、模型参数的差异以及不同效果体现、模型的部署和训练微调、开源模型以及商业模型等等  多模态数据：RAG相关的AI应用，离不开数据的处理，在很多LLM大模型中，也标注为多模态大模型，包括文生图、图生图等等，但在应用领域，文本(pdf/word/html/text等)、图片、视频、音频等等格式的数据处理是无可避免的，还包括市面上很多非结构化的数据处理等内容，工程层面的技术可以说是如星辰大海般辽阔，技术人员学习之路无穷无尽。  基础知识：在做应用层面的开发上，当然离不开基础知识点的学习，常用的包括HTTP SSE协议、向量等等知识点。  基础工具包:工欲善其事，必先利其器，在当下的开源大环境下，有非常多的优秀的工具辅助开发者开发生产级别的应用，以Python、Java这两大语言生态为标杆，生态及其丰富，而我们在做应用成技术的开发离不开这些优秀的组件，掌握组件的用法也是必须的。  基础算法：虽然是做应用层面的开发，基础的常用算法，该学习的还是需要去了解的，像贝叶斯、KNN、决策树等等，了解算法的原理实践，对于生产环境的代码编写时非常有指导思想的，否则你都不知道这段代码为何这么写，而每个算法解决的都是非常实际的问题。  应用场景：技术人员在开发产品时，也应该关注应用场景及市场，开发出来的产品解决了什么问题，有什么价值作为技术人员也应该学会思考。在大模型领域，以RAG赛道来看，触及的场景其实也是非常多的，比如：智能客服、以图搜图/视频等等，要关注实际的产品需求，然后转化为技术输出，这样我们作为开发人员所写的代码才是有价值的。  RAG：RAG全称Retrieval Augmented Generation(检索增强生成)，是属于AI生成式技术领域范围，解决大模型的幻觉(胡说八道)、数据不及时(数据未更新)等领域的问题，通过将企业自己的数据通过传统的工程技术结合向量Embeding进行处理，然后通过检索的方式将企业内部数据构建送给大模型进行内容的回答生成，这种方式有效的避免了大模型胡说八道和数据不准确的问题，在企业不同的领域中有非常宽广的应用领域，当然这里面所涵盖的面以及问题也是非常的广，比如：          大模型出现幻觉(送给LLM的Context不准，导致大模型胡说八道)如何解决？      按固定size进行分割，出现上下文语义丢失，核心信息检索问答生成失败，回答不准确      千万级数据量文档检索效率问题      大模型Token限制问题导致在一个文档中出现多段落讲解同一个事情的情况下会回答不完整如何处理      ……      这些都只是AI大模型、RAG等领域的冰山一角，千里之行，始于足下，作为技术人员，那么就从现在开始，一步步学起来吧～最后如果你最近也在做RAG领域相关的技术研究或者产品开发，欢迎关注、沟通交流合作！！！"
  },
  
  {
    "title": "Knife4jInsight平台版-MVP版本v1.0.0发布",
    "url": "/posts/knife4j-insight-mvp/",
    "categories": "Knife4jInsight",
    "tags": "",
    "date": "2023-09-18 00:00:00 +0800",
    





    
    "snippet": "在之前发布的《Knife4j新产品的想法》一文中，我提到想给Knife4j的生态做一些扩展，区别于目前市面上不一样的功能或者工具产品。主要还是聚焦在Knife4j这个开源项目上，然后将自己的一些想法进行输出,并将一些在单体工具组件中无法解决落地的需求场景，共同灌注在这个新的产品中。今天,Knife4jInsight平台版-MVP(Minimum Viable Product)最小可行性版本v...",
    "content": "在之前发布的《Knife4j新产品的想法》一文中，我提到想给Knife4j的生态做一些扩展，区别于目前市面上不一样的功能或者工具产品。主要还是聚焦在Knife4j这个开源项目上，然后将自己的一些想法进行输出,并将一些在单体工具组件中无法解决落地的需求场景，共同灌注在这个新的产品中。今天,Knife4jInsight平台版-MVP(Minimum Viable Product)最小可行性版本v1.0.0终于来了Knife4jInsight是简单、方便的OpenAPI接口规范文档聚合开放平台！产品地址：http://knife4j.net写在前面在很多年前，我的工作中的老大哥卢员外(微信公众号:土猛的员外)，那时候我们经常讨论如何创造产品、一个公司的产品及商业模式要如何保持市场竞争力，多年过去了,令我印象最深刻的就是三级火箭理论  第一级火箭:提供基本产品或服务，搭建高频头部流量  第二级火箭:沉淀用户的商业场景，吸引更多用户和收入；  第三级火箭:完成商业闭环，创造更多价值。以360的产品三级火箭为例：  360的第一级火箭是免费杀毒工具。它利用这级火箭打破了持续10年的杀毒软件市场三国鼎立的局面，成为用户量最大的安全工具  360的第二级火箭是从免费杀毒工具变为安全网络平台，进而推出360安全浏览器和360安全网址导航  360的第三级火箭就是它最终承载的商业闭环，从安全浏览器和网址导航的广告收入，获得企业的经营利润在迄今为止,我给Knife4j造了一些生态组件，主要如下：  ✅ Knife4j：开源ui库,区别于官方swagger-ui组件，根据OpenAPI规范，重写ui交互，开发者在文档预览及调试时可以拥有不同的文档体验  ✅ Knife4j-aggregation: 基于Servlet体系下的聚合组件,打通众多注册中心实现聚合  ✅ knife4j-gateway：基于Spring Cloud Gateway网关组件下的聚合组件，开发者在网关组件下聚合微服务OpenAPI接口只需要简单的4行配置即可完成聚合，为开发者提供文档聚合能力的同时，也有效降低了开发者的学习成本将三级火箭理论应用到开源项目Knife4j上面，到今天为止，我觉得算是勉强完成了第一级别的火箭路程，我也希望能够将这个项目一直维护下去,按照这个产品理论去执行,算是一种人生经历。而Knife4jInsight平台版本的诞生，我觉得是时候去落地一些商业化的场景了  我不确定现在三级火箭理论是否已经过时，但创造更好的产品一直是每个技术人应该追求的目标如果将开源项目Knife4j比做一次创业,那这正是一次践行实战之旅，做商业化的场景需求落地，从这个产品本身而言我觉得有几个好处：  产品本身是来源于社区,Knife4jInsight和开源Knife4j组件并不冲突，一个是单体组件,一个是平台,职责会有所不同  来自商业化产品的挑战,付费用户驱动者产品的迭代更新,提供更好的产品功能和服务  商业化产品的更新迭代以及开源项目同驱动项目的发展,在哪怕得到一小部分资金收入的保障,对于开源作者也是一种宝贵财富,避免项目停更烂尾  个人想法的践行与市场的融合,是挑战，令人兴奋产品定位该产品主要功能定位：  🌱 基于开源项目Knife4j而来，整合开源单体组件中无法解决的企业级需求场景  🔒 聚焦Swagger2、OpenAPI3、AsyncAPI等接口规范的文档展示和调试功能  🏝️ 提供OpenAPI规范接口文档的存档、历史版本、预览、调试、导出、鉴权等一系列功能操作  🏝️ 为开发者提供统一的OpenAPI接口文档开放、预览、调试服务，开箱即用  ⛺ 未来，我们是：统一OpenAPI接口开放平台、统一OpenAPI接口文档管理平台产品名称给产品取名是一件令人头痛的事情，从目前的功能定位来看，可能将该产品命名为Knife4jCloud可能更合适一些，cloud意为云数据中心，将Knife4j界面功能提供的数据整合到云上，进行统一处理。但我还是更钟意Knife4jInsight，主要有几层含义：  语意上,Insight有洞察之意,对于聚焦在API接口领域而言，提供对OpenAPI接口的全方位洞察、了解  不仅仅只是将OpenAPI接口进行云上数据聚合,区别于Cloud，这为以后产品的新功能扩展迭代奠定基调  作为OpenAPI接口的平台,平台的职责需要把OpenAPI接口内容讲清楚,说明白哪怕目前Knife4jInsight还没有达到产品名所定位的寓意高度,但也这驱使我们努力向前,为客户创造更有价值的功能。技术架构技术架构图如下：技术架构平台的定位是开放平台和接口文档管理平台进行职责区分：  OpenAPI接口开放平台：对于开放平台的接口路由，统一通过Apache APIXIS实现服务的鉴权及下游服务的转发  OpenAPI接口文档平台：对于OpenAPI接口文档的预览、调试，则由平台进行统一处理，提供基于开源项目Knife4j的文档展示方案在Knife4jInsight的前期，我们着重先把OpenAPI接口文档平台的功能做好，因为产品依靠开源项目Knife4j起家,这是该产品的本职工作.功能架构  在功能架构中，我们加入了一些未来产品要加入的功能,虽然目前MVP版本并未实现,但会在迭代Knife4j开源版本的同时,保持对该版本的升级迭代功能架构图如下：在功能上，主要是三大块的功能：  开放文档的统一管理：借助于Knife4j的前端界面，接口文档完全遵循Swagger2/OpenAPI3规范，下游或者外游服务的接口文档，只需要是符合规范的，都可以统一在平台进行管理维护，并提供文档最基础的预览、调试、鉴权访问等功能  开发密钥统一管理：开发者开放的API接口，很多时候，如果要对外的情况下，通常开发者们都需要实现接口的鉴权控制逻辑，而如果每个服务或不同的项目都实现一遍，那太耗费精力了，对于聚合上来的接口文档，所对应的下游服务，都可以通过该平台进行统一的管理，分配鉴权及管理开放用户  下游服务统一管理：一旦涉及到开放平台，那么网关的企业级别高性能要求不可避免，这不是Knife4j的强项，作为开放平台网关层，这里考虑Apache APISIX来实现服务的分发，依靠Apache APISIX提供的Admin API接口，平台通过将下游服务的转发规则进行动态注册，这样接口文档和开放平台就从功能职责上进行了区分，互相存在依赖关系，但职责分工不同平台的网关鉴权，通过实现Apache APIXIS的鉴权插件，植入到网关组件中，此时所有开放平台的网关入口流量，都会通过该插件与Knife4jInsight中的开发密钥进行联动，实现接口的鉴权。产品定价Knife4jInsight版本是商业化产品,但是我想既然面对的主要群体都是开发者,虽然是平台，但也更多的是工具,为开发者提供方便的工具也思考了良久，最终产品价格定价在49.9元，主要是软件license的价格主要体现在：      在目前Knife4jInsight在线版本中，可以在线体验，付费后不限Namespace、ApiRegister的数量        以Docker镜像提供交付,开发者可以将该版本独立部署在私有环境,保证企业数据安全        购买的License是永久期限使用,没有时间限制        License限定部署域名(最大支持5个域名/ip授权)        License限定平台更新周期,平台免费更新期限1年    即自购买该license后，Knife4jInsight在之后1年内的任何版本更新，都可以使用该license进行免费更新,超过期限后的新版本,则需要重新购买license  技术支持、技术咨询、开源社区issue、开发交流群  有任何技术问题可通过社区issue、交流群找到作者进行沟通反馈，或者通过邮箱:xiaoymin@foxmail.com与作者取得联系Knife4jInsight提供了在线版本，域名：https://console.knife4j.net开发者可以在线试用,及完成license的购买行为最后目前是Knife4jInsight的MVP版本，该产品还在发展中，我给该产品规划了roadmap，主要如下：  如果您有好的想法或者建议，可以通过在开源项目Knife4j中提issues或者discussions进行反馈            功能      进度      发布日期      发布版本                  平台管理OpenAPI数据源接口文档自动i18n,支持中英双语      待开发      -      -              微服务OpenAPI规范数据源自动注册上报      待开发      -      -              整合开源swagger-ui组件，平台中可进行OpenAPI规范接口设计      待开发      -      -              打通开源注册中心(Nacos\\Eureka\\Consul等等),获取服务中的OpenAPI数据源      待开发      -      -      产品首页：http://knife4j.net产品试用：https://console.knife4j.net期待Knife4j和Knife4jInsight齐头并进,创造更好的产品服务！！！"
  },
  
  {
    "title": "Knife4jInsight的产品开发历程",
    "url": "/posts/knife4j-insight-dev/",
    "categories": "Knife4jInsight",
    "tags": "",
    "date": "2023-09-17 00:00:00 +0800",
    





    
    "snippet": "前言大家好，在昨天Knife4jInsight的1.0.0MVP版本发布之后，在Knife4j的交流群分享说，希望Knife4j后面的版本，不管是开源版本还是商业版本，希望以：开源项目生态+付费产品闭源+Build On Public的模式一直走下去！！！今天这篇则是践行Build On Public策略，分享在开发Knife4jInsight过程中的一些感悟及想法！在很早之前分享的Knif...",
    "content": "前言大家好，在昨天Knife4jInsight的1.0.0MVP版本发布之后，在Knife4j的交流群分享说，希望Knife4j后面的版本，不管是开源版本还是商业版本，希望以：开源项目生态+付费产品闭源+Build On Public的模式一直走下去！！！今天这篇则是践行Build On Public策略，分享在开发Knife4jInsight过程中的一些感悟及想法！在很早之前分享的Knife4j5.0规划里面，我提到希望重写Knife4j的前端实现，并且能够将工具事项一直发展先去，把Knife4j始终定为一个工具组件，提供一些让开发者在日常文档开发过程中方便使用的功能为先。而在大概2个月前，我在交流群时常会碰到很多人在问Knife4jInsight开源版本的问题，在之前Knife4jInsight开源版本中，我主要实现了讲各个注册中心进行集成，所有的数据源存储在本地磁盘或者Nacos配置中心作为数据源来存储。我个人认为在思路上是没有什么问题的，但是在产品的使用上，程序员思维太验证了，没有提供一个可操作的界面供用户操作使用，提了一些概念，对用户使用来说，现在回想起来简直是灾难。基于这个想法，加上后面对希望Knife4j改版的热情，就产生了将开源版本Knife4jInsight转换为付费版本的想法。主要考虑一下几点：  降低之前开源版本Knife4jInsight的使用难度，提供可操作的可视化界面，简化流程和概念  将开源版本中一些无法实现的企业需求都灌注在这个平台版本中进行实现,毕竟这是一个独立运行的平台，可以很好的整合各种业务需求，而Knife4j开源版本是单体组件,碰到很多有意思的需求时,往往会存在瓶颈  商业产品和开源版本共同驱动的模式,开源产品能很好的吸收用户的反馈声音以增强改进软件迭代发展,而商业产品能保证Knife4j这个开源作品使作者获取一些微薄的收入,投入更多的时间去维护项目的开发，我觉得是一种正相关的开发模式，毕竟我们见过太多靠爱发电的开源项目最终都停更了，Knife4j目前也基本是靠爱发电的项目确定了想法之后，说干就干，最终在Xmind大致罗列了下这个产品最终的具体事项，主要4个方面，如下：  系统用户：平台既然以OpenAPI规范数据源管理为主，而OpenAPI规范是企业的数字资产,那么用户功能必然必不可少,接口文档是企业的隐私,需要用户权限来限定谁可以访问,谁不可以访问  平台特性：主要是确定平台的特点及功能风格  主要功能：确定确定MVP版本的基础功能  进度计划：开发迭代这个产品需要确定的计划事项系统用户平台以OpenAPI规范数据源管理为主，而OpenAPI规范是企业的数字资产,那么用户功能必然必不可少,接口文档是企业的隐私,需要用户权限来限定谁可以访问,谁不可以访问。在用户层面，以用户和角色进行展开：  用户：平台使用者，可以注册(基于Email)使用的用户,登录后可以维护OpenAPI规范数据源  角色：平台主要分两个角色(平台用户、管理员)          平台用户：角色是平台的最小可用角色，仅可以使用平台      管理者：则可以对用户进行统一管理，在标准版中，会分配1个默认管理者账号，管理者对用户进行创建、禁用、重置密码等操作      平台特性平台特性主要是确定平台等风格，如下图：  界面排版：习惯了所有菜单风格的我，这次决定使用一下上下风格的模式  文档访问：对于文档的访问，可以开放鉴权功能，对于需求鉴权的文档，用户访问时则需要校验登录，否则不予访问  数据隔离：每个用户的数据都是相互之间隔离的，只能看到自己的数据主要功能主要功能则是在开发MVP版本期间确定的功能以及想到的后期一些扩张功能，如下图：  NameSpache(命名空间)：命名空间是平台中抽象的概念,一个namespace下可以允许存在多个OpenAPI规范实例，用户可以讲该功能理解为企业、项目、部门、产品等等  ApiRegister(OpenAPI规范数据源):服务实例是一个OpenAPI规范的最小单元,讲OpenAPI接口规范数据源通过自动注册或手动填报的方式,保存在平台中后即可进行接口文档的在线预览功能  用户中心：平台用户可以参与OpenAPI文档的建设及授权,用户数据之间完全隔离  授权中心：Knife4jInsight在线版本的功能，对用户购买后的license授权及查看等操作  登录/注册：在线版本保持了基于邮箱账号的注册/找回密码等功能，而在私有化标准版本中，用户的注册等操作没有，需要管理员账号进行开户操作至于二期功能，则是在开发过程中想到的一些功能点，在xmind中记录，后来我把这些功能又单独在项目的官网文档上进行了维护，主要是产品的RoadMap官网功能RoadMap地址：http://knife4j.net/roadmap/后期的功能：  平台管理OpenAPI数据源接口文档自动i18n,支持中英双语  对于注册上来的OpenAPI数据源,平台基于开放的翻译API接口对OpenAPI结构进行解析，解析完成后自动翻译文档注释说明，这样我觉得企业开发者在做i18n文档国际化时，在代码层面只需要按常规的固定流程开发即可,而无需从代码框架层面实现i18n，整合i18n功能到平台中可以不止做一种语言，后面扩展更多的语言支持也是及其方便的  微服务OpenAPI规范数据源自动注册上报  目前MVP版本还是手动上报填写，但平台已经预留了接口自动上报的函数接口，基于用户的开发密钥，将自动上报功能整合到Knife4j开源的各项starter组件中，开箱即用，即可在项目启动后自动上报OpenAPI规范数据至Insight平台中，这样即可避免各种404、鉴权等集成Knife4j组件的问题，开发者只需要将Insight平台中的文档提供出去即可进行接口对接  整合开源swagger-ui组件，平台中可进行OpenAPI规范接口设计  开源Swagger-editor组件提供了在线设计接口及所见即所得的能力，整合后可以先设计规范接口，后实现代码，后期还可以考虑整合OpenAPI规范生态的代码生成功能,在线提供各种导出、代码生成等功能  打通开源注册中心(Nacos\\Eureka\\Consul等等),获取服务中的OpenAPI数据源  微服务开发是目前当下主流的开发技术栈，而打通各个注册中心则可以在平台端主动去pull拉取各个子服务的OpenAPI数据源，对于手工填写OpenAPI规范管理提供了便利，和微服务OpenAPI规范数据源自动注册上报功能相比，一个是主动pull拉取，而另外一个则是被动推送到Insight平台，是两种策略进度计划确定好了功能，那么就是计划排期了计划排期开发一个产品要做的事情针对太多了，首先是确定MVP版本的开发周期因为作者也是在职，所以不可能全职参与这项工作,只能是利用下班后或周六周日的时间来进行开发，MVP版本也是保证产品的最小可用版本，所以计划的是花1-2个月的时间来完成  以下是GitHub的提交记录，大概从7月份开始有想法之后，开源和产品的迭代基本上是每天一有空闲则进行代码的提交上线准备当项目功能开发完成后，需要做一些上线准备的事情，这里面主要包括：  云服务器：既然有在线试用版本，那么云服务器是跑不了的,在开发技术选型阶段，所有的功能都是以单体架构进行技术选型，后面我会把平台的技术选型分享出来，主要是避免大量中间件的使用，节省资源成本。在云服务器成本上主要是两个：          ECS：购买了阿里云的ECS服务器，张家口的节点，2c4GB配置，带宽4M      RDS：购买的是腾讯云的MySQL，配置1c1gb，20gb存储，三年648        官网域名：既然是商业化产品,官网域名跑步了，干脆就以开源项目Knife4j进行命名，最后发现.com和.cn的域名都已经被人注册了😂，最后发现knife4j.net的域名还在，那就自己注册了吧，85RMB/年，net的域名比com和cn略贵一些，购买域名之后，就是域名备案了，前后大概花了半个月左右吧，备案真的周期太长了  官网文档：有产品、有域名，最后就是写文档了，考虑到我也非专业前端人员，写css不是我的强项，我只会写markdown，那就市面上选一个markdown的文档生成产品吧，主要参考有很多，我之前都用过，包括docusaurus、vuePress、VitePress,最终被VitePress的界面风格吸引，加上是新的，所以就选择用vitepress来写官网文档了，文档编写前后大概花了一周的时间运营推广开发好了，也上线了，就考虑推广的事情了，另外也要考虑产品的定价产品定价：对于产品的定价，既然是工具组件为主,我所期望的是还是更平民一些，更高的价格则代表着更高的要求和产品价值,Knife4jInsight是一个初次尝试的商业化产品，我觉得获得市场认同感很重要，毕竟商业版我更多的想法也是想驱动开源Knife4j版本的迭代更新，是开源版本Knife4j的补充，企业需求的能量池，更多的算是一种开源变现的手段吧，就定价在49.9/年产品license：license是软件启动时所需要的,在思考license职责过程中，我也思考了很多，比如使用期限、边界、产品交付物等等方面，最终思考如下：      购买的License是永久期限使用,没有时间限制        License限定部署域名(最大支持5个域名/ip授权),避免license传播泛滥        License限定平台更新周期,平台免费更新期限1年          即自购买该license后，Knife4jInsight在之后1年内的任何版本更新，都可以使用该license进行免费更新,超过期限后的新版本,则需要重新购买license      运营推广：之后产品上线后就是运营推广了，我觉得这是一个长期的事情，在保持对产品的持续迭代输出之余，通过公众号或者官网文档、技术交流群等，都可以进行推文，写文章也算是一种锻炼，而践行Build On Public历程我觉得对于我自己来说也是一种不同的开发体验，即使是在开源项目中。  公众号的推广包括对平台的介绍、功能介绍，这个在后期的开发迭代阶段会一一分享  开发历程、自己的思考及产品的价值  技术的选型，每个功能的想法及价值思考  等等很多方面的内容都可以一一写出来最后Knife4j并不完美,期待Knife4j及Knife4jInsight与用户一起共同成长见证～～～官网地址：http://knife4j.net/"
  },
  
  {
    "title": "Knife4j新产品的想法",
    "url": "/posts/knife4j-new-product/",
    "categories": "Knife4jInsight",
    "tags": "",
    "date": "2023-09-15 00:00:00 +0800",
    





    
    "snippet": "写在开头Knife4j的发展已经有好几个年头了，最近想来，虽然这个小组件不太稳定，但有每天依然收到很多小伙伴的积极反馈，这让我又不由自主的对这个项目产生了羁绊。一直以来，总想把一些工作中的想法，以及和Knife4j周边生态相关的内容结合起来，做一些不一样的事情。在Knife4j目前的生态中，我主要为Knife4j写了一些技术的组件，主要包括：  Knife4j-ui：前端组件部分，主要基于S...",
    "content": "写在开头Knife4j的发展已经有好几个年头了，最近想来，虽然这个小组件不太稳定，但有每天依然收到很多小伙伴的积极反馈，这让我又不由自主的对这个项目产生了羁绊。一直以来，总想把一些工作中的想法，以及和Knife4j周边生态相关的内容结合起来，做一些不一样的事情。在Knife4j目前的生态中，我主要为Knife4j写了一些技术的组件，主要包括：  Knife4j-ui：前端组件部分，主要基于Swagger2/OpenAPI3规范的识别，通过不同的展现及交互，为开发者提供不同的体验  knife4j-aggregation:前期基于Servlet生态体系下的聚合组件，解决在Spring Cloud Gateway等异步编码较困难的人文档聚合问题，打通各个注册中心组件(Nacos\\Eureka\\Consul等)实现接口文档的聚合  knife4j-gateway：Spring Cloud Gateway网关下的聚合组件，4行配置搞定网关下的接口文档聚合  Knife4j-extension:基于Chrome浏览器的调试插件，只要是Swagger2/OpenAPI规范，就可以预览文档/调试文档，为了上架还开通了vista卡，付费给Google5美元，现在下架了(长时间没更新代码有漏洞被迫下架)😂。。。  knife4j-insight：独立运行的聚合中间件，将硬盘/Nacos等作为Swagger2/OpenAPI3规范的数据源，复用aggregation的生态，聚合各个注册中心，实现平台化，聚合所有接口规范，统一预览/调试。。更新了3个版本(我觉得自己思路挺好的)。。😂新想法最近这段时间，主要思考的是Knife4j这个项目应该如何发展下去，如果做新产品，与市面上已经存在的其他产品如何做差异化的竞争。思来想去，我又有了新的方向和目标～！  折腾新产品的心态一直没停过。。市面上的产品包括Postman、Apifox、Apipost等等，专注在自己的领域里面，覆盖面都挺广的，而Knife4j好像以Ui界面交互起家，受众要宅一些，想想这些产品的词云关键字：API文档、调试、协作、测试、API设计等等每一个关键字里面所需要投入的精力，都是Knife4j无法企及的，而且我在很早之前分享Knife4j的定位时，我一直想把他作为一个工具输出，单纯的工具，因此，包括：协作、涉及、自动化等等标签，都不适合我那么，应该做什么？做一点不一样的呢？Knife4jInsight这个产品的思路我自认为还是得发展下去,只不过需要更加产品化一下，做成平台，给用户提供更方便的可操作化的界面，简化整个使用步骤。基于这个想法，和脑子里蹦出了一些新的Idea，包括：开放平台、接口展示、LLM大模型。我有了一个产品的大致雏形，我画了一个草图，大概是这个样子：在上图中，Knife4jInsight是一个独立服务组件，依附在Apache APISIX网关组件下的服务。那么，产品定位是什么呢？产品定位：统一的通用接口文档及开放平台服务系统在功能上，主要是三大块的功能：  开放文档的统一管理：借助于Knife4j的前端界面，接口文档完全遵循Swagger2/OpenAPI3规范，下游或者外游服务的接口文档，只需要是符合规范的，都可以统一在平台进行管理维护，并提供文档最基础的预览、调试、鉴权访问等功能  开发密钥统一管理：开发者开放的API接口，很多时候，如果要对外的情况下，通常开发者们都需要实现接口的鉴权控制逻辑，而如果每个服务或不同的项目都实现一遍，那太耗费精力了，那么我觉得只要是聚合上来的接口文档，所对应的下游服务，都可以通过该平台进行统一的管理，分配鉴权及管理开放用户  下游服务统一管理：一旦涉及到开放平台，那么网关的企业级别高性能要求不可避免，这不是Knife4j的强项，作者也没这个能力，作为开放平台网关层，这里考虑Apache APISIX来实现服务的分发，依靠Apache APISIX提供的Admin API接口，平台通过将下游服务的转发规则进行动态注册，这样接口文档和开放平台就从功能职责上进行了区分，互相存在依赖关系，但职责分工不同平台的网关鉴权，通过实现Apache APIXIS的鉴权插件，植入到网关组件中，此时所有开放平台的网关入口流量，都会通过该插件与Knife4jInsight中的开发密钥进行联动，实现接口的鉴权。开放文档的统一管理先来看开放文档的统一管理，考虑到我们要与开源Knife4j项目共同发展，因此产品的功能上，也是以开源Knife4j为主，接口文档完全遵循Swagger2/OpenAPI3规范，在这个场景下，实现文档的统一管理和聚合主要包括两个功能：  Namespace：命名空间(namespace)是平台中抽象的概念,一个namespace下可以允许存在多个OpenAPI规范实例，用户可以讲该功能理解为企业、项目、部门、产品等等  ApiRegister：服务实例(ApiRegister)是一个OpenAPI规范的最小单元,将OpenAPI接口规范数据源通过自动注册或手动填报的方式,保存在平台中后即可进行接口文档的在线预览功能，这样的好处是我们即可以对接口文档进行归档保存，又可以和下游服务联动，打通调试。  文档用户中心: 每一个namespace下的文档都是有鉴权属性的，用户可以选择对齐是否开放，这样的好处是保持接口的🔐安全，避免所有人都能访问先来看下一界面原型。命名空间(namespace)：namespace列表可以查看所有的项目列表，并且namespac是可以直接访问的，如果当前namespace下面有接口实例，那么就可以通过Knife4j的前端界面进行预览和调试点击namespaceId查看文档效果如下：服务实例(ApiRegister):是一个OpenAPI规范的最小单元,可以通过接口自动注册上来，也可以通过平台进行主动编辑添加  包括接口的规范类型，数据来源类型，注册类型等等信息。明细信息展示如下：同样，当个APIRegister也是可以独立访问的，平台提供的单实例的访问方法：开发密钥统一管理开发者开放的API接口，很多时候，如果要对外的情况下，通常开发者们都需要实现接口的鉴权控制逻辑，而如果每个服务或不同的项目都实现一遍，那太耗费精力了，那么我觉得只要是聚合上来的接口文档，所对应的下游服务，都可以通过该平台进行统一的管理，分配鉴权及管理开放用户下游服务统一管理一旦涉及到开放平台，那么网关的企业级别高性能要求不可避免，这不是Knife4j的强项，作者也没这个能力，作为开放平台网关层，这里考虑Apache APISIX来实现服务的分发，依靠Apache APISIX提供的Admin API接口，平台通过将下游服务的转发规则进行动态注册，这样接口文档和开放平台就从功能职责上进行了区分，互相存在依赖关系，但职责分工不同LLM大模型结合目前，AIGC火热发展的当下，大模型落地更多产品的场景，我觉得是不可避免的，而对于在Knife4jInsight平台中，我目前也想到了一些LLM大模型可以落地的场景，主要包括：      接口的i18n转化：本身Knife4j提供的界面目前是支持中英文的，但是开发者如果要提供英文的接口文档描述，通常在项目开发阶段，或者定义OpenAPI接口规范时，技术层面就需要提供支持，而如果通过平台中大模型的翻译工具，基于Prompt工程，将OpenAPI数据源直接生成对应的目标语言，那么开发者就无需在技术启动接口考虑i18n的事情，Knife4jInsight平台中自动集成即可快速实现。            代码模版：将Prompt工程+OpenAPI规范结合，植入到Knife4j到每一个功能点中，包括代码示例生成、curl等等不同的场景，调试LLM大模型的Prompt工程，将幂等性的接口输出到应用测，给予开发者更多的便利。      结尾以上就是我的一些新想法，如果您对该产品感兴趣，欢迎和我联系(xiaoymin@foxmail.com)～～～"
  },
  
  {
    "title": "Spring Cloud Gateway网关下的文档聚合?就用它了",
    "url": "/posts/knife4j-gateway-introduce/",
    "categories": "Knife4j",
    "tags": "",
    "date": "2023-08-13 00:00:00 +0800",
    





    
    "snippet": "大家好，这篇文章主要是介绍分享Knife4j-gateway网关聚合文档组件,自4.0版本发布该组件后，得到了大家的积极响应，我们也是积极响应用户的需求，持续迭代优化该组件是一个非常轻量级的网关聚合组件，适用于开发者使用Spring Cloud Gateway网关组件进行Swagger2、OpenAPI3规范的文档聚合🌾 1.前言在考虑写这个组件之前，开发者在Spring Cloud Gat...",
    "content": "大家好，这篇文章主要是介绍分享Knife4j-gateway网关聚合文档组件,自4.0版本发布该组件后，得到了大家的积极响应，我们也是积极响应用户的需求，持续迭代优化该组件是一个非常轻量级的网关聚合组件，适用于开发者使用Spring Cloud Gateway网关组件进行Swagger2、OpenAPI3规范的文档聚合🌾 1.前言在考虑写这个组件之前，开发者在Spring Cloud Gateway网关组件下进行聚合Swagger2/OpenAPI3可能存在各种各样的问题我认为主要包括：  适配不同的Spring Cloud Gateway版本，没有形成统一稳定的技术解决方案  Gateway组件下Webflux异步编码的风格，学习成本异常陡峭，初学者一时之间难以掌握微服务体系  聚合文档代码强耦合业务代码，无法灵活配置  文档Ui无法随心所欲的配置  各种404或路径错误等问题  等等…..🔥 2.解决方案我们从开发者的实际需求出发，结合Knife4j多年开源以来积累的宝贵经验，决定了我们需要开发一个Gateway网关下的聚合组件将开发者的需求、问题聚合在一起，众人拾薪火焰高，形成一个统一的技术解决方案knife4j-gateway组件就是在这样的场景下诞生的该组件主要的特点：  ✅ 使用简单(最低4行配置搞定聚合)，学习成本低  ✅ 解耦Spring Cloud Gateway网关组件，聚焦文档聚合功能，职责单一  ✅ 提供手动配置、微服务自动发现两种灵活配置方式聚合子服务文档  ✅ 可以同时聚合Swagger2、OpenAPI3两种不同的规范  ✅ 灵活配置聚合规则，自定义排除规则支持  ✅ 微服务场景下支持服务的上线、下线场景，文档状态与子服务保持一致，无需重启服务🌚 3.深入了解我们结合knife4j-gateway组件的特点来深入分析，带着疑惑来一步步揭开她的神秘面纱~！✅ 3.1 使用简单(最低4行配置搞定聚合)，学习成本低首先，我们既然都已经封装成组件了，那么学习和使用成本是我们首先就需要考虑的事情，需要把复杂，难处理的业务逻辑、技术细节，全部封装在组件里，而对于上层用户，我们提供简化后的配置，开发者只需要开箱即用即可这是组件的价值，剩下学习时间成本。当然我说使用简单(最低4行配置搞定聚合)，这只是有点宣传吹牛的口吻，对于开发者来说，我又要学习了解你这个knife4j-gateway组件的四行配置，那也是学习成本啊这个我无从反驳~~~😂如果开发者的项目、产品采用Spring Cloud微服务体系，网关组件使用Spring Cloud Gateway，那么对于Swagger、OpenAPI3的文档聚合，采用knife4j-gateway组件的话，就可以使用组件的discover自动发现模式，实现自动聚合在项目中的application.yml配置文件中进行如下配置，就搞定了，配置如下：knife4j:  gateway:    # ① 第一个配置，开启gateway聚合组件    enabled: true    # ② 第二行配置，设置聚合模式采用discover服务发现的模式    strategy: discover    discover:      # ③ 第三行配置，开启discover模式      enabled: true      # ④ 第四行配置，聚合子服务全部为Swagger2规范的文档      version: swagger2我们没有使用广告法禁止的最简单、非常简单等宣传口吻进行宣传摸着良心去看这个配置，用disocver模式进行聚合，四行配置达到开发者的目的，确实很方便啊，学习成本低~~~!✅ 3.2 解耦Spring Cloud Gateway网关组件，聚焦文档聚合功能，职责单一为什么我说解耦呢？因为文档功能其实是一个开发阶段的需求，是开发团队在配合完成项目、产品过程中，团队之前提升效率的一个潜在的需求场景当我们的项目、产品开发完成，上线到生产环境的时候，或者在不同的项目开发过程中，开发者的需求又涌现出来了，例如：  接口规范是非常重要的内部信息，生产环境应该屏蔽          请参考文章生产环境如何屏蔽Knife4j、Swagger等Ui资源和接口        聚合代码在不同的项目中来回Copy  升级Gateway组件导致聚合代码失效，调试不同的Gateway版本，在线搜索解决方案  ….还有一些其他的需求场景，一线开发者可以自行脑补，上面说列的需求，你是否在开发场景中也碰到了呢？既然文档聚合功能和项目、产品本身并没有太大的关系，是开发者开发过程中提高效率的产物，那么对于统一的事情，我们应该避免重复操作，用独立的中间件来解决这些问题knife4j-gateway组件聚焦Swagger2/OpenAPI3规范的文档聚合,一旦团队之间确定使用Swagger2/OpenAPI3规范，并且有聚合的需求场景，那么引入一个jar组件就能解决的事情，何乐而不为呢？✅ 3.3 提供手动配置、微服务自动发现两种灵活配置方式聚合子服务文档上面我们从学习成本、解耦两个方面阐述了该组件的价值，那么接下来，当我们深入去探索网关组件的下的聚合场景时，站在中间件组件的立场下，我们就需要考虑不同的团队、不同的人员的需求进行兼容合并目前为之，结合开发任何及自身的实际工作经验，总结出了两种文档聚合的场景，供开发者进行使用  手动配置聚合(manual): 开发者手动配置，灵活配置展示文档          优点：使用简单、灵活，学习成本低.试错成本低      缺点：服务众多时较繁琐，无法感知子服务的上下线状态        服务发现自动聚合(discover)：基于注册中心，主动聚合服务          优点：使用及配置简单、学习成本低.      缺点：暂时没想到，欢迎你来体验反馈      ✅ 3.4 可以同时聚合Swagger2、OpenAPI3两种不同的规范我们的项目/产品在长期迭代开发过程中，或者不同的团队配合开发中,有时候子服务的标准可能不尽统一。而我们需要一起聚合怎么办呢?好在在Knife4j的前端Ui组件已经完全适配了Swagger2和OpenAPI3规范，在网关层面，我们只需要根据该组件提供的手动配置策略配置上就解决了该问题，可参考下面的文章介绍。✅ 3.5 灵活配置聚合规则，自定义排除规则支持灵活配置是knife4j-gateway组件为网关聚合服务提供的带刀侍卫，保障开发者们在手动/服务发现两大场景下配合使用以达到最终目的他主要提供的服务包括：  设定网关层面聚合的排除规则，支持正则表达式或者开发者根据SPI接口自定义实现          例如有Dubbo服务的接口，需要在网关层面进行排除，禁止聚合        子服务的服务名称别名、展示顺序、接口顺序等配置自定义  子服务的自定义ContextPath自由灵活配置，满足业务需要1、在网关层面，排除不需要的子服务时，我们可以基于正则表达式(自4.3.0版本进行支持)，配置如下：knife4j:  gateway:    enabled: true    strategy: discover    discover:      version: swagger2      enabled: true      # 排除不需要聚合的子服务，基于正则表达式(支持多个)      excluded-services:        # 排除order开头的服务        - order.*        # 排除服务中包含dubbo字样的服务        - .*?dubbo.*2、配置子服务的别名，排序，自定义配置如下：knife4j:  gateway:    enabled: true    strategy: discover    discover:      version: swagger2      enabled: true      excluded-services:        - order.*    # 自定义配置子服务的别名，排序规则      service-config:        order-service:          - group-name: 订单服务            order: 1        user-service:          - group-name: 用户服务            order: 23、网关成统一开启配置子服务的tag、operation排序规则knife4j:  gateway:    enabled: true    strategy: discover    discover:      version: swagger2      enabled: true    # 排序规则    tags-sorter: order    operations-sorter: order🐐 4.聚焦两大使用场景(手动/服务发现自动)聚合4.1 手动配置聚合(manual)手动配置聚合，顾名思义,开发者需要自行写子服务的规则或者路径,这和微服务场景下自动复现聚合是形成互补机制，双剑合璧威力之下，完成最终成果输出该场景解决不同的问题，包括：  子服务同时存在Swagger2/OpenAPI3规范的服务  子服务存在不同的package包分组的的规范实例，用过springfox或者springdoc的开发者应该清楚可以根据package包路径、path路由创建接口分组如下图：这是一个简单的示意图，我们有三个服务：  gateway-service:网关服务，负责网关路由鉴权、路由转发  order-service:子服务之一，基于OpenAPI3规范暴露规范地址:/v3/api-docs  user-service: 子服务之一，基于Swagger2规范暴露规范地址：/v2/api-docs我们从服务架构流程图中了解到了我们需要的信息，那么在gateway-service组件中，就可以使用knife4j-gateway组件提供的手动配置聚合，将文档进行聚合展示简单的配置如下：knife4j:  gateway:    enabled: true    # 选择手动    strategy: manual    routes:      - name: 用户服务        service-name: user-service        url: /user/v2/api-docs      - name: 订单服务        service-name: order-service        url: /order/v3/api-docs4.2 服务发现自动聚合(discover)手动聚合的唯一问题就是，一旦我们的产品/项目，子服务数量众多，纯靠手动去配，那对于开发者来说也是极其痛苦的，就好像是侮辱开发者一样。。我都能写代码了，你还让我写这么多繁杂的配置，那是对程序员的不尊重。基于服务发现自动聚合的需求场景，就由此诞生.  在上面我们介绍knife4j-gateway特点时，我们提到该组件解耦，聚焦文档聚合功能，职责单一，这里得以体现对于服务发现场景下的自动聚合，配置就更简单了，但对我们也有一些小小的约束  ⚠️ 我们的子服务规范实现需要统一，要么全部用Swagger2规范，或者OpenAPI3规范配置如下：knife4j:  gateway:    # ① 第一个配置，开启gateway聚合组件    enabled: true    # ② 第二行配置，设置聚合模式采用discover服务发现的模式    strategy: discover    discover:      # ③ 第三行配置，开启discover模式      enabled: true      # ④ 第四行配置，聚合子服务全部为Swagger2规范的文档      version: swagger2这个特点和我们前面提到的使用简答这一条又对上了，真的只有三四行配置。但是在微服务聚合场景下，我们虽然封装内部实现，也有必要和大家分享一下，具体的处理规则原理先来看一张简单的架构图-服务发现的场景，如下图：在服务发现的场景中，我们依赖注册中心组件，这里以Nacos为例，但我们将网关服务gateway-service也注册到Nacos中时本身基于Spring Cloud微服务体系的DiscoverClient.java接口，在Nacos组件实例下，会为我们解决各个子服务注册上来的服务发现问题，包括子服务实例对象，是否上线、心跳检测等等而我们依赖Spring体系提供的ApplicationEvent事件监听体系，就可以从统一的DiscoverClient体系下，实现我们的自动聚合场景，这样的好处是不用关心各个注册中心的差异，在Spring Cloud的微服务体系下，注册中心需要遵循DiscoverClient接口进行标准实现。在knife4j-gateway的服务发现场景下，我们通过@EventListener实现对微服务场景下的事件监听，以填充网关成文档的数据实现监听事件回调处理源码如下：@Slf4j@AllArgsConstructorpublic class ServiceChangeListener {        final DiscoveryClient discoveryClient;    final ServiceDiscoverHandler serviceDiscoverHandler;    final Knife4jGatewayProperties knife4jGatewayProperties;        @EventListener(classes = {ApplicationReadyEvent.class, HeartbeatEvent.class, RefreshRoutesEvent.class})    public void discover() {        log.debug(\"discover service.\");        List&lt;String&gt; services = discoveryClient.getServices();        if (Objects.equals(knife4jGatewayProperties.getStrategy(), GatewayStrategy.DISCOVER)) {            this.serviceDiscoverHandler.discover(services);        }    }}通过注册中心在DiscoverClient体系下的实现，包括调度(Scheduler)、心跳检测(HeartBeat)、事件回调(ApplicationEvent)等机制，实现微服务网关层面文档的自动聚合。🐮 5.服务发现的路由聚合策略-数据来源在上面章节中，我们从使用特点、两大场景(手动/服务发现)等全面介绍了knife4j-gateway组件，在文末，还是有必要和大家讲讲该组件在discover服务发现模式下，子服务的是数据来源处理规则主要是4个方面，包括：  基于Spring Cloud Gateway配置的routes规则解析子服务路由，数据来源：spring.cloud.gateway.routes  在discover服务发现场景下，针对自定义添加的routes，默认再次追加，数据来源：knife4j.gateway.routes  服务发现discover模式下，开发者在网关成的路由转发模式默认通过DiscoveryClient的默认方式转发路由，规则是pattern:/service-id/**  接收编码方式动态注入Spring Cloud Gateway网关的路由，进行聚合转发5.1 手动配置-自定义Routes自定义Routes主要是开发者根据Knife4j-gateway组件提供的开发配置，在进行手动聚合时，填写的配置，这部分的配置是网关聚合的数据来源之一而配置内容knife4j-gateway组件不会做任何处理,开发者配置什么就展示什么示例配置如下：knife4j:  gateway:    enabled: true    # 选择手动    strategy: manual    routes:      - name: 用户服务        service-name: user-service        url: /user/v2/api-docs5.2 DiscoverClient自动发现如果开发者在Spring Cloud Gateway网关组件下没有配置子服务的转发路由规则，完全依靠默认的转发规则(pattern:/service-id/**)，其实就是根据子服务名称进行转发在这种规则下，knife4j-gateway组件会读取DiscoverClient组件下注入的DiscoveryClientRouteDefinitionLocator路由列表进行解析在Spring Cloud Gateway网关的配置，开启该规则，配置如下：spring:    # 路由网关配置    gateway:      # 启用了自动根据服务名建立路由      discovery:        locator:          enabled: true          lower-case-service-id: true而knife4j-gateway组件中，就是直接获取该模式下的子服务列表转发规则，注入到knife4j-gateway组件下的数据源，作为ui层面的转发依据部分源码解析如下:public class DiscoverClientRouteServiceConvert extends AbstactServiceRouterConvert {        final DiscoveryClientRouteDefinitionLocator discoveryClientRouteDefinitionLocator;    final Knife4jGatewayProperties knife4jGatewayProperties;    @Override    public void process(ServiceRouterHolder holder) {        log.debug(\"Spring Cloud Gateway DiscoverClient process.\");        // 取默认子服务的路径规则        discoveryClientRouteDefinitionLocator.getRouteDefinitions()                .filter(routeDefinition -&gt; ServiceUtils.startLoadBalance(routeDefinition.getUri()))                .filter(routeDefinition -&gt; ServiceUtils.includeService(routeDefinition.getUri(), holder.getService(), holder.getExcludeService()))                .subscribe(routeDefinition -&gt; parseRouteDefinition(holder, this.knife4jGatewayProperties.getDiscover(), routeDefinition.getPredicates(), routeDefinition.getUri().getHost(),                        routeDefinition.getUri().getHost()));    }    //others...}5.3 Spring Gateway网关Routes配置该配置属性和自定义配置knife4j-gateway组件的routes一样，开发者一般会自定义配置子服务的路由转发策略，通过spring.cloud.gateway.routes进行配置而knife4j-gateway会获取该部分的数据源，通过读取子服务配置的Predicate来获取子服务的Path前缀ContextPath规则进行聚合5.4 动态路由注册配置动态路由注册可能在某些特殊的场景下也有需求，因此knife4j-gateway也会把动态注入进来的路由进行聚合，作为文档数据源进行展示动态数据源来源于RouteDefinitionRepository对象6.👻 总结好了，本文介绍到这里也基本涵盖了knife4j-gateway网关聚合组件的方方面面，希望该组件能给你带来帮助~~!您有更多的想法或者建议，可以关注公众号”八一菜刀”，参与Knife4j的交流群进行沟通反馈，谢谢"
  },
  
  {
    "title": "枚举烦恼终结!在Knife4j文档中如何优雅的处理枚举类型的展示及调试问题",
    "url": "/posts/knife4j-handler-enum/",
    "categories": "Knife4j",
    "tags": "",
    "date": "2023-08-07 00:00:00 +0800",
    





    
    "snippet": "本文主要介绍在Knife4j中如何处理枚举，主要包含两个方面：  通过技术手段，将枚举的value值以及描述在文档界面进行呈现，完善接口信息展示  能通过Knife4j的调试功能针对枚举参数快速调试。关联Issues：  ✅ 枚举类参数value和desc的注释  ✅ 4.1.0版本下，枚举类@ToString方法自定义可用值和@JsonValue注解不兼容  ……🏖️ 本文仓库：knife...",
    "content": "本文主要介绍在Knife4j中如何处理枚举，主要包含两个方面：  通过技术手段，将枚举的value值以及描述在文档界面进行呈现，完善接口信息展示  能通过Knife4j的调试功能针对枚举参数快速调试。关联Issues：  ✅ 枚举类参数value和desc的注释  ✅ 4.1.0版本下，枚举类@ToString方法自定义可用值和@JsonValue注解不兼容  ……🏖️ 本文仓库：knife4j-handler-enum需求场景分析通常我们在定义枚举时，不管是简单的枚举定义，或者枚举类中包含多种属性，在Swagger或者springdoc的界面中，都只能通过枚举的name属性进行展示，例如如下枚举类:@AllArgsConstructor@Getterpublic enum CourseType {    MATH(1,\"数学\"),    ENGLISH(2,\"英语\"),    CHINESE(3,\"语文\"),    COMPUTER(4,\"计算机\");    /**     * 课程编码     */    final int code;    /**     * 课程标签     */    final String label;}最终在文档页面展示效果如下图：:::danger 问题这种效果可能无法满足我们的要求，主要是我们提供给外部调用我们的接口文档的开发者，如果我们的枚举name属性定义的通俗易懂，那么是没有问题，如果有其他的场景定义，那么只通过name属性是很难达到文档解释清楚的对于文档中，开发者可能更希望将枚举说代表的label意义在文档中进行展示，这对于接口对接人员可以一目了然清楚枚举的最终定义和说明:::解决方案对于枚举类型展示明细的description,最简单的方案就是重写枚举类的toString方法，开发者可以将枚举的字典定义以及description描述信息统一在该方法中进行重写输出示例代码如下：@AllArgsConstructor@Getterpublic enum CourseType {    MATH(1,\"数学\"),    ENGLISH(2,\"英语\"),    CHINESE(3,\"语文\"),    COMPUTER(4,\"计算机\");    /**     * 课程编码     */    final int code;    /**     * 课程标签     */    final String label;    @Override    public String toString() {        return this.name()+\":\"+this.label;    }}我们通过重写toString方法，将枚举的name属性和label属性进行拼接，label属性一般将我们该枚举说要展示的意思描述清楚，知道该枚举类说代表的意思。在Ui中最终效果展示如下：我们虽然解决了文档展示问题，但是又会带来新的问题,如果我们的请求是form的情况下，在调试时，枚举类型参数选择下拉框，枚举类参数下拉框的值也会随之变成value - desc，导致传参异常：报错信息（数据绑定异常）：2023-08-07T20:04:35.640+08:00  WARN 40180 --- [io-19001-exec-8] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.bind.MethodArgumentNotValidException: Validation failed for argument [0] in public org.springframework.http.ResponseEntity&lt;com.xiaominfo.knife4j.core.CourseInfo&gt; com.xiaominfo.knife4j.rest.EnumRestController.form(com.xiaominfo.knife4j.core.CourseInfo): [Field error in object 'courseInfo' on field 'courseType': rejected value [2]; codes [typeMismatch.courseInfo.courseType,typeMismatch.courseType,typeMismatch.com.xiaominfo.knife4j.core.CourseType,typeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [courseInfo.courseType,courseType]; arguments []; default message [courseType]]; default message [Failed to convert property value of type 'java.lang.String' to required type 'com.xiaominfo.knife4j.core.CourseType' for property 'courseType'; Failed to convert from type [java.lang.String] to type [@io.swagger.v3.oas.annotations.media.Schema com.xiaominfo.knife4j.core.CourseType] for value [2]]] ]如issues:枚举类参数value和desc的注释中反馈的一样  ⚠️ 该问题在swagger2规范下会复现，openapi3存在解析问题，但是调试问题依然存在那么，如何解决调试问题呢?数据调试我们在解决这样的场景时，需要要考虑到两种不同接口在Spring Boot框架中的参数赋值情况，主要是：  application/x-www-form-urlencoded:基于表单请求的方式，Spring Boot框架针对提交的请求参数主要通过WebDataBinder组件实现提交参数的数据转换、绑定、格式化等处理操作  application/json:而对于JSON提交的接口参数，对于数据的转换这主要依赖于数据的反序列化这两种方式对于springdoc-openapi处理也是一样，会存在不同的差异，开发者需要分开进行处理。接下来就针对这这两种不同的接口场景，对于枚举类型展示明细的description提供不同的处理方案表单请求针对表单请求，我们需要为WebDataBinder组件单独提供枚举类的数据绑定逻辑，通过实现PropertyEditorSupport接口，并且在Spring Boot框架中Controller增强为WebDataBinder初始化不同枚举类的数据绑定。考虑到在实际项目中的通用解决方案(为每个枚举提供数据绑定解析),抽象一个通用接口public interface CommonFormEnumParser&lt;T extends Enum&lt;T&gt;&gt; {    /**     * Realize the instantiation of the enumeration according to the input input     * @param input input character     * @return enumeration instance     */    T fromValue(String input);}我们在枚举类中实现该接口，提供根据外部数据进行枚举实例对象转换的方法，如下：@Slf4j@AllArgsConstructor@Getterpublic enum CourseType implements CommonFormEnumParser&lt;CourseType&gt; {    MATH(1,\"数学\"),    ENGLISH(2,\"英语\"),    CHINESE(3,\"语文\"),    COMPUTER(4,\"计算机\");    /**     * 课程编码     */    final int code;    /**     * 课程标签     */    final String label;    @Override    public String toString() {        return this.name()+\":\"+this.label;    }    @Override    public CourseType fromValue(String input) {        log.info(\"input:{}\",input);        for (CourseType courseType : CourseType. values()) {            // 根据规则自定义实现            if (input.startsWith(Objects.toString(courseType))||input.equalsIgnoreCase(courseType.name())) {                return courseType;            }        }        throw new IllegalArgumentException(\"Invalid CourseType value: \" + input);    }}根据反射class创建一个默认的PropertyEditorSupport实现，代码如下：@AllArgsConstructorpublic class GenericEnumPropertySupport &lt;T extends Enum&lt;T&gt;&gt; extends PropertyEditorSupport {    final Class&lt;T&gt; enumClass;    @Override    public void setAsText(String text) throws IllegalArgumentException {        if (enumClass.isEnum()){            //必须是枚举            if (CommonFormEnumParser.class.isAssignableFrom(enumClass)){                T[] values=enumClass.getEnumConstants();                if (values!=null&amp;&amp;values.length&gt;0){                    // 因为都实现了CommonFormEnumParser接口，随便取一个枚举元素都行                    CommonFormEnumParser&lt;T&gt; one= (CommonFormEnumParser&lt;T&gt;) values[0];                    setValue(one.fromValue(text));                }            }        }    }}最后通过Spring框架提供的Advice增强注入到框架中，实现@InitBinder绑定逻辑@RestControllerAdvicepublic class GlobalRestAdvice {    @InitBinder    public void initBinder(WebDataBinder binder) {        //这里可以做成scan扫描包的方式，扫描所有枚举类，然后分批注入，或者其他的方式也行，看自己项目的规则        binder.registerCustomEditor(CourseType.class,new GenericEnumPropertySupport&lt;&gt;(CourseType.class));    }}由于我们自定义了枚举的初始化数据绑定方法，逻辑是：名称相等或者和name匹配if (input.startsWith(Objects.toString(courseType))||input.equalsIgnoreCase(courseType.name())) {    return courseType;}此时，我们在form表单接口提交请求时，对于枚举的类型，就可以参考常规的方案，提交枚举的name进行调试，如下图：JSON请求而对于JSON的请求，就简单很多，我们在上面提过，JSON的数据绑定是在Spring Boot框架中是通过反序列化进行处理。以框架中用jackson为例，首先需要更改枚举类的toString方法，通过@JsonValue注解将枚举的属性值列出来，以便文档展示，其次，反序列化时，提供反序列化的规则。代码如下：@Slf4jpublic class CourseTypeDeserializer   extends JsonDeserializer&lt;CourseType&gt; {    @Override    public CourseType deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException {        log.info(\"des....\");        String input = jsonParser.getValueAsString();        log.info(\"value:{}\",input);        for (CourseType courseType : CourseType.values()) {            // 根据规则自定义实现            if (input.startsWith(Objects.toString(courseType))||input.equalsIgnoreCase(courseType.name())) {                return courseType;            }        }        throw new IllegalArgumentException(\"Invalid CourseType value: \" + input);    }}并且在枚举类中通过注解@JsonDeserialize强指定反序列化规则@Slf4j@AllArgsConstructor@Getter@JsonDeserialize(using = CourseTypeDeserializer.class)public enum CourseType implements CommonFormEnumParser&lt;CourseType&gt; {    //others...}总结以上就是针对枚举在Knife4j中通过文档展示以及Debug调试的通用方案分享，对于代码中枚举的反序列化以及通过WebDataBinder组件进行数据绑定的操作，本文只是提供了一个思路方案，开发者可以在本文基础上进行扩展优化例如对于所有枚举类的scan扫描class的方式，批量在WebDataBinder组件中进行添加，等等，希望本文能给开发者提供一个思路，开发者根据此内容举一反三，处理自己在实际项目中碰到的问题。您有更多的想法或者建议，可以关注公众号”八一菜刀”，参与Knife4j的交流群进行沟通反馈，谢谢"
  },
  
  {
    "title": "生产环境如何屏蔽Knife4j、Swagger等Ui资源和接口",
    "url": "/posts/knife4j-production-forbidden-ui/",
    "categories": "Knife4j",
    "tags": "",
    "date": "2023-07-19 00:00:00 +0800",
    





    
    "snippet": "本文主要介绍在 Spring Boot 应用中,如何在生产环境屏蔽Knife4j及相关Swagger资源关联Issues：  ✅ 开启生产环境,屏蔽所有资源接口  ✅ 生产环境屏蔽bug  ✅ 3.0.2 配置生产环境屏蔽后，依然可以访问部分接口  ✅ yml格式 屏蔽Swagger所有资源，不生效  ✅ 生产环境swagger-ui屏蔽  ✅ 开启生产环境,屏蔽Swagger所有资源接口 ...",
    "content": "本文主要介绍在 Spring Boot 应用中,如何在生产环境屏蔽Knife4j及相关Swagger资源关联Issues：  ✅ 开启生产环境,屏蔽所有资源接口  ✅ 生产环境屏蔽bug  ✅ 3.0.2 配置生产环境屏蔽后，依然可以访问部分接口  ✅ yml格式 屏蔽Swagger所有资源，不生效  ✅ 生产环境swagger-ui屏蔽  ✅ 开启生产环境,屏蔽Swagger所有资源接口 建议  ✅ 生产环境屏蔽配置&amp;2.0.9版本问题  ✅ 4.1.0 basic 验证， 任意请求都会导致请求通过，从而导致doc.html 不提示验证  ✅ springcloud 生产环境无法关闭  ……🏖️ 本文仓库：knife4j-forbidden-api从仓库的issues中不难发现，该需求确确实实存在，虽然在Knife4j之前的版本，并没有提供屏蔽资源相关的配置，但也有很多开发者提了建议这在之后的版本迭代中,Knife4j主要提供了Basic验证和Production暴力屏蔽的手段，这些都是基于实际需求场景出发来做的,生产环境屏蔽接口描述也是为了保护应用程序安全的一种手段。本文主要站在实际需求以及业务场景的角度，去分析如何在生产环境进行屏蔽接口从issues中，我们屏蔽的场景主要发生在：  ✅ 单体Spring Boot应用屏蔽接口和静态ui资源  ✅ 微服务Spring Cloud、Spring Cloud Gateway网关场景下屏蔽接口和静态资源屏蔽的手段主要包括以下几种(欢迎补充):  🌱 基于Spring Boot框架提供的@Conditional条件控制相关@Bean的生效  ⛔ 基于Servlet体系下的Filter过滤器进行拦截屏蔽  ⛰️ 基于Gateway网关体系下的Filter过滤器进行拦截屏蔽  💀 基于Maven项目的jar排除机制从根源解决问题  💣 基于生产环境Nginx、Ingress等控制请求路径处理1.目的通过开发者提出的issues，屏蔽的目的及提供Basic验证的方案来分析，我觉得主要有以下几点：  🔐 生产环境上线的系统，屏蔽接口描述性规范，对于生产系统是一种安全保护机制  🔐 Basic方案更希望的是能够上线后也保留接口，解决生产环境出问题时便于调试定位问题，当Basic能起到一定的安全防护作用2.解决方案2.1 🌱 基于Spring Boot框架提供的@Conditional条件控制相关@Bean的生效在Spring Boot开发框架中，提供了一种条件注入的机制注解@Conditional,顾名思义就是可以指定我们的代码在特定环境才生效。开发者在写第三方的starter的包时，是一种经常使用的手段。有关@Conditional注解等条件注入的说明，可以参考我之前分享的一篇Blog《Spring Boot框架中如何优雅的注入实体Bean》我们的需求场景是：在生产环境中能够屏蔽部分接口以及Ui资源，那么我们是否可以结合@Conditional注解以及@Profile注解来实现不同环境的@Bean加载机制呢？答案当然是可以的,考虑到在Spring Boot环境中大部分的中间件都提供了配置化,类似enable属性来开启加载配置，这里可以使用spring.profiles通过配置进行区分简单的例子：我们对于Knife4j的配置文件有两个，分别对应dev环境和prod环境配置文件如下：  开发环境(dev)```yml title=”application-dev.yml”knife4j:  enable: true  ## other properties…….- 生产环境(prod)```yml title=\"application-prod.yml\"knife4j:  enable: false  ## other properties.......在这种情况下，我们程序在启动时，只需要通过设定Spring Boot应用的Profiles，就可以实现我们的接口无法访问，如果我们指定prod环境，那么访问文档时，会出现接口404的情况~总结：这种情况是对于Java后端应用的Configuration类级别的控制，通过Spring Boot框架提供的@Conditional注解来达到条件注入及部分代码可配置生效的目的虽然界面可访问，但是对于接口的规范描述并没有作用。2.2 ⛔ 基于Servlet体系下的Filter过滤器进行拦截屏蔽基于Servlet体系下的Filter过滤器进行拦截屏蔽是一种拦截机制，主要利用了Servlet规范下的Filter机制，对所有的请求资源进行拦截，开发者可以对所有涉及到Knife4j、Swagger资源的请求都进行拦截屏蔽场景的资源拦截地址可以参考文档《访问权限控制》我们知道了要屏蔽的资源，以及Filter机制，此时，开发者即可以自己实现Filter代码，并将其注入到Spring Boot的应用框架中接口在Knife4j提供的ProductionSecurityFilter.java 如下：public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {    HttpServletRequest httpServletRequest = (HttpServletRequest) request;    if (production) {        String uri = httpServletRequest.getRequestURI();        // 匹配判断uri地址是否我们需要屏蔽的资源        if (!match(uri)) {            chain.doFilter(request, response);        } else {            HttpServletResponse resp = (HttpServletResponse) response;            resp.setStatus(customCode);            resp.sendError(customCode, \"You do not have permission to access this page\");        }    } else {        chain.doFilter(request, response);    }}   2.3 ⛰️ 基于Gateway网关体系下的Filter过滤器进行拦截屏蔽基于Gateway网关体系下的Filter过滤器进行拦截屏蔽和Servlet体系下的Filter进行拦截是同一种思想，因为Spring Cloud Gateway是基于Netty驱动设计实现，但思想方法是同一种无非是使用Spring Cloud Gateway提供的Filter接口，自定义实现match后屏蔽过滤可以参考Knife4j代码中的WebFluxSecurityBasicAuthFilter.java2.4 💀 基于Maven项目的jar排除机制从根源解决问题该方法也是利用Maven项目提供的Profiles机制，我们在项目打包构建的时候，可以对一些不需要的jar包进行exclusion排除，比如Knife4j的ui包或者swagger官方ui包，这种jar包都是webjar类型，里面全部是静态资源Maven的Profiles是一种配置管理机制，允许你根据不同的环境或条件设置和激活不同的构建配置。可以使用Profiles来定义一组插件、依赖项和构建选项，这些选项在特定的构建环境中生效如果我们想在生产环境无需访问提供外部入口，那么我们在打包构建的时候可以直接排除即可基于这种思想，我们可以考虑在项目的pom.xml中配置Maven的Profiles，配置如下：&lt;profiles&gt;    &lt;profile&gt;        &lt;id&gt;dev&lt;/id&gt;        &lt;activation&gt;            &lt;!-- 激活条件为\"dev\"系统属性存在 --&gt;            &lt;property&gt;                &lt;name&gt;env&lt;/name&gt;                &lt;value&gt;dev&lt;/value&gt;            &lt;/property&gt;        &lt;/activation&gt;    &lt;/profile&gt;    &lt;profile&gt;        &lt;id&gt;prod&lt;/id&gt;        &lt;activation&gt;            &lt;!-- 激活条件为\"prod\"环境变量存在 --&gt;            &lt;property&gt;                &lt;name&gt;env&lt;/name&gt;                &lt;value&gt;prod&lt;/value&gt;            &lt;/property&gt;        &lt;/activation&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;                &lt;artifactId&gt;knife4j-openapi3-spring-boot-starter&lt;/artifactId&gt;                &lt;exclusions&gt;                    &lt;exclusion&gt;                        &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;                        &lt;artifactId&gt;knife4j-openapi3-ui&lt;/artifactId&gt;                    &lt;/exclusion&gt;                    &lt;exclusion&gt;                        &lt;groupId&gt;org.webjars&lt;/groupId&gt;                        &lt;artifactId&gt;swagger-ui&lt;/artifactId&gt;                    &lt;/exclusion&gt;                &lt;/exclusions&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/profile&gt;&lt;/profiles&gt;在上面的配置中，主要作用如下：  ✅ 声明了两个Profile类型，id分别为dev、prod  ✅ 配置了两种Profile类型的激活条件，通过环境变量名称来进行区分  ✅ 在prod类型下面，我们配置的引用jar的exclusions规则，该Profile类型下会排除knife4j-openapi3-ui、swagger-ui这两个jar包，而这两个包分别是Knife4j和swagger官网提供的Ui资源包此时，当我们在项目构建打包时，我们就可以通过传入变量，进行构建，排除相关的jar包，命令如下：mvn clean package -Pprod2.5 💣 基于生产环境Nginx、Ingress等控制请求路径处理上面2.1~2.4提供的方案都是通过代码或者工程上进行配置以达到目的，如果我们的服务已经上线，不管是Nginx或者在Kubernetes集群环境中，都可以通过Nginx、Ingress等代理服务器进行配置拦截处理也不失为一种处理方式。在Nginx中，我们只需要配置拦截资源接口，配置如下：location /doc.html {    return 403;  # 返回 403 状态码表示禁止访问}location /swagger-ui.html {    return 403;  # 返回 403 状态码表示禁止访问}// 其他路由接口及资源而在Kubernetes集群环境中，可以通过使用Ingress控制请求,配置示例如下：apiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: my-ingressspec:  rules:    - http:        paths:        # 转发doc.html到error-service,可以在该服务中定义一个错误页面或返回适当的错误码          - path: /doc.html            pathType: Prefix            backend:              service:                name: error-service                port:                  number: 803.总结本文从工程、代码等多方角度给大家提供了一种解决思路方案，希望能对大家有所帮助。"
  },
  
  {
    "title": "使用Claude修改Knife4j中的issues",
    "url": "/posts/knife4j-use-claude-fixed-issue/",
    "categories": "Knife4j",
    "tags": "",
    "date": "2023-07-15 00:00:00 +0800",
    





    
    "snippet": "本文和Knife4j使用无关，主要分享作者在解决Knife4j的issues过程中如何通过Claude.Ai快速解决问题关联Issues：  ✅ 能否出个swagger转ts的插件,在文档管理中多一个,导出ts,想帮我的下游减轻工作量  ✅ https://github.com/xiaoymin/knife4j/issues/568📹 视频地址：https://www.bilibili.co...",
    "content": "本文和Knife4j使用无关，主要分享作者在解决Knife4j的issues过程中如何通过Claude.Ai快速解决问题关联Issues：  ✅ 能否出个swagger转ts的插件,在文档管理中多一个,导出ts,想帮我的下游减轻工作量  ✅ https://github.com/xiaoymin/knife4j/issues/568📹 视频地址：https://www.bilibili.com/video/BV1mm4y1E7iV/?vd_source=ef34098d916a578698508a43063099ac🌋 背景在上面的issues中，有用户提到在目前的Knife4j的界面中，对于生成的Script代码(主要是TypeScript)，对于实体类部分，缺失属性定义，于是需要解决主要的问题点：  ❓ Knife4j的Script功能来源于PR  ❓ 代码中使用了babel/generator,而我对该组件并不熟悉🔥 解决过程传统方案1、首先，我直接定位到函数的源码，查看源码，看是否有属性直接能够使用，部分源码：export interface TSPropertySignatureBuilder {    (key: K.ExpressionKind, typeAnnotation?: K.TSTypeAnnotationKind | null, optional?: boolean): namedTypes.TSPropertySignature;    from(params: {        comments?: K.CommentKind[] | null;        computed?: boolean;        initializer?: K.ExpressionKind | null;        key: K.ExpressionKind;        loc?: K.SourceLocationKind | null;        optional?: boolean;        readonly?: boolean;        typeAnnotation?: K.TSTypeAnnotationKind | null;    }): namedTypes.TSPropertySignature;}在源码中，有comments属性，在没有查看官网文档的情况下，我姑且一试,直接给comments赋值，看直接传递是否奏效,结果并未不满意。2、这种情况下只能去去看了babel/generator的官方文档了，去翻看部分函数的doc文档参数，希望能够快速找到能够为生成的interface的属性标注comment的方法但我并没有找到我所需要的，能够为生成的properties增加注释的方法💯 求助AI想到之前在网上看到Claude2已经发布，支持100k的上下文并且免费，因此决定试试看1、首先我将Knife4j中整段js函数作为附件进行了上传，并且构建了Prompt，如下图：Claude2也给出了答案，但好像并不是我想要的，如下图：2、于是我在继续追问，因为知道具体的函数所执行的位置，所以直接问函数中的某一个方法，看看Claude2是否能够定位问题这一次，Claude2好像理解了我的意图，并定位出了问题所在，我根据提示，在代码中进行了修改，代码修改如下：export function getInterfaceBody(props, openOptional) {  return props.map(p =&gt; {    let ta = t.tsTypeAnnotation(getTsType(p, getBaseType(p.type), openOptional), p.description);    let key = t.identifier(p.name);    let pro = t.tsPropertySignature(      key,      ta,      openOptional ? !p.require : false,    )    // 增加注释    pro.leadingComments = [{      type: \"CommentBlock\",      value: `${p.description} `    }]    return pro;  })}此时在界面中，再次刷新界面，Knife4j的Scirpt中，每一个定义的interface都有了comment，如下图："
  },
  
  {
    "title": "自定义API接口在Knife4j的Ui界面中显示",
    "url": "/posts/knife4j-customer-add-api/",
    "categories": "Knife4j",
    "tags": "",
    "date": "2023-07-13 00:00:00 +0800",
    





    
    "snippet": "本文主要介绍在 Spring Boot 应用中,如何使用 springfox 和 springdoc 框架自定义添加外部 API 接口,并在 Knife4j 的 UI 界面中展示。关联Issues：  ✅ 添加SpringSecurity登录接口到knife4j中🏖️ 本文仓库：knife4j-customer-api📹 视频地址：https://www.bilibili.com/video...",
    "content": "本文主要介绍在 Spring Boot 应用中,如何使用 springfox 和 springdoc 框架自定义添加外部 API 接口,并在 Knife4j 的 UI 界面中展示。关联Issues：  ✅ 添加SpringSecurity登录接口到knife4j中🏖️ 本文仓库：knife4j-customer-api📹 视频地址：https://www.bilibili.com/video/BV19h4y1j7y9/?vd_source=ef34098d916a578698508a43063099ac🌱 本质我们要实现将自定义的API接口添加到Ui界面中显示，其实最简单的就是在我们接口渲染的Swagger或者OpenAPI对象中，添加相应的新对象(PS:用于在OpenAPI规范中描述接口定义的Operation对象)属性就好了这需要借助于底层解析框架对外是否提供了开放接口，允许我们这么做，还好目前不管是springfox或者springdoc，其实都支持开发者自定义。主要的区别是：  ✅ springfox提供的是spring-plugin体系，在解析时添加Operation对象，这是进行中的处理行为  ✅ springdoc提供的全局Customer接口，springdoc已经完成了所有接口的对象解析，但开发者实现Customer接口可以自定义更改，这是后置行为📜 springfox在springfox的框架中，提供了基于spring-plugin体系的解析接口，开发者如果阅读过springfox的源码后，应该很轻松就能实现主要的动作包括：  🎠 自定义plugin接口，实现ApiListingScannerPlugin.java类，并且通过@Component或者Java Config得@Bean注解注入到Spring的容器中  🎢 创建Operation对象，该对象是一个接口的描述，包括：说明、参数、响应、请求类型等等，并且返回ApiListingScannerPlugin.java接口约束的方法类型  🏎️ springfox这种方式只能提供简单的form表单类型的接口，如果是类似@RequestBody类型的JSON、XML请求，那么建议放弃~示例:添加一个简单的login登录接口，代码如下：```javascript title=”com.xiaominfo.springfox.customer.CustomerApiPlugin.java”@Slf4j@Componentpublic class CustomerApiPlugin implements ApiListingScannerPlugin {@Overridepublic List&lt;ApiDescription&gt; apply(DocumentationContext context) {    // consumers、produces    Set&lt;String&gt; mediaSet = new HashSet&lt;&gt;();    mediaSet.add(MediaType.APPLICATION_JSON_VALUE);    // 设定参数    List&lt;Parameter&gt; parameters = new ArrayList&lt;&gt;();    parameters.add(new ParameterBuilder().name(\"username\").required(true).modelRef(new ModelRef(\"String\")).defaultValue(\"test\").description(\"用户名\").build());    parameters.add(new ParameterBuilder().name(\"password\").required(true).modelRef(new ModelRef(\"String\")).defaultValue(\"123\").description(\"密码\").build());    // 接口的Tag    Set&lt;String&gt; tags = new HashSet&lt;&gt;();    tags.add(\"首页\");    // 构建Operation对象    Operation usernamePasswordOperation = new OperationBuilder(new CachingOperationNameGenerator())            .method(HttpMethod.POST)            .tags(tags)            .summary(\"用户名密码登录\")            .notes(\"用户登陆获取token\")            .parameters(parameters)            .consumes(mediaSet)            .produces(mediaSet)            .build();        // 需要注意的是groupName需要和开发者创建的Docket对象赋值的groupName保持一致    ApiDescription loginApiDescription = new ApiDescription(\"hello\", \"/login\", \"登录接口描述\", Collections.singletonList(usernamePasswordOperation), false);    return Collections.singletonList(loginApiDescription);}@Overridepublic boolean supports(DocumentationType documentationType) {    return documentationType == DocumentationType.SWAGGER_2;} } ```📚 springdoc在springdoc中，其实和springdoc的思想是完全一致的,springdoc也开放了两种级别的customizer接口：  🏜️ GlobalOperationCustomizer：针对Operation级别的全局自定义扩展钩子函数，开发者可以对接口中每一个Operation进行扩展自定义实现，或调整，或修改，或增加扩展都行，Knife4j的部分增强特性就是基于此函数实现，可以参考代码Knife4jJakartaOperationCustomizer.java  🏝️ GlobalOpenApiCustomizer：是针对整个OpenAPI级别的,开发者在分组或者分包后，得到的单个OpenAPI实例，开发者可以操纵全局的OpenAPI实例，该OpenAPI对象已经是springdoc解析过的实例对象，例如该issues中的需求，开发者只需要自定义创建新Operation对象，然后通过OpenAPI实例对象进行add添加即可完成此需求，部分扩展可以参考代码：Knife4jOpenApiCustomizer.java  🎠 扩展实现类接口后，注入Spring的容器中即可考虑到我们是新增自定义的API接口，因此，可以实现GlobalOpenApiCustomizer类进行扩展代码示例如下：// com.xiaominfo.springdoc.customer.CustomerOperation.java@Slf4j@Componentpublic class CustomerOperation implements GlobalOpenApiCustomizer {        @Override    public void customise(OpenAPI openApi) {        log.info(\"customer.\");        // 因为要新增自定义的接口，直接这里add        PathItem pathItem = new PathItem();        // 基础信息 构建Operation        Operation operation = new Operation();        operation.operationId(\"login\");        operation.summary(\"登录接口\");        operation.description(\"根据用户名和密码登录获取token\");        operation.tags(Collections.singletonList(\"登录\"));        // 构建参数        List&lt;Parameter&gt; parameters = new ArrayList&lt;&gt;();        parameters.add(new Parameter().name(\"name\").example(\"zhangFei\").description(\"用户名\").required(true).schema(new StringSchema()).in(\"query\"));        parameters.add(new Parameter().name(\"password\").example(\"123456\").description(\"密码\").required(true).schema(new StringSchema()).in(\"query\"));        operation.parameters(parameters);        // 构建响应body        ApiResponses apiResponses = new ApiResponses();        ApiResponse apiResponse = new ApiResponse();        apiResponse.description(\"ok\").content(new Content().addMediaType(\"*/*\", new MediaType().schema(new StringSchema())));        apiResponses.addApiResponse(\"200\",apiResponse);        operation.responses(apiResponses);        // 该自定义接口为post        pathItem.post(operation);        openApi.path(\"/login\", pathItem);    }}此时，我们可以在界面中查看，已经存在了我们自定义新增的接口，如下图：📖 总结本文主要介绍了基于springfox或者springdoc框架，添加自定义API接口的示例，开发者可以根据其中的思想自行扩展，达到自己的业务需求。"
  },
  
  {
    "title": "Knife4j框架相关的blog",
    "url": "/posts/knife4j-action-index/",
    "categories": "Knife4j",
    "tags": "",
    "date": "2023-07-10 00:00:00 +0800",
    





    
    "snippet": "  温馨提醒Knife4jInsight(简单、方便的OpenAPI接口文档私有化聚合平台),地址：http://knife4j.net最近想来,Knife4j的Gitee和Github的仓库已经有接近2000+的issues了,issues中有包含的内容大部分都是提问为主，因此有一个想法，针对Knife4j仓库中的issues中的典型问题，整理成文章，分享给大家大家也可以作为教程进行参考。...",
    "content": "  温馨提醒Knife4jInsight(简单、方便的OpenAPI接口文档私有化聚合平台),地址：http://knife4j.net最近想来,Knife4j的Gitee和Github的仓库已经有接近2000+的issues了,issues中有包含的内容大部分都是提问为主，因此有一个想法，针对Knife4j仓库中的issues中的典型问题，整理成文章，分享给大家大家也可以作为教程进行参考。  😄 Welcome Join Us也欢迎大家投稿、提交PR一起参与进来我想一篇内容主题输出的主要的形式包括：  📝 一篇文章 : 文章会在官网的Blog专栏和微信公众号同步发表  🌱 一份Git仓库代码 ：每篇文章的代码仓库会同步更新到Github，仓库地址: knife4j-demo  ✅ 关联N个issues : 主要以仓库issues或者交流群的问题为文章的来源,透过问题希望能讲清楚  🎥 一个视频 : 看是否有足够的时间，录制一个简单的视频继续加以说明主要目的：  💪 磨练自己的性格，做事的性格和毅力  🔥 为Knife4j 、 Swagger 、 OpenAPI生态添砖加瓦Blog列表：  📝 2023/07/13: 如何自定义添加API接口在Knife4j界面中显示  📝 2023/07/15: 使用Claude修改Knife4j中的issues  📝 2023/07/19: 生产环境如何屏蔽Knife4j、Swagger等Ui资源和接口  📝 2023/08/07: 枚举烦恼终结!在Knife4j文档中如何优雅的处理枚举类型的展示及调试问题  📝 2023/08/13: Spring Cloud Gateway网关下的文档聚合?就用它了  📝 2023/09/07: Knife4j新产品的想法  📝 2023/09/19: Knife4jInsight平台版-MVP版本v1.0.0发布  📝 2023/09/20: Knife4jInsight的产品开发历程"
  },
  
  {
    "title": "2023年6月最新注册ChatGPT账号流程",
    "url": "/posts/chatgpt-register/",
    "categories": "大模型",
    "tags": "",
    "date": "2023-06-10 00:00:00 +0800",
    





    
    "snippet": "ChatGPT是什么？ChatGPT（全名：Chat Generative Pre-trained Transformer），是OpenAI 研发的聊天机器人程序,于2022年11月30日发布 。ChatGPT是人工智能技术驱动的自然语言处理工具，它能够通过理解和学习人类的语言来进行对话，还能根据聊天的上下文进行互动，真正像人类一样来聊天交流，甚至能完成撰写邮件、视频脚本、文案、翻译、代码，...",
    "content": "ChatGPT是什么？ChatGPT（全名：Chat Generative Pre-trained Transformer），是OpenAI 研发的聊天机器人程序,于2022年11月30日发布 。ChatGPT是人工智能技术驱动的自然语言处理工具，它能够通过理解和学习人类的语言来进行对话，还能根据聊天的上下文进行互动，真正像人类一样来聊天交流，甚至能完成撰写邮件、视频脚本、文案、翻译、代码，写论文 等任务。账号注册流程(准备工作)由于ChatGPT在中国服务不可用，而注册ChatGPT最终需要通过手机号短信验证才能最终完成注册。这对于没有国外手机号的小伙伴而言就很苦恼了。而解决短信验证问题，我们可以通过虚拟手机号短信平台来平替，最终帮助我们完成注册。所以，在注册ChatGPT之前。你需要准备：  可以稳定科学上网的工具  一个常用的邮箱账号，建议使用Google的GMail邮箱  充值购买虚拟短信平台的SMS账号(1美元，支持支付宝)ChatGPT官网地址：https://chat.openai.com虚拟短信SMS平台科学上网的工具大家自行查找获取吧，这里只分享给大家虚拟短信平台SMS的流程可以访问网站：https://smspva.com/进行充值，支持支付宝，充值1美元即可。网站如下图：首先进行充值，点击充值余额按钮，进入充值页面(选择支付宝):当你充值完成后，首先需要选择国家(建议选择美国，成功率高一些)，选择国家后，即可以看到OpenAPI的供应商，点击即可选择OpenAI API选项后，在右边会出现一个手机号码，这个手机号码在你最终注册ChatGPT账号获取短信验证的时候，填入电话号码，然后等待网站显示ChatGPT发送的短信验证码即可：iPhone手机下载ChatGPT的APP准备工作在iPhone手机中，如果你要下载ChatGPT官方的APP，那么你需要以下准备工作：  一个美区的AppleID，注册流程可以参考知乎文章五分钟注册美区AppleID  在iPhone上面能够科学上网的工具下载官方App我们在上面注册ChatGPT账号成功后，就可以在Web端成功使用ChatGPT了。如果你的手机是iPhone,那么也可以通过下载官方(请认准官方，APP Store上面太多李鬼了)提供的APP进行使用iOS地址：https://apps.apple.com/app/openai-chatgpt/id6448311069最后好了，上面就是分享的最新ChatGPT的账号注册以及IOS下载的流程。如果你对本篇文中中的任何步骤存在疑问，可以关注下面公众号加入交流群获取帮助。关注我，获取更多开源、AI等方面的最新资讯信息"
  },
  
  {
    "title": "Final.激活Knife4j官网的文档搜索功能",
    "url": "/posts/knife4j-document-active-search/",
    "categories": "Knife4j",
    "tags": "",
    "date": "2023-05-31 00:00:00 +0800",
    





    
    "snippet": "1.前言在很早之前,Knife4j的官网文档就通过docusaurus进行了重构，在网上找了一个自己还算满意的模板，将所有的Knife4j的Markdown文档进行了重新梳理改造。但是后面有一段时间，也是自己懒的原因，文档中的搜索功能一直不可用。每天都会收到搜索的统计结果报告，提示的都是在搜索的请求中，未匹配结果的概率始终100%看的也是相当难受，这两天终于投入了时间，决心解决这个问题。2....",
    "content": "1.前言在很早之前,Knife4j的官网文档就通过docusaurus进行了重构，在网上找了一个自己还算满意的模板，将所有的Knife4j的Markdown文档进行了重新梳理改造。但是后面有一段时间，也是自己懒的原因，文档中的搜索功能一直不可用。每天都会收到搜索的统计结果报告，提示的都是在搜索的请求中，未匹配结果的概率始终100%看的也是相当难受，这两天终于投入了时间，决心解决这个问题。2.AlgoliaKnife4j的官网搜索主要集成了Algolia来提供搜索服务，因为docusaurus纯天然支持Algolia来集成文档搜索服务，如果用过Algolia的服务的朋友可能知道，如果你的网站文档是开源项目，那么是可以提交申请来获取免费服务的，主要条件：  必须是文档网站的 所有者，网站必须是 公开的。  网站内容必须是 开源项目的技术文档 或 技术博客。  网站申请服务时必须有 完整稳定的设计和内容，即确认网站做好生产准备。2.1 自动爬虫索引数据申请链接地址：https://docsearch.algolia.com/apply/但你提交了申请，并且官方社区审核通过后，你会收到邮件，按邮件的内容进行回复就可以了。但我们把所有的工作流程准备就绪后，我们就可以前往Algolia管理自己的后台数据了，主要步骤：步骤一、登录到Algolia里面的控制台步骤二、可以查看当前自己的Application应用的Plan类别，如下：  Plan类别是DOCSEARCH类型的应用，代表我们可以免费使用Algolia的爬虫服务，会自动爬取我们的网站文档进行索引  如果是FREE类别，则没有这种服务，你也登录不了Algolia的爬虫后台步骤三、点击Search后，即可查看该文档页面的Index数据集这里Index有数据是核心和关键，如果你的搜索服务不可用，首先要确认一下该Index中是否有数据，或者你文档中配置的搜索配置信息是否正确。第三，确认自己的爬虫后台是否有问题，登录到Algolia的爬虫后台，地址：https://crawler.algolia.com/admin/crawlers  确认右侧Indices中有数据才正常因为Knife4j的DocSearch申请的已经有一段时间了，只是在搜索的时候一直无法展示结果(这让我也一直很困惑)，所以，我们就可以使用docusaurus提供的官方algolia插件进行集成搜索2.2 自己通过Algolia的爬虫送数据Algolia除了通过DocSearch的方式进行申请，免费使用Algolia的爬虫服务，如果有一些特殊原因，或者最终没有被Algolia的官方社区审核通过，那么也是可以使用Algolia的搜索服务的，可以自己注册Algolia的后台，然后创建Application(应用)创建应用后，就可以通过Algolia提供的爬虫程序(离线工具)自己设置爬虫规则，将爬取的数据送到Algolia控制台。本文只介绍通过Docker镜像来运行爬虫的工具，其他方式可以参考官方文档：https://docsearch.algolia.com/docs/legacy/run-your-owndocker命令docker run -it --env-file=.env algolia/docsearch-scraper然后配置.env环境变量，主要有三个：  APPLICATION_ID：应用APPID，这个可以在Algolia的后台进行创建然后获取得到  API_KEY:密钥key，在Algolia的后台，可以创建API_KEY，也可以使用当前应用的AdminKey(ps:因为爬虫程序在你本机使用，没有人知道，所以用admin的key可以一步到位,避免一些权限问题会提示key无效或者无权限等问题的发生)  CONFIG: 目标网站的爬虫规则，详细规则参考文档：https://docsearch.algolia.com/docs/legacy/config-fileConfig示例如下:{    \"index_name\": \"knife4j\",    \"start_urls\": [        \"https://doc.xiaominfo.com/docs/middleware-sources\",        \"https://doc.xiaominfo.com/docs/oas\",        \"https://doc.xiaominfo.com/docs/action\",        \"https://doc.xiaominfo.com/docs/changelog\",        \"https://doc.xiaominfo.com/docs/faq\",        \"https://doc.xiaominfo.com/v2/\"    ],    \"selectors\": {        \"lvl0\": \".docMainContainer_gTbr header h1\",        \"lvl1\": \".docMainContainer_gTbr article h1\",        \"lvl2\": \".docMainContainer_gTbr article h2\",        \"lvl3\": \".docMainContainer_gTbr article h3\",        \"lvl4\": \".docMainContainer_gTbr article h4\",        \"lvl5\": \".docMainContainer_gTbr article h5\",        \"text\": \".docMainContainer_gTbr header p,.docMainContainer_gTbr section p,.docMainContainer_gTbr section ol\"    }}几个重要的参数：  index_name:索引名称，这个是在algolia后台创建的  start_urls:目标文档网站的目标页  selectors：选择器规则，也就是告诉爬虫，你需要爬取的网页，最终通过选择器获取的类容规则，包括id选择器、类选择、标签选择器等等，如果你用过jQuery,看到这个规则应该会非常熟悉当然还有更详细的规则，具体的可以参考文档进行配置即可。最终运行docker命令爬虫效果如下：等我们的爬虫在本地运行完成后，我们就可以登录后台查看我们的记录是否成功，现在的records就是最终的文档记录数3.简单验证Algolia的数据结果&amp;搜索在上面的章节中我们介绍了怎么在Algolia进行索引数据，主要包括两种方式：  官方提交DocSearch申请，通过Algolia提供的爬虫自动爬取我们的公开网站，需要审核  自己运行Algolia的爬虫程序，离线将自己的网站索引数据送到Algolia中这两种方式任何一种你都可以成功索引文档数据，如果在Algolia的控制台能看到数据，那么你可以通过下面一个小demo来验证搜索结果了，废话不多说，直接上html测试代码：&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;  &lt;meta charset=\"UTF-8\"&gt;  &lt;title&gt;Title&lt;/title&gt;  &lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@docsearch/css@3\"/&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"test\"&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/@docsearch/js@3\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt;  docsearch({    appId:\"替换为你自己的appid\",    apiKey: \"替换为你自己的apikey\",    indexName: \"替换为你自己的indexName\",    container: '#test',    debug: false // Set debug to true if you want to inspect the modal  });&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;界面效果如下：代码中的appid、key需要替换为自己的，可以在Algolia后台获取：4.Docusaurus集成前面已经提过，由于docusaurus官方提供了对Algolia的支持，所以万事俱备，只需要配置即可，在docusaurus.config.js配置文件中，直接配置appid、key就可以了themeConfig:    /** @type {import('@docusaurus/preset-classic').ThemeConfig} */ ({            // others....            algolia: {                appId: '3CRIMRK623',                apiKey: 'ae4f57f208e3c7749017e09582f0b8a4', // search only (public) API key                indexName: 'xiaominfo',                contextualSearch: false,                debug: true            },        }),效果如下:docusaurus的搜索插件可以查看文档：https://docusaurus.io/zh-CN/docs/next/search介绍的都是比较详细的，但是最值得注意的来了(这也是Knife4j在Algolia后台数据有了，就是死活搜索不出来)最坑的就是这个上下文搜索参数：contextualSearch由于该参数在Docusaurus的插件中默认开启，导致他会和上下文约束面过滤器 (contextual facet filters) 会和 algolia.searchParameters.facetFilters 合并配合使用，增加了一些不必要的过滤器，最终就会搜索没有结果如果你没有该需求或者场景，那么需要给他关闭，配置修改contextualSearch参数为false我也是对比了步骤3中通过一个简单的html集成查看Algolia请求参数的差异才发现这个区别，为啥Knife4j明明数据有了，就是搜索不出来。。。。。累了。。。。5.最后目前Knife4j的官网文档终于开启了搜索功能，希望能够帮助到使用Knife4j的同学更好的检索文档。"
  },
  
  {
    "title": "Spring Security框架中踢人下线技术探索",
    "url": "/posts/spring-security-out-session/",
    "categories": "SpringBoot",
    "tags": "",
    "date": "2021-04-20 00:00:00 +0800",
    





    
    "snippet": "1.背景在某次项目的开发中，使用到了Spring Security权限框架进行后端权限开发的权限校验，底层集成Spring Session组件，非常方便的集成Redis进行分布式Session的会话集群部署。系统正式上线后，各个部署节点能够非常方便的进行集群部署，用户的Session会话信息全部保存在Redis中间件库中，开发者不用关心具体的实现，Spring Session组件已经全部集成...",
    "content": "1.背景在某次项目的开发中，使用到了Spring Security权限框架进行后端权限开发的权限校验，底层集成Spring Session组件，非常方便的集成Redis进行分布式Session的会话集群部署。系统正式上线后，各个部署节点能够非常方便的进行集群部署，用户的Session会话信息全部保存在Redis中间件库中，开发者不用关心具体的实现，Spring Session组件已经全部集成好了。但是在系统的用户管理模块中，提供了对系统用户账号的删除功能以及禁用功能,针对这两个功能，需求方给出的具体要求是：  删除：当管理员删除当前用户账号时,如果当前账号已经登录系统,则需要剔除下线，并且不可登录  禁用：当管理员对当前账号禁用操作时，如果当前账号已经登录系统,则需要剔除下线，并且登录时，提示当前账号已禁用2.需求分析从上面的需求来看，不管是删除还是禁用功能，都需要实现，如果当前账号已经登录系统，则需要剔除下线，而禁用操作只需要再登录时给出提示信息即可，这个在业务登录方法中就可以实现，不必从底层框架进行考虑。因此，从底层技术测进行考虑时，我们需要探索如何在Spring Security权限框架中实现踢人下线的功能。既然需求已经明确，从功能的实现可能性方面入手，我们则需要从几个方面进行考虑：  1)、在Spring Security框架中，用户登录的Session会话信息存储在哪里？  2)、在Spring Security框架中，Session会话如何存储，主要存储哪些信息?  3)、如何根据账号收集当前该账号登录的所有Session会话信息？  4)、如何在服务端主动销毁Session对象？1)、在Spring Security框架中，用户登录的Session会话信息存储在哪里？如果我们不考虑分布式Session会话的情况，单体Spring Boot项目中，服务端Session会话肯定存储在内存中，这样的弊端是如果当前应用需要做负载均衡进行部署时,用户请求服务端接口时，会存在Session会话丢失的情况，因为用户登录的会话信息都存在JVM内存中，没有进程之间的共享互通。为了解决分布式应用Session会话不丢失的问题,Spring Session组件发布了，该组件提供了基于JDBC\\Redis等中间件的方式，将用户端的Session会话存储在中间件中，这样分布式应用获取用户会话时，都会从中间件去获取会话Session，这样也保证了服务可以做负载部署以保证Session会话不丢失。本文主要讨论的也是这种情况,集成Redis中间件用来保存用户会话信息。2)、在Spring Security框架中，Session会话如何存储，主要存储哪些信息?由于我们使用了Redis中间件，所以，在Spring Security权限框架中产生的Session会话信息，肯定存储与Redis中，这点毫无疑问，那么存储了哪些信息呢？我会在接下来的源码分析中进行介绍3)、如何根据账号收集当前该账号登录的所有Session会话信息？我们从上面的需求分析中已经得知Session会话已经存储在Redis中，那么我们是否可以做这样的假设，我们只需要根据Spring Security中在Redis中存储的键值，找到和登录用户名相关的Redis缓存数据，就可以通过调用Security封装的方法进行获取，得到当前登录账号的会话信息呢？这个我们需要在源码中去找到答案4)、如何在服务端主动销毁Session对象？如果是单体的Spring Boot应用，Session信息肯定存储在JVM的内存中，服务端要主动销毁Session对象只需要找到Security权限框架如何存储的就可以进行删除。在分布式的Spring Boot应用中，我们从上面已经得知Session会话信息以及存储在Redis中间件中，那么我们只需要得到当前登录的Session在Redis中的键值，就可以调用方法进行删除操作，从而主动在服务端销毁Session会话3.源码分析在上面的需求分析中，我们已经提出了假设，并且根据假设，做出来技术性的判断，接下来我们需要从Spring Security以及Spring Session组件的源码中，去寻找我们需要的答案。首先，我们在源码分析前，我们需要找到入口，也就是我们在使用Spring Security框架，并且使用Spring Session组件时，我们如何使用的。在pom.xml文件中引入组件的依赖是必不可少的，如下：&lt;!--Spring Security组件--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--Spring针对Redis操作组件--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--Spring Session集成Redis分布式Session会话--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;    &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;接下来，我们在Spring Boot项目中，需要添加@EnableRedisHttpSession注解，以开启Redis组件对Session会话的支持，该注解我们需要制定Spring Session在Redis中存储的Redis命名空间，已经Session会话的时效性，示例代码如下：@SpringBootApplication@EnableRedisHttpSession(redisNamespace = \"fish-admin:session\",maxInactiveIntervalInSeconds = 7200)public class FishAdminApplication {    static Logger logger= LoggerFactory.getLogger(FishAdminApplication.class);    public static void main(String[] args) throws UnknownHostException {        ConfigurableApplicationContext application=SpringApplication.run(FishAdminApplication.class, args);        Environment env = application.getEnvironment();        String host= InetAddress.getLocalHost().getHostAddress();        String port=env.getProperty(\"server.port\");        logger.info(\"\\n----------------------------------------------------------\\n\\t\" +                        \"Application '{}' is running! Access URLs:\\n\\t\" +                        \"Local: \\t\\thttp://localhost:{}\\n\\t\" +                        \"External: \\thttp://{}:{}\\n\\t\"+                        \"Doc: \\thttp://{}:{}/doc.html\\n\\t\"+                        \"----------------------------------------------------------\",                env.getProperty(\"spring.application.name\"),                env.getProperty(\"server.port\"),                host,port,                host,port);    }在上面的代码中，我们指定Redis的命名空间是fish-admin:session，默认最大失效7200秒。如果开发者默认不指定这两个属性的话，命名空间默认值是spring:session,默认最大时效则是1800秒在上面我们已经说过了，既然是看源码，我们需要找到入口，这是看源码最好的方式，我们在使用Spring Session组件时，需要使用@EnableRedisHttpSession注解，那么该注解就是我们需要重点关注的对象，我们需要搞清楚，该注解的作用是什么？EnableRedisHttpSession.java部分源码如下：@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(RedisHttpSessionConfiguration.class)@Configuration(proxyBeanMethods = false)public @interface EnableRedisHttpSession {     //more property..   }在该注解中，我们可以看到，最关键的是在该注解之上，使用@Import注解导入了RedisHttpSessionConfiguration.java配置类，如果你经常翻看Spring Boot相关的源码，你会敏锐的察觉到，该配置类就是我们最终要找的类先来看该类的UML图，如下：该类实现了Spring框架中很多Aware类型接口，Aware类型的接口我们都知道，Spring容器在启动创建实体Bean后，会调用Aware系列的set方法传参赋值当然，最核心的，我们从源码中可以看到，是Spring Session组件会向Spring容器中注入两个实体Bean，代码如下：@Beanpublic RedisIndexedSessionRepository sessionRepository() {    RedisTemplate&lt;Object, Object&gt; redisTemplate = createRedisTemplate();    RedisIndexedSessionRepository sessionRepository = new RedisIndexedSessionRepository(redisTemplate);    sessionRepository.setApplicationEventPublisher(this.applicationEventPublisher);    if (this.indexResolver != null) {        sessionRepository.setIndexResolver(this.indexResolver);    }    if (this.defaultRedisSerializer != null) {        sessionRepository.setDefaultSerializer(this.defaultRedisSerializer);    }    sessionRepository.setDefaultMaxInactiveInterval(this.maxInactiveIntervalInSeconds);    if (StringUtils.hasText(this.redisNamespace)) {        sessionRepository.setRedisKeyNamespace(this.redisNamespace);    }    sessionRepository.setFlushMode(this.flushMode);    sessionRepository.setSaveMode(this.saveMode);    int database = resolveDatabase();    sessionRepository.setDatabase(database);    this.sessionRepositoryCustomizers        .forEach((sessionRepositoryCustomizer) -&gt; sessionRepositoryCustomizer.customize(sessionRepository));    return sessionRepository;}@Beanpublic RedisMessageListenerContainer springSessionRedisMessageListenerContainer(    RedisIndexedSessionRepository sessionRepository) {    RedisMessageListenerContainer container = new RedisMessageListenerContainer();    container.setConnectionFactory(this.redisConnectionFactory);    if (this.redisTaskExecutor != null) {        container.setTaskExecutor(this.redisTaskExecutor);    }    if (this.redisSubscriptionExecutor != null) {        container.setSubscriptionExecutor(this.redisSubscriptionExecutor);    }    container.addMessageListener(sessionRepository,                                 Arrays.asList(new ChannelTopic(sessionRepository.getSessionDeletedChannel()),                                               new ChannelTopic(sessionRepository.getSessionExpiredChannel())));    container.addMessageListener(sessionRepository,                                 Collections.singletonList(new PatternTopic(sessionRepository.getSessionCreatedChannelPrefix() + \"*\")));    return container;}RedisIndexedSessionRepository以及RedisMessageListenerContainer的实体Bean  RedisMessageListenerContainer:该类是Redis的消息通知回调机制实体类，Redis提供了针对不同Key的操作回调消息通知，比如常见的删除key、key过期等事件的回调，在Spring Session组件中注入该实体Bean，从代码中也可以看出是用来监听处理Session会话的过期以及删除事件  RedisIndexedSessionRepository:该类是Spring Session组件提供基于Redis的针对Session会话一系列操作的具体实现类，是我们接下来源码分析的重点。先来看RedisIndexedSessionRepository类的UML类图结构，如下图：RedisIndexedSessionRepository实现了FindByIndexNameSessionRepository接口，而FindByIndexNameSessionRepository接口又继承Spring Security权限框架提供的顶级SessionRepository接口，UML类图中，我们可以得到几个重要的信息：  RedisIndexedSessionRepository拥有创建Session会话、销毁删除Session会话的能力  RedisIndexedSessionRepository由于实现自FindByIndexNameSessionRepository接口，而该接口提供了根据PrincipalName查找Session会话的能力  拥有Redis回调事件的处理消息能力，因为实现了MessageListener接口SessionRepository是Spring Security提供的顶级接口，源码如下：public interface SessionRepository&lt;S extends Session&gt; {\t/**\t * Creates a new {@link Session} that is capable of being persisted by this\t * {@link SessionRepository}.\t *\t * &lt;p&gt;\t * This allows optimizations and customizations in how the {@link Session} is\t * persisted. For example, the implementation returned might keep track of the changes\t * ensuring that only the delta needs to be persisted on a save.\t * &lt;/p&gt;\t * @return a new {@link Session} that is capable of being persisted by this\t * {@link SessionRepository}\t */\tS createSession();\t/**\t * Ensures the {@link Session} created by\t * {@link org.springframework.session.SessionRepository#createSession()} is saved.\t *\t * &lt;p&gt;\t * Some implementations may choose to save as the {@link Session} is updated by\t * returning a {@link Session} that immediately persists any changes. In this case,\t * this method may not actually do anything.\t * &lt;/p&gt;\t * @param session the {@link Session} to save\t */\tvoid save(S session);\t/**\t * Gets the {@link Session} by the {@link Session#getId()} or null if no\t * {@link Session} is found.\t * @param id the {@link org.springframework.session.Session#getId()} to lookup\t * @return the {@link Session} by the {@link Session#getId()} or null if no\t * {@link Session} is found.\t */\tS findById(String id);\t/**\t * Deletes the {@link Session} with the given {@link Session#getId()} or does nothing\t * if the {@link Session} is not found.\t * @param id the {@link org.springframework.session.Session#getId()} to delete\t */\tvoid deleteById(String id);}该接口提供四个方法：  createSession:创建Session会话  save:保存Session会话  findById:根据SessionId查找获取Session会话对象信息  deleteById:根据SessionId进行删除FindByIndexNameSessionRepository源码主要是提供根据账号名称进行查询的功能，如下：public interface FindByIndexNameSessionRepository&lt;S extends Session&gt; extends SessionRepository&lt;S&gt; {\t/**\t * 当前存储的用户名前缀，使用Redis进行存储时，存储的key值是:redisNamespace+\t */\tString PRINCIPAL_NAME_INDEX_NAME = FindByIndexNameSessionRepository.class.getName()\t\t\t.concat(\".PRINCIPAL_NAME_INDEX_NAME\");\t/**\t * Find a {@link Map} of the session id to the {@link Session} of all sessions that\t * contain the specified index name index value.\t * @param indexName the name of the index (i.e.\t * {@link FindByIndexNameSessionRepository#PRINCIPAL_NAME_INDEX_NAME})\t * @param indexValue the value of the index to search for.\t * @return a {@code Map} (never {@code null}) of the session id to the {@code Session}\t * of all sessions that contain the specified index name and index value. If no\t * results are found, an empty {@code Map} is returned.\t */\tMap&lt;String, S&gt; findByIndexNameAndIndexValue(String indexName, String indexValue);\t/**\t * Find a {@link Map} of the session id to the {@link Session} of all sessions that\t * contain the index with the name\t * {@link FindByIndexNameSessionRepository#PRINCIPAL_NAME_INDEX_NAME} and the\t * specified principal name.\t * @param principalName the principal name\t * @return a {@code Map} (never {@code null}) of the session id to the {@code Session}\t * of all sessions that contain the specified principal name. If no results are found,\t * an empty {@code Map} is returned.\t * @since 2.1.0\t */\tdefault Map&lt;String, S&gt; findByPrincipalName(String principalName) {\t\treturn findByIndexNameAndIndexValue(PRINCIPAL_NAME_INDEX_NAME, principalName);\t}}该接口最核心的功能是提供了根据用户名查找获取Session会话的接口，这对我们后面实现踢人功能很有帮助。通过查看SessionRepository接口以及FindByIndexNameSessionRepository接口的源码我们得知：  Redis的实现最终实现了这两个接口，因此获得了基于Redis中间件创建及销毁Session会话的能力  根据账号去查找当前的所有登录会话Session符合我们最终需要服务端主动踢人下线的功能需求。接下来我们只需要关注RedisIndexedSessionRepository的实现即可。首先来看findByPrincipalName方法，源码如下：@Overridepublic Map&lt;String, RedisSession&gt; findByIndexNameAndIndexValue(String indexName, String indexValue) {    //如果名称不匹配，则直接反馈空集合Map    if (!PRINCIPAL_NAME_INDEX_NAME.equals(indexName)) {        return Collections.emptyMap();    }    //获取拼装的Key值    String principalKey = getPrincipalKey(indexValue);    //从Redis中获取该Key值的成员数    Set&lt;Object&gt; sessionIds = this.sessionRedisOperations.boundSetOps(principalKey).members();    //初始化Map集合    Map&lt;String, RedisSession&gt; sessions = new HashMap&lt;&gt;(sessionIds.size());    //循环遍历    for (Object id : sessionIds) {        //根据id查找Session会话        RedisSession session = findById((String) id);        if (session != null) {            sessions.put(session.getId(), session);        }    }    return sessions;}String getPrincipalKey(String principalName) {    return this.namespace + \"index:\" + FindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME + \":\"        + principalName;}接下来我们看删除Session会话的方法实现：@Overridepublic void deleteById(String sessionId) {    //根据sessionId获取Session会话    RedisSession session = getSession(sessionId, true);    if (session == null) {        return;    }\t//从Redis中移除所有存储的针对principal的key值    cleanupPrincipalIndex(session);    //Redis中删除SessionId所对应的key值    this.expirationPolicy.onDelete(session);    //移除Session会话创建时，存储的过期key值    String expireKey = getExpiredKey(session.getId());    this.sessionRedisOperations.delete(expireKey);    //设置当前session会话最大存活时间为0    session.setMaxInactiveInterval(Duration.ZERO);    //执行save方法    save(session);}从上面的代码中，我们已经知道了Spring Session组件对于Session相关的处理方法，其实我们基于上面的两个核心方法，我们已经获得了踢人下线的能力，但是，既然RedisIndexedSessionRepository实现了MessageListener接口，我们需要继续跟踪一下该接口的具体实现方法，我们直接来看onMessage方法，代码如下：@Overridepublic void onMessage(Message message, byte[] pattern) {    byte[] messageChannel = message.getChannel();    byte[] messageBody = message.getBody();    String channel = new String(messageChannel);    if (channel.startsWith(this.sessionCreatedChannelPrefix)) {        // TODO: is this thread safe?        @SuppressWarnings(\"unchecked\")        Map&lt;Object, Object&gt; loaded = (Map&lt;Object, Object&gt;) this.defaultSerializer.deserialize(message.getBody());        handleCreated(loaded, channel);        return;    }    String body = new String(messageBody);    if (!body.startsWith(getExpiredKeyPrefix())) {        return;    }    boolean isDeleted = channel.equals(this.sessionDeletedChannel);    if (isDeleted || channel.equals(this.sessionExpiredChannel)) {        int beginIndex = body.lastIndexOf(\":\") + 1;        int endIndex = body.length();        String sessionId = body.substring(beginIndex, endIndex);        RedisSession session = getSession(sessionId, true);        if (session == null) {            logger.warn(\"Unable to publish SessionDestroyedEvent for session \" + sessionId);            return;        }        if (logger.isDebugEnabled()) {            logger.debug(\"Publishing SessionDestroyedEvent for session \" + sessionId);        }        cleanupPrincipalIndex(session);        if (isDeleted) {            handleDeleted(session);        }        else {            handleExpired(session);        }    }}private void handleDeleted(RedisSession session) {\t\tpublishEvent(new SessionDeletedEvent(this, session));}private void handleExpired(RedisSession session) {    publishEvent(new SessionExpiredEvent(this, session));}private void publishEvent(ApplicationEvent event) {    try {        this.eventPublisher.publishEvent(event);    }    catch (Throwable ex) {        logger.error(\"Error publishing \" + event + \".\", ex);    }}在onMessage方法中，最核心的是最后一个判断，分别执行handleDeleted和handleExpired方法，从源码中我们可以看到，当当前Session会话被删除或者失效时，Spring Session会通过ApplicationEventPublisher广播一个事件，分别处理SessionExpiredEvent和SessionDeletedEvent事件这是Spring Session组件为开发者预留的针对Session会话的Event事件，如果开发者对于当前的Sesssion会话的删除或者失效有特殊的处理需求，则可以通过监听该事件进行处理。例如，开发者针对Session会话的操作都需要做业务操作，记录日志保存到DB数据库中，此时，开发者只需要使用Spring提供的EventListener实现就可以很轻松的实现，示例代码如下：@Componentpublic class SecuritySessionEventListener {    @EventListener    public void sessionDestroyed(SessionDestroyedEvent event) {        //session销毁事件处理方法...    }    @EventListener    public void sessionCreated(SessionCreatedEvent event) {        //session创建会话事件处理方法...    }    @EventListener    public void sessionExired(SessionExpiredEvent event) {        //session会话过期事件处理方法...    }}4.解决方案我们分析了Spring Session针对Session基于Redis的实现，接下来，我们从源码中已经知道了该如何查找Session会话以及销毁会话的方法，此时，我们可以来改造我们的框架代码了创建SessionService接口，代码如下：public interface SessionService {    /**     *     * @param account     * @return     */    boolean hasLogin(String account);    /**     * 根據账号查找当前session会话     * @param account 账号     * @return     */    Map&lt;String, ? extends Session&gt; loadByAccount(String account);    /**     * 销毁当前session会话     * @param account     */    void destroySession(String account);}声明该接口主要包含3个方法：  hasLogin:通过传递登录账号，判断该账号是否已经登录过，该方法是一个业务的延伸，比如我们对当前账号判断是否已经登录过，如果登录则提示需要退出才能继续登录的操作等  loadByAccount:根据登录账号获取当前已经登录的Session会话Map集合  destroySession:根据登录账号销毁当前所有该账号的Session会话信息，此接口和产品经理要求的踢人下线操作一致接下来就是实现类，由于我们是基于Redis来处理，因此，我们需要将源码分析中的RedisIndexedSessionRepository实体Bean进行引入，借助该类实现该接口方法RedisSessionService方法实现如下：/** * SpringSession集成底层Redis实现，如果底层分布式会话保持方式不是基于Redis,则该类无法正常使用 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt; * 2021/04/20 16:23 * @since:fish 1.0 */public class RedisSessionService implements SessionService {    Logger logger= LoggerFactory.getLogger(RedisSessionService.class);    final RedisIndexedSessionRepository redisIndexedSessionRepository;    final ApplicationEventPublisher applicationEventPublisher;    public RedisSessionService(RedisIndexedSessionRepository redisIndexedSessionRepository, ApplicationEventPublisher applicationEventPublisher) {        this.redisIndexedSessionRepository = redisIndexedSessionRepository;        this.applicationEventPublisher = applicationEventPublisher;    }    @Override    public boolean hasLogin(String account) {        return CollectionUtil.isNotEmpty(loadByAccount(account));    }    @Override    public Map&lt;String, ? extends Session&gt; loadByAccount(String account) {        logger.info(\"收集当前登录会话session，账号:{}\",account);        return redisIndexedSessionRepository.findByIndexNameAndIndexValue(FindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME,account);    }    @Override    public void destroySession(String account) {        logger.info(\"销毁当前登录session会话,账号：{}\",account);        Map&lt;String,? extends Session&gt; sessionMap=loadByAccount(account);        if (CollectionUtil.isNotEmpty(sessionMap)){            logger.info(\"当前登录会话size:{}\",sessionMap.size());            for (Map.Entry&lt;String,? extends Session&gt; sessionEntry:sessionMap.entrySet()){                String key=sessionEntry.getKey();                Session session=sessionEntry.getValue();                logger.info(\"destroy session key:{}\",key);                //删除                redisIndexedSessionRepository.deleteById(session.getId());                //广播Session会话销毁事件                applicationEventPublisher.publishEvent(new SessionDestroyedEvent(redisIndexedSessionRepository,session));            }        }    }}在destroySession方法实现中，首先根据账号获取当前所有登录会话信息，如果会话不为空，则遍历会话Map集合，执行删除会话操作，并且通过applicationEventPublisher广播一个会话被销毁的事件。该广播事件非必须，但是从代码的全局进行考虑，还是需要加上接下来，我们就可以将该类注入到Spring的容器中的，注入实体Bean代码如下：@Beanpublic RedisSessionService sessionService(RedisIndexedSessionRepository redisIndexedSessionRepository, ApplicationEventPublisher applicationEventPublisher){    return new RedisSessionService(redisIndexedSessionRepository,applicationEventPublisher);}  PS:我们为什么需要创建接口而不是直接创建class的方式通过@Service等注解进行注入，而是通过抽象接口实现类的方式，最终通过JavaConfig的方式进行注入呢？从代码的耦合度上来看，由于Spring Session提供处理基于Redis的能力处理Session会话之外，还提供了诸如JDBC\\mongo等多元化的扩展方式，因此，为了代码解耦，通过抽象接口的方式是更合理的。接下来，我们在我们的用户管理的业务Service方法中就可以进行操作了删除用户的业务Service方法/*** 根据主键id删除用户管理* @param id 主键id* @return 是否删除成功*/@Overridepublic RestfulMessage&lt;String&gt; delete(Integer id) {    logger.info(\"根据主键id删除用户管理,id:{}\",id);    FishUserInfo fishUserInfo=fishUserInfoMapper.selectByPrimaryKey(id);    assertArgumentNotEmpty(fishUserInfo,\"请求数据非法\");    int ret=fishUserInfoMapper.deleteByPrimaryKey(id);    //删除成功，如果该角色在线，则强制剔除下线    if (ret&gt;0){        logger.info(\"用户会话剔除下线\");        sessionService.destroySession(fishUserInfo.getAccount());    }    return ret&gt;0?RestfulMessage.success(\"删除成功\"):RestfulMessage.error(\"删除失败\");}禁用用户  禁用用户其实操作方法和删除一样，区别在于禁用操作只是将用户在数据库中的状态进行变更，而删除则是将该用户的数据从数据库DB中进行删除。更新库的用户状态后，调用destroySession删除该账号的所有Session会话操作即可"
  },
  
  {
    "title": "Spring Boot框架中使用Jackson的处理总结",
    "url": "/posts/spring-boot-code-action-jackson/",
    "categories": "SpringBoot",
    "tags": "",
    "date": "2021-03-26 00:00:00 +0800",
    





    
    "snippet": "1.前言通常我们在使用Spring Boot框架时，如果没有特别指定接口的序列化类型，则会使用Spring Boot框架默认集成的Jackson框架进行处理，通过Jackson框架将服务端响应的数据序列化成JSON格式的数据。本文主要针对在Spring Boot框架中使用Jackson进行处理的经验进行总结，同时也结合在实际开发场景中碰到的问题以及解决方案进行陈述。本文涉及到的源码地址：ht...",
    "content": "1.前言通常我们在使用Spring Boot框架时，如果没有特别指定接口的序列化类型，则会使用Spring Boot框架默认集成的Jackson框架进行处理，通过Jackson框架将服务端响应的数据序列化成JSON格式的数据。本文主要针对在Spring Boot框架中使用Jackson进行处理的经验进行总结，同时也结合在实际开发场景中碰到的问题以及解决方案进行陈述。本文涉及到的源码地址：https://gitee.com/dt_research_institute/code-in-action  PS:目前市面上针对JSON序列化的框架很多,比较出名的就是Jackson、Gson、FastJson。如果开发者对序列化框架没有特别的要求的情况下，个人建议是直接使用Spring Boot框架默认集成的Jackson，没有必要进行更换。2.统一序列化时间格式在我们的接口中，针对时间类型的字段序列化是最常见的需求之一，一般前后端开发人员会针对时间字段统一进行约束，这样有助于在编码开发时，统一编码规范。在Spring Boot框架中，如果使用Jackson处理框架，并且没有任何配置的情况下，Jackson针对不同时间类型字段，序列化的格式也会不尽相同。先来看一个简单示例，User.java实体类编码如下：public class User {    private String name;    private Integer age;    private LocalDateTime birthday;    private Date studyDate;    private LocalDate workDate;        private Calendar firstWorkDate;        public static User buildOne(){        User user=new User();        LocalDateTime now=LocalDateTime.now();        user.setWorkDate(now.plusYears(25).toLocalDate());        user.setStudyDate(Date.from(now.plusYears(5).atZone(ZoneId.systemDefault()).toInstant()));        user.setName(\"姓名-\"+RandomUtil.randomString(5));        user.setAge(RandomUtil.randomInt(0,100));        user.setBirthday(now);        user.setFirstWorkDate(Calendar.getInstance());        return user;    }        //getter and setter...}接口代码层也很简单，返回一个User的实体对象即可，代码如下：@RestControllerpublic class UserApplication {    @GetMapping(\"/queryOne\")    public ResponseEntity&lt;User&gt; queryOne(){        return ResponseEntity.ok(User.buildOne());    }}如果我们对框架代码没有任何的配置，此时我们通过调用接口/queryOne，拿到的返回结果数据如下图：Jackson序列化框架针对四个不同的时间类型字段，序列化处理的操作是不同的，如果我们对时间字段有格式化的要求时，我们应该如何处理呢？2.1 通过@JsonFormat注解最直接也是最简单的一种方式，是我们通过使用Jackson提供的@JsonFormat注解，对需要格式化处理的时间字段进行标注，在@JsonFormat注解中写上我们的时间格式化字符，User.java代码如下：public class User {    private String name;    private Integer age;    @JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\")    private LocalDateTime birthday;    private Date studyDate;    private LocalDate workDate;    private Calendar firstWorkDate;    //getter and setter...}此时，我们再通过调用接口，拿到的返回结果如下图：通过对birthday字段标注@JsonFormat注解，最终Jackson框架会将该字段序列化为我们标注的格式类型。2.2 配置全局application.yml通过@JsonFormat注解的方式虽然能解决问题，但是我们在实际的开发当中，涉及到的时间字段会非常多，如果全部都用注解的方式对项目中的时间字段进行标注，那开发的工作量也会很大，并且多团队一起协同编码时，难免会存在遗漏的情况，因此，@JsonFormat注解只适用于针对特定的接口，特定的场景下，对序列化响应的时间字段进行约束，而在全局的角度来看，开发者应该考虑通过在application.yml配置文件中进行全局配置针对Spring Boot框架中Jackson的全局配置，我们在application.yml进行配置时，IDEA等编辑器会给出相应的提示，包含的属性如下图：开发者可以通过org.springframework.boot.autoconfigure.jackson.JacksonProperties.java查看所有配置的源码信息            配置属性      说明                  date-format      日期字段格式化，例如:yyyy-MM-dd HH:mm:ss      针对日期字段的格式化处理，我们只需要使用date-format属性进行配置即可，application.yml配置如下：spring:  jackson:    date-format: yyyy-MM-dd HH:mm:ss当然，如果有必要的话，还需要配置time-zone时区属性，不过该属性不配置的情况下，Jackson会使用系统默认时区。我们从Spring Boot的源码中可以看到对Jackson的时间处理逻辑,JacksonAutoConfiguration.java中部分代码如下：private void configureDateFormat(Jackson2ObjectMapperBuilder builder) {    // We support a fully qualified class name extending DateFormat or a date    // pattern string value    String dateFormat = this.jacksonProperties.getDateFormat();    if (dateFormat != null) {        try {            Class&lt;?&gt; dateFormatClass = ClassUtils.forName(dateFormat, null);            builder.dateFormat((DateFormat) BeanUtils.instantiateClass(dateFormatClass));        }        catch (ClassNotFoundException ex) {            SimpleDateFormat simpleDateFormat = new SimpleDateFormat(dateFormat);            // Since Jackson 2.6.3 we always need to set a TimeZone (see            // gh-4170). If none in our properties fallback to the Jackson's            // default            TimeZone timeZone = this.jacksonProperties.getTimeZone();            if (timeZone == null) {                timeZone = new ObjectMapper().getSerializationConfig().getTimeZone();            }            simpleDateFormat.setTimeZone(timeZone);            builder.dateFormat(simpleDateFormat);        }    }}从上面的代码中，我们可以看到的处理逻辑：  从yml配置文件中拿到dateFormat属性字段  首先通过ClassUtils.forName方法来判断开发者配置的是否是格式化类，如果配置的是格式化类，则直接配置dateFormat属性  类找不到的情况下,捕获ClassNotFoundException异常，默认使用JDK自带的SimpleDateFormat类进行初始化最终，我们在application.yml配置文件中配置了全局的Jackson针对日期处理的格式化信息，此时我们再看/queryOne接口响应的内容是什么情况呢？如下图：从图中我们可以发现，除了LocalDate类型的字段，包含时分秒类型的日期类型：LocalDateTime、Date、Calendar全部按照我们的要求将日期序列化成了yyyy-MM-dd HH:mm:ss格式，达到了我们的要求。3.Jackson在Spring Boot框架中的配置选项在上面的时间字段序列化处理，我们已经知道了如何配置，那么在Spring Boot的框架中，针对Jackson的各个配置项主要包含哪些呢？我们通过IDEA的提示可以看到，配置如下图：在上面的12个属性中，每个属性的配置都会对Jackson产生不同的效果，接下来，我们逐一详解每个属性配置的作用3.1 date-format日期格式化date-format在前面我们已经知道了该属性的作用，主要是针对日期字段的格式化3.2 time-zone时区time-zone字段也是和日期字段类型，使用不同的时区,最终日期类型字段响应的结果会不一样时区的表示方法有两种：  指定时区的名称，例如：Asia/Shanghai,America/Los_Angeles  通过格林威治平时GMT针对时分秒做+或者-自定义操作通过指定时区的名称，假设我们指定当前的项目是America/Los_Angeles，那么接口响应的数据是什么效果呢?  PS:时区名称如果不是很清楚的话，一般在Linux服务器的/usr/share/zoneinfo目录可以进行查看，如下图：  application.yml:spring:  jackson:    date-format: yyyy-MM-dd HH:mm:ss    time-zone: America/Los_Angeles效果图如下：我们在结合代码来分析：//User.javapublic static User buildOne(){    User user=new User();    LocalDateTime now=LocalDateTime.now();    user.setWorkDate(now.plusYears(25).toLocalDate());    user.setStudyDate(Date.from(now.plusYears(5).atZone(ZoneId.systemDefault()).toInstant()));    user.setName(\"姓名-\"+RandomUtil.randomString(5));    user.setAge(RandomUtil.randomInt(0,100));    user.setBirthday(now);    user.setFirstWorkDate(Calendar.getInstance());    return user;}由于洛杉矶时区与上海时区相差16个小时，因此，Jackson框架针对日期的序列化时，分别做了不同类型的处理，但我们也能看出差别  LocalDateTime、LocalDate类型的字段，Jackson的时区设置不会对该字段产生影响(因为这两个日期类型自带时区属性)  Date、Calendar类型的字段受Jackson序列化框架的时区设置影响另外一种方式是通过格林威治平时(GMT)做加减法，主要有两种格式支持：  GMT+HHMM或者GMT-HHMM或者GMT+H:其中HH代表的是小时数，MM代表的是分钟数，取值范围是0-9,例如我们常见的GMT+8代表东八区，也就是北京时间  GMT+HH:MM或者GMT-HH:MM:其中HH代表的是小时数，MM代表的是分钟数，取值范围是0-9，和上面意思差不多可以自己写测试代码进行测试，示例如下：public class TimeTest {    public static void main(String[] args) {        LocalDateTime localDateTime=LocalDateTime.now();        DateTimeFormatter dateTimeFormatter=DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\");        System.out.println(localDateTime.format(dateTimeFormatter));        System.out.println(LocalDateTime.now(ZoneId.of(\"GMT+0901\")).format(dateTimeFormatter));        System.out.println(LocalDateTime.now(ZoneId.of(\"GMT+09:01\")).format(dateTimeFormatter));    }}3.3 locale本地化JSON序列化时Locale的变量设置3.4 visibility访问级别Jackson支持从私有字段中读取值,但是默认情况下不这样做,如果我们的项目中存在不同的序列化反序列化需求，那么我们可以在配置文件中对visibility进行配置我们将上面User.java代码中的name属性的get方法修饰符从public变更为private,其他字段保持不变代码如下：public class User {    private String name;    private Integer age;    private Date nowDate;    private LocalDateTime birthday;    private Date studyDate;    private LocalDate workDate;    private Calendar firstWorkDate;    //getter方法修饰符从public修改为private    private String getName() {        return name;    }    //other setter and getter}此时，我们通过调用/queryOne接口响应结果如下：从结果中我们可以看到，由于我们将name属性的getter方法设置为了private，因此jackson在序列化时，没有拿到该字段此时，我们再修改application.yml的配置，如下：spring:  jackson:    visibility:      getter: any我们通过将getter设置为any级别的类型，再调用/queryOne接口，响应结果如下：从图中可以看出，jackson序列化结果中又出现了name属性，这代表即使name字段的属性和getter方法都是private，但是jackson还是获取到了该成员变量的值，并且进行了序列化处理。通过设置visibility属性即可达到上面的效果。开发者根据自己的需要自行进行选择。3.5 property-naming-strategy属性命名策略通常比较常见的我们针对java代码中的实体类属性一般都是驼峰命名法(Camel-Case)，但是Jackson序列化框架也提供了更多的序列化策略，而property-naming-strategy就是配置该属性的。先来看Spring Boot框架如何配置jackson的命名策略JacksonAutoConfiguration.javaprivate void configurePropertyNamingStrategyField(Jackson2ObjectMapperBuilder builder, String fieldName) {    // Find the field (this way we automatically support new constants    // that may be added by Jackson in the future)    Field field = ReflectionUtils.findField(PropertyNamingStrategy.class, fieldName,                                            PropertyNamingStrategy.class);    Assert.notNull(field, () -&gt; \"Constant named '\" + fieldName + \"' not found on \"                   + PropertyNamingStrategy.class.getName());    try {        builder.propertyNamingStrategy((PropertyNamingStrategy) field.get(null));    }    catch (Exception ex) {        throw new IllegalStateException(ex);    }}通过反射，直接获取PropertyNamingStrategy类中的成员变量的值PropertyNamingStrategy定义了Jackson(2.11.4)框架中的命名策略常量成员变量package com.fasterxml.jackson.databind;//other importpublic class PropertyNamingStrategy // NOTE: was abstract until 2.7    implements java.io.Serializable{    /**     * Naming convention used in languages like C, where words are in lower-case     * letters, separated by underscores.     * See {@link SnakeCaseStrategy} for details.     *     * @since 2.7 (was formerly called {@link #CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES})     */    public static final PropertyNamingStrategy SNAKE_CASE = new SnakeCaseStrategy();    /**     * Naming convention used in languages like Pascal, where words are capitalized     * and no separator is used between words.     * See {@link PascalCaseStrategy} for details.     *     * @since 2.7 (was formerly called {@link #PASCAL_CASE_TO_CAMEL_CASE})     */    public static final PropertyNamingStrategy UPPER_CAMEL_CASE = new UpperCamelCaseStrategy();    /**     * Naming convention used in Java, where words other than first are capitalized     * and no separator is used between words. Since this is the native Java naming convention,     * naming strategy will not do any transformation between names in data (JSON) and     * POJOS.     *     * @since 2.7 (was formerly called {@link #PASCAL_CASE_TO_CAMEL_CASE})     */    public static final PropertyNamingStrategy LOWER_CAMEL_CASE = new PropertyNamingStrategy();        /**     * Naming convention in which all words of the logical name are in lower case, and     * no separator is used between words.     * See {@link LowerCaseStrategy} for details.     *      * @since 2.4     */    public static final PropertyNamingStrategy LOWER_CASE = new LowerCaseStrategy();    /**     * Naming convention used in languages like Lisp, where words are in lower-case     * letters, separated by hyphens.     * See {@link KebabCaseStrategy} for details.     *      * @since 2.7     */    public static final PropertyNamingStrategy KEBAB_CASE = new KebabCaseStrategy();    /**     * Naming convention widely used as configuration properties name, where words are in     * lower-case letters, separated by dots.     * See {@link LowerDotCaseStrategy} for details.     *     * @since 2.10     */    public static final PropertyNamingStrategy LOWER_DOT_CASE = new LowerDotCaseStrategy();        //others...}从源码中我们可以看到，有六种策略供我们进行配置，配置示例如下：spring:  jackson:    date-format: yyyy-MM-dd HH:mm:ss    locale: zh_CN    time-zone: GMT+8    visibility:      getter: any    property-naming-strategy: LOWER_CAMEL_CASESNAKE_CASESNAKE_CASE主要包含的规则,详见SnakeCaseStrategy：  java属性名称中所有大写的字符都会转换为两个字符，下划线和该字符的小写形式，例如userName会转换为user_name,对于连续性的大写字符，近第一个进行下划线转换，后面的大小字符则是小写，例如theWWW会转换为the_www  对于首字母大写的情况，近转成小写，例如:Results会转换为results，并不会转换为_results  针对属性中已经包含下划线的情况，仅做小写转换处理  下划线出现在首位的情况下，会被去除处理，例如属性名：_user会被转换为user真实效果如下图：UPPER_CAMEL_CASEUPPER_CAMEL_CASE顾名思义，驼峰命名法的规则，只是首字母会转换为大写，详见UpperCamelCaseStrategy真实效果图如下：LOWER_CAMEL_CASELOWER_CAMEL_CASE效果和UPPER_CAMEL_CASE正好相反，其首字母会变成小写，详见LowerCamelCaseStrategy效果图如下：LOWER_CASELOWER_CASE从命名来看很明显，将属性名 全部转为小写，详见LowerCaseStrategyKEBAB_CASEKEBAB_CASE策略和SNAKE_CASE规则类似，只是下划线变成了横线-,详见KebabCaseStrategy效果图如下：LOWER_DOT_CASELOWER_DOT_CASE策略和KEBAB_CASE规则相似，只是由横线变成了点.，详见LowerDotCaseStrategy效果图如下：总结：看了上面这么多属性名称的策略，其实每一种类型只是不同的场景下才需要，如果上面jackson给定的默认策略名称无法满足，我们从源码中也能看到，通过自定义实现类，也能满足企业的个性化需求，非常方便。3.6 mapper通用功能开关配置mapper属性是一个Map类型，主要是针对MapperFeature定义开关属性，是否启用这些特性/*** Jackson general purpose on/off features.*/private final Map&lt;MapperFeature, Boolean&gt; mapper = new EnumMap&lt;&gt;(MapperFeature.class);在MapperFeature.java中，我们可以跟踪源码来看：/** * Enumeration that defines simple on/off features to set * for {@link ObjectMapper}, and accessible (but not changeable) * via {@link ObjectReader} and {@link ObjectWriter} (as well as * through various convenience methods through context objects). *&lt;p&gt; * Note that in addition to being only mutable via {@link ObjectMapper}, * changes only take effect when done &lt;b&gt;before any serialization or * deserialization&lt;/b&gt; calls -- that is, caller must follow * \"configure-then-use\" pattern. */public enum MapperFeature implements ConfigFeature{    //.......}MapperFeature是一个枚举类型，对当前jackson的一些特性通过枚举变量的方式来定义开关属性，也是方便使用者来使用的。主要包含以下枚举变量：  USE_ANNOTATIONS:  USE_GETTERS_AS_SETTERS  PROPAGATE_TRANSIENT_MARKER  AUTO_DETECT_CREATORS  AUTO_DETECT_FIELDS  AUTO_DETECT_GETTERS  AUTO_DETECT_IS_GETTERS  AUTO_DETECT_SETTERS  REQUIRE_SETTERS_FOR_GETTERS  ALLOW_FINAL_FIELDS_AS_MUTATORS  INFER_PROPERTY_MUTATORS  INFER_CREATOR_FROM_CONSTRUCTOR_PROPERTIES  CAN_OVERRIDE_ACCESS_MODIFIERS  OVERRIDE_PUBLIC_ACCESS_MODIFIERS  USE_STATIC_TYPING  USE_BASE_TYPE_AS_DEFAULT_IMPL  DEFAULT_VIEW_INCLUSION  SORT_PROPERTIES_ALPHABETICALLY  ACCEPT_CASE_INSENSITIVE_PROPERTIES  ACCEPT_CASE_INSENSITIVE_ENUMS  ACCEPT_CASE_INSENSITIVE_VALUES  USE_WRAPPER_NAME_AS_PROPERTY_NAME  USE_STD_BEAN_NAMING  ALLOW_EXPLICIT_PROPERTY_RENAMING  ALLOW_COERCION_OF_SCALARS  IGNORE_DUPLICATE_MODULE_REGISTRATIONS  IGNORE_MERGE_FOR_UNMERGEABLE  BLOCK_UNSAFE_POLYMORPHIC_BASE_TYPES3.7 serialization序列化特性开关配置serialization属性同mapper类似，也是一个Map类型的属性/*** Jackson on/off features that affect the way Java objects are serialized.*/private final Map&lt;SerializationFeature, Boolean&gt; serialization = new EnumMap&lt;&gt;(SerializationFeature.class);3.8 deserialization反序列化开关配置deserialization反序列化配置/*** Jackson on/off features that affect the way Java objects are deserialized. */private final Map&lt;DeserializationFeature, Boolean&gt; deserialization = new EnumMap&lt;&gt;(DeserializationFeature.class);3.9 parser配置3.10 generator配置3.11 defaultPropertyInclusion序列化包含的属性配置该属性是一个枚举配置，主要包含：  ALWAYS:顾名思义，始终包含，和属性的值无关  NON_NULL:值非空的属性才会包含属性  NON_ABSENT:值非空的属性，或者Optional类型的属性非空  NON_EMPTY: 空值的属性不包含  NON_DEFAULT：不使用jackson的默认规则对该字段进行序列化,详见示例  CUSTOM:自定义规则  USE_DEFAULTS:配置使用该规则的属性字段，将会优先使用class上的注解规则，否则会使用全局的序列化规则，详见示例CUSTOM自定义规则是需要开发者在属性字段上使用@JsonInclude注解，并且指定valueFilter属性，该属性需要传递一个Class，示例如下：//User.java//指定value级别是CUSTOM@JsonInclude(value = JsonInclude.Include.CUSTOM, valueFilter = StringFilter.class)private String name;StringFilter则是判断非空的依据，该依据由开发者自己定义，返回true将会被排除，false则不会排除，示例如下：//自定义非空判断规则public class StringFilter {    @Override    public boolean equals(Object other) {        if (other == null) {            // Filter null's.            return true;        }        // Filter \"custom_string\".        return \"custom_string\".equals(other);    }}4.Spring Boot针对Jackson的约定配置做的事情在前面的文章中，我们已经详细的了解了Jackson在Spring Boot框架中的各个配置项，那么Spring Boot针对Jackson框架在约定配置时会做哪些事情呢?在Spring Boot的spring-boot-autoconfigure-x.x.jar包中，我们可以看到Spring Boot框架针对jackson的处理源码，如下图：主要包含三个类：  JacksonProperties:Spring Boot框架提供jackson的配置属性类，即开发者在application.yml配置文件中的配置项属性  JacksonAutoConfiguration:Jackson的默认注入配置类  Jackson2ObjectMapperBuilderCustomizer:自定义用于注入jackson的配置辅助接口核心类是JacksonAutoConfiguration.java,该类是Spring Boot框架将Jackson相关实体Bean注入Spring容器的关键配置类。其主要作用：  注入Jackson的ObjectMapper实体Bean到Spring容器中  注入ParameterNamesModule实体Bean到Spring容器中  注入Jackson2ObjectMapperBuilder实体Bean  注入JsonComponentModule实体Bean  注入StandardJackson2ObjectMapperBuilderCustomizer实体Bean，该类是上面Jackson2ObjectMapperBuilderCustomizer的实现类，主要用于接收JacksonProperties属性，将Jackson的外部配置属性接收，然后最终执行customize方法，构建ObjectMapper所需要的Jackson2ObjectMapperBuilder属性，最终为ObjectMapper属性赋值准备源码如下：@Configuration(proxyBeanMethods = false)@ConditionalOnClass(ObjectMapper.class)public class JacksonAutoConfiguration {\tprivate static final Map&lt;?, Boolean&gt; FEATURE_DEFAULTS;\tstatic {\t\tMap&lt;Object, Boolean&gt; featureDefaults = new HashMap&lt;&gt;();\t\tfeatureDefaults.put(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false);\t\tfeatureDefaults.put(SerializationFeature.WRITE_DURATIONS_AS_TIMESTAMPS, false);\t\tFEATURE_DEFAULTS = Collections.unmodifiableMap(featureDefaults);\t}\t@Bean\tpublic JsonComponentModule jsonComponentModule() {\t\treturn new JsonComponentModule();\t}\t@Configuration(proxyBeanMethods = false)\t@ConditionalOnClass(Jackson2ObjectMapperBuilder.class)\tstatic class JacksonObjectMapperConfiguration {\t\t@Bean\t\t@Primary\t\t@ConditionalOnMissingBean\t\tObjectMapper jacksonObjectMapper(Jackson2ObjectMapperBuilder builder) {\t\t\treturn builder.createXmlMapper(false).build();\t\t}\t}\t@Configuration(proxyBeanMethods = false)\t@ConditionalOnClass(ParameterNamesModule.class)\tstatic class ParameterNamesModuleConfiguration {\t\t@Bean\t\t@ConditionalOnMissingBean\t\tParameterNamesModule parameterNamesModule() {\t\t\treturn new ParameterNamesModule(JsonCreator.Mode.DEFAULT);\t\t}\t}\t@Configuration(proxyBeanMethods = false)\t@ConditionalOnClass(Jackson2ObjectMapperBuilder.class)\tstatic class JacksonObjectMapperBuilderConfiguration {\t\t@Bean\t\t@Scope(\"prototype\")\t\t@ConditionalOnMissingBean\t\tJackson2ObjectMapperBuilder jacksonObjectMapperBuilder(ApplicationContext applicationContext,\t\t\t\tList&lt;Jackson2ObjectMapperBuilderCustomizer&gt; customizers) {\t\t\tJackson2ObjectMapperBuilder builder = new Jackson2ObjectMapperBuilder();\t\t\tbuilder.applicationContext(applicationContext);\t\t\tcustomize(builder, customizers);\t\t\treturn builder;\t\t}\t\tprivate void customize(Jackson2ObjectMapperBuilder builder,\t\t\t\tList&lt;Jackson2ObjectMapperBuilderCustomizer&gt; customizers) {\t\t\tfor (Jackson2ObjectMapperBuilderCustomizer customizer : customizers) {\t\t\t\tcustomizer.customize(builder);\t\t\t}\t\t}\t}    @Configuration(proxyBeanMethods = false)\t@ConditionalOnClass(Jackson2ObjectMapperBuilder.class)\t@EnableConfigurationProperties(JacksonProperties.class)\tstatic class Jackson2ObjectMapperBuilderCustomizerConfiguration {\t\t@Bean\t\tStandardJackson2ObjectMapperBuilderCustomizer standardJacksonObjectMapperBuilderCustomizer(\t\t\t\tApplicationContext applicationContext, JacksonProperties jacksonProperties) {\t\t\treturn new StandardJackson2ObjectMapperBuilderCustomizer(applicationContext, jacksonProperties);\t\t}\t\tstatic final class StandardJackson2ObjectMapperBuilderCustomizer\t\t\t\timplements Jackson2ObjectMapperBuilderCustomizer, Ordered {\t\t\tprivate final ApplicationContext applicationContext;\t\t\tprivate final JacksonProperties jacksonProperties;\t\t\tStandardJackson2ObjectMapperBuilderCustomizer(ApplicationContext applicationContext,\t\t\t\t\tJacksonProperties jacksonProperties) {\t\t\t\tthis.applicationContext = applicationContext;\t\t\t\tthis.jacksonProperties = jacksonProperties;\t\t\t}\t\t\t@Override\t\t\tpublic int getOrder() {\t\t\t\treturn 0;\t\t\t}\t\t\t@Override\t\t\tpublic void customize(Jackson2ObjectMapperBuilder builder) {\t\t\t\tif (this.jacksonProperties.getDefaultPropertyInclusion() != null) {\t\t\t\t\tbuilder.serializationInclusion(this.jacksonProperties.getDefaultPropertyInclusion());\t\t\t\t}\t\t\t\tif (this.jacksonProperties.getTimeZone() != null) {\t\t\t\t\tbuilder.timeZone(this.jacksonProperties.getTimeZone());\t\t\t\t}\t\t\t\tconfigureFeatures(builder, FEATURE_DEFAULTS);\t\t\t\tconfigureVisibility(builder, this.jacksonProperties.getVisibility());\t\t\t\tconfigureFeatures(builder, this.jacksonProperties.getDeserialization());\t\t\t\tconfigureFeatures(builder, this.jacksonProperties.getSerialization());\t\t\t\tconfigureFeatures(builder, this.jacksonProperties.getMapper());\t\t\t\tconfigureFeatures(builder, this.jacksonProperties.getParser());\t\t\t\tconfigureFeatures(builder, this.jacksonProperties.getGenerator());\t\t\t\tconfigureDateFormat(builder);\t\t\t\tconfigurePropertyNamingStrategy(builder);\t\t\t\tconfigureModules(builder);\t\t\t\tconfigureLocale(builder);\t\t\t}\t\t\t//more configure methods...\t}}总结：通过一系列的方法，最终构造一个生产级别可用的ObjectMapper对象，供在Spring Boot框架中对Java对象实现序列化与反序列化操作。5.Jackson常见注解使用示例  备注：本小结内容来源https://www.baeldung.com/jackson-annotations,如果工作中对于jackson的注解使用较少的情况下，可以看看该篇文章，是一个非常好的补充。5.1 序列化5.1.1 @JsonAnyGetter@JsonAnyGetter注解运行可以灵活的使用Map类型的作为属性字段实体类如下：public class ExtendableBean {    public String name;    private Map&lt;String, String&gt; properties;    @JsonAnyGetter    public Map&lt;String, String&gt; getProperties() {        return properties;    }    public ExtendableBean(String name) {        this.name = name;        this.properties=new HashMap&lt;String, String&gt;();    }    public void add(String key,String value){        this.properties.put(key,value);    }}通过序列化该实体Bean，我们将会得到Map属性中的所有Key作为属性值，测试序列化代码如下：@Testpublic void whenSerializingUsingJsonAnyGetter_thenCorrect()  throws JsonProcessingException {     ExtendableBean bean = new ExtendableBean(\"My bean\");    bean.add(\"attr1\", \"val1\");    bean.add(\"attr2\", \"val2\");    String result = new ObjectMapper().writeValueAsString(bean);     assertThat(result, containsString(\"attr1\"));    assertThat(result, containsString(\"val1\"));}最终输出结果如下：{    \"name\":\"My bean\",    \"attr2\":\"val2\",    \"attr1\":\"val1\"}如果不使用@JsonAnyGetter注解，那么最终序列化结果将会在properties属性下面，结果如下：{    \"name\": \"My bean\",    \"properties\": {        \"attr2\": \"val2\",        \"attr1\": \"val1\"    }}5.1.2 @JsonGetter@JsonGetter注解是一个替代@JsonProperty的注解，可以将一个方法标注为getter方法例如下面的示例中，我们通过注解@JsonGetter将方法getTheName()作为属性name的getter方法public class MyBean {    public int id;    private String name;    @JsonGetter(\"name\")    public String getTheName() {        return name;    }}5.1.3 @JsonPropertyOrder可以通过使用@JsonPropertyOrder注解来指定属性的序列化顺序实体bean定义如下：@JsonPropertyOrder({ \"name\", \"id\" })public class MyBean {    public int id;    public String name;}最终序列化结果为：{    \"name\":\"My bean\",    \"id\":1}也可以通过@JsonPropertyOrder(alphabetic=true)来指定按照字母排序，那么响应结果将是：{    \"id\":1,    \"name\":\"My bean\"}5.1.4 @JsonRawValue@JsonRawValue注解可以指定字符串属性类为json，如下代码：public class RawBean {    public String name;    @JsonRawValue    public String json;}创建RawBean的示例，给属性json赋值,代码如下： RawBean bean = new RawBean(\"My bean\", \"{\\\"attr\\\":false}\");String result = new ObjectMapper().writeValueAsString(bean);最终序列化结果如下：{    \"name\":\"My bean\",    \"json\":{        \"attr\":false    }}5.1.5 @JsonValue@JsonValue注解主要用于序列化整个实例对象的单个方法，例如，在一个枚举类中，@JsonValue注解进行标注，代码如下：public enum  TypeEnumWithValue {    TYPE1(1, \"Type A\"), TYPE2(2, \"Type 2\");    private Integer id;    private String name;    TypeEnumWithValue(Integer id, String name) {        this.id = id;        this.name = name;    }    @JsonValue    public String getName() {        return name;    }}测试代码如下：String enumAsString = new ObjectMapper()                .writeValueAsString(TypeEnumWithValue.TYPE1);System.out.println(enumAsString);最终通过序列化代码得到的结果将是：\"Type A\"5.1.6 @JsonRootName@JsonRootName注解旨在给当前序列化的实体对象加一层包裹对象。举例如下：//RootUser.javapublic class RootUser {    private String name;    private String title;    public RootUser(String name, String title) {        this.name = name;        this.title = title;    }     \t//getter and setters  }在上面的实体类中，正常情况下，如果要序列号RootUser对象，其结果格式为：{    \"name\": \"name1\",    \"title\": \"title1\"}在RootUser加上@JsonRootName注解后，该类改动如下：//RootUser.java@JsonRootName(value = \"root\")public class RootUser {    private String name;    private String title;    public RootUser(String name, String title) {        this.name = name;        this.title = title;    }     \t//getter and setters  }启用ObjectMapper对象的WRAP_ROOT_VALUE特性，测试代码如下：ObjectMapper objectMapper=new ObjectMapper();objectMapper.enable(SerializationFeature.WRAP_ROOT_VALUE);String result=objectMapper.writeValueAsString(new RootUser(\"name1\",\"title1\"));最终序列化JSON结果如下：{    \"root\": {        \"name\": \"name1\",        \"title\": \"title1\"    }}5.1.7 @JsonSerialize@JsonSerialize注解允许开发者自定义序列化实现,来看代码实现public class EventWithSerializer {    public String name;    @JsonSerialize(using = CustomDateSerializer.class)    public Date eventDate;        public Date publishDate;        //getter and setter...}在上面的代码中，针对eventDate字段，我们通过使用@JsonSerialize注解，自定义了一个序列化实现类CustomDateSerializer,该类实现如下：//CustomDateSerializer.javapublic class CustomDateSerializer extends StdSerializer&lt;Date&gt; {    private static SimpleDateFormat formatter       = new SimpleDateFormat(\"dd-MM-yyyy hh:mm:ss\");    public CustomDateSerializer() {         this(null);     }     public CustomDateSerializer(Class&lt;Date&gt; t) {        super(t);     }    @Override    public void serialize(      Date value, JsonGenerator gen, SerializerProvider arg2)       throws IOException, JsonProcessingException {        gen.writeString(formatter.format(value));    }}最终序列化的结果格式如下：{    \"name\": \"名称\",    \"eventDate\": \"24-03-2021 06:14:32\",    \"publishDate\": 1616580872574}从结果我们可以得知，针对某个特定的字段序列化的方式，我们可以完全自定义，非常的方便。5.2 反序列化5.2.1 @JsonCreator@JsonCreator配合@JsonProperty注解能到达在反序列化实体对象时，指定不变更属性名称的效果例如有如下JSON:{    \"id\":1,    \"theName\":\"My bean\"}在实体类中，我们没有属性名称是theName，但我们想把theName属性反序列化时赋值给name，此时实体类对象结构如下：public class BeanWithCreator {    public int id;    public String name;    @JsonCreator    public BeanWithCreator(      @JsonProperty(\"id\") int id,       @JsonProperty(\"theName\") String name) {        this.id = id;        this.name = name;    }}在BeanWithCreator的构造函数中添加@JsonCreator注解，并且配合@JsonProperty注解进行属性指向，最终反序列化代码如下：@Testpublic void whenDeserializingUsingJsonCreator_thenCorrect()  throws IOException {     String json = \"{\\\"id\\\":1,\\\"theName\\\":\\\"My bean\\\"}\";    BeanWithCreator bean = new ObjectMapper()      .readerFor(BeanWithCreator.class)      .readValue(json);    assertEquals(\"My bean\", bean.name);}5.2.2 @JacksonInject@JacksonInject注解可以指定反序列化对象时，属性值不从来源JSON获取，而从injection中获取实体类如下：public class BeanWithInject {    @JacksonInject    public int id;        public String name;}反序列化代码@Testpublic void whenDeserializingUsingJsonInject_thenCorrect()  throws IOException {     String json = \"{\\\"name\\\":\\\"My bean\\\"}\";        InjectableValues inject = new InjectableValues.Std()      .addValue(int.class, 1);    BeanWithInject bean = new ObjectMapper().reader(inject)      .forType(BeanWithInject.class)      .readValue(json);        assertEquals(\"My bean\", bean.name);    assertEquals(1, bean.id);}5.2.3 @JsonAnySetter@JsonAnySetter和@JsonAnyGetter注解意思一致，只不过是针对序列化与反序列化而言，@JsonAnySetter注解可以将来源JSON最终转化为Map类型的属性结构实体代码如下：public class ExtendableBean {    public String name;    private Map&lt;String, String&gt; properties;    @JsonAnySetter    public void add(String key, String value) {        properties.put(key, value);    }}JSON源如下：{    \"name\":\"My bean\",    \"attr2\":\"val2\",    \"attr1\":\"val1\"}通过@JsonAnySetter的注解标注，最终attr1及attr2的值将会添加到properties的Map对象中示例代码如下：@Testpublic void whenDeserializingUsingJsonAnySetter_thenCorrect()  throws IOException {    String json      = \"{\\\"name\\\":\\\"My bean\\\",\\\"attr2\\\":\\\"val2\\\",\\\"attr1\\\":\\\"val1\\\"}\";    ExtendableBean bean = new ObjectMapper()      .readerFor(ExtendableBean.class)      .readValue(json);        assertEquals(\"My bean\", bean.name);    assertEquals(\"val2\", bean.getProperties().get(\"attr2\"));}5.2.4 @JsonSetter@JsonSetter注解是@JsonProperty的替代注解，用于标注该方法为setter方法当我们需要读取一些JSON数据时，但是目标实体类与该数据不完全匹配是，该注解是非常有用的。示例代码如下：public class MyBean {    public int id;    private String name;    @JsonSetter(\"name\")    public void setTheName(String name) {        this.name = name;    }}通过指定setTheName作为属性name的setter方法，反序列化时可以达到最终效果示例如下：@Testpublic void whenDeserializingUsingJsonSetter_thenCorrect()  throws IOException {     String json = \"{\\\"id\\\":1,\\\"name\\\":\\\"My bean\\\"}\";    MyBean bean = new ObjectMapper()      .readerFor(MyBean.class)      .readValue(json);    assertEquals(\"My bean\", bean.getTheName());}5.2.5 @JsonDeserialize@JsonDeserialize注解和序列化注解@JsonSerialize的效果是一致的，作用与反序列化时，针对特定的字段，存在差异化的发序列化效果public class EventWithSerializer {    public String name;    @JsonDeserialize(using = CustomDateDeserializer.class)    public Date eventDate;}CustomDateDeserializer代码如下：public class CustomDateDeserializer  extends StdDeserializer&lt;Date&gt; {    private static SimpleDateFormat formatter      = new SimpleDateFormat(\"dd-MM-yyyy hh:mm:ss\");    public CustomDateDeserializer() {         this(null);     }     public CustomDateDeserializer(Class&lt;?&gt; vc) {         super(vc);     }    @Override    public Date deserialize(      JsonParser jsonparser, DeserializationContext context)       throws IOException {                String date = jsonparser.getText();        try {            return formatter.parse(date);        } catch (ParseException e) {            throw new RuntimeException(e);        }    }}最终，反序列化JSON，时，得到eventDate字段，测试代码如下：@Testpublic void whenDeserializingUsingJsonDeserialize_thenCorrect()  throws IOException {     String json      = \"{\"name\":\"party\",\"eventDate\":\"20-12-2014 02:30:00\"}\";    SimpleDateFormat df      = new SimpleDateFormat(\"dd-MM-yyyy hh:mm:ss\");    EventWithSerializer event = new ObjectMapper()      .readerFor(EventWithSerializer.class)      .readValue(json);        assertEquals(      \"20-12-2014 02:30:00\", df.format(event.eventDate));}5.2.6 @JsonAlias@JsonAlias注解作用于可以指定一个别名与JSON数据中的字段进行对于，最终反序列化时，能将该值最终反序列化时赋值给对象实体如下：public class AliasBean {    @JsonAlias({ \"fName\", \"f_name\" })    private String firstName;       private String lastName;}上面的代码中，firstName字段通过@JsonAlias注解指定了两个别名字段，意思是反序列化时可以从JSON中读取fName或者f_name的值赋值到firstName中测试代码如下：@Testpublic void whenDeserializingUsingJsonAlias_thenCorrect() throws IOException {    String json = \"{\\\"fName\\\": \\\"John\\\", \\\"lastName\\\": \\\"Green\\\"}\";    AliasBean aliasBean = new ObjectMapper().readerFor(AliasBean.class).readValue(json);    assertEquals(\"John\", aliasBean.getFirstName());}5.3 属性注解5.3.1 @JsonIgnoreProperties使用@JsonIgnoreProperties注解作用于class级别中可以达到在序列化时忽略一个或多个字段的效果实体代码如下：@JsonIgnoreProperties({ \"id\" })public class BeanWithIgnore {    public int id;    public String name;}最终在序列化BeanWithIgnore实体对象时，字段id将会被忽略5.3.2 @JsonIgnore@JsonIgnore注解作用与属性级别中，在序列化时可以忽略该字段实体代码如下：public class BeanWithIgnore {    @JsonIgnore    public int id;    public String name;}最终在序列化BeanWithIgnore实体对象时，字段id将会被忽略5.3.3 @JsonIgnoreType@JsonIgnoreType指定忽略类型属性public class User {    public int id;    public Name name;    @JsonIgnoreType    public static class Name {        public String firstName;        public String lastName;    }}在上面的示例中，类型Name将会被忽略5.3.4 @JsonInclude使用@JsonInclude注解可以排除属性值中包含empty/null/default的属性@JsonInclude(Include.NON_NULL)public class MyBean {    public int id;    public String name;}在MyBean中使用了Include.NON_NULL则代表该实体对象序列化时不会包含空值5.3.5 @JsonAutoDetect@JsonAutoDetect可以覆盖实体对象属性中的默认可见级别，比如私有属性可见与不可见实体对象如下：public class PrivateBean {    private int id;    private String name;    public PrivateBean(int id, String name) {        this.id = id;        this.name = name;    }}在PrivateBean中，没有给属性字段id、name设置公共的getter方法，此时，如果我们如果直接对该实体对象进行序列化时，jackson会提示错误Exception in thread \"main\" com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class com.xiaoymin.boot.action.jackson.model.PrivateBean and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS)我们修改PrivateBean中的代码，增加@JsonAutoDetect注解，代码如下：@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.ANY)public class PrivateBean {    private int id;    private String name;    public PrivateBean(int id, String name) {        this.id = id;        this.name = name;    }}此时，在序列化该实体对象，将会得到响应结果PrivateBean bean = new PrivateBean(1, \"My bean\");String result = new ObjectMapper().writeValueAsString(bean);System.out.println(result);5.4 常规注解5.4.1 @JsonProperty我们可以添加@JsonProperty批注以在JSON中指示属性名称。当实体对象中没有标准的getter/setter方法时，我们可以使用该注解进行指定属性名称已方便jackson框架进行序列化/反序列化public class MyBean {    public int id;    private String name;    @JsonProperty(\"name\")    public void setTheName(String name) {        this.name = name;    }    @JsonProperty(\"name\")    public String getTheName() {        return name;    }}5.4.2 @JsonFormat针对日期字段可以通过使用@JsonFormat注解进行格式化输出public class EventWithFormat {    public String name;    @JsonFormat(      shape = JsonFormat.Shape.STRING,      pattern = \"dd-MM-yyyy hh:mm:ss\")    public Date eventDate;}5.4.3 @JsonUnwrapped@JsonUnwrapped注解可以指定jackson框架在序列化/反序列化时是否需要对该字段进行wrapped操作示例代码：public class UnwrappedUser {    public int id;    @JsonUnwrapped    public Name name;        //getter and setter...    public static class Name {        public String firstName;        public String lastName;        //getter and setter    }}通过注解@JsonUnwrapped标注name属性，最终序列化该对象时，会和正常情况下有所区别UnwrappedUser.Name name = new UnwrappedUser.Name(\"John\", \"Doe\");UnwrappedUser user = new UnwrappedUser(1, name);String result = new ObjectMapper().writeValueAsString(user);我们得到的结果如下：{    \"id\": 1,    \"firstName\": \"John\",    \"lastName\": \"Doe\"}5.4.4 @JsonView通过View的方式来指定序列化/反序列化时是否包含属性示例代码如下：View定义public class Views {    public static class Public {}    public static class Internal extends Public {}}实体代码：public class Item {    @JsonView(Views.Public.class)    public int id;    @JsonView(Views.Public.class)    public String itemName;    @JsonView(Views.Internal.class)    public String ownerName;    //getter and setter..}最终序列化代码示例：Item item = new Item(2, \"book\", \"John\");String result = new ObjectMapper().writerWithView(Views.Public.class).writeValueAsString(item);System.out.println(result);最终序列化结果输出：{\"id\":2,\"itemName\":\"book\"}##"
  },
  
  {
    "title": "Spring Boot框架中针对数据文件模板的下载总结",
    "url": "/posts/spring-boot-common-file-download/",
    "categories": "SpringBoot",
    "tags": "",
    "date": "2021-03-03 00:00:00 +0800",
    





    
    "snippet": "1.前言在我们的日常开发中，经常会碰到注入导入Excel数据到系统中的需求，而在导入Excel数据时，一般的业务系统都会提供数据的Excel模板，只有提交的Excel数据满足业务系统要求的模板时，数据才能够正常的导入系统中。因此针对这种需求，一般我们会在系统中提供一个Excel模板的下载按钮，业务人员在使用时，可以先下载Excel模板，然后按照模板中的格式将数据填充，即可导入成功。本文主要总...",
    "content": "1.前言在我们的日常开发中，经常会碰到注入导入Excel数据到系统中的需求，而在导入Excel数据时，一般的业务系统都会提供数据的Excel模板，只有提交的Excel数据满足业务系统要求的模板时，数据才能够正常的导入系统中。因此针对这种需求，一般我们会在系统中提供一个Excel模板的下载按钮，业务人员在使用时，可以先下载Excel模板，然后按照模板中的格式将数据填充，即可导入成功。本文主要总结目前在开发这类需求时碰到的问题。2.解决方案从需求上来看，目前有大致三种解决方案，针对数据文件的模板下载，分别是：  模板文件直接存放在前端，作为静态资源，前端直接可以发送请求进行下载  模板文件存服务器磁盘，提供接口下载  模板文件存储在项目jar包中，提供接口下载2.1 作为静态资源直接下载第一种方式是最简单的，将数据文件直接作为静态资源放在前端目录，前端通过请求即可进行下载2.2 模板文件存储在服务器，提供接口下载第二种也是我们经常使用的方法，开发人员将模板文件放在服务器中的某个目录下，通过在代码中配置存储目录的方式，并且提供下载接口，当前端发起接口请求时，服务端根据请求将文件写入到响应流中示例代码如下：@Value(\"${templateFile}\")String downloadFilePath;@GetMapping(\"/download\")public void downloadExcel(HttpServletResponse response){    logger.info(\"下载Excel模板\");    try {        File file=new File(downloadFilePath);        ServletUtil.write(response,file);    } catch (IOException e) {        logger.error(e.getMessage(),e);    }}因为文件存储在磁盘中，并且通过Spring提供的@Value注解将文件的位置在配置文件中进行配置，因此文件对象我们可以直接通过new File的方式直接获取到文件，最终调用工具类ServletUtil将该文件写入到HttpServletResponse的流中去，实现下载的目录2.3 模板文件存在在jar中，提供接口下载通过上面的两种下载方式，我们基本已经能实现文件的下载，满足业务的需要，但有时候我也会思考，是否把数据模板文件直接放在Spring Boot的jar中，这种方式的优势：  防止模板文件存储在磁盘时被误删的操作发送  如果程序部署需要迁移服务器，能有效避免下载接口的容错，忘记迁移模板文件等情况会导致程序异常  和程序代码存储在一起更加完整基于上面的优势，因此，针对数据模板文件，我认为应该和项目直接放在一起，这样对于程序部署等都是非常有利的。一般，在Spring Boot的开发框架中，我们可以在resources目录下建立文件夹，然后将相应的数据文件放入目录中，再提供接口读取该文件进行下载目录结构如下：|---project|--------src/main/java|--------src/main/resources|------------data# 模板文件|--------------template.xlsx因为我们将文件放在了resources目录下，此时如果要读取该文件，我们需要利用到Spring提供的ClassPathResource类进行读取，调用代码如下：ClassPathResource classPathResource=new ClassPathResource(\"data/tag_data_template.xlsx\");此时，我们的下载接口代码如下：@GetMapping(\"/download\")public void downloadExcel(HttpServletResponse response){    logger.info(\"下载Excel模板\");    ClassPathResource classPathResource=new ClassPathResource(\"data/template.xlsx\");    try {        //创建临时文件        File file=File.createTempFile(\"template\",\".xlsx\");        //从当前resources目录下的文件流拷贝到File中        FileUtils.copyInputStreamToFile(classPathResource.getInputStream(),file);        logger.info(\"fileName:{}\",file.getName());        //将临时文件写出到流中        ServletUtil.write(response,file);    } catch (IOException e) {        logger.error(e.getMessage(),e);    }}这里会有1个疑问点，就是我们既然已经使用了Spring提供的ClassPathResource进行读取文件，而该类通过继承AbstractFileResolvingResource也提供了getFile方法获取File对象，为何不直接调用?比如下载的接口代码改成这样：@GetMapping(\"/download\")public void downloadExcel(HttpServletResponse response){    logger.info(\"下载Excel模板\");    ClassPathResource classPathResource=new ClassPathResource(\"data/template.xlsx\");    try {        //直接获取文件        File file=classPathResource.getFile();        //将临时文件写出到流中        ServletUtil.write(response,file);    } catch (IOException e) {        logger.error(e.getMessage(),e);    }}通过源码来分析//AbstractFileResolvingResource.getFile@Overridepublic File getFile() throws IOException {    URL url = getURL();    if (url.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) {        return VfsResourceDelegate.getResource(url).getFile();    }    return ResourceUtils.getFile(url, getDescription());}//ResourceUtils/** URL protocol for a file in the file system: \"file\". */public static final String URL_PROTOCOL_FILE = \"file\";//ResourceUtils.getFilepublic static File getFile(URL resourceUrl, String description) throws FileNotFoundException {    Assert.notNull(resourceUrl, \"Resource URL must not be null\");    if (!URL_PROTOCOL_FILE.equals(resourceUrl.getProtocol())) {        throw new FileNotFoundException(            description + \" cannot be resolved to absolute file path \" +            \"because it does not reside in the file system: \" + resourceUrl);    }    try {        return new File(toURI(resourceUrl).getSchemeSpecificPart());    }    catch (URISyntaxException ex) {        // Fallback for URLs that are not valid URIs (should hardly ever happen).        return new File(resourceUrl.getFile());    }}在最终的ResourceUtils.getFile方法获取File对象时，Spring会对当前URL对象的协议进行判断,如果文件的协议不是file，则会抛出异常，提示 class path resource [data/tag_data_template.xlsx] cannot be resolved to absolute file path because it does not reside in the file system: jar:file:/home/app.jar/BOOT-INF/classes!/data/template.xlsx大致的意思就是该文件不在文件系统中，既然Spring不允许这么干，那么我们只能通过获取该文件的输入流的方式，将流写到临时文件中去，最终将该临时文件写出。//FileUtils.copyInputStreamToFile方法//commons-io 包中提供的方法public static void copyInputStreamToFile(InputStream source, File destination) throws IOException {    try {        FileOutputStream output = openOutputStream(destination);        try {            IOUtils.copy(source, output);            output.close(); // don't swallow close Exception if copy completes normally        } finally {            IOUtils.closeQuietly(output);        }    } finally {        IOUtils.closeQuietly(source);    }}以上的操作完成后，我们可能还会碰到部署时，代码还是会抛异常的问题，说文件找不到，这种情况一般会和我们项目的maven打包配置有关，我们需要在项目的maven配置中将模板文件也一起打包进去，例如增加配置如下：&lt;resources&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/resources&lt;/directory&gt;        &lt;includes&gt;\t\t   &lt;!--包含data目录下的所有文件一起打包--&gt;            &lt;include&gt;**/data/**&lt;/include&gt;        &lt;/includes&gt;        &lt;filtering&gt;false&lt;/filtering&gt;    &lt;/resource&gt;&lt;/resources&gt;至此，就大功告成了！！！3.附录3.1 ServletUtil.write方法ServletUtil工具类是引用的开源项目Hutool中的一个关于Servlet的工具类封装.write方法提供了将文件写入到流中的封装，来看具体的源码：  封装了我们工作中基础的写出流的操作，我们在代码中也可以通过调用此方法简化我们的代码。/** 默认缓存大小 8192*/public static final int DEFAULT_BUFFER_SIZE = 2 &lt;&lt; 12;/** * 返回文件给客户端 *  * @param response 响应对象{@link HttpServletResponse} * @param file 写出的文件对象 * @since 4.1.15*/public static void write(HttpServletResponse response, File file) {    final String fileName = file.getName();    //根据文件名称获取文件的响应类型，如果没有则默认application/octet-stream    final String contentType = ObjectUtil.defaultIfNull(FileUtil.getMimeType(fileName),\"application/octet-stream\");    BufferedInputStream in = null;    try {        in = FileUtil.getInputStream(file);        //再次调用，写出Header等信息        write(response, in, contentType, fileName);    } finally {        IoUtil.close(in);    }}/** * 返回数据给客户端 *  * @param response 响应对象{@link HttpServletResponse} * @param in 需要返回客户端的内容 * @param contentType 返回的类型 * @param fileName 文件名 * @since 4.1.15*/public static void write(HttpServletResponse response, InputStream in, String contentType, String fileName) {    final String charset = ObjectUtil.defaultIfNull(response.getCharacterEncoding(), CharsetUtil.UTF_8);    response.setHeader(\"Content-Disposition\", StrUtil.format(\"attachment;filename={}\", URLUtil.encode(fileName, charset)));    response.setContentType(contentType);    //写出    write(response, in);}/** * 返回数据给客户端 *  * @param response 响应对象{@link HttpServletResponse} * @param in 需要返回客户端的内容*/public static void write(HttpServletResponse response, InputStream in) {\twrite(response, in, IoUtil.DEFAULT_BUFFER_SIZE);}/** * 返回数据给客户端 *  * @param response 响应对象{@link HttpServletResponse} * @param in 需要返回客户端的内容 * @param bufferSize 缓存大小*/public static void write(HttpServletResponse response, InputStream in, int bufferSize) {    ServletOutputStream out = null;    try {        out = response.getOutputStream();        IoUtil.copy(in, out, bufferSize);    } catch (IOException e) {        throw new UtilException(e);    } finally {        IoUtil.close(out);        IoUtil.close(in);    }}"
  },
  
  {
    "title": "基于Servlet体系的HTTP请求代理转发Spring Boot组件",
    "url": "/posts/spring-boot-servlet-gateway-compoents/",
    "categories": "SpringBoot",
    "tags": "",
    "date": "2021-02-03 00:00:00 +0800",
    





    
    "snippet": "背景概述两个项目组原本都是各自负责两个产品线(产品A、产品B)，由于公司业务的发展，目前需要将两个产品合并成一个大产品(功能整合，部分做取舍,最终产出产品C)，前后端代码必然也需要整合，包括两个产品线的用户体系等。并且给出的时间节点很紧张。目前两个产品线的区别点：产品A  前端模块载体是微信小程序，没有H5、APP等需求，因此所采用的技术栈是原生写法，没有用到技术框架  服务端技术架构是单体...",
    "content": "背景概述两个项目组原本都是各自负责两个产品线(产品A、产品B)，由于公司业务的发展，目前需要将两个产品合并成一个大产品(功能整合，部分做取舍,最终产出产品C)，前后端代码必然也需要整合，包括两个产品线的用户体系等。并且给出的时间节点很紧张。目前两个产品线的区别点：产品A  前端模块载体是微信小程序，没有H5、APP等需求，因此所采用的技术栈是原生写法，没有用到技术框架  服务端技术架构是单体架构，Spring Boot框架，管理后台框架采用的是Apache Shiro  前后端接口调用采用的是服务端token鉴权的方式交互  用户体系简单,小程序端没有会员等业务，仅涉及到微信openid，管理后台涉及权限菜单.  后端管理系统前端开发技术框架是React产品B  前端模块载体多样，包括微信小程序、H5、APP等，因此采用的是多端统一框架，例如：union-app  服务端技术架构单体架构，Spring Boot框架  前后端接口调用采用的是服务端token鉴权的方式交互  用户体系复杂，有会员、优惠券等业务，管理后台涉及权限菜单  后端管理系统前端开发技术框架是Vue产品C  载体是微信小程序，没有H5、APP等需求  产品A中的功能居多,产品B中的功能占用少部分鉴于上面的背景，我们讨论接下来产品线合并的可能性  前端代码重写，虽说是产品线合并，但是原来两个产品线的功能点只是做整合，并没有太多新增的功能，因此原来的部分功能模块可以复用，采用原生写法，不用多端框架  后端用户体系复用产品B中的体系，基本控制菜单权限即可  考虑到时间紧迫，因此原本产品A\\B两个产品线的已有的功能基本不动，只对新增模块的功能进行开发。  产品B的后端系统功能菜单、权限系统较A完善，因此作为产品C的管理后端进行复用，将产品A的后端功能全部移动到产品C中，由于两个产品线管理后台开发的技术栈不一样，因此产品C中的部分功能需要重写，将产品A的功能使用Vue的技术栈移到产品C中游客端(小程序端)针对产品C的小程序端，由于需要包含产品A中的某一核心功能，因此不太可能使用多端框架进行重写(PS:主要是领导给的时间不够)，因此采用的做法是直接在产品A的基础上衍生一个版本，最终将产品B中的部分功能，通过原生框架，最终在产品C中进行呈现。因为小程序的接口调用方式是直连，通过发起HTTPS的接口请求即可,因此服务端接口逻辑不动，前端开发人员只需要和产品B的人员进行接口对接即可，最终接口调用流程示意图如下：管理端(PC端)管理端则不同，由于是使用的产品B中的后台，因此产品A中的权限控制需要去除(例如登录后才能调用接口等限制),而产品A中的接口权限控制需要交给B来管，发送请求时需要校验当前请求的权限，校验通过后再转发给A，调用时序图如下：上面这张图也是这个组件雏形，寄希望与通过该转发组件,通过提供不同的转发方式，封装转发HTTP请求的能力，达到直连服务的目的  如果单纯从一个新产品C的角度出发，ServiceA中的服务接口代码应该合并到ServiceB，最终形成一个新的ServiceC，但是考虑到时间紧迫，所以代码层面的合并并没有形成，因此考虑直接将请求HTTP转发的方式，最终将任务完成。程序设计从需求背景出发，在程序设计上需要考虑的几个点：  上游服务接收到的固定请求头，或者请求参数，比如多租户系统需要接收一个租户的请求header，因此转发组件需要有配置固定header的能力，以便在实际转发过程中发送到下游服务，方便系统扩展  需要提供权限验证的接口，不同的权限框架可能验证方式不同，有些系统是Shiro，或者Spring Security,或者自研，因此在最终权限校验时，考虑到和系统的兼容性，对于下游的转发服务接口，需要提供和系统兼容的验证接口，不可打破原系统的稳定性  转发的方式支持类别，考虑到系统的健壮性，需要提供不同的转发类别支撑由于是基于Servlet体系，因此对于接口的请求，需要做一层拦截判断，以验证当前的请求是否是需要转发到下游服务，核心过滤器如下：public class ServletGatewayRouteProxyFilter implements Filter {    //执行器对象    private final RouteDispatcher routeDispatcher;    //权限对象    private final ServletGatewayAuthentication servletGatewayAuthentication;    Logger logger= LoggerFactory.getLogger(ServletGatewayRouteProxyFilter.class);    /**     * 狗仔ProxyHttpFilter 对象实例     * @param routeDispatcher 执行器对象     * @param servletGatewayAuthentication 权限校验对象     */    public ServletGatewayRouteProxyFilter(RouteDispatcher routeDispatcher, ServletGatewayAuthentication servletGatewayAuthentication) {        this.routeDispatcher = routeDispatcher;        this.servletGatewayAuthentication = servletGatewayAuthentication;    }     @Override    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {        HttpServletRequest request= (HttpServletRequest) servletRequest;        HttpServletResponse response=(HttpServletResponse) servletResponse;        //根据程序配置方式，截取当前请求是否符合转发请求        Optional&lt;ServiceRoute&gt; serviceRouteOptional=routeDispatcher.assertServletRequest(request);        if (serviceRouteOptional.isPresent()){            logger.info(\"转发目标服务，地址:{}\",request.getRequestURI());            if (servletGatewayAuthentication.required()){                if (servletGatewayAuthentication.auth(servletRequest,servletResponse)){                    routeDispatcher.execute(request,response,serviceRouteOptional.get());                }else{                    servletGatewayAuthentication.failedHandle(servletRequest,servletResponse);                }            }else{                routeDispatcher.execute(request,response,serviceRouteOptional.get());            }        }else{            //不符合，继续执行            filterChain.doFilter(servletRequest,servletResponse);        }    } \t    //other code...}对于当前的HttpServletRequest信息做判断，获取当前请求的ServiceRoute对象，以此来判断请求是否需要转发ServiceRoute对象主要包含下游转发服务的HTTP地址、端口号、固定Header信息public class ServiceRoute {    /**     * 转发模式     */    private RouteModeEnum mode;    /**     * 匹配值     */    private String value;    /**     * 转发目标地址，例如：http://192.179.0.1:8999     */    private String uri;    /**     * 发送请求头     */    private Map&lt;String,String&gt; headers;    //getter and setter}而ServiceRoute是最终交给开发者配置的信息，转发请求方式，判断逻辑如下：/*** 校验当前路由规则是否符合* @param serviceRoute 路由实例* @param servletRequest 请求对象* @return 是否符合规则*/protected boolean checkRoute(ServiceRoute serviceRoute,HttpServletRequest servletRequest){    boolean flag=false;    if (serviceRoute!=null){        switch (serviceRoute.getMode()){            //基于请求头            case ROUTE_MODE_HEADER:                String value=servletRequest.getHeader(ROUTE_MODE_HEADER_NAME);                flag=StrUtil.equalsIgnoreCase(value,serviceRoute.getValue());                break;            //基于URI的前缀匹配            case ROUTE_MODE_PREFIX:                flag=servletRequest.getRequestURI().startsWith(serviceRoute.getValue());                break;            //基于URI的后缀匹配            case ROUTE_MODE_SUFFIX:                flag=servletRequest.getRequestURI().endsWith(serviceRoute.getValue());                break;        }    }    return flag;}针对权限的设计，在ServletGatewayRouteProxyFilter中，提供了ServletGatewayAuthentication接口，该接口设计如下：public interface ServletGatewayAuthentication {    /**     * 权限校验     * @param request 请求request对象     * @param response 响应对象     * @return 是否权限校验通过     */    boolean auth(ServletRequest request, ServletResponse response);    /**     * 权限校验失败后的处理逻辑     * @param request 请求对象     * @param response 响应对象     */    void failedHandle(ServletRequest request, ServletResponse response);    /**     * 是否需要鉴权，默认true     * @return 是否需要鉴权     */    default boolean required(){return true;}}主要包含三个接口：  auth:权限验证，返回布尔值，该接口方法主要是兼容系统中的权限，对于当前的请求，可以方便的做出权限判断，交由开发者实现  failedHandle:如果权限验证失败，最终响应信息给前端，开发者实现  required:是否需要鉴权的标志，默认是true，代表需要鉴权最后再来看代理请求的执行逻辑(RouteDispatcher.java#execute()方法)，部分核心代码如下：public void execute(HttpServletRequest request, HttpServletResponse response,ServiceRoute serviceRoute){    try{        //构建请求对象        RouteRequestContext routeContext=new RouteRequestContext();        //请求对象赋值        this.buildContext(routeContext,request,serviceRoute);        //发送请求        RouteResponse routeResponse=routeExecutor.executor(routeContext);        //响应结果        writeResponseHeader(routeResponse,response);        writeBody(routeResponse,response);    }catch (Exception e){        logger.error(\"has Error:{}\",e.getMessage());        logger.error(e.getMessage(),e);        //write Default        writeDefault(request,response,e.getMessage());    }}针对请求上下文的赋值，主要是接收当前请求的请求参数以及请求头，并且根据ServiceRoute路由基础信息，进行基础赋值，代码如下：/** * 构建路由的请求上下文 * @param routeRequestContext 请求上下文对象 * @param request 请求 * @param serviceRoute 路由实例 * @throws IOException IO异常 */protected void buildContext(RouteRequestContext routeRequestContext,HttpServletRequest request,ServiceRoute serviceRoute) throws IOException {    //String uri=\"http://knife4j.xiaominfo.com\";    String uri=serviceRoute.getUri();    if (StrUtil.isBlank(uri)){        throw new RuntimeException(\"Uri is Empty\");    }    String host=URI.create(uri).getHost();    String fromUri=request.getRequestURI();    StringBuilder requestUrlBuilder=new StringBuilder();    requestUrlBuilder.append(uri);    //判断当前聚合项目的contextPath    if (StrUtil.isNotBlank(this.rootPath)&amp;&amp;!StrUtil.equals(this.rootPath,ROUTE_BASE_PATH)){        fromUri=fromUri.replaceFirst(this.rootPath,\"\");    }    if (serviceRoute.getMode()== RouteModeEnum.ROUTE_MODE_PREFIX){        //前缀转发，替换        fromUri=fromUri.replaceFirst(serviceRoute.getValue(),\"/\");    }    if (!StrUtil.startWith(fromUri,\"/\")){        requestUrlBuilder.append(\"/\");    }    requestUrlBuilder.append(fromUri);    //String requestUrl=uri+fromUri;    String requestUrl=requestUrlBuilder.toString();    logger.info(\"目标请求Url:{},请求类型:{},Host:{}\",requestUrl,request.getMethod(),host);    routeRequestContext.setOriginalUri(fromUri);    routeRequestContext.setUrl(requestUrl);    routeRequestContext.setMethod(request.getMethod());    Enumeration&lt;String&gt; enumeration=request.getHeaderNames();    while (enumeration.hasMoreElements()){        String key=enumeration.nextElement();        String value=request.getHeader(key);        if (!ignoreHeaders.contains(key.toLowerCase())){            routeRequestContext.addHeader(key,value);        }    }    //是否有默认Header需要发送    if (CollectionUtil.isNotEmpty(serviceRoute.getHeaders())){        for (Map.Entry&lt;String,String&gt; entry:serviceRoute.getHeaders().entrySet()){            routeRequestContext.addHeader(entry.getKey(),entry.getValue());        }    }    routeRequestContext.addHeader(\"Host\",host);    Enumeration&lt;String&gt; params=request.getParameterNames();    while (params.hasMoreElements()){        String name=params.nextElement();        String value=request.getParameter(name);        //logger.info(\"param-name:{},value:{}\",name,value);        routeRequestContext.addParam(name,value);    }    routeRequestContext.setRequestContent(request.getInputStream());}使用指南servlet-gateway-spring-boot-starter组件是一组基于Servlet体系的业务转发HTTP组件,主要目的是在现有Spring Boot 框架的基础上，添加基于Filter过滤器的转发能力,丰富框架的业务能力。目前支持三种模式：  ROUTE_MODE_HEADER:基于请求头的转发  ROUTE_MODE_PREFIX:基于请求Uri的请求前缀匹配转发  ROUTE_MODE_SUFFIX:基于请求URI的后缀匹配转发规则使用方法，在Spring Boot的框架中，pom.xml中引入当前组件，代码如下：&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;servlet-gateway-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt;在Spring Boot框架的application.yml配置文件中进行配置，示例如下：server:  servlet:    gateway:      enable: true       cloud:         enable: true         # Routes节点，可以配置多个         routes:           - mode: ROUTE_MODE_PREFIX           \t # 将所有以/abb开头的请求接口全部转发到uri中的目标服务             value: /abb/             uri: http://knife4j.xiaominfo.com             # 配置发送默认请求头(可选配置)             headers:               code: TESS针对代理请求鉴权功能,该组件提供了ServletGatewayAuthentication接口,对于接入该组件的项目需要实现该接口，并且注入到 Spring 的容器中public interface ServletGatewayAuthentication {    /**     * 权限校验     * @param request 请求request对象     * @param response 响应对象     * @return 是否权限校验通过     */    boolean auth(ServletRequest request, ServletResponse response);    /**     * 权限校验失败后的处理逻辑     * @param request 请求对象     * @param response 响应对象     */    void failedHandle(ServletRequest request, ServletResponse response);    /**     * 是否需要鉴权，默认true     * @return 是否需要鉴权     */    default boolean required(){return true;}}以下是一个项目中通过Shiro控制权限的例子，对于代理的请求，需要验证当前的请求是否已经登录过public class AideShiroAuthentication implements ServletGatewayAuthentication {    private final OtsWebSessionManager otsWebSessionManager;    private final RedisTemplate redisTemplate;    Logger logger= LoggerFactory.getLogger(AideShiroAuthentication.class);    public AideShiroAuthentication(OtsWebSessionManager otsWebSessionManager, RedisTemplate redisTemplate) {        this.otsWebSessionManager = otsWebSessionManager;        this.redisTemplate = redisTemplate;    }    @Override    public boolean auth(ServletRequest request, ServletResponse response) {        Serializable sessionId = otsWebSessionManager.getShiroSessionId(request, response);        if (sessionId!=null){            Object object= redisTemplate.opsForValue().get(MyRedisSessionDao.PREFIX + sessionId.toString());            if (object!=null){                Session session = (Session)object;                return session!=null&amp;&amp;session.getId()!=null;            }        }        return false;    }    @Override    public void failedHandle(ServletRequest request, ServletResponse response) {        logger.info(\"权限校验失败\");        response.setCharacterEncoding(\"UTF-8\");        response.setContentType(\"application/json; charset=utf-8\");        RestResult&lt;String&gt; result = new RestResult&lt;&gt;();        result.setErrCode(BusinessErrorCode.NO_CURRENT_LOGIN_USER.getCode());        result.setData(BusinessErrorCode.NO_CURRENT_LOGIN_USER.getMessage());        try (PrintWriter out = response.getWriter()) {            out.append(JSON.toJSONString(result));        } catch (IOException e2) {            return;        }    }}通过自定义权限接口后，需要注入到Spring的容器中(注意：需要添加@Primary注解)，代码如下：@Configurationpublic class AuthConfig {    @Bean    @Primary    public AideShiroAuthentication aideServletGatewayAuthentication(@Autowired OtsWebSessionManager otsWebSessionManager,@Autowired RedisTemplate redisTemplate){        return new AideShiroAuthentication(otsWebSessionManager,redisTemplate);    }}"
  },
  
  {
    "title": "Spring Boot自定义starter必知必会条件",
    "url": "/posts/spring-boot-self-starter/",
    "categories": "SpringBoot",
    "tags": "",
    "date": "2020-12-10 00:00:00 +0800",
    





    
    "snippet": "前言在目前的Spring Boot框架中,不管是Spring Boot官方还是非官方,都提供了非常多的starter系列组件,助力开发者在企业应用中的开发,提升研发人员的工作效率,Spring Boot框架提出的约定大于配置的规则，确实帮助开发者简化了以前Spring MVC时代的很多繁杂的配置。让开发者用起来也是非常爽的。尽管Spring Boot或者一些开源组件已经帮助我们提供了非常多的...",
    "content": "前言在目前的Spring Boot框架中,不管是Spring Boot官方还是非官方,都提供了非常多的starter系列组件,助力开发者在企业应用中的开发,提升研发人员的工作效率,Spring Boot框架提出的约定大于配置的规则，确实帮助开发者简化了以前Spring MVC时代的很多繁杂的配置。让开发者用起来也是非常爽的。尽管Spring Boot或者一些开源组件已经帮助我们提供了非常多的starter组件，在满足日常的开发中,已经完全没有问题了。但有时候因为需求的可变性，导致企业架构也会随着调整，那么在Spring Boot框架中，官方或开源的第三方starter肯定不能满足企业内部研发人员的要求，这时候就需要开发者自定义企业内部的starter了。企业或个人自定义Spring Boot的starter组件主要从哪些方面来入手呢，或者什么时候需要自定义starter组件？我个人认为主要有以下几个方面：  规范企业内部编码流程，统一各个技术中间件的代码规范  减少不同类型中间件的使用成本，提升研发人员的研发工作效率  减少冗余代码的使用，统一封装，统一管理。  屏蔽中间件底层细节，暴露配置属性及方法，减少学习使用成本  可能还有更多？本篇博客结合自身的开发经验以及目前Spring Boot如何配置元数据的官方介绍文档进行结合，进行综合阐述。Spring Boot官方元数据文档地址：https://docs.spring.io/spring-boot/docs/current/reference/html/appendix-configuration-metadata.html封装Spring Boot的starter范围可以是一组规范的业务方法，也可以是通用的中间件底层。开发者通过封装，一定程度上也能起到规范企业编码的作用,同时也能组合复用公共业务逻辑。那么我们在自定义Spring Boot框架的starter组件时,我们需要准备什么呢？我认为主要包含以下几个方面：  自定义starter的作用  命名规范  理解Maven或者Gradle依赖包管理的jar包引用传递机制  理解Spring Boot框架中基于Java代码的Configuration配置  理解Spring Boot框架自动装载的过程  学会利用Spring Boot提供的@Conditional系列条件注入充分发挥Spring Boot的优点  学会如何配置自定义starter组件时对外的属性注释配置，可以参考官方文档自定义starter的作用我们在自定义starter组件之前，开发者首先需要想清楚，这个starter组件能带来什么，简化开发？或者复用组件的封装供其他同事使用，不写重复代码等等，这些都是需要思考清楚的。自定义starter的场景很多，例如：  项目中发送短信对接了不同的云服务商，那么可以封装一个短信的starter，屏蔽对接的细节，开发者只需要配置相应的厂商配置信息就可以使用该服务商发送短信了  OSS存储对接不同的云服务商，例如阿里云、七牛云、腾讯云等等  企业内部中间件封装使用，简化开发配置  more…根据笔者的经验,我认为自定义的starter的作用无外乎以下几个方面：  充分利用Spring的特性，容器/依赖注入特性，将核心的类组件注入容器中,方便开发者通过注入直接获取拿来使用  通过属性初始化中间件的流程，屏蔽具体的细节  ….starter命名规范根据Spring Boot的官方要求，如果是开发者指定第三方的starter组件，那么命名规范是yourname-spring-boot-starter拿Knife4j举例说明如下：&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索2.X最新版本号--&gt;    &lt;version&gt;2.0.8&lt;/version&gt;&lt;/dependency&gt;而Spring Boot官方维护发布的starter名称规范则是：spring-boot-starter-name例如我们引用最多的web组件，引用maven配置如下：&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;jar包引用传递依赖机制这是自定义封装Spring Boot的starter的前提条件，Gradle笔者并未使用过，这里仅以Maven为例进行阐述说明！通常我们在封装一个SDK的jar包时，该jar包可能需要引用到第三方的jar包作为依赖包来辅助我们完成对该jar包的封装，但是我们在引用的时候是有讲究的。针对Spring Boot的自定义starter说到底也是一个jar包，既然是jar包必然会用到第三方的jar(ps:全部都是你写的代码除外)，那么我们应该如何明确在starter中的jar包的依赖传递，我认为主要有以下方面：  作为第三方组件使用jar包时，明确第三方组件的版本  作为编译期间的包，需要修改默认的scope范围值，仅仅在编译期间生效，最终打包后引用不传递  自定义封装starter必须引用Spring Boot官方提供的在定义Spring Boot的第三方starter时，主要用到Maven管理jar包中的两种依赖隔离方式(均可以使用)，分别如下：  明确使用&lt;optional&gt;true&gt;&lt;/optional&gt;属性来强指定jar包不传递  使用&lt;scope&gt;provided&lt;/scope&gt;仅仅在编译期间有效，jar包依赖性不传递一般我们在自定义Spring Boot的starter组件时，都需要引用Spring Boot提供给开发者的依赖包，如下：&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;    &lt;version&gt;2.3.0.RELEASE&lt;/version&gt;    &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;当然，你也可以使用optional模式，如下： &lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;     &lt;version&gt;2.3.0.RELEASE&lt;/version&gt;     &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;Java代码方式的Configuration基于Java编码的方式配置Spring的Bean已经成了目前的主流，这主要也是得益于Spring Boot框架的流行！在Spring MVC框架流行的时候，开发人员一般都是通过配置XML文件来注入实体Bean的而通过java编码的方式注入Bean的前提是@Configuration注解加在一个配置Java实体类上即可，示例如下：@Configurationpublic class MyAutoConfiguration{        //do others...    }Spring Boot框架的自动装载对于Spring Boot框架自定义的starter组件来说，提供的使用方式而言，我认为目前主要有3种方式，这个主要看封装starter组件的作者如何开放来定手工@Import导入第一种情况：使用者使用@Import注解将封装的starter组件的Java编码Configuration配置文件进行导入假设目前封装的一个简单的Configuration配置如下：@Configurationpublic class DemoAuthConfiguration {    @Bean    public DemoClient demoClient(){        return new DemoClient();    }}开发者通过DemoAutoConfiguration.java向Spring的容器中注入了一个DemoClient的实体Bean,由于隶属于不同的package包路径，自定义的starter组件包路径是：com.demo.spring而开发者的项目主目录包路径是：com.test,所以Spring Boot框架默认是不会加载该配置的，此时，如果开发者要在Spring的容器中获取DemoClient的实体Bean应该怎么办呢？使用者应该在自己的主配置中使用@Import注解将该配置导入进来交给Spring容器初始化时进行创建，示例如下：@Import(DemoAutoConfiguration.class)@SpringBootApplicationpublic class DemoDemoApplication {        public static void main(String[] args){        SpringApplication.run(DemoDemoApplication.class, args);    }}提供便于记忆的注解@EnableXXX@Enablexxx系列注解相信开发者并不陌生，比如我们要使用Spring Boot的定时任务功能，我们会在启动入口引入@EnableScheduling注解，我们使用Springfox的Swagger组件，我们会引入@EnableSwagger2注解其实这种方式只是为了让开发者能够更加方便的记忆，一个@Enablexxx系列注解，其所代表的功能特点也基本符合该starter组件，是在上面手工通过@Import注解的升级版本。毕竟Enable单词所代表的含义是启用,这有利于开发者记忆继续通过上面第一种的示例进行改在，此时，我们可以提供@EnableDemoClient注解，代码示例如下：@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Import(DemoAutoConfiguration.class)public @interface EnableDemoClient {}大家应该也看到了，我们在该@EnableDemoClient注解中，使用了@Import注解的方式导入了DemoAutoConfiguration配置此时，我们在项目中可以使用@EnableDemoClient注解了，代码示例如下：@EnableDemoClient@SpringBootApplicationpublic class DemoDemoApplication {        public static void main(String[] args){        SpringApplication.run(DemoDemoApplication.class, args);    }}当然，@Enable这种注解作用不仅仅局限于此，还可以在该注解上定义外部的配置属性，通过配置该注解的方式达到最终初始化的目的。自动装载自动装载是Spring Boot的一重大特点，开发者通过配置文件的方式即可默认加载第三方的starter配置，非常的方便，是上面两种方式的升级版在之前的基础上，如果开发者希望在Maven的pom.xml工程中引入了该组件，就可以使用DemoClient类，那么此时我们应该怎么做呢？我们需要在工程中创建spring.factories文件，文件目录：src/resources/META-INF/spring.factories在spring.factories文件中,配置开发者自定义的configuration类，如下：org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.demo.spring.DemoAutoConfiguration配置好后，此时再打包我们自定义的starter组件，Spring Boot框架默认会自动装载该配置类，我们在业务代码中也就可以直接使用了我们可以在SpringApplication.java源码中看到Spring Boot初始化获取该类列表的过程private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) {\t\tClassLoader classLoader = getClassLoader();\t\t// Use names and ensure unique to protect against duplicates\t\tSet&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader));\t\tList&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names);\t\tAnnotationAwareOrderComparator.sort(instances);\t\treturn instances;}上述方法中的SpringFactoriesLoader.loadFactoryNames方法如下：public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) {\t\tString factoryTypeName = factoryType.getName();\t\treturn loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList());}private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) {    MultiValueMap&lt;String, String&gt; result = cache.get(classLoader);    if (result != null) {        return result;    }    try {        //加载META-INF/spring.factories配置，创建MultiValueMap集合放到该集合中        Enumeration&lt;URL&gt; urls = (classLoader != null ?                                 classLoader.getResources(FACTORIES_RESOURCE_LOCATION) :                                 ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));        result = new LinkedMultiValueMap&lt;&gt;();        while (urls.hasMoreElements()) {            URL url = urls.nextElement();            UrlResource resource = new UrlResource(url);            Properties properties = PropertiesLoaderUtils.loadProperties(resource);            for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) {                String factoryTypeName = ((String) entry.getKey()).trim();                for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) {                    result.add(factoryTypeName, factoryImplementationName.trim());                }            }        }        cache.put(classLoader, result);        return result;    }    catch (IOException ex) {        throw new IllegalArgumentException(\"Unable to load factories from location [\" +                                           FACTORIES_RESOURCE_LOCATION + \"]\", ex);    }}充分利用Spring Boot提供的@Conditional条件注入组件通过上面的文章介绍，为Spring Boot框架制定一个简单的starter组件相信已经不在话下。但是，这才仅仅开始而已。在上面介绍的自动装载过程中，开发者是否会存在疑问？  当我们在pom.xml引入我们自定义的starter组件后,Spring Boot框架默认会将该组件直接注入到Spring的容器中，这种方式虽然在使用上并没有什么问题，但当我们封装给第三方使用时,这种方式往往会存在冲突，假设开发者自定义的starter组件中包含了向容器中注入Filter等过滤器,那么该过滤器直接生效,会全范围影响整个应用程序.这在实际开发中是不允许的！  那么应该怎么办呢?此时，我们就需要充分利用Spring Boot框架为开发者提供的@Conditional系列条件注入了条件注入顾名思义,就是只有使用者满足了组件规定的条件时，组件才会向Spring容器中进行注入Bean或者初始化的操作.这种方式也是将选择权直接交给使用者进行选择，减少非必要的组件冲突，是在Spring Boot自定义starter组件中必不可少的一环。条件注入通常也配合属性类一起来进行使用,提供配置属性选项也是方便使用者在Spring Boot的配置文件application.yml或者application.properties进行配置开启操作，例如我们常见的配置操作如下：server:  port: 18568  servlet:    context-path: /test为Spring Boot的程序指定启动端口号和context-path属性.我们继续以上面示例中的DemoClient为例进行阐述  假设我们的DemoClient是对接外部API接口的封装组件，该组件规定访问外部API时需要提供appid和secret,根据appid及secret获取token，最后根据token才能调用API获取接口数据，那么,此时，我们的DemoClient的部分模拟接口代码可能会如下面示例：public class DemoClient {    private final String appid;    private final String secret;    public DemoClient(String appid, String secret) {        this.appid = appid;        this.secret = secret;    }    /**     * 获取资源     * @return     */    public String listResources(){        //获取token        String token=getToken();        //根据Token请求数据        return UUID.randomUUID().toString();    }    private String getToken() {        //根据appid &amp; secret获取第三方API接口token        return null;    }}在上面的代码示例中，如果开发者要使用DemoClient的方法调用第三方的接口资源，那么需要传递appid及secret参数才能构造实体类，又考虑到我们需要利用Spring Boot的条件注入，只有开发者配置了开启操作，才能在Spring容器中使用DemoClient的方法。那么此时，我们可以给该starter组件抽象一个DemoProperties的外部配置类来交给使用者在配置文件中进行配置开启操作，代码示例如下：@ConfigurationProperties(prefix = \"demo\")public class DemoProperties {    /**     * 是否启用     */    private boolean enable=false;        private String appid;    private String secret;        //getter and setter...}在配置类属性中，我们使用到了@ConfigurationProperties注解，并配置了prefix前缀参数,配置前缀也是自定义starter组件中所必须的，这约束了命名空间。一般是结合自身的业务以及starter组件所代表的功能含义进行命名prefix,有助于开发使用者记忆。此时，我们的DemoAutoConfiguration.java配置类进行了调整，代码如下：@Configuration@EnableConfigurationProperties(DemoProperties.class)@ConditionalOnProperty(name = \"demo.enable\",havingValue = \"true\")public class DemoAutoConfiguration {    @Bean    public DemoClient demoClient(DemoProperties demoProperties){        return new DemoClient(demoProperties.getAppid(), demoProperties.getSecret());    }}和上面的配置类进行比较不难发现,此处我们又多用了两个注解：  @EnableConfigurationProperties:该注解是我们自定义指定Proerpty实体类时，必须启用的注解，和实体类中的@ConfigurationProperties注解配合一起使用  @ConditionalOnProperty:Spring Boot框架中条件注入的一种，代码根据配置的属性进行条件判断注入，此处我们配置了只有当demo.enable=true时，DemoAutoConfiguration配置类才会加载，向Spring容器中注入DemoClient的实体Bean当自定义starter组件封装到这一步时，基本已经快完结了，开发者可以通过在Spring Boot的配置文件中进行配置，来开启是否使用DemoClient组件demo:  # 通过配置该属性的true 或者false ，来开启组件的使用  enable: true  appid: xxx  secret: xxxx属性元数据配置通过上面的配置，我们已经能够自定义一个Spring Boot框架的starter组件了，但是对于使用者来说，封装该starter组件的开发者还尚有最后一步需要完成，那就是给属性类提供元数据注释，提供元数据注释也是为了让使用者在配置application.yml属性时，通过IDEA等编辑器能够给出提示，这对使用者而已是大有裨益的，因为每一个属性都会有相应的注释供开发者进行参考。例如Knife4j组件提供的元数据注释如下图：那么我们在制定starter组件时，如何给属性类提供元数据注释呢？目前主要有两种方式：引入spring-boot-configuration-processor自动注释我们可以在自定义是starter组件中引入该组件，依赖如下：&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;    &lt;version&gt;2.3.0.RELEASE&lt;/version&gt;    &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;引入该组件后，此时，我们只需要在我们的Java属性类中给每一个属性使用标准的javadoc进行注释即可，如下：@ConfigurationProperties(prefix = \"demo\")public class DemoProperties {    /**     * 是否启用     */    private boolean enable=false;    /**     * 第三方appid     */    private String appid;    /**     * 第三方secret     */    private String secret;        //getter and setter...}最终在使用时，就会出现提示，如下图：这种方式如果属性类不是太多的情况下，开发者可以使用，很方便手工编写spring-configuration-meatadata.json文件spring-boot-configuration-processor组件最终在打包生成starter的jar包时，也是帮助我们自动生成了spring-configuration-metadata.json文件,该文件和上面提到的spring.factories是同级目录手工编写spring-configuration-metadata.json也是我推荐的方式，因为不仅仅是每个属性的注释，有时候我们还可以用更多的属性配置以便使用者使用。结果如下：{  \"groups\": [    {      \"name\": \"demo\",      \"type\": \"com.demo.spring.DemoProperties\",      \"sourceType\": \"com.demo.spring.DemoProperties\"    }  ],  \"properties\": [    {      \"name\": \"demo.appid\",      \"type\": \"java.lang.String\",      \"description\": \"第三方appid\",      \"sourceType\": \"com.demo.spring.DemoProperties\"    },    {      \"name\": \"demo.enable\",      \"type\": \"java.lang.Boolean\",      \"description\": \"是否启用\",      \"sourceType\": \"com.demo.spring.DemoProperties\",      \"defaultValue\": false    },    {      \"name\": \"demo.secret\",      \"type\": \"java.lang.String\",      \"description\": \"第三方secret\",      \"sourceType\": \"com.demo.spring.DemoProperties\"    }  ],  \"hints\": []}我们主要使用到的属性有3个：groups、properties、hintsgroups字面意思分组，按我的理解即当我们使用的实体时，配置的prefix即代表该group，例如上面我们为DemoProperties配置了prefix的前缀是demo,那么分组这里可以设置为demo,当然如果DemoProperties类中包含的属性是一个第三方类，假设如下：public class DemoProperties{        private OtherProperties other;}那么我们可以在groups属性中配置一个名为demo.other的分组名称其包含的属性如下：            属性名称      类型      说明                  name      String      分组名称，可以理解为prefix              type      String      组数据类名              description      String      分组简单的描述，可以省略              sourceType      String      组数据源类名,同type，如果源类型未知，可以忽略该属性              sourceMethod      String      组方法的名称，（例如，带@ConfigurationProperties注解的@Bean方法的名称）。 如果源方法未知，则可以省略。      properties顾名思义，就是我们实体类每个属性的配置，有多少属性需要添加元数据注释说明，就需要在该数组下全部添加，需要注意的是配置name时需要配置全路径，例如：demo.enable等其包含的属性如下：            属性名称      类型      说明                  name      String      属性名称              type      String      属性类型              description      String      属性的简介说明              sourceType      String      该属性归属于那个类型              defaultValue      Object      该属性默认值              deprecation      Deprecation      用于指定该属性是否过时      过时选项Deprecation包含以下几个属性：            名称      类型      说明                  level      String      过时的级别,可以指定warning或者error,当指定为warning时，代表该属性还可用，而指定error则代表彻底废弃              reason      String      原因              replacement      String      替换属性      hints针对该属性，我的理解是类似于Java中的枚举，只不过是给每一个属性的值配置一个说明，方便使用者在配置的时候能够按照规定的值进行正确配置例如上面我们的示例：demo.enable属性，该属性类型为Boolean类型，要配置也只有两种值(true或者false)那么我们可以给该值配置一个hints进行说明，示例如下：\"hints\": [    {      \"name\": \"demo.enable\",      \"values\":[        {          \"value\": true,          \"description\": \"启用DemoClient组件\"        },        {          \"value\": false,          \"description\": \"禁用DemoClient组件\"        }      ]    }]当我们进行这样的配置后，最终使用者在使用时就会出现如下图所示的提示:这对使用该starter组件的开发者来说，每个属性都有相应的说明，是非常方便的hints主要包含的属性如下：            名称      类型      说明                  name      String      属性名称              values      ValueHint[]      一个ValueHint的数组              providers      ValueProvider[]      一个ValueProvinder数组      ValueHint是对其提供的值进行注释说明，其属性如下:            名称      类型      说明                  value      Object      属性对应的值              description      String      该值的描述信息      ValueProvider包含属性：            名称      类型      说明                  name      String      属性名称              parameters      JSON Object      提供程序支持的其他参数类型      在上面我提过，hints类似于枚举，这映射到ValueHint属性，当我们配置了hints属性中的values时而不提供providers属性时，如果开发者最终在使用时，只能配置ValueHint中定义的值，否则配置其他值时会在IDEA编辑器中就会爆红出错还是以上面的示例，假设我们给appid配置hint值，如下：\"hints\": [    {      \"name\": \"demo.appid\",      \"values\":[        {          \"value\": \"test1\",          \"description\": \"测试appid1\"        },        {          \"value\": \"test2\",          \"description\": \"测试appid2\"        }      ]    }]那么我们在使用组件时，在application.yml配置文件中配置其他值时，idea会提示错误，如下图：此时，providers属性就可以排上用场了修改上面的配置如下：\"hints\": [    {      \"name\": \"demo.appid\",      \"values\":[        {          \"value\": \"test1\",          \"description\": \"测试appid1\"        },        {          \"value\": \"test2\",          \"description\": \"测试appid2\"        }      ],      \"providers\":[        {          \"name\":\"any\"        }      ]    }]我们可以配置providers为any,这样说明开发者除了可以配置test1、test2外，当配置其他值时，也是允许的针对providers中的name属性，主要有以下类别供选择：            Name      Description                  any      Permits any additional value to be provided.              class-reference      Auto-completes the classes available in the project. Usually constrained by a base class that is specified by the target parameter.              handle-as      Handles the property as if it were defined by the type defined by the mandatory target parameter.              logger-name      Auto-completes valid logger names and logger groups. Typically, package and class names available in the current project can be auto-completed as well as defined groups.              spring-bean-reference      Auto-completes the available bean names in the current project. Usually constrained by a base class that is specified by the target parameter.              spring-profile-name      Auto-completes the available Spring profile names in the project.      附录  Spring Boot框架中如何优雅的注入实体Bean  Spring Boot Configuration Metadata Document"
  },
  
  {
    "title": "有意思的两段java代码",
    "url": "/posts/funin-java8/",
    "categories": "Java",
    "tags": "",
    "date": "2020-12-06 00:00:00 +0800",
    





    
    "snippet": "首先，创建一个实体类Order对象，代码如下：public class Order{        private String orderNo;        private String name;        public Order(){            setOrderNo(\"order:\"+ UUID.randomUUID().toString());          ...",
    "content": "首先，创建一个实体类Order对象，代码如下：public class Order{        private String orderNo;        private String name;        public Order(){            setOrderNo(\"order:\"+ UUID.randomUUID().toString());            setName(\"name:\"+UUID.randomUUID().toString());        }        public String getOrderNo() {            return orderNo;        }        public void setOrderNo(String orderNo) {            this.orderNo = orderNo;        }        public String getName() {            return name;        }        public void setName(String name) {            this.name = name;        }}第一个 方法，使用for循环遍历查找，即使找到也不做任何事，代码片段如下：private static void test2(){        List&lt;Order&gt; orderList=new ArrayList&lt;&gt;();        for (int i=0;i&lt;1000;i++){            orderList.add(new Order());        }        System.out.println(\"aaaaa\");        boolean flag=true;        AtomicLong atomicLong=new AtomicLong(0);        do {            //遍历            for (Order order:orderList){                if (order.getName().equals(\"abc\")){                    //find but do nothing                    Optional.of(order);                }            }            //orderList.stream().filter(order -&gt; order.getName().equals(\"abc\")).findFirst();            long value=atomicLong.incrementAndGet();            if (value&gt;10000L){                System.out.println(\"推出\");                flag=false;            }        }while (flag);}第二个方法，使用java8中的lambda表达式stream中的filter进行查找,代码如下：private static void test1(){        List&lt;Order&gt; orderList=new ArrayList&lt;&gt;();        for (int i=0;i&lt;1000;i++){            orderList.add(new Order());        }        System.out.println(\"aaaaa\");        boolean flag=true;        AtomicLong atomicLong=new AtomicLong(0);        do {            //遍历            orderList.stream().filter(order -&gt; order.getName().equals(\"abc\")).findFirst();            long value=atomicLong.incrementAndGet();            if (value&gt;10000L){                System.out.println(\"推出\");                flag=false;            }        }while (flag);}两段代码如果不设置java的Xmx参数，都能正常运行，假设设置参数java -Xmx2m那么第二段使用java8的lambda表达式的程序将会报错，抛出异常Exception in thread \"main\" java.lang.InternalError: zero_L=Lambda(a0:L)=&gt;{    t1:L=LambdaForm.identity_L((null));t1:L}\tat java.lang.invoke.MethodHandleStatics.newInternalError(MethodHandleStatics.java:127)\tat java.lang.invoke.LambdaForm.compileToBytecode(LambdaForm.java:660)\tat java.lang.invoke.LambdaForm.prepare(LambdaForm.java:635)\tat java.lang.invoke.MethodHandle.&lt;init&gt;(MethodHandle.java:461)\tat java.lang.invoke.BoundMethodHandle.&lt;init&gt;(BoundMethodHandle.java:58)\tat java.lang.invoke.SimpleMethodHandle.&lt;init&gt;(SimpleMethodHandle.java:37)\tat java.lang.invoke.SimpleMethodHandle.make(SimpleMethodHandle.java:41)\tat java.lang.invoke.LambdaForm.createIdentityForms(LambdaForm.java:1783)\tat java.lang.invoke.LambdaForm.&lt;clinit&gt;(LambdaForm.java:1833)\tat java.lang.invoke.DirectMethodHandle.makePreparedLambdaForm(DirectMethodHandle.java:222)\tat java.lang.invoke.DirectMethodHandle.preparedLambdaForm(DirectMethodHandle.java:187)\tat java.lang.invoke.DirectMethodHandle.preparedLambdaForm(DirectMethodHandle.java:176)\tat java.lang.invoke.DirectMethodHandle.make(DirectMethodHandle.java:83)\tat java.lang.invoke.MethodHandles$Lookup.getDirectMethodCommon(MethodHandles.java:1655)\tat java.lang.invoke.MethodHandles$Lookup.getDirectMethodNoSecurityManager(MethodHandles.java:1612)\tat java.lang.invoke.MethodHandles$Lookup.getDirectMethodForConstant(MethodHandles.java:1797)\tat java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1746)\tat java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:477)\tat com.github.xiaoymin.Java8Test.test1(Java8Test.java:63)\tat com.github.xiaoymin.Java8Test.main(Java8Test.java:24)Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\tat jdk.internal.org.objectweb.asm.ByteVector.&lt;init&gt;(ByteVector.java:84)\tat jdk.internal.org.objectweb.asm.MethodWriter.visitAnnotation(MethodWriter.java:555)\tat java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCodeBytes(InvokerBytecodeGenerator.java:640)\tat java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCode(InvokerBytecodeGenerator.java:618)\tat java.lang.invoke.LambdaForm.compileToBytecode(LambdaForm.java:654)\t... 18 more*** java.lang.instrument ASSERTION FAILED ***: \"!errorOutstanding\" with message can't create byte arrau at JPLISAgent.c line: 813*** java.lang.instrument ASSERTION FAILED ***: \"!errorOutstanding\" with message can't create byte arrau at JPLISAgent.c line: 813*** java.lang.instrument ASSERTION FAILED ***: \"!errorOutstanding\" with message can't create byte arrau at JPLISAgent.c line: 813那么，是否可以认为在超过2层的for循环中，对于集合的筛选或者等其他各种操作，应该禁用java8的stream操作？因为一旦外层for循环次数较多，java8中的stream操作将会创造很多临时对象，必然导致JVM频繁的GC操作！！"
  },
  
  {
    "title": "第一篇 Redis常用数据结构介绍及基本操作",
    "url": "/posts/redis-1/",
    "categories": "Redis",
    "tags": "",
    "date": "2020-11-29 00:00:00 +0800",
    





    
    "snippet": "目前Redis支持的主要数据结构包含5种,分别是：  字符串(string)  散列(hash)  列表(list)  集合(set)  有序集合(sorted set)1.1 常用数据结构介绍1.1.1 字符串(String)字符串结构是开发人员平常使用最多的结构,同时也是最简单的，它的值不仅仅是字符串,也可以是数值.常用命令包括：GET、SET、INCR、DECR、MGET等等主要应用场...",
    "content": "目前Redis支持的主要数据结构包含5种,分别是：  字符串(string)  散列(hash)  列表(list)  集合(set)  有序集合(sorted set)1.1 常用数据结构介绍1.1.1 字符串(String)字符串结构是开发人员平常使用最多的结构,同时也是最简单的，它的值不仅仅是字符串,也可以是数值.常用命令包括：GET、SET、INCR、DECR、MGET等等主要应用场景：字符串是最常见的数据类型之一,普通的键/值存储可以使用该数据结构进行存储.从而可以完全实现当前的Memcached所实现的功能并提高效率。还可以享受Redis的定时持久性，操作日志和复制功能。除了提供GET，SET，INCR，DECR等操作外，Redis还提供以下功能：  获取字符串的长度  字符串的内容进行追加  设置并获取一部分字符串  设置并获取字符串某一个bit  批量设置一系列字符串的内容常用的方案：使用该数据结构缓存程序计数器，例如：微博数量、粉丝数量等等1.1.2 散列(Hash)常用命令：HGET、HSET、HGETALL等Hash和java语言中的Map集合结构很相似,只不过在Redis中,一个Hash结构需要一个key进行关联，数据结构有点类似于如下图：上图中黑色加粗的key1所代表的是Redis中存储的键值,而虚线框中的key1所代表的是Hash数据结构中的键值简单操作如下：127.0.0.1:6379&gt; hget tenant tenantId(nil)127.0.0.1:6379&gt; hset tenant tenantId abc(integer) 1127.0.0.1:6379&gt; hset tenant title test(integer) 1127.0.0.1:6379&gt; hget tenant tenantId\"abc\"127.0.0.1:6379&gt; hgetall tenant1) \"tenantId\"2) \"abc\"3) \"title\"4) \"test\"127.0.0.1:6379&gt;假设我们需要存储包含以下信息的用户信息对象数据：用户ID是要查找的键，储值用户对象包含名称，年龄，生日等信息，如果要以普通的键/值结构进行存储，主要有以下两种存储方法：      第一种方法是将用户的ID作为Redis中的Key,值则是序列号的用户对象，这样做的缺点是在存储和获取时,增加了序列化/反序列化的成本,如果要修改用户的某一个属性时,则需要对整个对象进行操作，在并发条件下,会出现CAS之类的问题.        第二种方法是将多少个该用户信息对象的成员保存到键值数目中，其中用户id +相应属性的名称作为唯一标识符来获取相应属性的值，尽管这样做的代价是序列化和并发性被省略，但是用户ID被重复存储，如果存在大量此类数据，则存在内存大量浪费的情况。  因此，Redis提供的哈希是解决此问题的好方法，Redis哈希实际上是内部存储的值作为哈希图，并提供对映射成员接口的直接访问，例如：也就是说，键仍然是用户ID，值是地图，地图键是属性名称的成员，值是属性值，以便可以通过其内部地图键直接修改和访问数据（Redis称为内部映射键字段），这意味着可以通过键（用户ID）+字段（属性标签）来操纵相应的属性数据，而无需重复存储数据，也没有序列化和并发修改控制的问题。是一个很好的解决方案。还需要注意的是，Redis提供了一个可以直接获取所有属性数据的接口（Hgetall），但是如果内部映射具有大量成员，则涉及遍历整个内部映射，这可能很耗时由于Redis单线程模型。其他客户端请求根本没有响应，这需要格外注意。使用情况：存储部分更改数据，例如用户信息。1.1.3 列表(list)Redis的列表结构,存放一个string类型的链表.常用命令：lpush、rpush、lpop、rpop、lrange等应用场景：例如一个网站上的粉丝列表、监控列表、消息队列、日志收集器list底层是一个双向链接的数据结构，相信自己具有数据结构知识的人应该能够理解其结构。使用列表结构，我们可以轻松实现最新消息排名和其他功能。也可以用作消息队列，你可以使用列表的推操作将任务放置在列表中，然后工作线程使用弹出操作将任务取出。 Redis还提供了用于操作列表的一部分的API，您可以直接查询以从列表的一部分中删除元素。简单命令操作：127.0.0.1:6379&gt; lpush list-user uid001(integer) 1127.0.0.1:6379&gt; lpush list-user uid002(integer) 2127.0.0.1:6379&gt; lrange list-user 0 11) \"uid002\"2) \"uid001\"127.0.0.1:6379&gt; rpush list-user uid003(integer) 3127.0.0.1:6379&gt; lrange list-user 0 21) \"uid002\"2) \"uid001\"3) \"uid003\"127.0.0.1:6379&gt; lpop list-user\"uid002\"127.0.0.1:6379&gt; llen list-user(integer) 2127.0.0.1:6379&gt; lrange list-user 0 21) \"uid001\"2) \"uid003\"127.0.0.1:6379&gt; rpush list-user uid004(integer) 3127.0.0.1:6379&gt; llen list-user(integer) 3127.0.0.1:6379&gt; lrange list-user 0 21) \"uid001\"2) \"uid003\"3) \"uid004\"127.0.0.1:6379&gt; rpop list-user\"uid004\"127.0.0.1:6379&gt; lrange list-user 0 21) \"uid001\"2) \"uid003\"127.0.0.1:6379&gt;   1.1.4 集合(Set)Set对外提供的功能类似于列表(list)，但是Set更加轻量级(对于内存来说),Set存储的元素是不重复的也可以根据不同的Set集合取交集、并集等常用操作命令：sadd、smembers、scard、sinter、sdiff、srem等常见命令操作：127.0.0.1:6379&gt; sadd myset a1 a2 a3 a4 a5 a6 a7(integer) 7127.0.0.1:6379&gt; smembers myset1) \"a6\"2) \"a1\"3) \"a2\"4) \"a3\"5) \"a5\"6) \"a7\"7) \"a4\"127.0.0.1:6379&gt; 比如在微博系统中,每一个用户都会有一个关注列表,此时有如下需求：  如何找出两个用户共同关注的人  如何找出用户1与用户2关注的不同的人假设用户1的关注列表中有：u1、u2、u3、u4、u5、u6用户2的关注用户列表中有：u2、u5、u7、u8从上面的结果来看,用户1和用户2共同关注的用户有：u2\\u5用户1关注的不同的人：u1\\u3\\u4\\u6用户2关注的不同的人：u7\\u8通过Redis的set集合来进行实现,命令如下：# 先集合初始化 u1set \\u2set127.0.0.1:6379&gt; sadd u1set u1 u2 u3 u4 u5 u6(integer) 6127.0.0.1:6379&gt; sadd u2set u2 u5 u7 u8(integer) 4127.0.0.1:6379&gt; smembers u1set1) \"u4\"2) \"u1\"3) \"u2\"4) \"u3\"5) \"u6\"6) \"u5\"127.0.0.1:6379&gt; smembers u2set1) \"u7\"2) \"u5\"3) \"u8\"4) \"u2\"# 找出u1与u2用户关注的不同人的集合127.0.0.1:6379&gt; sdiff u1set u2set1) \"u3\"2) \"u6\"3) \"u1\"4) \"u4\"# 找出u2与u1用户关注的不同人的集合127.0.0.1:6379&gt; sdiff u2set u1set1) \"u7\"2) \"u8\"# u1\\u2共同关注的人127.0.0.1:6379&gt; sinter u1set u2set1) \"u5\"2) \"u2\"127.0.0.1:6379&gt;  1.1.5 有序集合(Sorted Set)有序集合的数据结构类似于集合与哈希之间的混合体,与集合一样,其元素是由唯一非重复的字符串组成.但是集合(Set)中的元素没有排序,而有序集合排序后,其中的每个元素都与一个浮点数值相关联(这也是为什么说该数据结构与哈希结构类似的原因,因为其每个元素都映射了一个排序值)排序规则如下：  如果A和B是两个分数不同的元素,如果A.score&gt;B.store,那么A&gt;B  如果A和B的分数完全相同,由于A字符串在字典上大于B字符串,所以A&gt;B。AB不能相等,因为有序集合的元素具有唯一性常用操作命令：zadd、zrange、zrank、zrangebyscore、zcard简单操作命令：127.0.0.1:6379&gt; zadd mysort 10 ab 40 cb 60 db(integer) 3127.0.0.1:6379&gt; zrange mysort 0 21) \"ab\"2) \"cb\"3) \"db\"127.0.0.1:6379&gt; zadd mysort 55 eb(integer) 1127.0.0.1:6379&gt; zrange mysort 0 31) \"ab\"2) \"cb\"3) \"eb\"4) \"db\"127.0.0.1:6379&gt; zcard mysort(integer) 4127.0.0.1:6379&gt;                  1.2 Java语言Redis客户端介绍及操作Java语言中使用Redis比较常见的客户端：jedis、Redisson、lettuce            客户端      GitHub      star      说明                  jedis      https://github.com/xetorthio/jedis      9.4K      轻量级的java客户端              lettuce      https://github.com/lettuce-io/lettuce-core      3.6K      高级Redis客户端，用于线程安全的同步，异步和反应式使用。 支持群集，前哨，流水线和编解码器。              Redisson      https://github.com/redisson/redisson      14.6k      分布式以及可伸缩性更强      目前使用的Spring Boot框架底层主要提供了jedis、lettuce两种支持,开发者通过yml中进行配置,Spring Boot自动选择，Spring Boot框架目前默认使用lettuce作为Redis的客户端。以下主要是通过以上的客户端java库,对Redis的基本数据类型进行简单的操作1.2.1 使用Jedis进行操作通过Jedis操作Redis,根据Jedis提供的构造函数,主要有三种方式获取Jedis对象的实例  根据Redis的ip地址、端口简单创建获取实例  根据连接池配置获取Redis进行操作(推荐做法)  根据集群配置创建Jedis实例获取Redis的操作对象先来看第一种简单的创建Jedis对象的方式，代码如下：//Redis的ip及端口号Jedis simple=new Jedis(\"localhost\",6379);//如果Redis设置了密码,此处需要设置密码,反之则不用simple.auth(\"123456\");创建JedisPool连接池对象,从连接池获取Jedis实例，代码如下：GenericObjectPoolConfig poolConfig=new GenericObjectPoolConfig();//连接池中的最大空闲连接poolConfig.setMaxIdle(8);//连接池最大连接数（使用负值表示没有限制）poolConfig.setMaxTotal(8);// 连接池中的最小空闲连接poolConfig.setMinIdle(0);//连接池最大阻塞等待时间（使用负值表示没有限制）poolConfig.setMaxWaitMillis(-1);//jedisPool只需要初始化1次即可，每次获取Jedis直接调用getResource方法从连接池中获取JedisPool jedisPool=new JedisPool(poolConfig,\"localhost\",6379,5000,\"123456\");Jedis jedis=jedisPool.getResource();如果我们的Redis是集群部署,此时,我们可以通过集群的配置获取Jedis对象以操作Redis，代码如下：//创建连接池对象GenericObjectPoolConfig poolConfig=new GenericObjectPoolConfig();//连接池中的最大空闲连接poolConfig.setMaxIdle(8);//连接池最大连接数（使用负值表示没有限制）poolConfig.setMaxTotal(8);// 连接池中的最小空闲连接poolConfig.setMinIdle(0);//连接池最大阻塞等待时间（使用负值表示没有限制）poolConfig.setMaxWaitMillis(-1);//创建集群Set&lt;HostAndPort&gt; nodes=new HashSet&lt;&gt;();HostAndPort hostAndPort=new HostAndPort(\"192.168.0.11\",133);HostAndPort hostAndPort1=new HostAndPort(\"192.168.0.12\",133);nodes.add(hostAndPort);nodes.add(hostAndPort1);//1、connectionTimeout 连接超时时间//2、soTimeout 读取数据超时时间//3、maxAttempts 错误时最大尝试次数//4、password 密码//创建集群对象JedisCluster jedisCluster=new JedisCluster(nodes,2000,20000,3,\"123456\",poolConfig);不管是集群方式或者是连接池等,最终操作Redis的数据结构在客户端都是差不多的,接下来以Jedis为例来操作Redis的五种不同数据结构字符串(String)常用命令包括：GET、SET、INCR、DECR、MGET等等字符串操作直接看以下代码：Jedis jedis=getSimpleJedis();//获取stringString value=jedis.get(\"answertoken_abc\");System.out.println(value);//设置string类型的key-valuejedis.set(\"mykey\",\"myvalue\");//根据SetParams设置，主要包含四种：ex\\nx\\xx\\px//1、ex:设置键key的过期时间，单位时秒//2、px:设置键key的过期时间，单位毫秒//3、nx:只有键key不存在的时候才会设置key的值//4、xx:只有键key存在的时候才会设置key的值//第一种情况,设置一个key值，同时指定过期时间jedis.set(\"mykey\",\"myvalue1\",SetParams.setParams().ex(10));//第二种情况,当key值不存在时进行设置，并且设置过期时间jedis.set(\"mykey\",\"myvalue2\",SetParams.setParams().nx().ex(10));//第三种情况,当key值存在时进行设置,并且设置过期时间(分布式锁场景)jedis.set(\"mykey\",\"myvalue3\",SetParams.setParams().xx().ex(10));//自增操作jedis.set(\"mykey\",\"1\");//自增+1jedis.incr(\"mykey\");//自增+njedis.incrBy(\"mykey\",10);System.out.println(jedis.get(\"mykey\"));//自减操作jedis.decr(\"mykey\");//自减-Njedis.decrBy(\"mykey\",10);System.out.println(jedis.get(\"mykey\"));通过上面jedis对象对string结构提供的API方法进行操作还是非常方便的。散列(hash)常用命令：HGET、HSET、HGETALL等在Jedis客户端中操作Redis的hash结构和在命令行中差不多，jedis封装的api命令几乎没有什么区别java开发者在操作时，一个hash理解为在Java语言中的Map数据结构即可。//操作hashJedis jedis=getSimpleJedis();//赋值操作        String hashKey=\"myhashkey\";Map&lt;String,String&gt; values=new HashMap&lt;&gt;();values.put(\"name\",\"张三\");values.put(\"age\",\"13\");//批量一次性设置has的值jedis.hset(hashKey,values);//单个设置jedis.hset(hashKey,\"title\",\"Jedis牛逼\");//get操作//获取单个String hvalue=jedis.hget(hashKey,\"name\");//获取整个Map&lt;String,String&gt; hvalues=jedis.hgetAll(hashKey);//删除操作//提供可变数组，删除多个hash中的key值String[] hdelKeys=new String[]{\"age\",\"name\"};//删除某hash中的keyjedis.hdel(hashKey,hdelKeys);//删除整个hashjedis.del(hashKey);需要注意的是，针对批量设置hash值的操作，需要Redis版本大于等于4.0.0版本  As of Redis 4.0.0, HSET is variadic and allows for multiple field/value pairs.列表(list)列表中常用命令：lpush、rpush、lpop、rpop、lrange等//操作listJedis jedis=getSimpleJedis();String listKey=\"mylistkey\";String[] listValues=new String[]{\"a\",\"b\",\"c\"};//放入集合中jedis.lpush(listKey,listValues);//根据区间获取集合中的元素集合List&lt;String&gt; rangeValues=jedis.lrange(listKey,0,2);rangeValues.forEach(s -&gt; System.out.println(s));//从左侧链表取出一个值String lvalue=jedis.lpop(listKey);//此处值应该是cSystem.out.println(\"lpopValue:\"+lvalue);String rvalue=jedis.rpop(listKey);//此处值应该是aSystem.out.println(\"rpopValue:\"+rvalue);//删除jedis.del(listKey);集合(Set)常用操作命令：sadd、smembers、scard、sinter、sdiff、srem等集合(Set)和列表相比较而言，不会存在重复的值。//操作SetJedis jedis = getSimpleJedis();String setKey=\"mysetKey\";//此操作最终只会添加成功3个元素,因为存在abc重复jedis.sadd(setKey,\"abc\",\"ddd\",\"aaa\",\"abc\");Set&lt;String&gt; stringSet=jedis.smembers(setKey);stringSet.stream().forEach(s -&gt; System.out.println(\"SetValue:\"+s));String setKey1=\"mysetKey1\";//添加第二个集合jedis.sadd(setKey1,\"ab1c\",\"ddd\",\"aaa\",\"2abc\");//数量long set1Number=jedis.scard(setKey1);System.out.println(\"集合2数量:\"+set1Number);//比较第1个集合与其它集合的区别元素Set&lt;String&gt; diffSets=jedis.sdiff(setKey,setKey1);diffSets.stream().forEach(s -&gt; System.out.println(\"diffValue:\"+s));//取交集Set&lt;String&gt; sinters=jedis.sinter(setKey,setKey1);sinters.stream().forEach(s -&gt; System.out.println(\"sinterValue:\"+s));//取并集Set&lt;String&gt; sunions=jedis.sunion(setKey,setKey1);sunions.stream().forEach(s -&gt; System.out.println(\"sunionsValue:\"+s));//获取两个集合的并集jedis.del(setKey,setKey1);有序集合(Sorted Set)常用操作命令：zadd、zrange、zrank、zrangebyscore、zcard//操作SetJedis jedis = getSimpleJedis();String zsetKey=\"myzsetKey\";jedis.zadd(zsetKey,10,\"abc\");//多个一起添加Map&lt;String,Double&gt; zvalues=new HashMap&lt;&gt;();zvalues.put(\"c1\",230D);zvalues.put(\"c2\",110D);zvalues.put(\"c3\",130D);zvalues.put(\"c4\",21D);jedis.zadd(zsetKey,zvalues);//统计数量long size=jedis.zcard(zsetKey);System.out.println(\"数据量：\"+size);//获取Set&lt;String&gt; stringSet=jedis.zrange(zsetKey,0,2);stringSet.stream().forEach(s -&gt; System.out.println(s));//倒序System.out.println(\"倒序\");stringSet=jedis.zrevrange(zsetKey,0,2);stringSet.stream().forEach(s -&gt; System.out.println(s));jedis.del(zsetKey);jedis.close();以上操作仅仅只是部分api的展示，更多的操作开发者需要自行探索，结合Redis的命令介绍，才能更多的加深理解。1.2.2 使用Lettuce操作Redislettuce可能大家不常见，但是我们基于Spring Boot来操作的StringRedisTemplate大家肯定熟悉，如果开发者默认没有选择，那么StringRedisTemplate底层依赖的就是lettuce来作为默认依赖，最终来操作Redis。"
  },
  
  {
    "title": "跨语言跨平台聚合 OpenAPI 文档从来没有这么简单过",
    "url": "/posts/easy-aggregation-openapi/",
    "categories": "Blog",
    "tags": "",
    "date": "2020-11-26 00:00:00 +0800",
    





    
    "snippet": "Knife4j一直致力于将目前的Ui提供给更多的平台或者别的语言使用而努力，经过这么长时间的发展，Knife4j提供的轻量级聚合中间件终于诞生了，自2.0.8版本开始，Knife4j提供了knife4j-aggregation-spring-boot-starter组件，该组件是一个基于Spring Boot系统的starter，他提供了以下几种能力：  最轻量级、最简单、最方便的聚合Ope...",
    "content": "Knife4j一直致力于将目前的Ui提供给更多的平台或者别的语言使用而努力，经过这么长时间的发展，Knife4j提供的轻量级聚合中间件终于诞生了，自2.0.8版本开始，Knife4j提供了knife4j-aggregation-spring-boot-starter组件，该组件是一个基于Spring Boot系统的starter，他提供了以下几种能力：  最轻量级、最简单、最方便的聚合OpenApi规范的中间件  让所有的基于Spring Boot的Web体系拥有了轻松聚合OpenApi的能力  提供4种模式供开发者选择          基于本地静态JSON文件的方式聚合OpenAPI      基于云端HTTP接口的方式聚合      基于Eureka注册中心的方式聚合      基于Nacos注册中心的方式聚合        基于该starter发布了Docker镜像，跨平台与语言让开发者基于此Docker镜像轻松进行聚合OpenAPI规范  完美兼容所有Spring Boot版本，没有兼容性问题  开发者可以彻底放弃基于Zuul、Spring Cloud Gateway等复杂的聚合方式  兼容OpenAPI2规范以及OpenAPI3规范本文主要介绍5种模式来使用Knife4j提供的聚合组件进行OpenAPI文档的聚合  Disk本地文件模式  Cloud云端接口模式  Eureka注册中心  Nacos注册中心  Docker镜像跨语言Disk模式基于Disk模式聚合是最简单的，开发者只需要在Spring Boot的项目中存在OpenAPI规范的JSON文件即可进行聚合完整代码请参考knife4j-aggregation-disk-demo主要步骤如下：1、创建Spring Boot项目，引入Knife4jAggregation的依赖包，完整pom文件如下：&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.4.0&lt;/version&gt;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;    &lt;/parent&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-aggregation-disk-demo&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;name&gt;knife4j-aggregation-disk-demo&lt;/name&gt;    &lt;description&gt;通过基于Spring Boot的工程聚合任意微服务接口文档&lt;/description&gt;    &lt;properties&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;            &lt;artifactId&gt;knife4j-aggregation-spring-boot-starter&lt;/artifactId&gt;            &lt;version&gt;2.0.8&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;2、配置yml配置文件，如下：server:  port: 19081knife4j:  enableAggregation: true  disk:    enable: true    routes:      - name: 用户        location: classpath:openapi/user.json工程目录如下图：3、启动项目，访问doc.html进行查看，效果图如下Cloud模式聚合OpenAPI文档Cloud(云端)模式和Disk模式大同小异，主要的区别是获取OpenAPI规范的方式换成了基于HTTP接口而已完整代码请参考knife4j-aggregation-cloud-demo本次Cloud聚合以Knife4j目前部署的线上demo为例，本地聚合在线的OpenAPI，并且可以本地调试，Knife4jAggregation组件会自动帮助我们转发任意取目前Knife4j的线上demo两个OpenAPI规范接口地址：  http://knife4j.xiaominfo.com/v2/api-docs?group=2.X版本  http://knife4j.xiaominfo.com/v2/api-docs?group=3.默认接口主要步骤如下：1、创建Spring Boot项目，引入Knife4jAggregation的依赖包，完整pom文件如下：&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.4.0&lt;/version&gt;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;    &lt;/parent&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-aggregation-disk-demo&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;name&gt;knife4j-aggregation-disk-demo&lt;/name&gt;    &lt;description&gt;通过基于Spring Boot的工程聚合任意微服务接口文档&lt;/description&gt;    &lt;properties&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;            &lt;artifactId&gt;knife4j-aggregation-spring-boot-starter&lt;/artifactId&gt;            &lt;version&gt;2.0.8&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;2、配置yml配置文件，如下：server:  port: 19081knife4j:  enableAggregation: true  cloud:    enable: true    routes:      - name: 测试分组1        uri: knife4j.xiaominfo.com        location: /v2/api-docs?group=2.X版本      - name: 测试分组2        uri: knife4j.xiaominfo.com        location: /v2/api-docs?group=3.默认接口3、启动项目，访问doc.html进行查看，效果图如下：聚合效果：在线调试：Eureka注册中心聚合OpenAPI文档从Eureka注册中心进行聚合的模式和Cloud模式大同小异，主要的区别是通过serviceName来替代了真实的目标服务地址，而是从Eureka注册中心进行动态获取完整代码请参考knife4j-aggregation-eureka-demo先来看整个工程的目录：工程目录说明如下：            工程      说明                  service-server      Eureka注册中心              service-user      一个非常简单的用户服务，包含用户接口              service-order      一个非常简单的订单服务，包含订单接口              service-doc      聚合文档工程，也是一个Spring Boot工程，不过需要注意的是基于web的，而非webflux      Eureka注册中心以及service-user、order等都非常简单，按照注册中心、用户服务、订单服务依次进行启动即可此时，我们访问Eureka的主页，最终能看到我们的注册中心存在两个服务，如下图：那么，我们的目标是什么呢？从Eureka注册中心直接进行聚合，也就是将用户服务、订单服务的OpenAPI文档聚合在一起进行展示主要步骤如下：1、在service-doc工程引入knife4j-aggregation-spring-boot-starter依赖&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;com.xiaominfo.swagger&lt;/groupId&gt;        &lt;artifactId&gt;knife4j-aggregation-eureka-demo&lt;/artifactId&gt;        &lt;version&gt;1.0&lt;/version&gt;        &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt;    &lt;/parent&gt;    &lt;groupId&gt;com.xiaominfo.swagger&lt;/groupId&gt;    &lt;artifactId&gt;service-doc&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;name&gt;service-doc&lt;/name&gt;    &lt;description&gt;Eureka聚合&lt;/description&gt;    &lt;properties&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;            &lt;artifactId&gt;knife4j-aggregation-spring-boot-starter&lt;/artifactId&gt;            &lt;version&gt;2.0.8&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;2、配置yml配置文件，如下：server:  port: 10909knife4j:  enableAggregation: true  eureka:    enable: true    serviceUrl: http://localhost:10000/eureka/    routes:      - name: 订单服务        serviceName: service-order        location: /v2/api-docs?group=default        servicePath: /order      - name: 用户体系        serviceName: service-user        location: /aub/v2/api-docs?group=default        servicePath: /3、启动项目，访问doc.html进行查看，效果图如下：聚合效果：在线调试：只需要简单的配置，就轻松的将Eureka注册中心的各个服务进行了聚合，是不是比Spring Cloud Gateway、Zuul更加简单和轻量呢？关于Eureka的更多配置需要开发者参考文档Nacos注册中心聚合OpenAPI文档Nacos的配置和Eureka几乎一模一样，唯一不同的区别是在yml进行配置的时候，使用的是knife4j.nacos开头，其他基本都是一样关于Nacos的更多配置需要开发者参考文档基于Knife4j的Docker镜像快速聚合OpenAPI在前面的实战文章中，更多的是面向Java开发者，通过Spring Boot框架，快速聚合OpenAPI文档。那么其他语言能否也能这么方便的使用Knife4j呢？答案是肯定的，Knife4j为了让其他语言非常方便的使用Knife4j来渲染聚合OpenAPI文档，在DockerHub中推送了Knife4j的镜像，镜像地址：https://hub.docker.com/repository/docker/xiaoymin/knife4j如果你的本机或者服务器安装了Docker，那么利用Knife4j的镜像来聚合OpenAPI将会非常方便首先需要将镜像从DockerHub拉到本地，命令如下：docker pull xiaoymin/knife4j:latest如果pull速度比较慢的话，开发者可以配置镜像源(/etc/docker/daemon.json){  \"registry-mirrors\": [    \"https://registry.docker-cn.com\",    \"http://hub-mirror.c.163.com\",    \"https://3laho3y3.mirror.aliyuncs.com\",    \"https://mirror.ccs.tencentyun.com\"  ]}镜像下载到本地机器后，下面将详细介绍如何通过Knife4j的镜像实现上面文章介绍的4中不同方式的聚合OpenAPI文档镜像说明Knife4j的镜像是一个基于Spring Boot框架开发的Web项目，对外默认端口8888源码地址：https://gitee.com/xiaoym/knife4j/tree/v2/knife4j-aggregation-dockerFROM openjdk:8-jdk-alpineLABEL version=\"2.0\"LABEL released-date=2020/11/25LABEL author=\"xiaoymin@foxmail.com\"LABEL description=\"Knife4jAggregation OpenAPI,RunAnyWhere!!!\"MAINTAINER xiaoyminRUN mkdir /app# Disk模式数据挂载目录RUN mkdir /app/dataADD src/main/resources/application.yml /app/app.ymlADD target/knife4j-aggregation-docker-1.0.jar /app/app.jarENTRYPOINT [\"java\",\"-jar\",\"-Djava.security.egd=file:/dev/./urandom\",\"-Duser.timezone=Asia/Shanghai\",\"/app/app.jar\",\"--spring.config.location=/app/app.yml\"]#EXPOSE 8888:从Knife4j的Dockerfile文件中，我们可以看到为Knife4j的应用创建了一个/app目录和/app/data目录，用来存放jar文件和yml配置文件，该目录是通过外部文件与Docker容器进行挂载关联的关键。Disk模式Disk模式主要是从本地聚合OpenAPI规范，那么如何利用Knife4j的容器进行渲染呢？这里就要用到我们刚刚上面说的文件挂载第一步：在服务器(宿主机)上创建相关目录，例如：/home/openapi我们在该目录下主要存放两种类型的文件目录，1种是Knife4j镜像文件需要的yml配置文件，第二种是存放OpenAPI的规范JSON,目录结构如下：[root@izbpc3 openapi]# pwd/home/openapi[root@izbpc3 openapi]# lltotal 8-rw-r--r-- 1 root root  241 Nov 25 19:42 app.ymldrwxr-xr-x 2 root root 4096 Nov 25 19:41 data[root@izbpc3 openapi]# cd data[root@izbpc3 data]# lltotal 256-rw-r--r-- 1 root root  21448 Nov 25 19:41 open-api.json-rw-r--r-- 1 root root 237303 Nov 25 19:41 openapi.jsonDisk模式我们主要需要做的是修改app.yml配置文件中的配置，指定Knife4j的镜像从本地加载指定的openapi.json，通过界面显示app.yml配置修改如下：server:  port: 8888knife4j:  enableAggregation: true  disk:    enable: true    routes:      - name: 用户AAAAAAAAAAA        location: /app/data/open-api.json      - name: 用户BBBBBBBBBBBB        location: /app/data/openapi.json这里需要注意的是1、location我们使用的是容器的目录/app,我们最终创建容器的时候会将宿主机的目录(/home/openapi/data)挂载给容器，达到文件共享的目的2、在app.yml配置中指定的端口是容器的端口，Knife4j默认端口8888，如果开发者使用该配置并且修改了端口，那么需要在端口映射的时候也相应的进行修改第二步：启动Knife4j容器查看效果通过Docker命令创建容器，命令如下：[root@izbx23 app]# docker run -itd --name myopenapi -p 18002:8888 -v /home/openapi/app.yml:/app/app.yml -v /home/openapi/data:/app/data xiaoymin/knife4j3f0ed4cde46dd8a625e0338bc8cb1688059c7169447bda5681a34d93e2ba7c3e[root@izbx23 app]# docker ps CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                     NAMESe678bccd4d66        xiaoymin/knife4j    \"java -jar -Djava.se…\"   3 seconds ago       Up 2 seconds        0.0.0.0:18002-&gt;8888/tcp   myopenapi  –name命令是指定一个别名  -p代表端口映射 18002是宿主机端口号，8888是容器的端口号，  -v参数则是将本地目录挂载和容器共享,此处主要挂载两个文件，一个是app.yml配置文件，一个是openapi.json文件此时，我们通过端口号进行访问：http://localhost:18002/doc.html效果图如下：容器创建成功后，我们可以访问容器的文件系统，通过命令如下：[root@izbx23 conf.d]# docker exec -it myopenapi sh/ # lsapp    bin    dev    etc    home   lib    media  mnt    opt    proc   root   run    sbin   srv    sys    tmp    usr    var/ # cd app/app # lsapp.jar  app.yml  data/app # cd data/app/data # lsopen-api.json  openapi.json/app/data # 我们在容器中的文件系统中/app/data目录中，其实可以看到，这个目录中的文件和我们通过创建容器时-v参数挂载的目录文件是一致的。Cloud模式Cloud模式就相对简单多了，我们只需要修改当前的app.yml配置文件即可，然后创建容器时进行覆盖即可任意取目前Knife4j的线上demo两个OpenAPI规范接口地址：  http://knife4j.xiaominfo.com/v2/api-docs?group=2.X版本  http://knife4j.xiaominfo.com/v2/api-docs?group=3.默认接口配置yml配置文件，如下：server:  port: 8888knife4j:  enableAggregation: true  cloud:    enable: true    routes:      - name: cloud1        uri: knife4j.xiaominfo.com        location: /v2/api-docs?group=2.X版本      - name: cloud2        uri: knife4j.xiaominfo.com        location: /v2/api-docs?group=3.默认接口通过Docker命令创建容器，命令如下：[root@izbx23 openapi]# docker run -itd --name cloudapi -p 18002:8888 -v /home/openapi/app.yml:/app/app.yml xiaoymin/knife4j6b81844e0c605704eef3ffcb207e090a1139a9fbc8dcf0a43efdcb60f41d327c[root@izbx23 openapi]# docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                     NAMES6b81844e0c60        xiaoymin/knife4j    \"java -jar -Djava.se…\"   4 seconds ago       Up 3 seconds        0.0.0.0:18002-&gt;8888/tcp   cloudapi  –name命令是指定一个别名(cloudapi)  -p代表端口映射 18002是宿主机端口号，8888是容器的端口号，  -v参数则是将本地目录挂载和容器共享,此处只需要覆盖app.yml配置文件即可，因为我们的OpenAPI数据来源于HTTP接口此时，我们通过端口号进行访问：http://localhost:18002/doc.html效果图如下：注册中心(Eureka &amp;&amp; Nacos)至于从注册中心(Eureka &amp;&amp; Nacos)进行OpenAPI的聚合和Cloud模式下一样，开发者只需要修改app.yml配置文件，然后通过-v参数进行挂载覆盖文件即可。更多的配置需要参考聚合组件的文档参数详细介绍文档"
  },
  
  {
    "title": "Knife4j 2.0.8发布,轻量级微服务聚合文档中间件诞生",
    "url": "/posts/knife4j-2.0.8-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2020-11-22 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://xiaoym.gitee.io/knife4j/效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：ht...",
    "content": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://xiaoym.gitee.io/knife4j/效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化1、构建响应curl时，去除Knife4j自定义添加的部分Header头2、增加自定义主页的增强配置，开发者可以提供一个Markdown文档，用来自定义Home主页显示的内容Gitee #I24ZXIknife4j:\tenable: true\tsetting:\t\t# 是否自定义显示Home主页，默认为false\t\tenableHomeCustom: true\t\t# 自定义主页Home的markdown文档路径,只能设置1个，如果设置为目录，则默认取第一个\t\thomeCustomLocation: classpath:markdown/home.md3、OpenAPI开放接口可以通过增强配置是否显示Gitee #I25273knife4j:\tenable: true\tsetting:\t\t# 是否显示文档中的Open标签栏，默认为true\t\tenableOpenApi: false4、搜索框可以通过增强配置是否显示Gitee #I24ZYYknife4j:\tenable: true\tsetting:\t\t# 是否显示文档中的搜索框，默认为true，即显示\t\tenableSearch: false5、文档最下边的footerkey通过增强配置是否显示，并且可以自定义显示内容Gitee #I24ZYDknife4j:\tenable: true\tsetting:\t\t# 是否不显示Knife4j默认的footer，默认为true(显示)\t\tenableFooter: false\t\t# 是否自定义Footer，默认为false(非自定义)\t\tenableFooterCustom: true\t\t# 自定义Footer内容,支持Markdown语法\t\tfooterCustomContent: 中国XXX科技股份有限公司版权所有6、废弃springfox中的控制参数接口/swagger-resources/configuration/ui,针对是否开启Debug调试，通过Knife4j提供的个性化增强配置进行控制knife4j:\tenable: true\tsetting:\t\t# 是否显示调试Tab框架，默认为true(显示)\t\tenableDebug: false7、解决微服务架构下，丢失basePath的问题Gitee #I23NWM、Gitee #I23N6L、Gitee #I25ZTC、GitHub #2868、自定义文档以及自定义Home主页的Markdown支持Html语法Gitee #I24ZZA9、去除文档右上角？号的文档显示Gitee #I24ZYL10、增强配置增加开启动态请求参数配置的配置Gitee #I24EBOknife4j:\tenable: true\tsetting:\t\t# 开启动态请求参数调试,默认为false(不开启)\t\tenableDynamicParameter: true11、如果当前服务只有一个分组的情况下，开发者可以通过配置enableGroup项来控制界面的分组显示Gitee #I25MQG，配置如下：knife4j:\tenable: true\tsetting:\t\t# Ui界面不显示分组元素\t\tenableGroup: false最终效果图如下：12、基础类型的请求参数与响应参数示例显示优化Gitee #I24YKT13、@ApiOperationSupport和@DynamicParameters注解不能同时使用的问题Gitee #I24JWV14、解决V3版本中starter存在冲突的问题Gitee #I2420J15、优化markdown渲染的组件方式。16、离线文档导出移除导出PDF项，导出pdf功能不管是基于markdown或者是word都能轻松实现，因此Knife4j废弃此功能17、OpenAPI3结构中支持表单类型中scheme解析显示为jsonGitee #I24PCZ18、针对Authorize标志的接口，添加锁的icon在接口中进行体现Gitee #I23W0S19、增强配置本地缓存更新策略20、针对禁用文档管理菜单项后，同步禁用右上角个性化菜单的显示。Gitee #I262VN21、请求OpenAPI规范实例接口默认发送一个language的header，如果服务端做了i18n的配置可以根据此header动态返回不同的语言释义。21、解决根据路径设置界面i18n显示时，和服务端增强配置冲突的问题，如果开发者通过url路径来设置界面的i18n显示，则默认以路径中的为准，否则，取后端增强配置的language22、菜单收缩时显示存在异常的问题Gitee #I2646F23、OpenAPI3规范适配支持JSR303支持GitHub #28324、请求参数的数据类型为空的情况下优化，显示默认值string使用方法Java开发使用Knife4j目前有一些不同的版本变化，主要如下：1、如果开发者继续使用OpenAPI2的规范结构，底层框架依赖springfox2.10.5版本，那么可以考虑Knife4j的2.x版本&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索2.X最新版本号--&gt;    &lt;version&gt;2.0.8&lt;/version&gt;&lt;/dependency&gt;2、如果开发者使用OpenAPI3的结构，底层框架依赖springfox3.0.0,可以考虑Knife4j的3.x版本&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索3.X最新版本号--&gt;    &lt;version&gt;3.0.2&lt;/version&gt;&lt;/dependency&gt;3、如果开发者底层框架使用的是springdoc-openapi框架,则需要使用Knife4j提供的对应版本,需要注意的是该版本没有Knife4j提供的增强功能，是一个纯Ui。&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-springdoc-ui&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索3.X最新版本号--&gt;    &lt;version&gt;3.0.2&lt;/version&gt;&lt;/dependency&gt;Knife4jAggregation微服务聚合中间件自2.0.8版本开始，Knife4j提供了轻量级的聚合微服务OpenAPI文档的中间件，可以在任意Spring Boot服务中聚合文档，最简单、最轻量级、最方便的聚合组件&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-aggregation-spring-boot-starter&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索Knife4jAggregation最新版本号--&gt;  &lt;version&gt;2.0.8&lt;/version&gt;&lt;/dependency&gt;该组件提供了4种不同的模式以满足不同语言、不同模式的方式进行OpenAPI文档的聚合四种不同的方式：  Disk本地模式  Cloud云端接口模式  Eureka注册中心模式  Nacos注册中心模式更详细的介绍以及实战使用方法请参考文档特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构,点击预览导出离线Html效果，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁,点击在线预览效果，界面效果如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）"
  },
  
  {
    "title": "Knife4j 2.0.7发布,细节处理",
    "url": "/posts/knife4j-2.0.7-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2020-11-02 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://g...",
    "content": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化1、服务端创建Docket对象时配置globalOperationParameters参数时,header类型不选中或丢失的问题2、如果服务端写会的json参数中包含base64的图片格式，在响应栏增加图片标签直接显示3、springfox升级到2.10.5版本后，针对basePath会在解析时自动追加到path节点，因为以前的版本没有追加,所以会导致重复添加basePath的问题。Gitee #I230K8、Gitee #I23G5V4、导出出md离线文档请求参数部分字段的设置和文档中同步Gitee #I22UFA5、字段参数说明支持html标签样式。Gitee #I22RZ2示例代码：@ApiModelProperty(value = \"奖金名称,记住:&lt;br /&gt;&lt;span style=\\\"color:red\\\"&gt;我很重要&lt;/span&gt;\",example = \"MVP奖杯\")private String name;效果图：6、默认去除小蓝点的版本控制，开发者可以通过在服务端通过配置进行开启,详情请参考增强文档。knife4j:  enable: true  setting:\t#是否开启界面中对某接口的版本控制,如果开启，后端接口变化后Ui界面会存在小蓝点    enableVersion: true 7、可以通过配置重命名界面Swagger Models的命名,详情请参考增强文档，例如：knife4j:  enable: true  setting:    enableSwaggerModels: true    swaggerModelName: 实体类列表8、可以通过配置是否显示调试栏中的AfterScript功能，该属性默认为true,详情请参考增强文档，例如：knife4j:  enable: true  setting:    enableAfterScript: false9、支持@RequestMapping注解中的params参数Gitee #I22J5Q10、3.0版本不支持Authorize的问题Gitee #I22WVM11、增加局部刷新变量的按钮功能，可以通过服务端配置开启Gitee #I22XXI，该属性默认为false,详情请参考增强文档，例如：knife4j:  enable: true  setting:    enableReloadCacheParameter: true12、修复兼容性bug，当升级后，默认Swagger Models以及文档管理功能丢失的问题使用方法Java开发使用Knife4j目前有一些不同的版本变化，主要如下：1、如果开发者继续使用OpenAPI2的规范结构，底层框架依赖springfox2.10.5版本，那么可以考虑Knife4j的2.x版本&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索2.X最新版本号--&gt;    &lt;version&gt;2.0.7&lt;/version&gt;&lt;/dependency&gt;2、如果开发者使用OpenAPI3的结构，底层框架依赖springfox3.0.0,可以考虑Knife4j的3.x版本&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索3.X最新版本号--&gt;    &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;3、如果开发者底层框架使用的是springdoc-openapi框架,则需要使用Knife4j提供的对应版本,需要注意的是该版本没有Knife4j提供的增强功能，是一个纯Ui。&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-springdoc-ui&lt;/artifactId&gt;    &lt;!--在引用时请在maven中央仓库搜索3.X最新版本号--&gt;    &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构,点击预览导出离线Html效果，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁,点击在线预览效果，界面效果如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）"
  },
  
  {
    "title": "Knife4j 2.0.6发布,支持OpenAPI3及Auth2认证",
    "url": "/posts/knife4j-2.0.6-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2020-10-26 00:00:00 +0800",
    





    
    "snippet": "[v2.0.6-2020/10/26 Knife4j 2.0.6发布,支持OpenAPI3及Auth2认证]Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具关键词：OpenAPI3、Auth2.0、AfterScript、Springfox3.0、增强改善文档：https://doc.xiaominfo.com效果(旧版)：http://...",
    "content": "[v2.0.6-2020/10/26 Knife4j 2.0.6发布,支持OpenAPI3及Auth2认证]Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具关键词：OpenAPI3、Auth2.0、AfterScript、Springfox3.0、增强改善文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化2.0.6是继续在上个版本中进行迭代更新,开发者使用OpenAPI2的结构可以直接修改版本号即可进行升级,springfox框架升级到2.10.5  springfox 2.10.5 版本变化：  1、spring-plugin组件升级到2.0.0，移除了guava包  2、@EnableSwagger2注解升级为@EnableSwagger2WebMvcMaven引用：&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;    &lt;!--OpenAPI2.0的开发者继续使用Knife4j 2.x系列的版本--&gt;    &lt;version&gt;2.0.6&lt;/version&gt;&lt;/dependency&gt;1、OAuth2认证功能的支持:简化模式(implicit)、授权码模式(authorization_code)、密码模式(password)、客户端模式(client_credentials),详细规则请参考文档2、针对@RequestBody注解标注的请求实体类，在接口请求参数时是否必须(require)的显示异常的问题Gitee #I1VBGB、Gitee #I1YK2Q、Gitee #I1WCMF、Gitee #I1VDSH、GitHub #2773、针对服务端指定consumes的情况优化，如果服务端不指定,Ui会默认根据参数类型进行适配Gitee #I1VE254、解决在创建Docket对象时赋予Host属性后,文档界面显示接口地址异常的问题Gitee #I1XYG95、微服务网关聚合文档时,自定义分组名称导致增强失败的问题Gitee #I1Y79W6、针对query类型的参数，如果该参数是schema类型,解析该schema为json提作为请求值.Gitee #I1VLHH,如下图：  文档展示：  调试效果：7、调试栏新增AfterScript特性,开发者可根据Knife4j定义的全局变量编写自定义JavaScript脚本,增强接口交互体验Gitee #I1YNU3、Gitee #I1CAAD,关于AfterScript特性可参考文档主要应用场景：  针对JWT类型的接口,调用登录接口后,每个接口请求时带上Token参数,此时可以通过该脚本动态赋值全局token参数,省去复制粘贴的麻烦.假设某一个登录接口响应的JSON内容如下：{  \"code\": 8200,  \"message\": null,  \"data\": {    \"token\": \"1y1tn8tvw93fxixp79dcx0nugixkw4su\"  }}该接口是登录接口,除该接口外其余接口请求都需要带上token的请求头,因此我们访问登录接口后,设置全局Header参数token,此操作Knife4j接下来会为每一个请求接口带上token参数，代码如下：var code=response.data.code;if(code==8200){    //判断,如果服务端响应code是8200才执行操作    //获取token    var token=response.data.data.token;    //1、如何参数是Header，则设置全局Header    ke.global.setHeader(\"token\",token);}8、通过创建Docket对象时设置globalOperationParameters全局参数时,针对header类型的allowableValues不支持下拉框选择的问题Gitee #I1OC0H代码如下：parameters.add(new ParameterBuilder().name(\"header-test\").description(\"balabala\")                .modelRef(new ModelRef(\"string\"))                .parameterType(\"header\")                .allowableValues(new AllowableListValues(Arrays.asList(\"下拉1\", \"下拉2\"), \"string\"))                .required(false).order(1).build());new Docket(DocumentationType.SWAGGER_2)                .host(\"https://www.baidu.com\")                .apiInfo(apiInfo())                .groupName(\"2.X版本\")                .globalOperationParameters(parameters)最终效果：9、离线导出功能板块增加导出OpenAPI的原始JSON格式数据，导出该逻辑分组下所有接口的OpenAPI原始json格式。如下图：10、针对单个接口，提供OpenAPI的源码格式，可以通过复制或者下载该源码格式直接导入POSTMAN进行测试Gitee #I1Z7AP。如下图：11、增强注解@EnableKnfie4j增加Spring Boot中的Conditional条件@ConditionalOnWebApplication,仅在Web环境下加载，避免在使用junit单元测试时出现异常。12、增强模式的改进,主要有两个变化,更加详细的使用规则，开发者请参考文档：      提供spring.factories进行自动装置,开发者可以直接在Spring Boot的配置文件yml或者property等使用属性knife4j.enable:true进行开启使用，配置属性后无需再使用@EnableKnife4j注解        提供spring-configuration.meta.json文件，对Knife4j提供的各个增强配置属性进行注释，方便开发者在配置文件中进行配置，如下图：      13、针对其它文档的配置，开发者可以根据每一个逻辑分组Docket进行配置，其他文档支持自定义文档的分组标题14、接口排序需求无需再Ui界面勾选增强，只需要在配置文件中开启knife4j.enable=true接口，然后使用@ApiSupport注解或者@ApiSort在Controller类上进行使用，优先级@ApiSupport&gt;@ApiSort,该方式更加融合了springfox框架的特性，也更符合对扩展属性扩展的规范，在OpenAPI结构节点增加x-order扩展参数，如下图：15、移除增强扩展接口地址/v2/api-docs-ext,个性化配置及增强通过后端配置文件进行配置即可,通过更加规范的使用增强注解,符合OpenAPI的扩展属性规范。16、其他文档以更加符合OpenAPI的扩展规范进行展示，开发者可以在yml配置文件中配置多个分组文档(前提是knife4j.enable=true),然后再创建的Docket对象中使用Knife4j提供的OpenApiExtensionResolver扩展extension,最终配置的md文件会在文档中进行分组呈现.GitHub #115application.yml配置示例代码如下：knife4j:  enable: true  documents:    -      group: 2.X版本      name: 接口签名      locations: classpath:sign/*    -      group: 2.X版本      name: 另外文档分组请看这里      locations: classpath:markdown/*Java代码：@Configuration@EnableSwagger2WebMvc@Import(BeanValidatorPluginsConfiguration.class)public class SwaggerConfiguration {    private final OpenApiExtensionResolver openApiExtensionResolver;    @Autowired    public SwaggerConfiguration(OpenApiExtensionResolver openApiExtensionResolver) {        this.openApiExtensionResolver = openApiExtensionResolver;    }        @Bean(value = \"defaultApi2\")    public Docket defaultApi2() {        String groupName=\"2.X版本\";        Docket docket=new Docket(DocumentationType.SWAGGER_2)                .host(\"https://www.baidu.com\")                .apiInfo(apiInfo())                .groupName(groupName)                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.new2\"))                //.apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class))                .paths(PathSelectors.any())                .build()            //此处调用openApiExtensionResolver的方法获取extensions集合                .extensions(openApiExtensionResolver.buildExtensions(groupName))                .securityContexts(CollectionUtil.newArrayList(securityContext())).securitySchemes(CollectionUtil.newArrayList(apiKey()));        return docket;    }}最终Ui界面效果图：17、针对使用@ApiModelProperty注解，给予实体String类型的属性字段赋值example示例值json字符串时显示异常的问题GitHub #23318、请求示例和响应示例中的长整形精度丢失的问题GitHub #26919、针对当前接口存在Authorze认证情况下，没有点击该功能时参数不会默认在接口调试中的Bug以及query类型参数始终出现在请求头参数栏的情况Gitee #I1VC4I20、去除Ui界面中个性化设置中的启用增强配置。21、增强注解@ApiOperationSupport与@DynamicResponseParameters同时使用时,动态响应字段丢失的问题Gitee #I22K0R22、离线文档下载失败的问题，变量引用错误导致Gitee #I1W5UBOpenAPI3如果开发者想使用springfox的OpenAPI3的版本,Knife4j此次发布了两个版本,针对3.0版本,Knife4j底层升级springfox组件到springfox3.0.0,并且版本号从3.x系列开始,代表OpenAPI3,以区分2.x系列。Maven引用&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;    &lt;!--如果想使用springfox3.0及OpenAPI3请用3.x版本--&gt;    &lt;version&gt;3.0&lt;/version&gt;&lt;/dependency&gt;针对SpringFox3.0的版本,作者在开发过程中虽然在Ui上对OpenAPI3进行了支持,但是目前springfox3.0还存在诸多的问题，建议开发者慎重使用springfox3。不管是对于OpenApi2以及OpenApi3的支持，目前springfox3在兼容性等方面都存在一些问题,毕竟刚发布一个版本.相对而言,springfox2.x系列的版本较稳定.当Springfox对于3.0的结构相对稳定后,Knife4j的主分支版本会向3.0靠拢。相关ISSUES:  #I1UGH7 swagger 2.9.2 对 javax.validation 支持缺少，可考虑升级到 2.10.5  #I1R9J1 关于支持 Springfox Swagger 3.0.0  #I1VYDM 早日支持下springfox-boot-starter 3.0  #I1X27Y swagger 升级到3.0后的兼容问题  #I1QQYH knife4j-vue-v3 setInstanceBasicPorperties 方法中逻辑问题  #275 springfox-3.0.0与knife4j-2.0.5冲突？  #268 spring boot 2.3.3、springfox 3.0.0与knife4j2.0.4集成报错问题  #265 spring-plugin-core的兼容问题特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构,点击预览导出离线Html效果，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁,点击在线预览效果，界面效果如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）"
  },
  
  {
    "title": "Spring Boot框架中如何优雅的注入实体Bean",
    "url": "/posts/spring-boot-conditional/",
    "categories": "SpringBoot",
    "tags": "",
    "date": "2020-09-23 00:00:00 +0800",
    





    
    "snippet": "在Spring Boot框架中,注入实体Bean是几乎每一个Java程序员都能遇到的事情,因为Spring Boot采用约定优于配置的策略,去除了原来在Spring MVC中通过Xml进行注入的方式,全部通过Java Configuration的编码方式进行实体Bean的注入,因此我们在开发中，对于外部组件、自己封装的业务SDK等等都需要开发者自行将实体Bean注入到Spring的容器中，然...",
    "content": "在Spring Boot框架中,注入实体Bean是几乎每一个Java程序员都能遇到的事情,因为Spring Boot采用约定优于配置的策略,去除了原来在Spring MVC中通过Xml进行注入的方式,全部通过Java Configuration的编码方式进行实体Bean的注入,因此我们在开发中，对于外部组件、自己封装的业务SDK等等都需要开发者自行将实体Bean注入到Spring的容器中，然后通过注解在Spring的框架中方便的进行使用那么,在Spring Boot框架中,我们在注入实体Bean时,如何优雅的进行注入呢?或者我们在注入实体Bean的同时,我们应该注意什么?常规注入常规注入很简单,通过使用@Bean注解即可完成简单的实体Bean注入，如下示例：@Configurationpublic class AdminKernelConfig {    @Bean    public DynamicWechatRoute dynamicWechatRoute(){        return new DynamicWechatRoute();    }}在常规注入时,假如我们要注入的Bean是通过构造函数来创建的,此时主要有2中方式进行构造通过@Autowired注解引入外部依赖Bean，然后传递进行构造，如下代码：@Configurationpublic class AdminKernelConfig {    @Autowired     Environment environment;        @Bean    public DynamicWechatRoute dynamicWechatRoute(){        return new DynamicWechatRoute(environment);    }}另外也可以通过参数传递直接引用，代码如下：@Configurationpublic class AdminKernelConfig {        @Bean    public DynamicWechatRoute dynamicWechatRoute(Environment environment){        return new DynamicWechatRoute(environment);    }}配置注入很多时候我们创建的实体类都是需要通过外部传参进行构造的，通过基础类型参数或者封装的实体Property类进行构造，一般外部参数是通过写在Spring Boot的配置中通过@Value注解引入外部变量进行实体Bean构造,如下：@Configurationpublic class AdminKernelConfig {        @Value(\"${signKey}\")    String signKey;        @Bean    public DynamicWechatRoute dynamicWechatRoute(){        return new DynamicWechatRoute(signKey);    }}上面这种是很常规简单的做法,我们构造的实体类只需要一个基础String类型即可完成构造但通常情况下,外部参数通常都很多,这种情况我们通常会单独写一个配置属性类进行封装，然后在实体类中通过该配置属性类进行参数构造，通过@EnableConfigurationProperties和@ConfigurationProperties(prefix = \"your.prefix\")这两个注解配合使用实现效果@ConfigurationProperties注解作用于我们的配置属性类上,配置一个前缀属性即可,例如：@ConfigurationProperties(prefix = \"test\")public class TestProperties {    private String accessKeyId;    private String accessKeySecret;    //getter &amp; setter}配上属性前缀test,此时我们可以在application.yml的配置文件中进行配置，代码如下：test:    accessKeyId: abc    accessKeySecret: cdeeeeeeeeeeeee配置好后,我们在我们的JavaConfiguration配置类即可进行引用注入,如下：@Configuration@EnableConfigurationProperties(TestProperties.class)public class AdminKernelConfig {        @Bean    public DynamicWechatRoute dynamicWechatRoute(TestProperties testProperties){        return new DynamicWechatRoute(testProperties);    }    }这种方式的好处是避免我们在Config类中定义大量的注解@Value对属性进行引用，造成代码结构上混乱。条件注入条件注入作为Spring框架提供给开发者的高级特性而存在,开发者希望能针对某些特定的条件满足的情况下，才注入Bean到Spring的容器中,这种特性提供了很好的可扩展性。针对条件注入,Spring提供了@Conditional注解来解决这个问题.先来看@Conditional注解的源码：@Target({ElementType.TYPE, ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Conditional {\t/**\t * All {@link Condition Conditions} that must {@linkplain Condition#matches match}\t * in order for the component to be registered.\t */\tClass&lt;? extends Condition&gt;[] value();}@Condtional注解提供了一个属性value,该属性声明了一个Condition的class，Condition是Spring提供的接口源码：public interface Condition {\t/**\t * Determine if the condition matches.\t * @param context the condition context\t * @param metadata metadata of the {@link org.springframework.core.type.AnnotationMetadata class}\t * or {@link org.springframework.core.type.MethodMetadata method} being checked\t * @return {@code true} if the condition matches and the component can be registered,\t * or {@code false} to veto the annotated component's registration\t */\tboolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);}从源码可以得知,@Conditional注解可以作用于类、方法，只要提供的Condition全部满足的情况下,才会将实体Bean注入到所有的容器中.如果@Conditional作用于拥有@Configuration注解的类上,那么该类下的所有Bean的创建注入都需要满足@Conditional注解的条件才可以注入如果@Conditional作用于方法上,那么该方法需要注入Bean时,只有满足了条件的情况下才会注入.Spring Boot为我们提供了很多默认的Condition实现类,通过默认提供的Condition基本可以满足我们的日常需求,如果不满足,开发者可自定义Condtion的实现开发自己的装载Bean需求。接下来,先看Spring Boot为我们提供的默认Condition实现,包路径：org.springframework.boot.autoconfigure.condition，常用应用程序使用注解，主要包含以下:            注解      说明                  @ConditionalOnProperty      根据特定的属性进行条件注入              @ConditionalOnExpression      根据SPEL表达式组合复杂情况,满足的情况下条件注入              @ConditionalOnBean      根据容器中存在外部某个实体Bean的情况下条件注入              @ConditionalOnMissingBean      容器中不存在某个实体Bean的情况下条件注入              @ConditionalOnResource      资源文件存在的情况下载进行条件注入      常用注解以下关于@Conditional注解的是Spring Boot提供给开发者可以在应用程序中使用的注解。@ConditionalOnProperty@ConditionalOnProperty注解是Spring Boot框架中最常用的条件注解,它允许根据特定的环境属性有条件的进行Bean注入.示例代码如下：@Configuration@ConditionalOnProperty(value=\"knife4j.enabled\", havingValue = \"true\",matchIfMissing = true)public class Knife4jModule { //more..}在上面的代码示例中,仅当knife4j.enabled的属性为true时，才会加载Knife4jModule这个配置模块，如果开发者根本没有配置这个属性,由于我们将matchIfMissing定义为true，因此程序启动时仍将加载该模块。@ConditionalOnExpression如果我们需要基于多个属性的条件进行组合才能创建Bean,那么我们可以使用@ConditionalOnExpression注解示例代码如下：@Configuration@ConditionalOnExpression(value=\"${knife4j.enabled:true} and ${knife4j.basic.enabled:true}\")public class Knife4jModule { //more..}通过Spring提供的SPEL表达式组合多个表达式的复杂情况，仅到表达式中满足条件时，才会加载Knife4jModule这个配置模块@ConditionalOnBean通常情况下,我们希望只有在某一个Bean可用的情况下,我们在加载配置注入我们的实体Bean示例代码如下：@Configuration@ConditionalOnBean(SwaggerModule.class)public class Knife4jModule { //more..}在加载Knife4jModule之前,我们需要SwaggerModel的实体Bean在Spring的容器中存在可用时,才加载该配置@ConditionalOnMissingBean@ConditionalOnMissingBean和@ConditionalOnBean意思正好相反,只有在Spring的容器中不存在该实体Bean时才进行条件注入示例代码如下：@Configurationpublic class OnMissingBeanModule {  @Bean  @ConditionalOnMissingBean  public DataSource dataSource() {    return new InMemoryDataSource();  }}一般该注解作用于实体Bean本身,从上面的示例中,只有在Spring容器中不存在DataSource的实例Bean时,才进行加载条件注入Bean.@ConditionalOnResource根据某些资源的情况下载加载Bean的情况,可以使用@ConditionalOnResource注解示例代码如下：@Configuration@ConditionalOnResource(resources = \"/logback.xml\")public class LogbackModule {  //...}LogbackModule模块仅当logback.xml资源文件在当前环境中存在的情况下才加载.通过这种方式,我们可以根据找到自己模块的配置后才进行实体Bean的创建.不常用注解虽然Spring Boot提供了很多默认的@Conditional的注解扩展实现,但是并不是所有的扩展实现都是提供给开发者来使用的,有些则是提供给框架内部进行使用的.@ConditionOnClass仅当某个类在类路径上时才加载Bean@Configuration@ConditionalOnClass(name = \"this.clazz.does.not.Exist\")public class OnClassModule {\t//  ...}@ConditionalOnMissingClass仅当某个类不在类路径上时才加载Bean@Configuration@ConditionalOnMissingClass(value = \"this.clazz.does.not.Exist\")public class OnMissingClassModule {  //...}@ConditionalOnJndi仅当通过JNDI可以使用某些资源时才加载Bean@Configuration@ConditionalOnJndi(\"java:comp/env/foo\")public class OnJndiModule {  //...}@ConditionalOnJava仅当在java某个版本时才加载Bean@Configuration@ConditionalOnJava(JavaVersion.EIGHT)public class OnJavaModule {  //...}自定义通过上面的不常用注解,我们其实可以发现,针对各种条件下才能对Bean进行注入的实在太多,这种情况下,当我们的程序需要在某种情况下才能注入Bean时,Spring肯定不能满足,此时就需要自定义条件注入Condition简单的自定义实现  目前假设有需求,我们在创建某个实体Bean时,需要根据配置文件的某一个String属性进行对比,只有在Bean上给定的目标值和配置文件中给定的属性值相等的情况下才注入该Bean通过上面的需求,我们首先需要定义Condition接口的实现，代码如下public class ConditionOnKeyApply implements Condition {    @Override    public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) {        Map&lt;String, Object&gt; multiValueMap=annotatedTypeMetadata.getAnnotationAttributes(ConditionOnKey.class.getName());        //获取property        String propertyValue=Objects.toString(multiValueMap.get(\"property\"),\"\");        //获取目标值        String targetValue=Objects.toString(multiValueMap.get(\"targetValue\"),\"\");        if (StrUtil.isNotBlank(propertyValue)&amp;&amp;StrUtil.isNotBlank(targetValue)){            //都不为空的情况下            Environment environment=conditionContext.getEnvironment();            //从配置环境中获取值            String sourceValue=environment.getProperty(propertyValue);            System.out.println(\"环境值:\"+sourceValue+\",目标值:\"+targetValue);            // 进行比对            return StrUtil.equalsIgnoreCase(sourceValue,targetValue);        }        return false;    }}定义我们自定义的注解@ConditionOnKey，代码如下：@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE,ElementType.METHOD})@Documented//指定Conditional的实现类@Conditional(value = ConditionOnKeyApply.class)public @interface ConditionOnKey {    /**     * 获取某个属性的env值     * @return     */    String property();    /**     * 目标值     * @return     */    String targetValue() default \"true\";}在JavaConfiguration中进行注入@Configurationpublic class ConditionKeyConfig {    @Bean    @ConditionOnKey(property = \"key\",targetValue = \"test\")    public ConditionKeyModel conditionKeyModel(){        return new ConditionKeyModel();    }}从注入的代码中,如果我们在application.yml配置文件中配置一个属性为key，值为test的情况下，ConditionKeyModel这个实体会注入Spring容器中,否则不会进行注入.key: test外部导入通常我们在使用第三方技术组件时,只需要简单的在Spring Boot的启动类上加入@Enablexxx等这类注解，既可以帮我们快速集成第三方的技术能力。这种方式我们在自己封装时也可以使用,通常@Enablexx注解使用的是@Import注解来导入一个java configuration的配置文件类进行实现看一个Swagger的示例，一般我们在使用swagger的时候通常使用@EnableSwagger2来使用，如下代码：@Configuration@EnableSwagger2public class SwaggerConfiguration {    }@EnableSwagger2的注解源码如下：@Retention(value = java.lang.annotation.RetentionPolicy.RUNTIME)@Target(value = { java.lang.annotation.ElementType.TYPE })@Documented@Import({Swagger2DocumentationConfiguration.class})public @interface EnableSwagger2 {    }注解上除了标注该注解的作用目标以及Retention，还使用了@Import注解将Swagger2DocumentationConfiguration类进行了导入，来看源码：@Configuration@Import({ SpringfoxWebMvcConfiguration.class, SwaggerCommonConfiguration.class })@ComponentScan(basePackages = {    \"springfox.documentation.swagger2.mappers\"})@ConditionalOnWebApplicationpublic class Swagger2DocumentationConfiguration {  @Bean  public JacksonModuleRegistrar swagger2Module() {    return new Swagger2JacksonModule();  }  @Bean  public HandlerMapping swagger2ControllerMapping(      Environment environment,      DocumentationCache documentationCache,      ServiceModelToSwagger2Mapper mapper,      JsonSerializer jsonSerializer) {    return new PropertySourcedRequestMappingHandlerMapping(        environment,        new Swagger2Controller(environment, documentationCache, mapper, jsonSerializer));  }}源码中是一个Configuration类，然后通过上面我们说的最简单的常规注入了2个实体Bean一般这种方式我们可以在封装自己的组件时进行使用,通过提供一个@Enable系列的注解，方便外部人员使用和记忆."
  },
  
  {
    "title": "Knife4j 2.0.5发布,性能优化",
    "url": "/posts/knife4j-2.0.5-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2020-09-14 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://g...",
    "content": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化1、Ui整体性能优化,主要从以下几个方面展开Gitee #I1TYNK、Gitee #I1LWNM、Gitee #I1J52C、GitHub #243  获取接口初始化Swagger文档时,只初始化菜单、以及基础信息字段  接口path节点以及Model-definition节点作为异步解析，除了导出功能外只有展示的文档涉及到的信息才会进行解析，缩减没必要的内存开销和空间性能等待  SwaggerModels功能中的所有Model通过异步加载,减少内存开销.2、通过@EnableKnife4j注解注入的实体Bean包含部分Filter,Filter涉及到应用入侵,优化为只有在开发者启用了Knife4j提供的配置值时,该实体Bean才生效3、解决通过/plus路径来开启增强模式时失效的问题Gitee #I1OJCK4、接口描述信息支持Markdown语法渲染5、解决调试发送后,状态栏curl出现参数为null的问题Gitee #I1QC7Z、Gtiee #I1QXJ16、移除fastjson等不必要的依赖Gitee I1OIY97、在左侧菜单接口中新增接口类型,并且在分组中显示当前分组下包含的接口数量Gitee #I1PE0H，如下图：8、优化在当前分组名称/Controller名称/接口分词中带字符/导致页面空白的问题,如果包含使用字符-进行替换Gitee #I1SMAY9、Vue以及ant-design-vue版本升级到当前最新版10、导出的离线Html文档优化属性,去除无效的属性引用导致Html文档文件太大(降低5倍以上).11、增加导出Word文档的实现12、返回大数据量造成页面卡死的问题优化Gitee #I1QIJK13、优化默认的标题显示,开发者未设置分组服务标题时文档标题默认显示Knife4j 接口文档Gitee #I1P4OQ14、枚举类型针对Array数组类型支持多选Gitee #I1NOTE、GitHub #26715、针对POST、PUT、PATCH等请求方式,以x-www-form-urlencoded请求头发送请求时,请求参数在url追加的问题,以避免请求时400错误的发生.16、在i18n环境下离线文档导出时没有完全国际化的优化操作Gitee #I1MKP717、针对@RequestBody的请求下载接口响应乱码的问题修复Gitee I1U4LA18、调试返回状态栏数据大小的显示优化B.KB、MBGitHub #26419、支持UiConfiguration中方法调试的配置,如并未配置任何支持的方法,在ui界面中不会出现调试栏TabGitHub #241，代码如下：@Beanpublic UiConfiguration uiConfiguration(){    return UiConfigurationBuilder.builder()        .supportedSubmitMethods(new String[]{})        .build();}界面中的显示效果如下(仅显示文档)：20、接口文档中针对请求参数存在示例值的情况下,在接口的参数说明中予以显示GitHub #10921、去除doc.html对favicon.ico的请求,以避免开发者在网关微服务的架构中集成时出现404.特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构,点击预览导出离线Html效果，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁,点击在线预览效果，界面效果如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）"
  },
  
  {
    "title": "Knife4j 2.0.4发布,支持自定义 Host",
    "url": "/posts/knife4j-2.0.4-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2020-06-28 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://g...",
    "content": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化1、支持UiConfiguration中方法调试的配置,如并未配置任何支持的方法,在ui界面中不会出现调试栏Tab，代码如下：@Beanpublic UiConfiguration uiConfiguration(){    return UiConfigurationBuilder.builder()        .supportedSubmitMethods(new String[]{})        .build();}界面中的显示效果如下(仅显示文档)：2、在当前文档页添加复制接口功能，便于开发人员快速复制接口地址github #2383、修复Authorize修改或注销的问题gitee #I1IJK34、个性化配置新增Host属性的配置,如果当前对外提供的接口文档和接口本身Host属性存在冲突,可以自动配置此属性进行接口的联调，Host属性可以配置为ip:port的形式，这样默认是HTTP进行访问,开发者也可以配置完整的域名或者HTTPS等配置其工作原理是在调用axios组件进行接口调试时,配置其baseURL属性var baseUrl='';//默认是空//是否启用Hostif(this.enableHost){    baseUrl=this.enableHostText;}var requestConfig={    baseURL:baseUrl,//调用目标Host服务的接口    url: url,    method: methodType,    headers: headers,    params: formParams,    data: data,    //Cookie标志    withCredentials:this.debugSendHasCookie(headers),    timeout: 0}开发者要使用此Host的配置后端必须开启跨域的配置，如果是Spring Boot，示例代码如下：@Beanpublic CorsFilter corsFilter(){    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();    CorsConfiguration corsConfiguration=new CorsConfiguration();    corsConfiguration.setAllowCredentials(true);    corsConfiguration.addAllowedOrigin(\"*\");    corsConfiguration.addAllowedHeader(\"*\");    corsConfiguration.addAllowedMethod(\"*\");    corsConfiguration.setMaxAge(10000L);    source.registerCorsConfiguration(\"/**\",corsConfiguration);    CorsFilter corsFilter=new CorsFilter(source);    return corsFilter;}5、调试接口时,接口在无返回数据或者异常的情况下弹框错误信息,提示开发者6、图片预览接口无法在响应内容中在线预览图片的问题gitee #I1KP0Q7、修复针对Map字段时,Value指引是本类时出现递归死循环的问题,结构如下：\"SensorTable\": {            \"type\": \"object\",            \"properties\": {                \"attrib\": {                    \"type\": \"integer\",                    \"format\": \"int32\"                },                \"sensorMap\": {                    \"type\": \"object\",                    \"additionalProperties\": {                        \"originalRef\": \"SensorTable\",                        \"$ref\": \"#/definitions/SensorTable\"                    }                }                //more...            },            \"title\": \"SensorTable\"        },8、修复离线文档功能导出Markdown时,响应参数格式异常的问题gitee #I1LMYO9、修复在使用中间件对接口响应内容进行拦截处理时,响应内容不显示的bug，例如使用sentinel 进行QPS限流,一般在这种情况下是由于接口响应的Content-Type是json，但实际响应内容却是text导致gitee #I1JO73特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构,点击预览导出离线Html效果，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁,点击在线预览效果，界面效果如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）"
  },
  
  {
    "title": "Knife4j 2.0.3发布,支持springdoc和i18n",
    "url": "/posts/knife4j-2.0.3-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2020-05-24 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://g...",
    "content": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化knife4j1、读取Markdown文件时,当文件不存在时日志错误信息简化打印,开发者可以忽略该错误gitee #I1E1S1knife4j-spring-ui1、移除Vue中的pwa机制,解决service-work.js引起的各种问题github #2062、支持UiConfiguration中方法调试的配置,如并未配置任何支持的方法,在ui界面中不会出现调试栏Tab，代码如下：@Beanpublic UiConfiguration uiConfiguration(){    return UiConfigurationBuilder.builder()        .supportedSubmitMethods(new String[]{})        .build();}界面中的显示效果如下(仅显示文档)：3、GET请求出现参数未填的情况下发送Null的buggitee #I1BG4O、github #2134、针对开发者在调试时更改接口地址,在接口地址中添加参数的情况,出现发送请求失败的buggitee #I1C5OQ5、解决集成文档时各种basePath问题导致Ui的logo不显示的问题,通过Base64将logo图片转换处理,img标签直接显示base64字符串gitee #1CQ1F 6、左侧菜单栏在收缩状态下显示版本控制的标识导致菜单异常的问题,在收缩状态下禁用该项gitee #I1CCXT、gitee #I1DBDF7、增强功能忽略参数不完全的问题gitee PR#188、服务端在没有Write任何数据的情况下,针对非200状态码不显示状态的异常问题gitee #I1BKRH9、针对raw类型的请求接口类型,全局参数中只能是header参数的问题,支持query类型的全局参数gitee #I1C86F10、增加对Xml请求的适配支持,服务端consumes属性设为application/xml接口gitee #I1BCKB11、增加@ApiSupport注解，分组Controller下可以设置全局author属性，或者order排序属性12、剔除webjar文件中的favicon.ico文件,以避免和主项目产生冲突gitee #I1ELHN、github #21513、新增includeParameters属性,开发者可以在文档的参数中新增一种选择,该特性是和ignoreParameters对立,具体可以参考文档14、优化在editor编辑器中的属性字段显示效果gitee #I1G3G915、导出的Html、Markdown离线文件添加作者属性gitee #I1EXXO16、在Ui的全局参数配置中添加Header类型的请求参数后,非空情况下会自动合并每个接口的Header请求参数,接口中的Header如果和全局参数配置中的Header同名但是为空的情况下,Ui会使用全局参数配置中的Header参数gitee #I1GD8717、优化请求数据类型的显示问题,Ui自动根据参数的类型识别出当前接口的请求类型并进行展示,解决springfox等框架始终解析为json请求的buggitee #I1EMJ9、gitee #I1903T18、修复请求头Content-Type在调试时被忽略的问题,该问题具体参考gitee #I18HGS,knife4j在2.x版本使用的是axios组件,axios针对发送的请求头data属性如果没有传递的情况下会忽略Content-Type请求头,具体可参考https://github.com/axios/axios/issues/8619、添加I18n的支持,目前支持的语言：中文、English20、请求头携带Cookie的情况,如果要使用Cookie,请求头的名称请确保为Cookie,不能有小写或其他.21、添加对springdoc框架的集成支持，非常感谢teddygong提交的PR如果你后端是Java+Spring的技术栈，在使用springfox的同时，想换一个Swagger的Ui皮肤，通过在pom.xml中直接引入即可,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt;  &lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt;后端渲染OpenAPI的解析框架是springdoc，则添加如下依赖引用：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-springdoc-ui&lt;/artifactId&gt;  &lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt;Knife4j-Spring使用Spring Boot的技术栈可以通过引用starter的方式快速引入使用,注意该starter组件是包含Ui的,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;  &lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt;如果是微服务的情况下,微服务其实不需要引用Ui的jar包，只需要在网关引用Ui的jar包依赖,所以在微服务情况下,使用增强属性只需要引用微服务版本的starter依赖,如下：&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-micro-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt;Knife4j-Adminknife4j-admin是一个基于Spring Cloud Gateway网关,通过网关的特性,结合knife4j对Swagger的文档进行动态聚合的管理平台平台特点：  跨语言、跨平台  任意聚合Swagger文档,动态发布,调试  文档个性化配置、权限等  彻底告别聚合网关文档等由于软件版本等造成的技术集成问题  独立部署如果你有以上的需求的话,可以考虑使用一下knife4j-admin这个产品，产品文档点这里特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构,点击预览导出离线Html效果，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁,点击在线预览效果，界面效果如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）"
  },
  
  {
    "title": "Knife4j 2.0.2发布,Swagger接口文档赋能工具",
    "url": "/posts/knife4j-2.0.2-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2020-03-08 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版):http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://g...",
    "content": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档赋能的工具文档：https://doc.xiaominfo.com效果(旧版):http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.X版)：http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化knife4j1、新增knife4j-dependencies模块,管理knife4j的相关Maven引用,可以以Maven的BOM方式引入Knife4j2、官网文档同步更新.3、解决swagger-annotations导致的版本冲突gitee #I17G31、GitHub #191knife4j-spring-ui1、修复切换tab之后 再次发送请求不带参数且不显示响应数据的问题，调试异常等问题PR 13 @gitee、gitee #I17FFX、GitHub #196、GitHub #1872、优化调试框全部选中的问题,在取消全选时,只有在输入参数改变时才会选中该参数,取消原来默认选中全部参数gitee #I19V6D3、针对Form表单类型的请求构造curl命令行时在未输入值的情况下为null的情况,修改为空字符串gitee #I18IBZ4、优化全局参数设置功能,针对参数数据太长不换行问题，以及参数需要修改时需要重新删除的交互体验，开发者在新增参数后可以方便的更改参数数据值以及参数的类型gitee #I17OV1、gitee #I19GJK、gitee #I1A9V1、gitee #I18HMJ、GitHub #1765、请求参数在未给定example默认值的情况下,文本输入框的placeHolder属性显示该字段的文字说明gitee #I17RKI6、修复增强属性忽略参数不生效的问题gitee #PR-16、gitee #I136KU、gitee #I187VN、gitee #I16A717、调试参数框增加对后端枚举的支持,改输入框为下拉选择框gitee #I18MHO8、service-worker.js报404问题，构建打包时添加此文件gitee #I17D0Y、GitHub #1859、get请求参数出现特殊字符未编码处理导致出现400错误gitee #I19C8Y10、后端新增接口或者接口编辑后,在ui界面显示更新标志,在菜单上会出现一个蓝色的徽标gitee #I1AQFW，如下图:11、后端增强注解@ApiOperationSupport(author = \"xiaoymin@foxmail.com\")支持每个接口提供开发者的呈现,最终如下图：12、调试发送按钮增加loading效果,针对接口响应较长的情况下提升交互效果13、针对Authorize菜单栏的参数,保存参数是全局保存,其它逻辑分组的接口再调试时,不需要再保存一次新值gitee #I16Z1014、修复部分情况响应字段在ace-editor编辑器右边栏不显示字段说明的情况gitee #I17F5Y15、搜索框完善对接口请求Api地址栏的模糊搜索匹配gitee #I19EN0、gitee #I1B0Q916、调试响应数据行太长,无法换行的问题gitee #I17F1J17、在当前接口无参数的情况下,界面添加全局参数无效果的bug如果你后端是Java+Spring的技术栈，在使用springfox的同时，想换一个Swagger的Ui皮肤，通过在pom.xml中直接引入即可,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt;  &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt;Knife4j-Spring使用Spring Boot的技术栈可以通过引用starter的方式快速引入使用,注意该starter组件是包含Ui的,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;  &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt;如果是微服务的情况下,微服务其实不需要引用Ui的jar包，只需要在网关引用Ui的jar包依赖,所以在微服务情况下,使用增强属性只需要引用微服务版本的starter依赖,如下：&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-micro-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt;特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构,点击预览导出离线Html效果，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁,点击在线预览效果，界面效果如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）"
  },
  
  {
    "title": "Knife4j 2.0.1发布,细节处理！",
    "url": "/posts/knife4j-2.0.1-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-12-23 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档服务的工具文档：http://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.0版):http://knife4j.xiaominfo.com/doc.htmlGitee：https://gi...",
    "content": "Knife4j前身是swagger-bootstrap-ui,是一个为Swagger接口文档服务的工具文档：http://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.0版):http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化knife4j-spring-ui1、解决x-www-form-urlencoded类型的表单请求，参数勾选复选框无法取消的情况gitee #I16S142、个性化配置中新增是否开启动态参数选项,默认为false，不开启,如果有需要的可以勾选此选项,可以无限动态添加参数进行接口调试3、实现全局搜索功能gitee #I16ZW44、@Deprecated 标记的接口置为过时gitee #I1736T5、针对返回的数据太大,导致页面卡死的情况下,界面做限制处理，如果返回的数据大于2M，不进行格式化处理，弹出提示,提醒开发者在raw进行响应内容的查看,只显示纯文本gitee #I16ZV46、优化响应数据大小的格式化显示,BYTE\\KB\\MB7、实现图片预览功能gitee #I173AN如果你后端是Java+Spring的技术栈，在使用springfox的同时，想换一个Swagger的Ui皮肤，通过在pom.xml中直接引入即可,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt;  &lt;version&gt;2.0.1&lt;/version&gt;&lt;/dependency&gt;Knife4j-Spring使用Spring Boot的技术栈可以通过引用starter的方式快速引入使用,注意该starter组件是包含Ui的,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;  &lt;version&gt;2.0.1&lt;/version&gt;&lt;/dependency&gt;如果是微服务的情况下,微服务其实不需要引用Ui的jar包，只需要在网关引用Ui的jar包依赖,所以在微服务情况下,使用增强属性只需要引用微服务版本的starter依赖,如下：&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-micro-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;2.0.1&lt;/version&gt;&lt;/dependency&gt;特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁，如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）最后这次版本是基于Vue重写，对于某些问题有极大的可能难免考虑不周,大家在使用的过程中如果有问题也欢迎及时通过issues和我沟通,会尽快修正，谢谢大家~！！关注关注我的微信公众号,实时了解swagger-bootstrap-ui的最新资讯~~~~"
  },
  
  {
    "title": "Knife4j 2.0发布,涅槃重生~！",
    "url": "/posts/knife4j-2.0.0-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-12-16 00:00:00 +0800",
    





    
    "snippet": "Knife4j前身是swagger-bootstrap-ui,取名knife4j是希望她能像一把匕首一样小巧,轻量,并且功能强悍,更名也是希望把她做成一个为Swagger接口文档服务的通用性解决方案,不仅仅只是专注于前端Ui前端.虽然目前还只是在前端，但以后功能肯定不止于此.2.0版本主要是使用Vue+Ant Design Vue对前端Ui进行重写,该版本是真正的前后端分离版本，同时依赖于V...",
    "content": "Knife4j前身是swagger-bootstrap-ui,取名knife4j是希望她能像一把匕首一样小巧,轻量,并且功能强悍,更名也是希望把她做成一个为Swagger接口文档服务的通用性解决方案,不仅仅只是专注于前端Ui前端.虽然目前还只是在前端，但以后功能肯定不止于此.2.0版本主要是使用Vue+Ant Design Vue对前端Ui进行重写,该版本是真正的前后端分离版本，同时依赖于Vue的技术生态,以后会有更多有趣的功能实现,全方位满足开发者的需要.文档：http://doc.xiaominfo.com效果(旧版)：http://swagger-bootstrap-ui.xiaominfo.com/doc.html效果(2.0版):http://knife4j.xiaominfo.com/doc.htmlGitee：https://gitee.com/xiaoym/knife4jGitHub：https://github.com/xiaoymin/swagger-bootstrap-ui示例：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性 &amp; 优化knife4j-spring-ui1、使用Vue+Ant Design Vue对Ui进行重写,统一整体界面风格,更清晰的文档说明能力以及接口调试能力2、支持在界面中导出离线Markdown、离线Html格式的文档，Markdown、Html风格较之前都做了极致的优化，Markdown格式主要是针对树形Model的展示通过缩进的方式在md格式的table中显示更加直观,Html离线文档和在线版风格几乎没有区别，简洁、直观.点击预览导出离线Html效果3、单接口文档页的复制文档也是通过复制Markdown格式的问题，同上主要优化md格式的table显示问题，以缩进的方式显示树形表格4、对调试栏进行优化、区分请求头和请求体参数,使用tab标签页组件可以对请求参数进行动态的添加、维护、如果你使用对文档进行缓存,文档页的动态调试参数会持久化处理.5、文档的个性化配置(增强功能)有删减,目前只保留4项功能，即(请求参数缓存、过滤重复同类型接口、本地缓存打开tab接口、文档增强)6、Tab标签页打开接口、右键可以根据选择关闭不同的Tab标签页7、调试框请求头、请求体均支持动态参数，开发者可以自行添加动态参数进行调试,更加灵活方便8、提供增强直接访问地址，http://ip:port/doc.html#/plus，后端在保证开启增强注解的情况下可直接使用该地址,不需要在前端个性化配置中再进行配置,方便团队直接进行沟通9、响应下载类型增加至141种,几乎涵盖目前常见的文件类型10、修复响应体中会出现属性多余双引号的buggitee # I125B2、github #15611、修复请求参数数据类型的format不显示的问题,针对Long类型区分int64、int32- github #16112、解决多个Schema响应状态码的情况下SwaggerModels字段不显示的问题github #17013、调试请求默认追加一个Ui的请求头Request-Origion,值为Knife4j，原来该值是SwaggerBootsrapUi，在2.0版本中进行了变更.14、解决Models属性嵌套过多时,页面白板，效率问题github #106如果你后端是Java+Spring的技术栈，在使用springfox的同时，想换一个Swagger的Ui皮肤，通过在pom.xml中直接引入即可,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt;  &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;Knife4j-Spring1、移除增强注解@EnableSwaggerBootstrapUi,以后的增强开启注解请使用@EnableKnife4j2、knife4j-spring-boot-starter组件移除默认springfox的ui-jar包springfox-swagger-ui,只保留knife4j-spring-ui,开发者如果要使用springfox的ui包需要自行在项目中引入3、合并PR12-修复IDEA debug无法显示动态Response的问题,修复动态类加载不到的问题使用SpringBoot的技术栈可以通过引用starter的方式快速引入使用,注意该starter组件是包含Ui的,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;  &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;如果是微服务的情况下,微服务其实不需要引用Ui的jar包，只需要在网关引用Ui的jar包依赖,所以在微服务情况下,使用增强属性只需要引用微服务版本的starter依赖,如下：&lt;dependency&gt;    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;    &lt;artifactId&gt;knife4j-micro-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;特点  基于Vue+Ant Design构建的文档，更强大、清晰的接口文档说明能力以及接口调试能力  左右布局,基于Tabs组件的多文档查阅风格  支持在线导出Html、Markdown、Word、PDF等多种格式的离线文档  接口排序,支持分组及接口的排序功能  支持接口全局在线搜索功能  提供Swagger资源保护策略,保护文档安全  接口调试支持无限参数,开发者调试非常灵活，动态增加、删除参数  全局缓存调试信息,页面刷新后依然存在,方便开发者调试  以更人性化的table树组件展示Swagger Models功能  文档以多tab方式可显示多个接口文档  请求参数栏请求类型、是否必填着颜色区分  主页中粗略统计接口不同类型数量  支持自定义全局参数功能，主页包括header及query两种类型  JSR-303 annotations 注解的支持  更多个性化设置功能界面接口文档显示界面如下：接口调试界面如下：Swagger Models功能支持导出离线Markdown、Html功能，markdown的表格较原先版本通过缩减显示为树形结构，效果图如下：通过第三方Markdown软件导出的PDF效果如下图:同时提供了导出离线Html功能,Html功能界面风格和在线几乎没有区别,美观、大方、简洁，如下图：Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/knife4j点个Star吧~~ ：）最后这次版本是基于Vue重写，对于某些问题有极大的可能难免考虑不周,大家在使用的过程中如果有问题也欢迎及时通过issues和我沟通,会尽快修正，谢谢大家~！！关注关注我的微信公众号,实时了解swagger-bootstrap-ui的最新资讯~~~~"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.9.6 发布，解决长整型精度丢失的问题",
    "url": "/posts/swagger-bootstrap-ui-1.9.6-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-08-28 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.9.6 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger...",
    "content": "swagger-bootstrap-ui 1.9.6 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/swagger-bootstrap-ui示例:https://gitee.com/xiaoym/swagger-bootstrap-ui-demo重要说明这是swagger-bootstrap-ui的最后一个版本这是swagger-bootstrap-ui的最后一个版本这是swagger-bootstrap-ui的最后一个版本重要的事情说三遍!!!一开始项目初衷是为了写一个增强版本的Swagger 前端UI,但是随着项目的发展,面对越来越多的个性化需求,不得不编写后端Java代码以满足新的需求,在swagger-bootstrap-ui的1.8.5~1.9.6版本之间,采用的是后端Java代码和Ui都混合在一个Jar包里面的方式提供给开发者使用.这种方式虽说对于集成swagger来说很方便,只需要引入jar包即可,但是在微服务架构下显得有些臃肿。因此,项目正式更名为knife4j,取名knife4j是希望她能像一把匕首一样小巧,轻量,并且功能强悍,更名也是希望把她做成一个为Swagger接口文档服务的通用性解决方案,不仅仅只是专注于前端Ui前端.swagger-bootstrap-ui的所有特性都会集中在knife4j-spring-ui包中,并且后续也会满足开发者更多的个性化需求.主要的变化是,项目的相关类包路径更换为com.github.xiaoymin.knife4j前缀,开发者使用增强注解时需要替换包路径后端Java代码和ui包分离为多个模块的jar包,以面对在目前微服务架构下,更加方便的使用增强文档注解(使用SpringCloud微服务项目,只需要在网关层集成UI的jar包即可,因此分离前后端)knife4j沿用swagger-bootstrap-ui的版本号,第1个版本从1.9.6开始,关于使用方法,请参考文档由于更名给大家带来的不便深表歉意~！特性&amp;优化1、解决Spring路由PathVariable不显示的情况，并优化交互体验2、解决响应体中的长整型显示错误,精度丢失的问题#135 @GitHub3、优化请求头Header是中文的情况,如果包含中文则进行encodeURI函数处理,否则不做任何处理#140 @GitHub4、升级jQuery 1.X系列版本到最新版本1.12.45、初始化页面请求Swagger接口资源方式改为异步,在jQuery的ajax方法参数项async:false时,浏览器会抛出警告的问题(同步ajax请求会造成主线程阻塞,对用户体验不是很好,已被置为过时).6、支持supportedSubmitMethods,后端配置UiConfiguration的Bean#IVCQ0 @Gitee7、优化下载中文乱码问题,后端需要指定filename值,并且对名称进行URLEncoder.encode处理,UI前端会进行decode成中文,保证下载正常8、修复curl状态栏复制时内容被转义的bug#136 @GitHubUI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.9.6&lt;/version&gt;&lt;/dependency&gt;Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）关注关注我的微信公众号,实时了解swagger-bootstrap-ui的最新资讯~~~~"
  },
  
  {
    "title": "Kettle实战100篇 第28篇 Carte作业服务详解",
    "url": "/posts/kettle-28/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-23 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第27篇 系统级别任务调度调用转换&作业",
    "url": "/posts/kettle-27/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-22 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第26篇 生产环境部署Pentaho",
    "url": "/posts/kettle-26/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-21 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第25篇 作业核心对象设置变量组件",
    "url": "/posts/kettle-25/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-20 00:00:00 +0800",
    





    
    "snippet": "我们在很多场景下都需要用到设置变量组件,比如在分页查询数据时,然后分批次写入数据时,都需要事先定义好变量,一般作为作业中起始组件,设置变量的作业举足轻重,这考验你在一个完成的ETL过程中的逻辑能力,你的ETL是否能正常完美的执行,和开始设置的变量有很重要的关系.作业中的设置变量组件如下：我们可以通过设置变量组件中的变量以.properties文件的方式引入可以指定属性文件名为F:\\bak\\t...",
    "content": "我们在很多场景下都需要用到设置变量组件,比如在分页查询数据时,然后分批次写入数据时,都需要事先定义好变量,一般作为作业中起始组件,设置变量的作业举足轻重,这考验你在一个完成的ETL过程中的逻辑能力,你的ETL是否能正常完美的执行,和开始设置的变量有很重要的关系.作业中的设置变量组件如下：我们可以通过设置变量组件中的变量以.properties文件的方式引入可以指定属性文件名为F:\\bak\\testkettlevariable.properties然后在指定我们的变量名范围,那么我们接下来的整个ETL过程中都可以使用该变量使用文件的方式引入变量如下：我们在配置文件中设置我们的变量,如下图：我们的JavaScript脚本中打印出变量,脚本内容如下：var name=parent_job.getVariable(\"TEST_NAME\");var version=parent_job.getVariable(\"TEST_VERSION\");var subject=\"自定义日志输出\";//实例化工厂类var logFactory = new org.pentaho.di.core.logging.LogChannelFactory();//实例化日志channel对象var log= logFactory.create(subject);//日志输出log.logMinimal(\"name:\"+name+\",version:\"+version);true;脚本内容很简单,获取我们在文件中定义的变量,然后通过日志输出,最后运行,控制台打印如下：因为我们是在脚本中使用,使用的是Kettle的内置对象parent_job的getVariable方法拿到当前ETL中的变量,如果在后面组件中,可以是拥有$符号的输入框中通过${variable_name}来引用,或者使用%variableName%另外,我们在组件中也可以看到组件的作用范围,主要有四种：  当前作业有效:代表的是当前作业  在JVM中有效:Kettle由于是Java编写,而Java程序运行是在JVM中运行的,因此如果设置在JVM中有效则相当于是全局有效,因为整个ETL过程都是在JVM平台上作用的  在父作业中有效:父作业中有效  在根作业中有效:根作业有效"
  },
  
  {
    "title": "Kettle实战100篇 第24篇 日志报表输出",
    "url": "/posts/kettle-24/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-19 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第23篇 命令行介绍使用",
    "url": "/posts/kettle-23/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-18 00:00:00 +0800",
    





    
    "snippet": "我们在前面介绍的实战篇章中,基本都是在Spoon的图形化界面中点击运行按钮时来运行我们的作业或者转换的,但是Kettle也为我们提供了基于命令行的调用方式,基于命令行的方式可以方便我们通过Shell脚本或者Windows的Bat脚本来对作业&amp;转换进行调用,这方便我们配置作业&amp;转换的任务调度我们可以在类似Unix平台上使用crontab服务来调用我们的Kettle作业&amp;...",
    "content": "我们在前面介绍的实战篇章中,基本都是在Spoon的图形化界面中点击运行按钮时来运行我们的作业或者转换的,但是Kettle也为我们提供了基于命令行的调用方式,基于命令行的方式可以方便我们通过Shell脚本或者Windows的Bat脚本来对作业&amp;转换进行调用,这方便我们配置作业&amp;转换的任务调度我们可以在类似Unix平台上使用crontab服务来调用我们的Kettle作业&amp;转换,在Windows平台也可以编写bat脚本添加任务计划进行有规律的调用,这对ETL的自动化处理是非常方便的.本章就详细的介绍Kettle为我们提供的命令行工具命令行工具介绍在我们下载的Kettle目录下,我们可以看到存在几个bat或者sh文件,主要包含：  Pan:执行转换的命令行工具  Kitchen:执行作业的命令行工具  Encr：加密工具  import: 备份和还原资源库命令工具  Spoon：Kettle的Spoon图形化启动命令  runSample：执行Kettle为我们提供的转换示例  Carte：Kettle提供的基于Jetty的简单作业服务器,主要用于Kettle集群，不同于Kitchen命令的是,该服务是后台一直运行的转换执行工具(Pan)在Windows平台执行Pan.bat文件,如果是在类似Unix环境下需要执行pan.sh文件关于Pan工具我们如果不知道输入参数的话,可以直接运行,此时Kettle会为我们打印出来相关的参数介绍信息Options:/rep            : 资源库名称/user           : 资源库用户名/trustuser      : 资源库用户名/pass           : 资源库密码/trans          : 要启动的转换名称/dir            : 目录(不要忘了前缀 /)/file           : 要启动的文件名(转换所在的 XML 文件)/level          : 日志等级 (Basic,Detailed,Debug,Rowlevel,Error,Minimal,Nothing)/logfile        : 要写入的日志文件/listdir        : 列出资源库里的目录/listtrans      : 列出指定目录下的转换/listrep        : 列出可用资源库/exprep         : 将资源库里的所有对象导出到 XML 文件中/norep          : 不要将日志写到资源库中/safemode       : 安全模式下运行: 有额外的检查/version        : 显示版本,校订和构建日期/param          : Set a named parameter &lt;NAME&gt;=&lt;VALUE&gt;. For example -param:FOO=bar/listparam      : List information concerning the defined named parameters in the specified transformation./metrics        : Gather metrics during execution/maxloglines    : The maximum number of log lines that are kept internally by Kettle. Set to 0 to keep all rows (default)/maxlogtimeout  : The maximum age (in minutes) of a log line while being kept internally by Kettle. Set to 0 to keep all rows indefinitely (default)如果我们的转换是另存为XML文件存在在本地磁盘上的,我们可以通过pan这样来调用(Windows平台)Pan.bat -file=test.ktr -logfile=test.log -level=RowLevel作业执行工具(Kitchen)作业执行工具和转换差不多,可以直接运行Kitchen.bat来查看输入参数,参数如下：Options:  /rep            : 资源库名称  /user           : 资源库用户名  /trustuser      : 资源库用户名  /pass           : 资源库密码  /job            : 资源库中的作业名称  /dir            : 资源库中的作业目录  /file           : 本地作业XML文件路径  /level          : 日志级别(Basic,Detailed,Debug,Rowlevel,Error,Minimal,Nothing)  /logfile        : 日志文件  /listdir        : 列出当前资源库中的所有目录  /listjobs       : 列出指定目录下的所有子夜  /listrep        : 列出可用的资源库  /norep          : 不要将日志写到资源库中  /version        : 显示版本号  /param          : Set a named parameter &lt;NAME&gt;=&lt;VALUE&gt;. For example -param:FILE=customers.csv  /listparam      : List information concerning the defined parameters in the specified job.  /export         : Exports all linked resources of the specified job. The argument is the name of a ZIP file.  /custom         : Set a custom plugin specific option as a String value in the job using &lt;NAME&gt;=&lt;Value&gt;, for example: -custom:COLOR=Red  /maxloglines    : The maximum number of log lines that are kept internally by Kettle. Set to 0 to keep all rows (default)  /maxlogtimeout  : The maximum age (in minutes) of a log line while being kept internally by Kettle. Set to 0 to keep all rows indefinitely (default)如果我们的作业文件是存在磁盘则可以这样调用(Windows平台)Kitchen.bat -file=F:\\公共技术\\kettle\\任务调度系统同步ES日志作业.kjb -logfile=F:\\公共技术\\kettle\\mySqlToES.log -level=Rowlevel作业服务器(Carte)Usage: Carte &lt;Interface address&gt; &lt;Port&gt; [-h] [-p &lt;arg&gt;] [-s] [-u &lt;arg&gt;]orUsage: Carte &lt;Configuration File&gt;Starts or stops the carte server.     -h,--help               This help text     -p,--password &lt;arg&gt;     The administrator password.  Required only if                             stopping the Carte server.     -s,--stop               Stop the running carte server.  This is only                             allowed when using the hostname/port form of the                             command.     -u,--userName &lt;arg&gt;     The administrator user name.  Required only if                             stopping the Carte server.Example: Carte 127.0.0.1 8080Example: Carte 192.168.1.221 8081Example: Carte /foo/bar/carte-config.xmlExample: Carte http://www.example.com/carte-config.xmlExample: Carte 127.0.0.1 8080 -s -u cluster -p cluster通过命令行调用帮助可以查看，Carte -h加密工具(Encr)加密工具,我们在生产服务器部署时可以用到此工具,针对数据库密码等敏感信息进行加密处理定义：  encr &lt;-kettle|-carte&gt; &lt;password&gt;  Options:    -kettle: generate an obfuscated password to include in Kettle XML files    -carte : generate an obfuscated password to include in the carte password file 'pwd/kettle.pwd'主要分为kettle和carte两种不同类型的密码处理kettle是我们在XML文件中使用的carte主要用于作用于作业服务器中使用方法Encr.bat -kettle 123456最终生成字符串Encrypted 2be98afc86aa7f2e4cb79ff228dc6fa8c导入备份工具(import)导入脚本是一个命令行实用程序，可将内容从单个.kjb或.ktr文件或完整存储库导出XML文件中提取到企业或数据库存储库中您还必须声明一个规则文件，该文件定义要导入的数据集成内容的某些参数,们提供了一个名为import-rules.xml的示例文件，该文件包含在标准数据集成客户端工具分发中。它包含所有潜在规则，以及描述每个规则的作用的注释。您可以修改import-rules.xml文件或将其内容复制到另一个文件，然后将规则文件声明为命令行参数。下表定义了导入脚本的命令行选项，这些选项是使用特定于操作系统类型的语法声明的:      Linux    使用短划线（ - ）后跟选项名称，然后是等号（=）和值（如果适用）声明选项。例如：-option = value        Windows    使用正斜杠（/）后跟选项名称，然后使用冒号（:)和值（如果适用）声明选项。例如：/ option：value    注意：对于不需要输入值（替换，系数和版本）的选项，选项后面的破折号或斜线（取决于您的操作系统）相当于选择“是”;否则，该选项被忽略。            选项      说明                  rep      要导入的企业或数据库存储库的名称。              user      企业或数据库访问用户名              pass      密码              dir      存储库中要将内容复制到的目录。              limitdir      可选的。要包含的逗号分隔源目录列表（不包括未显式声明的那些目录）。              file      要从中导入的存储库导出文件的路径              rules      如上所述，规则文件的路径              comment      将为导入的转换和作业的新修订设置的注释。              replace      替换存储库中的现有转换和作业。 （默认为：No）              coe      发生错误时继续运行,忽略错误(默认：No)              version      显示导入脚本与之接口的PDI实例的版本，修订版和构建日期。 （默认为：No）        LinuxImport.sh -rep= Archive71 -user=admin -pass=password -coe -replace -dir=/home/admin -file= /Downloads/imagitasDemoEnclosure.ktr -rules=/Downloads/import-rules.xml -comment=\"New version upload from UAT\"  WindowsImport.bat /rep:Archive71 /user:admin /pass:password /coe /replace /dir:\\home\\admin /file:C:\\Downloads\\imagitasDemoEnclosure.ktr /rules:C:\\Downloads\\import-rules.xml /comment:\"New version upload from UAT\""
  },
  
  {
    "title": "Kettle实战100篇 第22篇 资源库的使用",
    "url": "/posts/kettle-22/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-17 00:00:00 +0800",
    





    
    "snippet": "我们在前面的实战博客中,都是将我们的作业和转换文件保存在磁盘中,这在小规模的使用中是没有问题的,可是当我们的ETL工程越来越庞大时,一个团队需要更多的ETL工程师来开发ETL的过程时,单人作战就很不合适了,这就和我们开发人员写代码一样,多人协作时需要一个代码的协作平台(GIT、SVN等)来帮助我们管理代码版本，合并代码等操作因此,当我们的ETL工程初具规模时,团队协作配合开发ETL时就需要K...",
    "content": "我们在前面的实战博客中,都是将我们的作业和转换文件保存在磁盘中,这在小规模的使用中是没有问题的,可是当我们的ETL工程越来越庞大时,一个团队需要更多的ETL工程师来开发ETL的过程时,单人作战就很不合适了,这就和我们开发人员写代码一样,多人协作时需要一个代码的协作平台(GIT、SVN等)来帮助我们管理代码版本，合并代码等操作因此,当我们的ETL工程初具规模时,团队协作配合开发ETL时就需要Kettle为我们提供的资源库功能,资源库主要的特点：  中心化：我们所有的转换、作业、调度等信息都保存在远程中心库上,可以远程更新、保存等,便于协作  版本机制：提供完整的版本信息、记录ETL的操作信息,可以回溯版本  安全性：文件保存在中央仓库,需要有数据权限的人才能更改ETL过程另外一个比较方便的是我们在操作关系型数据库连接的同时,如果是使用资源库的方式进行保存的话,该资源库下所有的数据库都是引用关系,不需要重新建立DB连接操作,这很大程度上提高了工作效率.Kettle为我们提供的资源库主要有三种类型：  数据库资源库：我们所有的作业、转换等ETL信息都保存在数据库中  Pentaho资源库：Pentaho资源库的一个插件,在Kettle的企业版本中有这个插件  文件资源库：文件资源库是在一个文件目录下定义一个资源库我们使用数据库资源库这一类型作为我们的中央资源库,这种方式更加方便初始化连接那么我们应该如何使用资源库呢?首先我们运行Spoon图形化程序时,在界面的右上角,我们会看到Connect这一工具栏,该工具栏代表的就是我们需要连接的中央资源库此时,我们点击Connect,选择Repository Manager按钮,我们进行添加操作选择数据库类型的资源库,然后点击Get Started按钮,接下来会让我们输入资源库的名称,选择数据库连接操作(如果没有则新建)我使用的是Mysql数据库作为我的资源库,建立好连接,点击Finish完成,点击后,我们的数据库因为是一个空库,在此时Kettle会我们创建好相关的表结构、初始化表数据信息.Kettle初始化完成后,在8.3版本中的资源库表结构如下图：初始化完成后,我们就可以连接我们创建好的资源库了。点击Connect Now输入用户名和密码,这里Kettle会为我们初始化两个用户：  admin：管理员用户,用户名和密码均是admin  guest:guest用户,用户名和密码军事guest在数据库中的r_user表中如果要修改密码的话,我们可以使用Kettle为我们提供的加密工具Encr.bat来完成加密,首先通过命令行Encr.bat yourPassword生成密文,然后在数据库查询面板通过update语句来更新密码即可udpate r_user set password='pass' where ID_USER=1;最后,连接成功后,右上角的工具类会显示用户名接下来,新建转换、作业等信息都会保存在我们的资源库中异常情况有时候会出现连接不上资源库的情况,或者干脆右上角的Connect工具栏都消失了,碰到这种情况时,解决办事有两种重启关掉我们的Spoon程序,重新运行清除重建我们在本机操作保存的资源库名称链接信息,Kettle全部保存在我们的${USER_HOME}/.kettle/目录下主要在文件repositories.xml中保存结构如下：Connect如果是消失的情况下有可能是该文件信息中存在乱码的情况,清除乱码即可或者将该文件的所有connection节点信息全部删除,再运行Spoon程序时,重新建立资源库的连接即可."
  },
  
  {
    "title": "Kettle实战100篇 第21篇 JavaScript内置函数说明",
    "url": "/posts/kettle-21/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-16 00:00:00 +0800",
    





    
    "snippet": "我们在使用JavaScript组件的时候,在左侧核心树对象栏中可以看到Kettle为我们提供了很多简洁强大的内置函数,帮助我们在写脚本的时候对数据、参数变量等能很轻松的做处理,体验编码的感觉.本篇将详细介绍JavaScript组件中的函数功能脚本组件包含的函数主要包括六大类,分别是：  字符串类型的函数(String Functions)  浮点型的函数(Numeric Functions)...",
    "content": "我们在使用JavaScript组件的时候,在左侧核心树对象栏中可以看到Kettle为我们提供了很多简洁强大的内置函数,帮助我们在写脚本的时候对数据、参数变量等能很轻松的做处理,体验编码的感觉.本篇将详细介绍JavaScript组件中的函数功能脚本组件包含的函数主要包括六大类,分别是：  字符串类型的函数(String Functions)  浮点型的函数(Numeric Functions)  日期类型函数(Date Functions)  逻辑判断型函数(Logic Functions)  特殊的函数(Special Functions)  文件处理类函数(File Functions)字符串类型函数(String Functions)顾名思义,字符串类型的函数肯定是针对字符串类型的参数、变量进行处理操作的函数日期转字符串(date2str)日期转字符串函数date2str主要有4个方法,分别是：  date2str(date):传入日期实例,转换成字符串类型  date2str(date,format):传入日期和格式化参数,进行格式化转换  date2str(date,format,iso):传入日期和参数格式化及ISO代码进行转换,(DE = German, EN = English, FR = France, …)  date2str(date,format,iso,zone):传入时区进行格式化,例如北京时区(GMT+8)日期格式化参数format参数类型供参考：yy / yyyy - 06 / 2006MM / MMM / MMMMM - 11 / Nov / Novemberd / dd  - 1 / 01E / EEEE - Tue / Tuesdayhh / HH - 11 / 23m / mm - 5 / 05s / ss - 8 / 08代码示例:var dValue = new Date();writeToLog(date2str(dValue,\"dd.MM.yyyy\"));writeToLog(date2str(dValue,\"dd.MM.yyyy HH:mm:ss\"));writeToLog(date2str(dValue,\"E.MMM.yyyy\",\"DE\"));writeToLog(date2str(dValue,\"dd.MM.yyyy HH:mm:ss\",\"EN\"));writeToLog(date2str(dValue,\"dd.MM.yyyy HH:mm:ss\",\"ZH\", \"GMT+8\"));writeToLog(date2str(dValue,\"yyyy-MM-dd HH:mm:ss\",\"ZH\", \"GMT+8\"));以上代码在控制台将会输出如下：2019/08/19 10:12:56 - JavaScript代码.0 - 19.08.20192019/08/19 10:12:56 - JavaScript代码.0 - 19.08.2019 10:12:562019/08/19 10:12:56 - JavaScript代码.0 - Mo.Aug.20192019/08/19 10:12:56 - JavaScript代码.0 - 19.08.2019 10:12:562019/08/19 10:12:56 - JavaScript代码.0 - 19.08.2019 10:12:562019/08/19 10:12:56 - JavaScript代码.0 - 2019-08-19 10:12:56转义HTMLescapeHtml(html)代码如下：var html=\"&lt;h1&gt;我是H2标题&lt;/h2&gt;\";writeToLog(escapeHtml(html))最终输出2019/08/19 10:16:13 - JavaScript代码.0 - &amp;lt;h1&amp;gt;&amp;#25105;&amp;#26159;H2&amp;#26631;&amp;#39064;&amp;lt;/h2&amp;gt;转义SQL(escapeSQL(var))var str1 = \"SELECT * FROM CUSTOMER WHERE NAME='\" + escapeSQL(\"McHale's Navy\") + \"'\";  writeToLog(str1)该函数会把单引号转成双引号,输出结果如下：2019/08/19 10:18:59 - JavaScript代码.0 - SELECT * FROM CUSTOMER WHERE NAME='McHale''s Navy'构造定长字符串(fillString(char,length))代码示例如下：writeToLog(fillString(\"x\",10));writeToLog(fillString(\"A\",3));最终会输出10个X和3个A,输出结果如下：2019/08/19 10:24:08 - JavaScript代码.0 - xxxxxxxxxx2019/08/19 10:24:08 - JavaScript代码.0 - AAA需要注意的是第一个是一个char类型的单字符,不能是字符串统计字符串出现频次(getOcuranceString(str,searchStr))第一个参数是要搜索的完整字符串,第二个参数是要搜索统计的字符串代码示例：var sef='2007-09-11';writeToLog(getOcuranceString(sef,'0'))writeToLog(getOcuranceString(sef,'00'))我们分别统计字符串0和00最终出现的次数,此时,日志最终打印的次数是3和1：2019/08/19 10:28:45 - JavaScript代码.0 - 32019/08/19 10:28:45 - JavaScript代码.0 - 1获取字符串下标索引(indexOf)获取下标索引主要有2个重构函数,分别是：  indexOf(string,subString):获取出现字符串的索引开始位置  indexOf(string,subString,fromIndex)；指定开始位置,获取字符串索引开始位置代码示例：var str1= \"Hello Pentaho!\";var str2= indexOf(str1, \"Pentaho\");var str3= indexOf(str1, \"o\", 7);writeToLog(\"Input : \" + str1);writeToLog(\"Index of 'Pentaho' : \" + str2);writeToLog(\"index of 'o', search from position 7 : \" + str3);最终控制台输出：2019/08/19 10:34:16 - JavaScript代码.0 - Input : Hello Pentaho!2019/08/19 10:34:16 - JavaScript代码.0 - Index of 'Pentaho' : 62019/08/19 10:34:16 - JavaScript代码.0 - index of 'o', search from position 7 : 12首字母大写(initCap)对指定字符串首字母大写处理,来看代码示例：var str1 = \"my home\";      writeToLog(initCap(str1));writeToLog(initCap('test a aaa cw'));writeToLog(initCap('myhome'));此时,最终控制台输出如下：2019/08/19 10:41:27 - JavaScript代码.0 - My Home2019/08/19 10:41:27 - JavaScript代码.0 - Test A Aaa Cw2019/08/19 10:41:27 - JavaScript代码.0 - Myhome字符串转小写(lower)将传入字符串全部转小写代码如下：var str1= \"Hello World!\";var str2= lower(str1);writeToLog(\"Input:\" + str1);writeToLog(\"Converted to LowerCase:\" + str2);writeToLog(lower('DDDHelloSWxss'))响应内容2019/08/19 10:43:09 - JavaScript代码.0 - Input:Hello World!2019/08/19 10:43:09 - JavaScript代码.0 - Converted to LowerCase:hello world!2019/08/19 10:43:09 - JavaScript代码.0 - dddhelloswxss字符串填充左侧(lpad(string,char,length))用指定长度的给定字符将字符串填充到左侧参数定义：  1：传入字符串  2：填充单字符  3：填充单字符长度如果length长度超过给定字符串的长度,将对填充字符串做减法，例如：var str1= \"Hello World!\"; writeToLog(\"Lpad:\" + lpad(str1, \"x\",20));此时,最终输出结果为：2019/08/19 10:46:38 - JavaScript代码.0 - Lpad:xxxxxxxxHello World!最终的完成长度是20个字符长度,因此填充的单字符x并没有填充20次如果length长度小于给定字符串的长度,则默认返回原字符串,不做填充,代码示例：var str1= \"Hello World!\"; writeToLog(\"Lpad:\" + lpad(str1, \"x\",5));此时最终的输出结果为：2019/08/19 10:46:38 - JavaScript代码.0 - Lpad:Hello World!去空字符(ltrim)从左侧开始去除空字符串数字转字符串(num2str)给定数字,转换为字符串,主要有3个构造函数：  num2str(num):转换num数字为字符串  num2str(num,format):格式化数字为指定字符串  num2str(num,format,iso):按照本地ISO编码进行格式化代码示例如下：var d1 = 123.40;var d2 = -123.40;writeToLog(num2str(d1));writeToLog(num2str(d1, \"0.00\"));writeToLog(num2str(d1, \"0.00\", \"EN\"));writeToLog(num2str(d2, \"0.00;(0.00)\", \"EN\"));最终控制台输出：2019/08/19 11:00:17 - JavaScript代码.0 - 123.42019/08/19 11:00:17 - JavaScript代码.0 - 123.402019/08/19 11:00:17 - JavaScript代码.0 - 123.402019/08/19 11:00:17 - JavaScript代码.0 - (123.40)XML保护标签函数转换(protectXMLCDATA)传入给定字符串,添加标准保护,代码示例var str1 = \"my home\";      writeToLog(protectXMLCDATA(str1));此时,将会给变量str1加上保护标签2019/08/19 11:02:09 - JavaScript代码.0 - &lt;![CDATA[my home]]&gt;移除字符串中CRLF字符(removeCRLF(str))给定字符串中删除CR END LF的字符串替换字符串(replace)替换字符串主要包括两个构造函数：  replace(str,searchStr,replaceStr):从指定字符串中查询，然后替换  replace(str,firstSearch,firstReplace,secondSearch,SecondReplace...)：无限查询替换代码示例如下：var str1 = \"Hello World, this is a nice function\";      var str2 = replace(str1,\"World\", \"Folk\");writeToLog(str2);var str2 = replace(str1,\"World\", \"Folk\", \"nice\",\"beautifull\");writeToLog(str2);最终输出:2019/08/19 11:10:21 - JavaScript代码.0 - Hello Folk, this is a nice function2019/08/19 11:10:21 - JavaScript代码.0 - Hello Folk, this is a beautifull function字符串右侧填充(rpad(string,char,length))使用方法同lpad,只是一个是左侧，一个是右侧去除空字符(右侧)(rtrim)正则切分(str2RegExp)出入一个正则表达式,对string字符串进行Split操作.代码如下：var strToMatch = \"info@proconis.de\";var strReg = \"^(\\\\w+)@([a-zA-Z_]+?)\\\\.([a-zA-Z]{2,3})$\";var xArr =  str2RegExp(strToMatch, strReg);if ( xArr != null ) {    for(i=0;i&lt;xArr.length;i++) {\t    writeToLog(xArr[i]);\t}}else {    writeToLog(\"no match\");}最终控制台输出：2019/08/19 13:21:19 - JavaScript代码.0 - info2019/08/19 13:21:19 - JavaScript代码.0 - proconis2019/08/19 13:21:19 - JavaScript代码.0 - de字符串截取(substr)通过制定索引开始对字符串进行截取操作,主要有两个重构参数：  substr(string,from):指定from索引开始截取字符串  substr(string,from,to):指定开始和截止索引进行截取代码示例：var str1= \"Hello Pentaho!\";var str2= substr(str1, 6);var str3= substr(str1, 6, 7);writeToLog(\"Input : \" + str1);writeToLog(\"From position 6: \" + str2);writeToLog(\"From position 6 for 7 long : \" + str3);控制台输出如下：2019/08/19 13:31:20 - JavaScript代码.0 - Input : Hello Pentaho!2019/08/19 13:31:20 - JavaScript代码.0 - From position 6: Pentaho!2019/08/19 13:31:20 - JavaScript代码.0 - From position 6 for 7 long : Pentaho去除左右空格(trim)不转义HTML(unEscapeHtml(html))针对以转义的HTML字符进行解密,代码如下：var w='&lt;h2&gt;我是H2标题&lt;/h2&gt;';var esW=escapeHtml(w);var unesw=unEscapeHtml(esW);writeToLog(esW);writeToLog(unesw);最终控制台输出：2019/08/19 13:38:16 - JavaScript代码.0 - &amp;lt;h2&amp;gt;&amp;#25105;&amp;#26159;H2&amp;#26631;&amp;#39064;&amp;lt;/h2&amp;gt;2019/08/19 13:38:16 - JavaScript代码.0 - &lt;h2&gt;我是H2标题&lt;/h2&gt;解码转义XML(unEscapeXml )字符串转大写(upper)将传入字符串全部转大写.例如:var str=\"Hello World\";writeToLog(upper(str));浮点型的函数(Numeric Functions)计算绝对值(abs(num))计算一个数值的绝对值,代码示例：var d1 = -1234.01;var d2 = 1234.01;writeToLog(abs(d1));writeToLog(abs(d2));最终控制台输出为：2019/08/19 13:51:00 - JavaScript代码.0 - 1234.012019/08/19 13:51:00 - JavaScript代码.0 - 1234.01最小双精度值(ceil(num))返回最小的双精度值。该值将被四舍五入。代码示例：var d1 = -1234.01;var d2 = 1234.01;writeToLog(ceil(d1));writeToLog(ceil(d2));最终控制台输出：2019/08/19 13:52:40 - JavaScript代码.0 - -12342019/08/19 13:52:40 - JavaScript代码.0 - 1235最大数值(floor(num))返回最大数值,该值将被四舍五入,代码示例：var d1 = -1234.01;var d2 = 1234.01;writeToLog(floor(d1));writeToLog(floor(d2));运行结果如下：2019/08/19 13:55:13 - JavaScript代码.0 - -12352019/08/19 13:55:13 - JavaScript代码.0 - 1234字符串转数值(str2num(var))字符串转数值主要包含两个构造函数,分别是  str2num(str):传入数值字符串,进行格式化转换  str2num(str,format):通过指定格式进行数值转换代码示例如下：var str1 = \"1.234,56\";var str2 = \"12\";writeToLog((str2num(str1,\"#,##0.00\")));writeToLog((str2num(str2)));最终控制台输出：2019/08/19 14:02:19 - JavaScript代码.0 - 1.2342019/08/19 14:02:19 - JavaScript代码.0 - 12截取数值(trunc)trunc(1234.9); // 返回 1234日期类型函数(Date Functions)日期相加(dateAdd)针对日期变量进行相应的添加时间,添加频率包括年、月、日、时、分、秒 等等函数定义:dateAdd(date,format,plusNum)  date:日期对象  format:要加的类型  plusNum:加的数值相加类型主要包括：  y:年  m：月  d:日  w:周  wd:工作日  hh:小时  mi:分钟  ss:秒代码示例如下：var d1 = new Date();var fmt='yyyy-MM-dd HH:mm:ss';writeToLog(\"当前时间:\"+date2str(d1,fmt));var py=dateAdd(d1,'y',1);var fy=date2str(py,fmt);writeToLog(\"加1年：\"+fy);最终控制台输出：2019/08/19 14:17:41 - JavaScript代码.0 - 当前时间:2019-08-19 14:17:412019/08/19 14:17:41 - JavaScript代码.0 - 加1年：2020-08-19 14:17:41日期比较(dateDiff)两个日期相互比较函数定义:dateDiff(startDate,endDate,type)  startDate:开始日期  endDate:截止日期  type：返回相差数值类型类型主要包括：  y:年  m：月  d:日  w:周  wd:工作日  hh:小时  mi:分钟  ss:秒获取指定日期数值(getDayNumber)根据类型获取指定日期的数值函数定义：getDayNumber(date,type)  date:当前日期实例  type:类别类别主要分四类  y:获取当年的天数  m:获取当月的天数  w:获取本周的天数  wm:获取当月中本周的天数代码示例：var d1 = new Date();writeToLog(getDayNumber(d1, \"y\"));writeToLog(getDayNumber(d1, \"m\"));writeToLog(getDayNumber(d1, \"w\"));writeToLog(getDayNumber(d1, \"wm\"));getFiscalDate// Returns the fiscal Date from the date value,// based on a given offset.//// Usage:// getFiscalDate(var);// 1: Date - The Variable with the Date.// 2: String - The Date/Month which represents// the fiscal Start Offset. Format allways \"dd.MM.\".//// 2006-11-15//var d1 = new Date();var str1 = \"01.07.\";var str2 = \"10.12.\";Alert(getFiscalDate(d1, str1));Alert(getFiscalDate(d1, str2));获取下一个工作日日期(getNextWorkingDay)传入当前日期,获取该日期后面一个工作日日期函数定义getNextWorkingDay(date)代码示例如下：var d1 = new Date();// 周1var d2=str2date('2019-08-19 16:36:00',fmt);//周 6var d3=str2date('2019-08-17 16:36:00',fmt);writeToLog(date2str(getNextWorkingDay(d1),fmt));writeToLog(date2str(getNextWorkingDay(d2),fmt));writeToLog(date2str(getNextWorkingDay(d3),fmt));我们这d2和d3变量中定义了不同的日期实例,分别是周1和周6,最终通过getNextWorkingDay能获取得到下一个工作日日期，控制台输出如下：2019/08/19 16:37:38 - JavaScript代码.0 - 2019-08-20 16:37:382019/08/19 16:37:38 - JavaScript代码.0 - 2019-08-20 16:36:002019/08/19 16:37:38 - JavaScript代码.0 - 2019-08-19 16:36:00获取当前月份数值(month(date))获取当前日期的月份数值,需要注意的是,该值的月份是从0开始的,因此我们最终得到的结果应该+1才是我们的真实月份数值，代码示例：var d1 = new Date();//2019/08/19writeToLog(month(d1)); //最终输出为7获取当前时间的季度值(quarter(date))根据指定日期获取当前季度数值var d1 = new Date();//2019/08/19writeToLog(quarter(d1));//最终输出为3(代表第三季度)字符串转日期(str2date)字符串转日期和日期转字符串有点类似,只不过主体对换了一下,但是传入的格式参数都是一样的，主要有4个重载函数:  str2date(str):默认转换  str2date(str,format):传入format格式化参数  str2date(str,format,iso):根据iso编码及格式化参数进行转换  str2date(str,format,iso,timezone):根据不同时区的iso编码进行格式化转换代码示例如下：writeToLog(str2date(\"01.12.2006\",\"dd.MM.yyyy\"));writeToLog(str2date(\"01.12.2006 23:23:01\",\"dd.MM.yyyy HH:mm:ss\"));writeToLog(str2date(\"Tue.May.2006\",\"E.MMM.yyyy\",\"EN\"));writeToLog(str2date(\"22.02.2008 23:23:01\",\"dd.MM.yyyy HH:mm:ss\",\"DE\"));writeToLog(str2date(\"22.02.2008 23:23:01\",\"dd.MM.yyyy HH:mm:ss\",\"DE\", \"EST\"));截取日期(truncDate(date,type))指定截取不同的日期部分,函数定义truncDate(date,type)  date:当前日期实例  type:截取类型类型主要有6中,分别是整型，从0-5：  5：截取月份  4：截取天数  3:截取小时  2：截取分钟  1：截取秒  0:截取毫秒代码示例 如下：var dateTime = new Date();var date0 = truncDate(dateTime, 0); // gives back today at yyyy/MM/dd HH:mm:ss.000var date1 = truncDate(dateTime, 1); // gives back today at yyyy/MM/dd HH:mm:00.000var date2 = truncDate(dateTime, 2); // gives back today at yyyy/MM/dd HH:00:00.000var date3 = truncDate(dateTime, 3); // gives back today at yyyy/MM/dd 00:00:00.000var date4 = truncDate(dateTime, 4); // gives back today at yyyy/MM/01 00:00:00.000var date5 = truncDate(dateTime, 5); // gives back today at yyyy/01/01 00:00:00.000获取当年的周数(week)获取指定日期的周数,代码示例：var d1 = new Date(); //2019/08/19 writeToLog(week(d1));// 返回34获取年份(year)获取传入日期的年份,代码示例：var d1 = new Date(); //2019/08/19 writeToLog(year(d1));// 返回2019逻辑判断型函数(Logic Functions)isCodepage判断字符串的codepage项,代码示例：var xStr = \"RÃ©al\";writeToLog(isCodepage(xStr, \"UTF-8\"));// truewriteToLog(isCodepage(xStr, \"windows-1250\"));// true是否日期(isDate(str))判断当前字符串是否日期var d1 = \"Hello World\";      var d2 = new Date();writeToLog(isDate(d1));//falsewriteToLog(isDate(d2));//true是否为空(isEmpty(str))判断字符串是否为空var d = \"Hello World\";      Alert(isEmpty(d));//false判断字符串是否为邮箱标准格式(isMailValid(str))判断一个字符串是否是邮箱判断是否是数值(isNum(str))判断一个字符串是否是数值var str1 = \"Hello World\";      var str2 = 123456;Alert(isNum(str1));//falseAlert(isNum(str2));//true是否正则匹配(isRegExp)判断给定的正则表达式是否匹配当前的字符串，主要有2个函数定义：  isRegExp(str,reg):给定正则判断字符串是否匹配  isRegExp(str,reg1,reg2,reg3…)；可以递归判断正则匹配最终返回的是匹配的次数数值,如果不匹配,返回-1代码示例如下：var email1 =\"info@proconis.de\";var email2= \"support@proconis.co.uk\";var email3= \"HelloWorld@x\";var reg1=\"^\\\\w+@[a-zA-Z_]+?\\\\.[a-zA-Z]{2,3}$\";var reg2=\"^[\\\\w-\\.]+@([\\\\w-]+\\\\.)+[\\\\w-]{2,4}$\";writeToLog(isRegExp(email1, reg1,reg2) + \" Matches\"); //1writeToLog(isRegExp(email2, reg1,reg2) + \" Matches\");  //2writeToLog(isRegExp(email3, reg1,reg2) + \" Matches\");// 1是否工作日(isWorkingDay(date))判断某日期是否是工作日,代码示例：var d1 = new Date();//周1var d2=str2date('2019-08-17','yyyy-MM-dd') //周六writeToLog(isWorkingDay(d1));//truewriteToLog(isWorkingDay(d2));//false特殊的函数(Special Functions)弹框信息(Alert(msg))在屏幕前弹出一个信息框加载JavaScript文件(LoadScriptFile)将一个javascript文件加载到实际的运行上下文中。应该从定义的StartScript调用此函数，否则，每次处理都会加载javascript文件行。代码示例如下：var xPfad = \"F:/bak/Hello.js\";LoadScriptFile(xPfad);此时,我们的外部JS文件仅仅是包含一句简单的输出，如下：writeToLog(\"Hello LoadScriptFile,outSide JS File \");最终运行时,控制台会打印出我们在外部JS中的输出行从当前Tab栏加载JS并运行(LoadScriptFromTab)如果我们在当前的JavaScript组件中通过模块化的方式编写了很多脚本代码,我们可以通过LoadScriptFromTab函数进行相互调用,这对于开发抽象来说是很好的,代码示例如下：writeToLog(\"外部Tab加载JS-------------------------\")LoadScriptFromTab('Item_1');有效卡号判断(LuhnCheck)如果给定的是一个有效的卡号,则返回truevar str1 = \"4444333322221111\";      writeToLog(str1 + \": \" + LuhnCheck(str1)); //truevar str2 = \"4444333322221110\";      writeToLog(str2 + \": \" + LuhnCheck(str2));//false      向文件中追加数据(appendToFile)向指定文件中追加数据,如果文件不存在则创建文件var file = \"F:/bak/log.txt\";for(var i=0;i&lt;100;i++){\tappendToFile(file,'TEST'+i+\"\\r\\n\");}此时,该代码会向log.txt文件输出100条数据行decode函数decode函数有点类似于IF-THEN-ELSE语句，即表示通过给定查询的字符串是否存在，如果存在，即替换,否则返回默认值代码示例：var str1 = \"Hallo\";writeToLog(decode(str1, \"Hallo\", \"Hello\"));writeToLog(decode(str1, \"1\", \"Mr\", \"2\", \"Mrs\", \"N/A\"));writeToLog(decode(str1, \"1\", \"Mr\", \"2\", \"Mrs\"));str1 = \"Mrs\";writeToLog(decode(str1, \"1\", \"Mr\", \"2\", \"Mrs\"));控制台输出：2019/08/19 17:39:01 - JavaScript代码.0 - Hello2019/08/19 17:39:01 - JavaScript代码.0 - N/A2019/08/19 17:39:01 - JavaScript代码.0 - Hallo2019/08/19 17:39:01 - JavaScript代码.0 - Mrs执行命令(execProcess)代码如下：var t=execProcess('ping www.baidu.com');writeToLog(t)调用命令行,ping百度的网址，最终输出返回数据执行SQL语句(fireToDB)通过获取数据库连接名称，传递SQL语句,以返回SQL查询的值,函数定义：  fireToDB(connectionName,SQL)；第一个参数为数据库连接名称，我们在JNDI中定义的名称，第二个参数为SQL语句var strConn = \"MY Connection\";var strSQL = \"SELECT COUNT(*) FROM ...\";var xArr = fireToDB(strConn, strSQL);仅仅获取数值(getDigitsOnly)在给定的字符串中仅仅筛选过滤得到数值，代码如下：var str1 = \"abc123cde\";      writeToLog(getDigitsOnly(str1));//返回123获取Kettle环境变量的值(getEnvironmentVar)获取在Kettle中的环境变量的值writeToLog(getEnvironmentVar(\"user.dir\"));writeToLog(getEnvironmentVar(\"user.name\"));获取当前进程的受影响行数(getProcessCount(type))根据类型获取当前进程的受影响行数，类型如下：  u:更新行数  i:插入行数  w:写入行数  r:读取行数  o:输出行数writeToLog(getProcessCount(\"u\"));writeToLog(getProcessCount(\"r\"));获取当前转换名称(getTransformationName)获取当前的转换名称var xTranName = getTransformationName();writeToLog(xTranName);获取Kettle环境中的变量值(getVariable)从当前的Kettle环境中获取指定的变量值,目前函数有2个重载：  getVariable(varName)；根据变量名称获取变量值  getVariable(varName,defaultValue):根据变量名获取值,如果不存在则使用默认值var strVarName=\"getVariableTest\";var strVarValue=\"123456\";Alert(getVariable(strVarName, \"\"));setVariable(strVarName,strVarValue, \"r\");Alert(getVariable(strVarName, \"\"));strVarValue=\"654321\";setVariable(strVarName,strVarValue, \"r\");Alert(getVariable(strVarName, \"\"));控制台打印(println)var str = \"Hello World!\";print(str);      移除数值(removeDigits)移除给定字符串中的数值，代码示例：var str1 = \"abc123cde\"; writeToLog(removeDigits(str1));//返回abccde发送邮件设置环境变量(setEnvironmentVar)通过在Script脚本组件中调用函数重新设置Kettle的环境变量var strVarName=\"setEnvTest\";var strVarValue=\"123456\";Alert(getEnvironmentVar(strVarName));setEnvironmentVar(strVarName,strVarValue);Alert(getEnvironmentVar(strVarName));strVarValue=\"654321\";setEnvironmentVar(strVarName,strVarValue);Alert(getEnvironmentVar(strVarName));设置变量(setVariable)通过setVariable函数设置环境变量,该用途可以用于重新赋值Kettle环境中已经存在的变量值或者重新生成变量值函数定义setVariable(key,value,level)  key:变量名称  value:变量值  level:级别,主要包括s(system)、r(root)、p(parent)、g(grandparent)四种类别代码示例如下：var strVarName=\"setEnvTest\";var strVarValue=\"123456\";Alert(getVariable(strVarName, \"\"));setVariable(strVarName,strVarValue, \"r\");Alert(getVariable(strVarName, \"\"));strVarValue=\"654321\";setVariable(strVarName,strVarValue, \"r\");Alert(getVariable(strVarName, \"\"));写入日志(writeToLog)打印并写入日志信息,该函数可能是我们用到的最多的函数,可以帮助我们调试信息,主要有两个重载：  writeToLog(msg):写入msg日志信息  writeToLog(level,msg)：根据level基本写入msg信息关于日志的级别,这里主要是简写的方式,主要如下：  d(Debug):调试模式  l(Detailed):详细  e(Error):错误  m(Minimal):最小日志  r(RowLevel):行级日志writeToLog(\"Hello World!\");writeToLog(\"r\", \"Hello World!\");文件处理类函数(File Functions)复制文件(copyFile)复制一个文件到目标目录,函数定义如下：copyFile(sourceFile,targetFile,overwrite)  sourceFile:源文件  targetFile:目标文件  overWrite:是否覆盖,如果目标文件存在的话,布尔类型var file1 = \"F:/bak/log.txt\";var targetFile=\"F:/bak/logTarget.txt\";copyFile(file1,targetFile,false)创建文件夹(createFolder)创建一个文件夹,代码示例如下：var strFolder = \"F:/bak/createFolder\";createFolder(strFolder);删除文件(deleteFile)删除一个文件(不能删除文件夹)var targetFile=\"F:/bak/logTarget.txt\"; deleteFile(targetFile);判断文件是否存在(fileExists())判断文件是否存在var targetFile=\"F:/bak/logTarget.txt\"; fileExists(targetFile);获取文件扩展名(getFileExtension)如果文件不存在,则返回null,代码示例var file1 = \"F:/bak/log.txt\"; var ext=getFileExtension(file1);writeToLog(\"扩展名：\"+ext)获取文件大小(getFileSize)获取文件大小,结果是一个long类型的长整型数值var file1 = \"F:/bak/log.txt\"; var ext=getFileSize(file1);writeToLog(\"大小：\"+ext)获取文件最后修改日期(getLastModifiedTime)获取文件最后修改日期,函数定义：getLastModifiedTime(filePath,format)  filePath:文件路径  format：日期格式化var file1 = \"F:/bak/log.txt\"; var ext=getLastModifiedTime(file1,\"yyyy-MM-dd HH:mm:ss\");获取文件的父文件夹名称(getParentFoldername)获取文件的父文件夹名称var file1 = \"F:/bak/log.txt\";var parentFolder=getParentFoldername(file1);获取文件简称(getShortName)获取文件简称var file1 = \"F:/bak/log.txt\";var shortName=getShortFilename(file1);writeToLog(\"简单名称:\"+shortName)//返回log.txt判断是否是一个文件(isFile)判断是否是一个文件var file1 = \"F:/bak/log.txt\";var flag=isFile(file1) //true判断是否是一个文件夹(isFolder)判断是否是一个文件夹var file1 = \"F:/bak/log.txt\";var flag=isFolder(file1) //false加载一个文件的内容(loadFileContent)从指定文件中加载内容,主要有两个重载函数：  loadFileContent(filePath):默认加载文件  loadFileContent(filePath,encoding):指定编码加载文件内容代码示例：var file1 = \"F:/bak/log.txt\";var content=loadFileContent(file1);var c1=loadFileContent(file1,\"UTF-8\")writeToLog(content)移动文件(moveFile)移动指定文件，函数定义moveFile(source,target,overWrite)  source:源文件  target:目标文件  overWrite；是否覆盖,如果目标文件存在,布尔类型值var file1 = \"F:/bak/log.txt\";var targetFile=\"F:/bak/logTarget.txt\";moveFile(file1,targetFile,false)创建一个空文件(touch)创建一个空文件var strFile = \"F:/bak/log.txt\";touch(strFile);总结以上就是Kettle 8.3版本中的内置函数方法,方法很多,写这篇博客也是很累,算是全部都学习了一遍,脑子里已经记忆了一遍,但是我们也不需要死记硬背,就和我们学些Linux命令一样,如果你知道man命令，对某个命令不是很了解的话直接通过man命令学习即可.Kettle也是如此,对于某个函数不是很了解的话,右键点击该函数,会出现sample字样菜单,点击该菜单即可弹出该函数的介绍和使用信息,里面包含了该函数的调用示例和函数详细介绍,也是很人性化的."
  },
  
  {
    "title": "Kettle实战100篇 第20篇 MySQL数据库导出到ElasticSearch",
    "url": "/posts/kettle-20/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-15 00:00:00 +0800",
    





    
    "snippet": "  业务需求：在系统上线后,原系统的日志信息是存储到MySQL数据库中,但是随着日志数据越来越大,导致数据查询缓慢,加上日志数据并非业务系统关键数据,因此,系统考虑改版升级,使用ElasticSearch来存储日志数据,因此需要将源存在MySQL数据库上的数据迁移到ES中简单示例我们先来看一个简单的ES导入数据范例,建立ES的索引结构PUT /scheduler_log建立字段信息PUT s...",
    "content": "  业务需求：在系统上线后,原系统的日志信息是存储到MySQL数据库中,但是随着日志数据越来越大,导致数据查询缓慢,加上日志数据并非业务系统关键数据,因此,系统考虑改版升级,使用ElasticSearch来存储日志数据,因此需要将源存在MySQL数据库上的数据迁移到ES中简单示例我们先来看一个简单的ES导入数据范例,建立ES的索引结构PUT /scheduler_log建立字段信息PUT scheduler_log/_mapping{    \"scheduler_log\": {        \"properties\": {            \"result\": {                \"type\": \"boolean\",                \"cql_collection\": \"singleton\"            },            \"number\": {                \"type\": \"double\",                \"cql_collection\": \"singleton\"            },            \"id\": {                \"type\": \"keyword\",                \"cql_collection\": \"singleton\",                \"cql_partition_key\": true,                \"cql_primary_key_order\": 1            },            \"type\": {                \"type\": \"keyword\",                \"cql_collection\": \"singleton\",                \"cql_partition_key\": true,                \"cql_primary_key_order\": 0            },            \"key\": {                \"type\": \"keyword\",                \"cql_collection\": \"singleton\",                \"cql_partition_key\": true,                \"cql_primary_key_order\": 2            }        }    }}主要有5个字段此时,我们建立转换,随机生成1条记录导入ES,最终转换如下图：生成记录组件很简单,设置ES索引中的字段即可,如下图：Elasticsearch bulk insert主核心的组件是Elasticsearch bulk insert组件，该组件维护批量加载核心树目录下.常规选项主要包含两个属性：索引和类型另外需要指定ID Field字段,作为主键值服务端组件这里需要输入ES的服务端地址和端口,注意,Kettle导入ES组件使用的是ES的Java Api,并非是调用ES的RESTful接口,因此,此处的端口是使用的Transport端口,一般是9300通过获取字段可以获取得到我们定义的字段另外在Settings选项卡中需要指定ES的集群名称参数cluster.name的值最后点击运行,查看我们的ES导入情况MySQL数据库导入简单导入从MySQL导入到ES也很简答,我们只需要使用表输入组件代替生成数据组件即可,在表数据组件中写上查询SQL语句,然后在ES组件设置匹配字段即可完成,转换图如下：表输入组件写上SQL查询语句然后在ES的组件中设置匹配字段此时 即可很方便的导入数据到ES中全量导入我们现在的需求是需要将原MySQL数据库中的表(ls_scheduler_log)全部迁移到ES中,原表目前记录大概在200W条因此我们需要通过分页来实现该需求.既然需要用到分页,因此我们的limit和页码需要使用变量来替代,并且需要通过作业来完成整体作业图如下：在作业中我们有两个转换和两个JavaScript组件第一个转换是为了得到MySQL目标表中的总记录数,以获取得到总页数第二个转换是分页同步MySQL中的数据到目标ES库中设置变量在第一步,因为我们是分页查询MySQL数据库,因此需要事先把用到的参数变量在第一个中先预先定义,如下图：计算单表总记录数第二步是得到我们MySQL记录表中的数据总量,以便用来计算总页数,为后面轮训分页导入到ES库做准备,转换如下图：表输入组件是一个很简单的count语句,如下图：此时,我们将查询结果复制到结果,供父作业组件中使用#### 计算总页码在上一个步骤中我们查询得到了总记录数,因此需要一个脚本组件,用来计算总页数，脚本内容如下：var subject=\"自定义日志输出\";var logFactory = new org.pentaho.di.core.logging.LogChannelFactory();var log= logFactory.create(subject); //获取总记录行数var preRows=previous_result.getRows();if(preRows ==null || preRows.size()==0){\tfalse;}else{\tvar logCount=preRows.get(0).getInteger(\"logCount\");\tlog.logMinimal(\"当前总记录数：\"+logCount)\t//获取变量,计算总页数,重新赋值\tvar pageSize=parent_job.getVariable(\"pageSize\");\tvar  cup=parent_job.getVariable('currentPage');\tvar ofs=parent_job.getVariable('offsetSize');\tvar nofs=(parseInt(cup)-1)*parseInt(ofs);\tlog.logMinimal('当前offsetSize:'+nofs)\tparent_job.setVariable('offsetSize',nofs);\tlog.logMinimal('pageSize:'+pageSize)\tvar tempRecord=\tparseInt(logCount)+parseInt(pageSize)-1;\t \tvar totalPage=Math.round(tempRecord/parseInt(pageSize));  \tlog.logMinimal(\"总页码:\"+totalPage);\t//赋值\tparent_job.setVariable('totalPage',totalPage);\ttrue;}通过previous_result对象获取得到上一个步骤的结果,最后计算得到总页码,调用setVariable方法覆盖变量的初始值设置轮训条件既然是分页导入,因此我们需要一个轮训条件,条件规则就是当前页码小于等于总页码开始同步至ES数据源同步ES数据转换如下：第一步是获取变量,我们在父作业组件中定义的分页变量数据,如下图：第二步则是在SQL分页查询中使用变量替代进行分页查询最后一步是设置ES的导入属性配置：计算页码最后我们分页导出时,需要动态更改我们的当前页码,因此需要一个脚本组件来动态计算,脚本内容如下：var subject=\"自定义日志输出\";var logFactory = new org.pentaho.di.core.logging.LogChannelFactory();var log= logFactory.create(subject); //此脚本需要计算offsetSize的值以及currentPage页码的值var currentPage=parent_job.getVariable('currentPage');var totalPage=parent_job.getVariable('totalPage');var pageSize=parent_job.getVariable('pageSize');log.logMinimal('当前页码1:'+currentPage);log.logMinimal('总页码1：'+totalPage);//如果当前页码《总页码 则为true//第二页的offset是currentPage*pageSize;if(parseInt(currentPage)&lt;=parseInt(totalPage)){\tvar noffSet=currentPage*pageSize;\tparent_job.setVariable('offsetSize',noffSet);\tlog.logMinimal('当前offsetSize:'+noffSet);\t//当前页码+1\tcurrentPage++;\tlog.logMinimal('当前页码:'+currentPage);\tlog.logMinimal('总页码：'+totalPage);\tparent_job.setVariable('currentPage',currentPage);\t\ttrue;}else{\tlog.logMinimal('条件不满足,退出了。。。')\tfalse;}"
  },
  
  {
    "title": "Kettle实战100篇 第19篇 转换核心对象Microsoft Excel输出组件",
    "url": "/posts/kettle-19/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-15 00:00:00 +0800",
    





    
    "snippet": "我们在上面的实战系列中,多次用到了Excel作为输入或输出组件,该篇主要是针对官方英文文档做一个翻译说明,主要包括输入、输出、写入组件Microsoft Excel 输出英文地址:https://help.pentaho.com/Documentation/8.3/Products/Microsoft_Excel_OutputMicrosoft Excel输出步骤允许您将数据写入一个或多个E...",
    "content": "我们在上面的实战系列中,多次用到了Excel作为输入或输出组件,该篇主要是针对官方英文文档做一个翻译说明,主要包括输入、输出、写入组件Microsoft Excel 输出英文地址:https://help.pentaho.com/Documentation/8.3/Products/Microsoft_Excel_OutputMicrosoft Excel输出步骤允许您将数据写入一个或多个Excel文件。以下部分介绍了可用于配置此步骤的功能。  说明：此步骤将数据导出到Microsoft Excel 2003电子表格文件（.xls）。如果要写入.xlsx文件（Excel 2007及更高版本），请参阅Microsoft Excel Writer步骤在我们的8.3版本中,Excel输出有两个组件对象,分别是Excel输出和Microsoft Excel 输出，第一个是仅支持2003版本的格式(有数量限制,且步骤设置较简单),后面Microsoft Excel 输出则包含了很多属性、规则设置,我们在选择Excel输出时应该选择后者,由于Spoon翻译的缘故,我们在转换核心对象树中看见的Microsoft Excel 输出组件实际上对应的是Microsoft Excel Writer组件文件选项            选项      说明                  步骤名称      指定当前步骤的唯一步骤名称              文件名      输出的Excel文件名称              创建父目录      如果当前目录不存在则创建父目录,该选项适应于指定的文件目录不存在的情况              启动时不创建文件      完成此步骤后，选择以创建输出文件。当数据流中没有行时，这可以避免创建空文件              扩展名      固定XLS格式(因为这是2003格式的Excel)              在文件中包含步骤数      选择在扩展名之前的输出文件名中添加副本号。例如：nnnn_0.ext              在文件名中包含日期      选择在扩展名之前输出日期，例如：_20190816              在文件名中包含时间      选择在扩展名之前输出时间,例如：_235959              指定时间格式      选择特定的时间格式进行格式化输出以上关于时间的配置              结果中添加文件名      选择将文件名添加到内部文件名结果集。此内部结果集稍后可用于处理所有已创建的文件      内容选项            选项      说明                  追加      选择将行附加到指定文件的末尾。如果该文件不存在，将创建一个新文件。              头      选择以显示标题（在“自定义”选项卡中定义）。标题将显示在电子表格网格数据之前。即输出表头              脚      选择以显示电子表格网格数据后面的页脚              编码      指定文件的输出编码，1、指定UTF-8或者UTF-16编码，2、空选项使用系统默认编码首次使用时，PDI客户端会在系统中搜索可用的编码并相应地填充此列表。              分隔每一行      指定要拆分文件的行数，并启动一个新的电子表格以继续输出数据。              工作表名称      Excel中的Sheet名称              保护工作表      选择密码保护工作表。您还必须在“密码”字段中指定密码。              自动调整列大小      选择此选项可自动将工作表列的大小设置为最大值。              保留Null值      选择此选项可在输出中保留空值。 如果未选择此选项，则使用空字符串替换空值。              使用临时文件      指定临时文件目录              使用模板      选择以使用指定的Excel模板来创建输出文件。如果选择此选项，则还必须在Excel模板字段中指定模板文件名。              追加Excel模板      选择将输出附加到指定的Excel模板      个性化选项个性化选项主要包含针对输出Excel的个性配置，主要分为表头和表数据两大部分：  表头：表头字体、大小、是否加粗、斜线、斜线字体、高度、颜色等  表数据：字体、大小、颜色、背景等字段选项卡“字段”选项卡定义导出字段的属性。单击“获取字段”以自动从输入流中检索字段列表并填充列表。最小宽度按钮可从输出中删除任何填充。            选项      描述                  名称      指定字段名称              类型      指定字段的数据类型(string、date或者number)              格式      指定字段最终输出格式      获取字段:\t单击“获取字段”以从输入流中检索字段列表并填充列表。最小宽度:\t单击“最小宽度”以从输出中删除任何多余的填充。  说明：您可以指定Excel中可用的任何格式定义。这些格式不限于任何特定于Kettle的格式元数据支持此步骤的所有字段都支持元数据注入。您可以将此步骤与ETL元数据注入一起使用，以便在运行时将元数据传递给转换。Microsoft Excel Writer官方文档:https://help.pentaho.com/Documentation/8.3/Products/Microsoft_Excel_WriterMicrosoft Excel Writer步骤将传入的行从PDI写入MS Excel文件，并支持.xls和.xlsx文件格式。 .xls文件使用更适合简单内容的二进制格式，而.xlsx文件使用Open XML格式，该格式适用于模板，因为它可以更好地保留图表和杂项对象。一般我们在做Excel导出时也是使用此组件居多.常规指定该步骤的名称文件&amp;工作表 选项选项卡主要分为三个部分：文件、工作表、模板文件此面板包括用于选择结果文件名，扩展名和时间戳信息的字段。如果数据分成多个行，则会创建多个文件。您还可以从此面板预览结果            字段      说明                  文件名称      用于指定文件输出名称、存储路径              扩展名      选择xls或者xlsx两种格式              Stream XSLX data (check box)      将大型XLSX文件写入输出文件时选择此选项1、如果要流式传输XLSX文件，请选择此选项。当您选中此复选框时，系统使用流API来编写大文件而没有任何内存限制（不超过MS Excel的1,048,575行和16,384列的限制）。2、如果您不想流式传输XLSX文件，请清除此复选框。只有选择扩展为xlsx格式时该选项才可用              分隔每一行数据      指定正数以在每个’n’个数据行中创建新的输出文件。例如，如果要每200个数据行拆分文件，则在此字段中输入200。文件将被编号。              文件名包含步骤数目      在多个副本中运行步骤时，选择此选项可在文件名（例如_0）中包含副本号，例如同时启动步骤的多个副本              文件名包含日期      文件名称包含日期,如：_20190916              文件名包含时间      文件名称包含时间，如：_235959              指定日期格式      指定日期的format格式              如果文件已存在      如果文件存在选择数据的输出方式，覆盖现有文件或者继续使用原文件输出              在接收到数据钱不创建文件      如果选择此选项，则该步骤仅在检测到行后才创建该文件。如果清除此选项，则始终会创建输出文件，无论行是否实际写入文件。                     使用此选项可将文件名添加到MS Excel输出文件中。      工作表            字段      说明                  工作表名      输出表的sheet名称              设为活动工作表      如果选中，则在Excel中打开文件时，默认情况下将在上面的工作表中打开MS Excel文件              如果输出文件以已经存在此工作表      如果已经存在则选择输出方式，一种是覆盖、一种是继续追加输出              保护工作表(仅限XLS格式)      保护当前XLS格式的Excel表格,选择此项后输入保护人及密码      模板When you create new files or replace existing files, you may choose to create a copy of an existing template file instead. Please make sure that the template file is of the same type as the output file: both must be either .xls or .xlsx. This panel includes fields for using template files and sheets in your Excel output file.            Field      Description                  Use template when creating new files (check box)      Select this option if you want to use a specified MS Excel template to create the output file.Select this option to specify an Excel template for use in creating the output file. If you select this option, you must also specify the template file name in the Template file field below.Clear this option if you do not want to specify a template file.              Template file      If you selected the Use template when creating new files check box above, then enter the template file name you want to use, or click the Browse button and navigate to it.              Use template when creating new sheets (check box)      Select this option if you want to use a specified template sheet to create the output sheet.Select this option to specify a template sheet for use in creating the output sheet. If you select this option, you must also specify the name of the template sheet in the Template sheet field below.Clear this option if you do not want to specify a template sheet.              Template sheet      If you selected the Use template when creating new sheets check box above, then enter the template sheet name you want to use, or click the Browse button and navigate to it.              Hide Template sheet (check box)      Decide if you want the template sheet to be visible when the MS Excel output file is opened.Select this option to hide the template sheet from users who open the output file.Clear this option to show the template sheet to users who open the output file.      内容选项内容选项卡主要从内容和已存在的工作表相关配置            字段      说明                  开始输出自单元格      默认A1,我们在分页导出数据输出到Excel时,该字段需要使用变量替代              当输出记录时      选择覆盖或者继续输出              输出表头      选择输出表头              输出表尾      输出表尾              自动调整列大小      选择此项后自动调整列大小              强制公式重新计算                     不改变现有单元格格式             Fields panelThis panel includes Fields table for specifying the fields that are written to the Excel files. The Fields table contains the following columns:            Column      Description                  Name      The name of the field.              Type      The data type of a field: String, Date, or Number.              Format      The Excel format to use in the sheet. Please consult the Excel manual for valid formats. There are some online references as well.              Style from cell      A cell in the Excel spreadsheet (letter column, number row) such as A1, B4, etc., to copy the styling from for this column. This value is usually a pre-styled cell in a template.              Field title      If set, this is used for the Header/Footer instead of the Kettle field name.              Header/Footer style from cell      A cell to copy the styling from for the Header/Footer (usually some pre-styled cell in a template).              field contains formula      Set to Yes if the field contains an Excel formula.You do not need to include the notation = before your field value.              Hyperlink      A field that contains the target to link to. Supported targets can be links to other Excel spreadsheet cells, website URL’s, ftp’s, email addresses, or local documents.              Cell comment (XLSX)      The XLSX format allows to put comments on cells. If you would like to generate comments, you may specify fields holding the comment and author for a given column.              Cell comment author (XLSX)      The XLSX format allows to put comments on cells. If you would like to generate comments, you may specify fields holding the comment and author for a given column.      "
  },
  
  {
    "title": "Kettle实战100篇 第18篇 JavaScript脚本组件使用示例",
    "url": "/posts/kettle-18/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-15 00:00:00 +0800",
    





    
    "snippet": "JavaScript内置对象我们可以在JavaScript脚本中使用内部API对象  TransformationName：转换名称获取访问变量转换如下图：JavaScript的脚本内容如下：var v1 = getVariable(\"VAR1\", \"\");var v2 = getVariable(\"java.io.tmpdir\", \"\");var subject=\"自定义日志输出\";//实...",
    "content": "JavaScript内置对象我们可以在JavaScript脚本中使用内部API对象  TransformationName：转换名称获取访问变量转换如下图：JavaScript的脚本内容如下：var v1 = getVariable(\"VAR1\", \"\");var v2 = getVariable(\"java.io.tmpdir\", \"\");var subject=\"自定义日志输出\";//实例化日志channel对象var log= new org.pentaho.di.core.logging.LogChannel(subject);//日志输出log.logMinimal(\"v1:\"+v1+\",v2:\"+v2);在生成记录中我们定义了限制数据为10条,运行后控制台输出："
  },
  
  {
    "title": "Kettle实战100篇 第17篇 JSONPath组件介绍说明",
    "url": "/posts/kettle-17/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-14 00:00:00 +0800",
    





    
    "snippet": "在我们使用JSON input组件的时候,设置字段映射时,由于Kettle使用的是JSONPath组件来进行解析的,因此我们就需要了解他的相关语法JSONPath是一个用于读取JSON的Java DSL操作库GitHub:https://github.com/json-path/JsonPath在线调试:http://jsonpath.herokuapp.com/表示法JSONPath表达式...",
    "content": "在我们使用JSON input组件的时候,设置字段映射时,由于Kettle使用的是JSONPath组件来进行解析的,因此我们就需要了解他的相关语法JSONPath是一个用于读取JSON的Java DSL操作库GitHub:https://github.com/json-path/JsonPath在线调试:http://jsonpath.herokuapp.com/表示法JSONPath表达式用于指定JSON结构元素(或一组元素)的路径.路径的表示法可以使用点表示,如下：$.store.book[0].title或者括号表示:$['store']['book'][0]['title']$所代表的是JSON根路径,在使用时可以忽略.例如$.foobar.name和foobar.name所表达的意思是一样的,同理$[0].status和[0].status也一样其他语法元素如下表:            表达式      说明                  $      根对象或者数组              .property      选择父对象中指定的属性              [property]      选择父对象中的指定属性。务必在属性名称周围加上单引号。如果属性名称包含空格等特殊字符，或者以A..Za..z_以外的字符开头，请使用此表示法              [n]      从数组中选择第n个元素。索引从0开始。              [index1,index2,…]      选择具有指定索引的数组元素。返回一个集合列表。              ..property      递归查找：递归搜索指定的属性名称，并返回具有此属性名称的所有值的数组。即使只找到一个属性，也始终返回一个列表。              *      通配符选择对象或数组中的所有元素，无论其名称或索引如何。例如，address.*。*表示地址对象的所有属性，book [*]表示书籍数组的所有项目              [start:end] or [start:]      从起始索引中选择数组元素，最多但不包括结束索引。如果省略end，则从开始到数组结束选择所有元素。返回一个列表。              [:n]      选择数组的前n个元素。返回一个列表。              [-n:]      选择数组的最后n个元素。返回一个列表。              [?expression]      过滤表达式。选择对象或数组中与指定过滤器匹配的所有元素。返回一个列表。              [(expression)]      可以使用脚本表达式代替显式属性名称或索引。一个例子是[(@.length-1)]，它选择数组中的最后一项。这里，length指的是当前数组的长度，而不是名为length的JSON字段。              @      在过滤器表达式中用于引用正在处理的当前节点。      注意：  JSONPath表达式(包括属性名称和值)区分大小写。  与XPath不同，JSONPath没有用于从给定节点访问父节点或兄弟节点的操作。过滤器过滤器是用于过滤数组的逻辑表达式。带有过滤器的JSONPath表达式的示例$.store.book[?(@.price &lt; 10)]其中@表示当前正在处理的数组项或对象。过滤器也可以使用$来引用当前对象之外的属性$.store.book[?(@.price &lt; $.expensive)]只指定属性名称的表达式如[?(@.isbn)]将匹配具有此属性的所有项目,无论值如何此外,过滤器支持一下运算符            操作符      说明                  ==      等于,1和'1'被认为是相等的,字符串值必须用单引号括起来(不是双引号)：例如[?(@.color=='red')]              !=      不等于。字符串值必须用单引号括起来。              &gt;      大于              &gt;=      大于等于              &lt;      小于              &lt;=      小于等于              =~      匹配JavaScript正则表达式,例如[?(@.description=~ /cat.*/i)]匹配描述以cat开头的项（不区分大小写）              !      用于否定,例如[?(!@.isbn)]匹配没有isbn属性的项目              &amp;&amp;      逻辑AND，用于组合多个过滤器表达式,例如：[?(@.category=='fiction' &amp;&amp; @.price &lt; 10 )]              ||      逻辑OR，用于组合多个过滤器表达式,例如：[?(@.category=='fiction' || @.price &lt; 10 )]      综合示例目前我们有如下JSON结构:{\"store\": { \"book\": [   {     \"category\": \"reference\",     \"author\": \"Nigel Rees\",     \"title\": \"Sayings of the Century\",     \"price\": 8.95   },   {     \"category\": \"fiction\",     \"author\": \"Herman Melville\",     \"title\": \"Moby Dick\",     \"isbn\": \"0-553-21311-3\",     \"price\": 8.99   },   {     \"category\": \"fiction\",     \"author\": \"J.R.R. Tolkien\",     \"title\": \"The Lord of the Rings\",     \"isbn\": \"0-395-19395-8\",     \"price\": 22.99   } ], \"bicycle\": {   \"color\": \"red\",   \"price\": 19.95 }},\"expensive\": 10}在下面的例子中,$符号是可选的,可以省略掉：            表达式      说明                  $.store.*      store对象下所有的属性(非递归)              $.store.bicycle.color      获取得到color属性的值,结果为red              $.store..price $..price      返回所有的price属性值集合,结果为[8.95,8.99,22.99,19.95]              $.store.book[*]$..book[*]      所有的book集合              $..book[*].title      返回book对象下的所有标题集合              $..book[0]      返回第一个book集合对象,结果为[{\"category\":\"reference\",\"author\":\"Nigel Rees\",\"title\":\"Sayings of the Century\",\"price\":8.95}]              $..book[0].title      返回第一个book集合对象中的title属性,结果是Sayings of the Century              $..book[0,1].title$..book[:2].title      返回前2个book集合对象的title属性,结果是[Sayings of the Century, Moby Dick]              $..book[-1:].title$..book[(@.length-1)].title      返回最后一个book对象的title属性集合,结果是[The Lord of the Rings]              $..book[?(@.author=='J.R.R. Tolkien')].title      返回book集合中所有的作者等于J.R.R. Tolkien的title集合,结果是[The Lord of the Rings]              $..book[?(@.isbn)]      返回所有book对象属性中含有isbn的属性，其结果是books集合              $..book[?(!@.isbn)]      返回book对象属性中不包含isbn的属性,结果是集合              $..book[?(@.price &lt; 10)]      返回所有book对象属性中price属性小于10的对象集合              $..book[?(@.price &gt; $.expensive)]      返回所有book对象属性中price属性值大于expensive值的对象集合              $..book[?(@.author =~ /.*Tolkien/i)]      返回所有book对象属性中的author属性是以Tolkien结尾(不区分大小写)的属性对象集合              $..book[?(@.category == 'fiction' || @.category == 'reference')]      返回book对象属性中category等于fiction的或者等于reference的对象集合              $..*      根目录下的JSON结构的所有成员（子对象，单个属性值，数组项）组合成一个数组。      返回多个元素的JSONPath表达式的注意事项JSONPath查询不仅可以返回单个元素，还可以返回匹配元素的列表。例如如下JSON结构：{\"name\": \"Rose Kolodny\",\"phoneNumbers\": [ {   \"type\": \"home\",   \"number\": \"954-555-1234\" }, {   \"type\": \"work\",   \"number\": \"754-555-5678\" }]}JSONPath表达式：phoneNumbers[*].number该表达式将会返回一个集合列表,如下：[954-555-1234, 754-555-5678]请注意，这不是JSON数组，它只是以逗号分隔的项列表，其中[]表示列表的开头和结尾。对匹配列表使用“equals”断言时，请指定[]中包含的预期值列表，并用逗号和一个空格分隔[apples, 15, false, [\"foo\",\"bar\"], {\"status\":\"ok\"}]除非引号是值的一部分，否则独立字符串（如apples）不应包含引号示例给定下面一个JSON:{ \"words\": [\"apples\", \"\\\"oranges\\\"\"] }$ .words [*]返回所有数组项的列表，因此预期值为[apples，“oranges”]。注意与$ .words的区别，它返回JSON中显示的数组本身，因此，在这种情况下，值将是[“apples”，“\\”oranges \\“”]作为JSON数组和对象的值保留内部引号，但是在它们的项之间缩小而没有空格：[“foo”，“bar”]，而不是[ “foo” ， “bar” ]。Java使用示例因为我是一名Java工程师,看到这里,既然JSONPath是一个用Java语言开发的组件,那自然是要学习一下的(非Java语言的同学可以忽略~~~)简单使用首先在Maven项目中加入JSONPath的引用&lt;!-- https://mvnrepository.com/artifact/com.jayway.jsonpath/json-path --&gt;&lt;dependency&gt;&lt;groupId&gt;com.jayway.jsonpath&lt;/groupId&gt;&lt;artifactId&gt;json-path&lt;/artifactId&gt;&lt;version&gt;2.4.0&lt;/version&gt;&lt;/dependency&gt;假设有如下JSON结构{\"name\": \"Rose Kolodny\",\"phoneNumbers\": [ {   \"type\": \"home\",   \"number\": \"954-555-1234\" }, {   \"type\": \"work\",   \"number\": \"754-555-5678\" }]}我们想获取得到number的数组集合,应该如何做呢String json=\"...\";System.out.println(\"JSON:\"+json);List&lt;String&gt; numbers= JsonPath.read(json,\"$..number\");for (String num:numbers){ System.out.println(num);}String name=JsonPath.read(json,\"$.name\");System.out.println(\"name:\"+name);最终控制台输出：954-555-1234754-555-5678Rose Kolodny上面这种方式很麻烦,因为你没读取一个JSON的字段属性,都需要将源JSON整体传入到方法中,在对于程序性能来说是一种消耗,因为都需要JSONPath组件重新解析一次JSON的结构如果你只想JSONPath只初始化一次就可以了,应该使用如下方式：private static void once(String json){ System.out.println(\"初始化一次\"); //初始化创建Document对象 Object document= Configuration.defaultConfiguration().jsonProvider().parse(json); List&lt;String&gt; numbers= JsonPath.read(document,\"$..number\"); for (String num:numbers){   System.out.println(num); } String name=JsonPath.read(document,\"$.name\"); System.out.println(\"name:\"+name);}此外,JSONPath还提供了流式API,方便开发者使用String json = \"...\";ReadContext ctx = JsonPath.parse(json);List&lt;String&gt; authorsOfBooksWithISBN = ctx.read(\"$.store.book[?(@.isbn)].author\");List&lt;Map&lt;String, Object&gt;&gt; expensiveBooks = JsonPath                         .using(configuration)                         .parse(json)                         .read(\"$.store.book[?(@.price &gt; 10)]\", List.class);返回预期在使用JSONPath组件时,了解结果中的预期类型非常重要,比如在上个json中,我们查询name属性时,使用JSONPath的表达式$.name和$..name就区别很大,一个是返回String类型的字符串,一个是返回数组,因此,根据JSONPath预判返回结果类型显得尤为关键。//将会抛出java.lang.ClassCastException异常,因为这是返回一个String字符串的JSONPath表达式List&lt;String&gt; list = JsonPath.parse(json).read(\"$.store.book[0].author\")//正确执行String author = JsonPath.parse(json).read(\"$.store.book[0].author\")在评估预判JSONPath的路径时,您需要了解路径何时确定的概念。如果路径包含，则路径是不确定的  ..:一个递归扫描的表示法  ?(&lt;expression&gt;)：一个JSONPath表达式  [&lt;number&gt;,&lt;number&gt;(,&lt;number&gt;)]:多个数组索引对于不确定的路径JSONPath始终返回一个数组列表默认情况下，MappingProvider SPI提供了一个简单的对象映射器。这允许您指定所需的返回类型，MappingProvider将尝试执行映射。在下面的示例中，演示了Long和Date之间的映射String json = \"{\\\"date_as_long\\\" : 1411455611975}\";Date date = JsonPath.parse(json).read(\"$['date_as_long']\", Date.class);如果将JSONPath配置为使用JacksonMappingProvider或者GsonMappingProvider，您甚至可以将JSONPath输出直接映射到POJO上Book book = JsonPath.parse(json).read(\"$.store.book[0]\", Book.class);要获得完整的泛型类型信息，请使用TypeRefTypeRef&lt;List&lt;String&gt;&gt; typeRef = new TypeRef&lt;List&lt;String&gt;&gt;() {};List&lt;String&gt; titles = JsonPath.parse(JSON_DOCUMENT).read(\"$.store.book[*].title\", typeRef);过滤有三种方法来创建JSONPath组件的过滤器规则内联List&lt;Map&lt;String, Object&gt;&gt; books =  JsonPath.parse(json)                                  .read(\"$.store.book[?(@.price &lt; 10)]\");您可以使用&amp;&amp;和||组合多个条件，[?(@.price &lt; 10 &amp;&amp; @.category == 'fiction')]、[?(@.category == 'reference' || @.price &gt; 10)]您也可以使用!表示非条件[?(!(@.price &lt; 10 &amp;&amp; @.category == 'fiction'))]过滤通过JSONPath提供的API来筛选import static com.jayway.jsonpath.JsonPath.parse;import static com.jayway.jsonpath.Criteria.where;import static com.jayway.jsonpath.Filter.filter;......Filter cheapFictionFilter = filter(where(\"category\").is(\"fiction\").and(\"price\").lte(10D));List&lt;Map&lt;String, Object&gt;&gt; books =  parse(json).read(\"$.store.book[?]\", cheapFictionFilter);注意占位符?对于路径中的过滤器。当提供多个过滤器时，它们将按顺序应用，其中占位符的数量必须与提供的过滤器数量相匹配。您也可以使用OR和AND对接过进行筛选组合Filter fooOrBar = filter(where(\"foo\").exists(true)).or(where(\"bar\").exists(true));Filter fooAndBar = filter(where(\"foo\").exists(true)).and(where(\"bar\").exists(true));Roll Your Own第三种是实现你自己的Predicate接口Predicate booksWithISBN = new Predicate() { @Override public boolean apply(PredicateContext ctx) {     return ctx.item(Map.class).containsKey(\"isbn\"); }};List&lt;Map&lt;String, Object&gt;&gt; books = reader.read(\"$.store.book[?].isbn\", List.class, booksWithISBN);值和路径在Goessner实现中，JsonPath可以返回Path或Value。值是默认值，以及上面的所有示例返回的内容。如果您更喜欢我们的查询所遇到的元素的路径，则可以使用选项来实现。Configuration conf = Configuration.builder().options(Option.AS_PATH_LIST).build();List&lt;String&gt; pathList = using(conf).parse(json).read(\"$..author\");assertThat(pathList).containsExactly( \"$['store']['book'][0]['author']\", \"$['store']['book'][1]['author']\", \"$['store']['book'][2]['author']\", \"$['store']['book'][3]['author']\");配置信息选项创建配置时，有一些选项标志可以改变默认行为。DEFAULT_PATH_LEAF_TO_NULL此选项使JsonPath为缺少的叶子返回null。考虑以下json[{   \"name\" : \"john\",   \"gender\" : \"male\"},{   \"name\" : \"ben\"}]Java代码Configuration conf = Configuration.defaultConfiguration();//正确运行String gender0 = JsonPath.using(conf).parse(json).read(\"$[0]['gender']\");//PathNotFoundException thrownString gender1 = JsonPath.using(conf).parse(json).read(\"$[1]['gender']\");Configuration conf2 = conf.addOptions(Option.DEFAULT_PATH_LEAF_TO_NULL);//Works fineString gender0 = JsonPath.using(conf2).parse(json).read(\"$[0]['gender']\");//返回nullString gender1 = JsonPath.using(conf2).parse(json).read(\"$[1]['gender']\");ALWAYS_RETURN_LIST即使路径是确定的，此选项也会将JsonPath配置为返回列表Configuration conf = Configuration.defaultConfiguration();//Works fineList&lt;String&gt; genders0 = JsonPath.using(conf).parse(json).read(\"$[0]['gender']\");//PathNotFoundException thrownList&lt;String&gt; genders1 = JsonPath.using(conf).parse(json).read(\"$[1]['gender']\");SUPPRESS_EXCEPTIONS此选项可确保不会从路径评估传播任何异常。它遵循以下简单规则  如果存在选项ALWAYS_RETURN_LIST，则将返回空列表  如果选项ALWAYS_RETURN_LIST不存在，则返回null"
  },
  
  {
    "title": "Kettle实战100篇 第16篇 JSON文件导入Mysql",
    "url": "/posts/kettle-16/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-14 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第15篇 Mysql数据库表迁移",
    "url": "/posts/kettle-15/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-14 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第14篇 参数与变量",
    "url": "/posts/kettle-14/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-14 00:00:00 +0800",
    





    
    "snippet": "设置变量组件是我们在作业中非常常用的一个组件,通过设置变量,我们的子转换中可以非常方便的解决动态数据处理的问题,比如分页查询数据、导出Excel变量等等我们在Kettle实战100篇 第2篇 调用RESTful接口导入JSON结果入库以及Kettle实战100篇 第9篇 Mysql数据库数据导出到Excel中都有介绍到设置变量组件的使用.本篇博客主要是详细Kettle中的变量及参数的说明及使...",
    "content": "设置变量组件是我们在作业中非常常用的一个组件,通过设置变量,我们的子转换中可以非常方便的解决动态数据处理的问题,比如分页查询数据、导出Excel变量等等我们在Kettle实战100篇 第2篇 调用RESTful接口导入JSON结果入库以及Kettle实战100篇 第9篇 Mysql数据库数据导出到Excel中都有介绍到设置变量组件的使用.本篇博客主要是详细Kettle中的变量及参数的说明及使用官方文档地址：https://wiki.pentaho.com/display/EAI/Set+variables+%28job+entry%29临时变量/参数定义临时变量即我们在使用Kettle的设置变量组件、生成记录等组件是定义的变量值,该变量作用于当前作业或者转换例如，如下设置变量组件：全局变量很多时候我们需要定义我们当前Kettle环境的全局变量,比如我们在新建数据库时,不希望一直在相关组件输入用户名、密码等信息,此时我们可以在Kettle的配置文件kettle.properties中设置,该文件存在于目录${KETTLE_HOME}/.kettle目录下在配置文件中定义我们的变量名称和值,只要在kettle.properties配置文件中定义的参数,是global全局参数,在当前环境下任意作业和转换中都可以使用.使用变量我们定义了变量,那么我们在作业或转换中应该如何使用变量呢？变量和参数的使用有两种方式：  第一种是通过${}符号来引用,例如${mysql_local_bi_ip}  第二种是通过两个百分号来引用,例如%mysql_local_bi_ip%另外还有一个技巧是我们在Spoon的可视化界面中,如果看到当前的输入框后面跟的有菱形的S符号标记,即表示我们可以使用变量,如下图:  注意：变量在运行时是以递归的方式进行解析,所以,可以在一个变量里面使用另外一个变量.这样使用变量具有通用性和复用性"
  },
  
  {
    "title": "Kettle实战100篇 第13篇 MySQL数据导出Excel数据乱码",
    "url": "/posts/kettle-13/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-13 00:00:00 +0800",
    





    
    "snippet": "该问题我在使用分页查询导出的时候碰到了乱码的情况,我的情况比较特殊,我通过浏览已经建立好的数据库连接的中的数据时并非乱码,而当我使用表输入组件中的预览数据时缺产生了乱码,因此我不得不设置我们的数据库连接参数乱码主要分几种情况一、查看我们的数据库的服务端字符集是否是UTF-8(常用字符集)可以使用navicat连接到我们的数据库,然后使用命令行，输入查询语句进行查看，如下：mysql&gt; ...",
    "content": "该问题我在使用分页查询导出的时候碰到了乱码的情况,我的情况比较特殊,我通过浏览已经建立好的数据库连接的中的数据时并非乱码,而当我使用表输入组件中的预览数据时缺产生了乱码,因此我不得不设置我们的数据库连接参数乱码主要分几种情况一、查看我们的数据库的服务端字符集是否是UTF-8(常用字符集)可以使用navicat连接到我们的数据库,然后使用命令行，输入查询语句进行查看，如下：mysql&gt; show variables like '%char%';+--------------------------+-----------------------------------------------+| Variable_name            | Value                                         |+--------------------------+-----------------------------------------------+| character_set_client     | utf8mb4                                       || character_set_connection | utf8mb4                                       || character_set_database   | utf8                                          || character_set_filesystem | binary                                        || character_set_results    | utf8mb4                                       || character_set_server     | utf8                                          || character_set_system     | utf8                                          || character_sets_dir       | D:\\Users\\xiaoymin\\Bin\\mariadb\\share\\charsets\\ |+--------------------------+-----------------------------------------------+8 rows in set (0.08 sec)其中character_set_server就是我们的数据库服务端编码我们也可以使用SQL语句查询我们的表字段编码，如下：mysql&gt; show full columns from fund;如果我们第一步检查是OK的,但是浏览数据依然是乱码,那么我们就需要修改Kettle中的配置参数点击表输入组件的编辑按钮，对数据库信息进行编辑1、选择高级选项卡,添加相关字符码2、高级选项卡中设置names值，网上的解决方案大多是使用utf8，但是我本机使用后发现还是乱码,因此我改成了gbk，这个大家自行根据自己的情况设定set names gbk;如下图："
  },
  
  {
    "title": "Kettle实战100篇 第12篇 自定义开发Java工具类并在JavaScript脚本中运用",
    "url": "/posts/kettle-12/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-13 00:00:00 +0800",
    





    
    "snippet": "我们在Kettle实战100篇 第1篇 介绍与安装中已经介绍过Kettle的相关目录结构,因为Kettle是使用纯Java语言开发,并且我们在JavaScript脚本中可以调用我们的Java类中的方法进行相关脚本的编写因此,为了开发JavaScript脚本方便,有时候我们需要自定义一些方法集,供我们自己在Kettle这种使用新建项目我们新建一个基于Maven的纯Java项目kettleInA...",
    "content": "我们在Kettle实战100篇 第1篇 介绍与安装中已经介绍过Kettle的相关目录结构,因为Kettle是使用纯Java语言开发,并且我们在JavaScript脚本中可以调用我们的Java类中的方法进行相关脚本的编写因此,为了开发JavaScript脚本方便,有时候我们需要自定义一些方法集,供我们自己在Kettle这种使用新建项目我们新建一个基于Maven的纯Java项目kettleInAction100-plugin新建工具类建立我们自己项目中需要的工具类,目前我在博客中频繁使用到分页,因此我需要一个计算总页码的方法，代码如下：package com.xiaominfo.kettle.util;import java.math.BigDecimal;/*** * 计算分页 * @since:kettleInAction100-plugin 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt; * 2019/08/10 11:07 */public class PaginationUtils {  /**   * 计算得到总页码   * @param totalRecords 总记录数   * @param pageSize 分页大小   * @return 总页码   */  public static int totalPage(String totalRecords,String pageSize){    int totalPage=0;    try{      BigDecimal records=new BigDecimal(totalRecords);      BigDecimal size=new BigDecimal(pageSize);      BigDecimal _tmp=records.add(size).subtract(new BigDecimal(1));      BigDecimal _tp=_tmp.divide(size).setScale(0,BigDecimal.ROUND_HALF_UP);      totalPage=_tp.intValue();    }catch (Exception e){      //error    }    return totalPage;  }}部署打包此时,我们的方法已经完成,将我们的项目打包，运行Maven的命令mvn package进行打包[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ kettleInAction100-plugin ---[INFO] Building jar: F:\\Kettle实战\\kettleInAction100-plugin\\target\\kettleInAction100-plugin-1.0.jar[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 15.126 s[INFO] Finished at: 2019-08-10T11:18:20+08:00[INFO] Final Memory: 16M/116M[INFO] ------------------------------------------------------------------------此时,我们将已经打包好的jar文件复制到到Kettle目录的lib目录下,然后重启Spoon图形界面JavaScript脚本中使用来看如下一段JavaScript脚本var preRows=previous_result.getRows();//获取上一个步骤的结果集var subject=\"自定义日志输出\";var logFactory = new org.pentaho.di.core.logging.LogChannelFactory();var log= logFactory.create(subject); if(preRows==null || preRows.size()==0){\tfalse;}else{var countBySql=preRows.get(0).getInteger(\"fundCount\");//赋值变量var pageSize=parent_job.getVariable(\"pageSize\");log.logMinimal(\"pageSize:\"+pageSize+\",countRecords:\"+countBySql); //计算总页码var totalPage=com.xiaominfo.kettle.util.PaginationUtils.totalPage(countBySql,pageSize);log.logMinimal(\"totalPage:\"+totalPage);//设置总页码parent_job.setVariable(\"totalPage\",totalPage);true;}从代码中我们可以看到我们首先获取得到记录总数,已经每页大小,最后通过我们自定义的工具类进行计算var totalPage=com.xiaominfo.kettle.util.PaginationUtils.totalPage(countBySql,pageSize);从控制台日志中我们可以看到结果：计算得到总页数为13页，结果是正确的.如果你是一名Java开发工程师的话,结合自身的编程能力,就可以很好的利用起来,显得相得益彰了."
  },
  
  {
    "title": "Kettle实战100篇 第11篇 JavaScript表达式变量说明",
    "url": "/posts/kettle-11/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-13 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第9篇 Mysql数据库数据导出到Excel",
    "url": "/posts/kettle-9/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-12 00:00:00 +0800",
    





    
    "snippet": "我们在第8篇的时候已经介绍了将Excel的数据导入到Mysql数据库中,那么,本章我们将介绍将数据从数据库导出到Excel中.较少数据导出我们数据库表数据如下图：数据库中总共存在36条数据,这是数据比较少的情况新建转换我们选择 文件 -&gt; 新建 -&gt;转换建立导出Excel的转换,输入转换名称然后保存表输入既然是从数据库表导出数据,所以我们的ETL的第一个步骤就是表输入新建数据库连...",
    "content": "我们在第8篇的时候已经介绍了将Excel的数据导入到Mysql数据库中,那么,本章我们将介绍将数据从数据库导出到Excel中.较少数据导出我们数据库表数据如下图：数据库中总共存在36条数据,这是数据比较少的情况新建转换我们选择 文件 -&gt; 新建 -&gt;转换建立导出Excel的转换,输入转换名称然后保存表输入既然是从数据库表导出数据,所以我们的ETL的第一个步骤就是表输入新建数据库连接在选择表输入组件时,我们首先需要创建我们的数据库连接点击新建按钮,在弹出的数据库编辑框中填入数据库信息，如下图：在输入完成后,我们可以点击测试按钮对数据库连接进行测试,以查看数据库是否可用信息无误后,点击确定此时，我们可以输入我们的查询SQL语句对表进行查询以获取结果点击预览按钮,弹出预览记录数量限制数量设置，即可以预览数据：预览无误,说明我们的信息是正确的,我们的表输入最终属性配置信息如下图：因为我们总数只有36条记录,因此在记录数量限制这里不妨可以设置一个最大值,此处我设置的是40Microsoft Excel输出因为我们最终是通过Excel输出,因此我们从转换的核心对象树的输出栏 选择Microsoft Excel输出组件设置输出组件的属性因为比较简单,因此我们只需要设置导出的Excel文件名称即可,如下图：运行此时我们的ETL转换已创建完成,如下图：此时,我们点击Spoon界面上的运行按钮,执行该转换过程,导出Excel结果如下：针对较少的数据,利用Kettle非常轻松的帮助我们导出了数据到Excel中.较多数据导出Excel我们在上个步骤中将数据库表中较少数据(36条)导出到了Excel中,这几乎没什么难度,那么如果我们的数据库表中数据比较多时,是否也能按这种方式导出呢？答案肯定是否定的,因为如果我们一次查询数据较多的话,很可能导致内存溢出的异常或者Kettle直接就崩溃了.此时我们可以使用分页技术,来将我们的数据按页码批量导出我们数据库拥有fund表,此时,我们想通过Kettle将fund表的记录全部导出,我们应该怎么做呢？分页导出我们首先先按照分页来进行数据的导出新建转换文件 -&gt; 新建  -&gt; 转换保存转换名为：分页导出数据设置分页变量我们都知道Mysql中可以使用limit关键字来进行分页查询数据,因此第一步,我们需要通过生成记录组件定义两个变量,分别是：  pageSize:每页查询数据大小  offset：数据库位移位置表输入设置好变量后,我们可以拖入表输入组件,进行相关的属性设置分别设置SQL查询语句,注意我们在SQL语句中使用了Mysql的limit分页,并且通过前面的变量来代替相关的值如下图：Microsoft Excel输出最后,我们通过Excel输出组件配置导出到Excel这里我们需要注意的是,扩展类型我们需要选择xlsx格式(因为97格式会有总记录的条数限制)运行此时,我们的最终转换如下图：最终查看我们导出的数据如下：全部导出上面我们使用了分页的方式将我们的数据按页码导到了Excel中,如果我们想把数据表中的全部数据都导入到Excel,应该如何做呢?此时,我们可以把分页导出转换作为一个作业子项,我们在作业子项中设置分页条件,轮训总页码进行批量导出,核心点在于我们只需要设置offsetSize变量,然后轮训进行替换即可我们需要两个计算页码的公式根据记录总数计算总页码：var totalPage= (totalRows+pageSize-1) / pageSize;计算Mysql中的offset值var nowOffSize= pageSize * page ;作业图我们先来梳理一下我们这个全部导出作业需要做的事情：  首先需要查询目标表的总记录数,然后根据我们设置的每页查询大小计算出总页数  轮训分页导出记录到Excel 组件因此,我们起码需要一个作业和两个转换,才能帮助我们完成数据的全部导出任务先来看我们已经完成的作业图,如下图：接下来我们逐步分析我们每个步骤的逻辑新建作业新建全部导出作业选择  文件 -&gt; 新建 作业设置变量我们在建立作业任务时,因为需要使用分页技术对数据进行查询,因此我们的分页导出数据中的转换SQL语句就不能使用常量,必须使用变量。因此我们的作业第一步是设置变量，如下图：我们主要定义了5个变量并赋予初始值,并且变量的方位都是在JVM中有效  offsetSize:该值是我们在使用MySQL分页查询语句limit的offset位移值  pageSize:每页查询的数据大小,默认2000  totalPage:总页数,我们在这里实现定义好变量,后面方便我们使用它  currentPage:当前页码,默认值1  shellFirst:该变量是我们在查询MySQL数据后需要追加到Excel的其实行数值,A1代表从第一行开始写入数据,随着翻页查询,shellFirst的值变化规则是A(offsetSize+1)获取目标数据表总记录数第二步我们就需要新建一个转换,用来获取我们的目标表总记录条数,转换如下图：这个转换很简单,只有两个组件：表输入、复制记录到结果表输入组件是我们编写从数据库查询目标表的统计SQL语句,如下图：统计fund表的总记录SQL语句：SELECT count(*) fundCount from fund然后将我们的结果复制到结果即可JavaScript脚本-计算总页数我们得到了目标表的总记录数,接下来我们需要一段JavaScript脚本帮助我们计算得到总页数，脚本内容如下：var preRows=previous_result.getRows();//获取上一个步骤的结果集var subject=\"自定义日志输出\";var logFactory = new org.pentaho.di.core.logging.LogChannelFactory();var log= logFactory.create(subject); if(preRows==null || preRows.size()==0){\tfalse;}else{    var countBySql=preRows.get(0).getInteger(\"fundCount\");    //赋值变量    var pageSize=parent_job.getVariable(\"pageSize\");    log.logMinimal(\"pageSize:\"+pageSize+\",countRecords:\"+countBySql);    //计算总页码    var totalPage=com.xiaominfo.kettle.util.PaginationUtils.totalPage(countBySql,pageSize);    log.logMinimal(\"totalPage:\"+totalPage);    //设置总页码    parent_job.setVariable(\"totalPage\",totalPage);    true;}这里有几个组件需要说明一下：  脚本中我们使用了Kettle的内置对象previous_result用以获取上一个步骤的记录行数,因为我们上一个步骤是获取总记录数的转换(记录行已经复制到结果),关于JavaScript脚本的内置对象，表达式介绍可以参考Kettle实战100篇 第11篇 JavaScript表达式变量说明  在脚本中我们使用了Kettle中的日志组件,日志组件可以在控制台输出关键信息,帮助我们快速定位问题，关于日志可以参考Kettle实战100篇 第10篇 JavaScript脚本中日志输出  最后一个是我们使用了自定义的Java类PaginationUtils,该类是我开发的工具集,方便在JavaScript脚本中使用快速计算的,totalPage方法就是一个根据总记录数以及pageSize来得到总页数的函数，关于自定义开发的功能,可以参考Kettle实战100篇 第12篇 自定义开发Java工具类并在JavaScript脚本中运用  我们得到总页码后,最后通过parent_job内置对象的setVariable方法再将我们得到的结果在重新赋值.检查字段的值初始化好我们的总页码后,接下来我们就需要设置轮训分页条件了，如下图设置当前的页面小于等于总页码数,符合条件即进行分页Excel导出转换的操作,否则程序结束.分页导出Excel转换在分页导出Excel转换中,区别于较少数据的转换,我们需要从父作业中获取变量，然后传递到子转换中的相关组件中使用变量,所以整个子转换如下图：第一步是获取变量,该操作和我们上面较少数据导出其实是大同小异,无非是把生成记录组件中定义的变量替换使用父作业中的变量 ，如下图：定义子转换中的相关变量。第二步是表输入组件,分页查询数据，如下图：在表输入组件中,我们使用定义的变量代替SQL语句中的limit分页数值,然后勾选替换SQL语句里的变量选项已经使用懒惰算法选项，记录数量限制为0（即不限制）最后我们选择Microsoft Excel 输出组件,把我们的结果输出到Excel中因为我们并非是一次全部导出,而是采取的分页,因此在设置好文件名及文件扩展后,需要选择如果文件已存在则使用现有文件输出工作表选项卡中如果输出文件中已存在工作表也选择继续输出至已存在的工作表中然后是内容选项卡：此处需要设置楷书输出子单元格的变量,即我们父作业中定义的shellFirst变量，在Excel的Sheet表格中即代表从哪一行开始输出数据然后勾选在表的末尾开始写(追加行)选项,最后点击确定保存检查页码条件接下来我们需要检查赋值我们的页码，通过JavaScript脚本来实现,脚本内容如下：var page=parent_job.getVariable('currentPage');var totalPage=parent_job.getVariable('totalPage');var subject=\"自定义日志\";var log= new org.pentaho.di.core.logging.LogChannel(subject);if(page==totalPage){ false;}else{\t//设置offsetSize的值\tvar pageSize=parent_job.getVariable('pageSize');\t//在page++之前先计算offset的值\t//offset方法为page*pageSize\tvar nowOffSize=com.xiaominfo.kettle.util.PaginationUtils.offset(page,pageSize);\tpage++;\tparent_job.setVariable('currentPage',page);\tvar shellFirst=parent_job.getVariable('shellFirst');\t\t//日志输出\tlog.logMinimal(\"offset：\"+nowOffSize);\tparent_job.setVariable('offsetSize',nowOffSize);\tvar shellNum=nowOffSize+1;\tvar newShellFirst=shellFirst.substring(0,1)+shellNum;\tlog.logMinimal(\"Shell单元格开始输出记录行:\"+newShellFirst);\tparent_job.setVariable('shellFirst',newShellFirst);\t\ttrue;}该代码逻辑主要步骤：  判断当前页码是否已经等于总页码,即如果是最后是总页码则程序返回false，不继续执行  如果当前页码小于总页码,首先计算下一个SQL语句翻页的offset的值(因为我在计算的时候并非是从0开始,因此这里的page++动作需要在后面执行),赋值下一个offset的值  当前页码+1，使用parent_job内置对象重新赋值当前页码变量  由offset值计算得到在输出Excel数据时从哪一行开始输出(不能计算错误,否则导出的 Excel数据不是缺失就是被覆盖错误),重新赋值shellFirst变量执行整个作业过程完成,运行该作业,得到我们导出的该fund表的全部数据24332条FAQ表输入组件预览数据、导出Excel数据乱码该问题我在使用分页查询导出的时候碰到了乱码的情况,我的情况比较特殊,我通过浏览已经建立好的数据库连接的中的数据时并非乱码,而当我使用表输入组件中的预览数据时缺产生了乱码,因此我不得不设置我们的数据库连接参数乱码主要分几种情况一、查看我们的数据库的服务端字符集是否是UTF-8(常用字符集)可以使用navicat连接到我们的数据库,然后使用命令行，输入查询语句进行查看，如下：mysql&gt; show variables like '%char%';+--------------------------+-----------------------------------------------+| Variable_name            | Value                                         |+--------------------------+-----------------------------------------------+| character_set_client     | utf8mb4                                       || character_set_connection | utf8mb4                                       || character_set_database   | utf8                                          || character_set_filesystem | binary                                        || character_set_results    | utf8mb4                                       || character_set_server     | utf8                                          || character_set_system     | utf8                                          || character_sets_dir       | D:\\Users\\xiaoymin\\Bin\\mariadb\\share\\charsets\\ |+--------------------------+-----------------------------------------------+8 rows in set (0.08 sec)其中character_set_server就是我们的数据库服务端编码我们也可以使用SQL语句查询我们的表字段编码，如下：mysql&gt; show full columns from fund;如果我们第一步检查是OK的,但是浏览数据依然是乱码,那么我们就需要修改Kettle中的配置参数点击表输入组件的编辑按钮，对数据库信息进行编辑1、选择高级选项卡,添加相关字符码2、高级选项卡中设置names值，网上的解决方案大多是使用utf8，但是我本机使用后发现还是乱码,因此我改成了gbk，这个大家自行根据自己的情况设定set names gbk;如下图："
  },
  
  {
    "title": "Kettle实战100篇 第10篇 JavaScript脚本中日志输出",
    "url": "/posts/kettle-10/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-12 00:00:00 +0800",
    





    
    "snippet": "我们在编写作业或者转换的时候,运行时,尽管将Kettle的日志级别调整到最大,但是依然无法帮助我们定位到问题所在,此时我们就需要通过日志来输出我们的相关变量,以编程的思维来帮助我们快速定位到问题,以解决问题旧版本Kettle借助于搜索引擎,如果你是使用的较旧的Kettle版本,可以使用如下方法进行日志输出：首先,得到日志输出实例var log = org.pentaho.di.core.lo...",
    "content": "我们在编写作业或者转换的时候,运行时,尽管将Kettle的日志级别调整到最大,但是依然无法帮助我们定位到问题所在,此时我们就需要通过日志来输出我们的相关变量,以编程的思维来帮助我们快速定位到问题,以解决问题旧版本Kettle借助于搜索引擎,如果你是使用的较旧的Kettle版本,可以使用如下方法进行日志输出：首先,得到日志输出实例var log = org.pentaho.di.core.logging.LogWriter.getInstance();按照日志的输出基本分别进行输出：public void logMinimal(String subject, String message, Object... args){     println(LOG_LEVEL_MINIMAL, subject, message, args) ; }public void logBasic(String subject, String message, Object... args){     println(LOG_LEVEL_BASIC, subject, message, args) ; }public void logDetailed(String subject, String message, Object... args){     println(LOG_LEVEL_DETAILED, subject, message, args); }public void logDebug(String subject, String message, Object... args){     println(LOG_LEVEL_DEBUG, subject, message, args); }public void logRowlevel(String subject, String message, Object... args){     println(LOG_LEVEL_ROWLEVEL, subject, message, args); }public void logError(String subject, String message, Object... args){     println(LOG_LEVEL_ERROR, subject, message, args); }我们只需要在我们的JavaScript脚本中按照编写Java代码的方式,定义日志变量,然后调用相关的方法即可进行日志输出var log = org.pentaho.di.core.logging.LogWriter.getInstance();log.logDebug(\"Debug日志输出\",\"日志信息Details...\")新版本Kettle由于在《Kettle实战100篇》博客系列中,我使用的是当前最新的Kettle版本8.3版上面的LogWriter已经被Kettle废弃不可用了,通过查询Kettle的javaApi我们得到新的方式主要是LogChannelFactory.java和LogChannel.javaKettle的JavaApi地址：https://javadoc.pentaho.com/可以选择查看不同版本的API Doc构造结构来看LogChannelFactory.java的主要方法构造package org.pentaho.di.core.logging;public class LogChannelFactory implements LogChannelInterfaceFactory {  public LogChannel create( Object subject ) {    return new LogChannel( subject );  }  public LogChannel create( Object subject, boolean gatheringMetrics ) {    return new LogChannel( subject, gatheringMetrics );  }  public LogChannel create( Object subject, LoggingObjectInterface parentObject ) {    return new LogChannel( subject, parentObject );  }  public LogChannel create( Object subject, LoggingObjectInterface parentObject, boolean gatheringMetrics ) {    return new LogChannel( subject, parentObject, gatheringMetrics );  }}通过create方法我们可以得到LogChannel对象LogChannel.java代码public LogChannel( Object subject ) {    logLevel = DefaultLogLevel.getLogLevel();    logChannelId = LoggingRegistry.getInstance().registerLoggingSource( subject );}@Overridepublic void logMinimal( String s ) {    println( new LogMessage( s, logChannelId, LogLevel.MINIMAL ), logLevel );}@Overridepublic void logBasic( String s ) {    println( new LogMessage( s, logChannelId, LogLevel.BASIC ), logLevel );}@Overridepublic void logError( String s ) {    println( new LogMessage( s, logChannelId, LogLevel.ERROR ), logLevel );}@Overridepublic void logError( String s, Throwable e ) {    println( new LogMessage( s, logChannelId, LogLevel.ERROR ), e, logLevel );}@Overridepublic void logBasic( String s, Object... arguments ) {    println( new LogMessage( s, logChannelId, arguments, LogLevel.BASIC ), logLevel );}@Overridepublic void logDetailed( String s, Object... arguments ) {    println( new LogMessage( s, logChannelId, arguments, LogLevel.DETAILED ), logLevel );}@Overridepublic void logError( String s, Object... arguments ) {    println( new LogMessage( s, logChannelId, arguments, LogLevel.ERROR ), logLevel );}@Overridepublic void logDetailed( String s ) {    println( new LogMessage( s, logChannelId, LogLevel.DETAILED ), logLevel );}@Overridepublic void logDebug( String s ) {    println( new LogMessage( s, logChannelId, LogLevel.DEBUG ), logLevel );}@Overridepublic void logDebug( String message, Object... arguments ) {    println( new LogMessage( message, logChannelId, arguments, LogLevel.DEBUG ), logLevel );}@Overridepublic void logRowlevel( String s ) {    println( new LogMessage( s, logChannelId, LogLevel.ROWLEVEL ), logLevel );}@Overridepublic void logMinimal( String message, Object... arguments ) {    println( new LogMessage( message, logChannelId, arguments, LogLevel.MINIMAL ), logLevel );}@Overridepublic void logRowlevel( String message, Object... arguments ) {    println( new LogMessage( message, logChannelId, arguments, LogLevel.ROWLEVEL ), logLevel );}通过代码 我们其实可以发现,新版本的Kettle在Api设计方便比就版本方便了很多使用方法通过查看Api,我们已经知道了具体的方法,主要有两种方式  通过LogChannelFactory工厂构造LogChannel对象,然后调用相应的日志方法进行输出  直接构造LogChannel方法,调用方法日志输出两种方式都可以，先来看第一种var subject=\"自定义日志输出\";//实例化工厂类var logFactory = new org.pentaho.di.core.logging.LogChannelFactory();//实例化日志channel对象var log= logFactory.create(subject);//日志输出log.logMinimal(\"XXXXXXXXXXXXXXXXXXXXXXXX-preRows:\"+preRows.size());第二种也是类似var subject=\"自定义日志输出\";//实例化日志channel对象var log= new org.pentaho.di.core.logging.LogChannel(subject);//日志输出log.logMinimal(\"XXXXXXXXXXXXXXXXXXXXXXXX-preRows:\"+preRows.size());最终我们运行时,可以在控制台看见我们的日志输出,方便我们调试,定位解决问题：简单方法在转换中的JavaScript脚本组件中,我们还可以使用内置函数进行日志输出,日志函数主要有2个：  writeToLog(msg):写入日志,传入msg要打印的信息  writeToLog(level,msg)：第一个是日志级别的简称,第二个是要输出的日志参数介绍说明：// Usage:// writeToLog(var);// 1: String - The Message which should be written to// the Kettle Debug Log//// writeToLog(var,var);// 1: String - The Type of the Log// d - Debug// l - Detailed// e - Error// m - Minimal// r - RowLevel代码如下：var test=\"测试日志\";writeToLog(test)writeToLog('d',test)// Debug级别输出另外需要注意的是,该函数只能在转换中的JavaScript脚本组件中使用,不能在作业的脚本组件中使用.日志级别我们在运行Kettle转换或者作业时,可以设置当前Kettle的日志级别,如下图：日志级别主要包括以下：  无日志：不打印任何日志,即使发生错误也不输出日志  错误日志(Error): 只打印输出错误日志,如果没有错误则不打印日志  最小日志(Minimal)：只打印出执行到那个转换和作业的日志信息  基本日志(Basic)：默认的日志级别,只打印出执行到那个步骤和作业项的日志信息  详细日志(Detailed): 比基本日志多输出一些内容,比如SQL查询语句和DDL语句等  调试日志(Debug):打印调试日志信息,但没有打印出所有的日志  行级日志(Rowlevel): 打印出Kettle里所有可用的日志信息,包括一些较复杂的步骤信息,最高级别"
  },
  
  {
    "title": "Kettle实战100篇 第8篇 Excel导入到Mysql数据库",
    "url": "/posts/kettle-8/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-11 00:00:00 +0800",
    





    
    "snippet": "操作步骤是：选择表格类型(引擎) -&gt; 浏览Excel文件 -&gt; 增加此时,切换到工作表选项卡可以点击获取工作表名称,然后设置读取的起始行、列第三步选择字段选项卡点击获取来自头部数据的字段,可以自动获取Excel表格中的字段header信息,编辑响应的字段类型、长度、精度等信息输出编辑好Excel输入后,此时我们编辑输出,因为我们目标是将Excel的数据导入到数据库中,因此我们的...",
    "content": "操作步骤是：选择表格类型(引擎) -&gt; 浏览Excel文件 -&gt; 增加此时,切换到工作表选项卡可以点击获取工作表名称,然后设置读取的起始行、列第三步选择字段选项卡点击获取来自头部数据的字段,可以自动获取Excel表格中的字段header信息,编辑响应的字段类型、长度、精度等信息输出编辑好Excel输入后,此时我们编辑输出,因为我们目标是将Excel的数据导入到数据库中,因此我们的输出目标是数据库表左侧核心对象树中选择 输出 -&gt; 表输出中间步骤使用Hops连接起来,表示一个数据的流转方向双击表输出,编辑属性在表输出的步骤中,我们需要建立目标数据库连接，然后选择目标表,最后勾选指定数据库字段在数据库字段选项卡中,选择相应的字段映射规则可以点击获取字段以从前一个步骤流中获取输出字段,然后编辑映射关系，保存运行通过以上步骤,我们即完成了这个简单的ETL过程，点击工具栏中的运行,查看结果弹出执行对话框我们选择本机执行,最终执行成功时,打印日志如下：最终导入入库效果：命令行运行转换以上过程保存完成后,Kettle会将我们的转换生成一个文件存储在本地文件系统中,一般转换以后缀.ker结尾此时,我们也可使用Spoon为我们提供的命令行工具Pan以执行转换，如下：D:\\Users\\xiaoymin\\Bin\\data-integration\\data-integration&gt;Pan.bat -file=F:\\kettle\\practic\\excel-mysql.ktr -logfile=F:\\kettle\\practic\\log.logDEBUG: Using JAVA_HOMEDEBUG: _PENTAHO_JAVA_HOME=C:\\Program Files\\Java\\jdk1.8.0_111DEBUG: _PENTAHO_JAVA=C:\\Program Files\\Java\\jdk1.8.0_111\\bin\\java.exeD:\\Users\\xiaoymin\\Bin\\data-integration\\data-integration&gt;\"C:\\Program Files\\Java\\jdk1.8.0_111\\bin\\java.exe\"  \"-Xmx2048m\" \"-XX:MaxPermSize=1024m\" \"-Djava.library.path=libswt\\win64\" \"-DKETTLE_HOME=\" \"-DKETTLE_REPOSITORY=\" \"-DKETTLE_USER=\" \"-DKETTLE_PASSWORD=\" \"-DKETTLE_PLUGIN_PACKAGES=\" \"-DKETTLE_LOG_SIZE_LIMIT=\" \"-DKETTLE_JNDI_ROOT=\" -jar launcher\\pentaho-application-launcher-5.4.0.1-130.jar -lib ..\\libswt\\win64  -main org.pentaho.di.pan.Pan -file F:\\kettle\\practic\\excel-mysql.ktr -logfile F:\\kettle\\practic\\log.logJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=1024m; support was removed in 8.02019/07/16 22:34:17 - Pan - 开始运行.2019/07/16 22:34:17 - excel-mysql - 为了转换解除补丁开始  [excel-mysql]2019/07/16 22:34:18 - 表输出.0 - Connected to database [local] (commit=1000)2019/07/16 22:34:24 - 外部Excel数据导入.0 - 完成处理 (I=146, O=0, R=0, W=146, U=0, E=02019/07/16 22:34:24 - 表输出.0 - 完成处理 (I=0, O=146, R=146, W=146, U=0, E=02019/07/16 22:34:24 - Pan - 完成!2019/07/16 22:34:24 - Pan - 开始=2019/07/16 22:34:17.718, 停止=2019/07/16 22:34:24.9952019/07/16 22:34:24 - Pan - 7 秒后处理结束.2019/07/16 22:34:24 - excel-mysql -2019/07/16 22:34:25 - excel-mysql - 进程 外部Excel数据导入.0 成功结束, 处理了 146 行. ( 20 行/秒)2019/07/16 22:34:25 - excel-mysql - 进程 表输出.0 成功结束, 处理了 146 行. ( 20 行/秒)D:\\Users\\xiaoymin\\Bin\\data-integration\\data-integration&gt;"
  },
  
  {
    "title": "Kettle实战100篇 第7篇 转换核心对象插入更新组件",
    "url": "/posts/kettle-7/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-10 00:00:00 +0800",
    





    
    "snippet": "待续",
    "content": "待续"
  },
  
  {
    "title": "Kettle实战100篇 第6篇 转换核心对象字段选择组件",
    "url": "/posts/kettle-6/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-09 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第5篇 转换核心对象生成记录组件",
    "url": "/posts/kettle-5/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-09 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle 实战100篇 目录",
    "url": "/posts/kettle-toc/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-08 00:00:00 +0800",
    





    
    "snippet": "在数据仓库技术中,ETL是必不可少,Kettle作为ETL的经典工具,已经得到广大ETL工程师的喜爱,甚至连开发工程师在使用ETL过程中,优先考虑的也是Kettle目前国内关于Kettle的资料很少,本着学习的态度,在使用和学习Kettle的过程中,将整个学习过程整理成博客,分享给大家,一方面是希望能对Kettle的使用有一个更深入的了解,另外也同大家一起来学习这款优秀的ETL工具.记录下自...",
    "content": "在数据仓库技术中,ETL是必不可少,Kettle作为ETL的经典工具,已经得到广大ETL工程师的喜爱,甚至连开发工程师在使用ETL过程中,优先考虑的也是Kettle目前国内关于Kettle的资料很少,本着学习的态度,在使用和学习Kettle的过程中,将整个学习过程整理成博客,分享给大家,一方面是希望能对Kettle的使用有一个更深入的了解,另外也同大家一起来学习这款优秀的ETL工具.记录下自己的学习过程.在2019/08/08这个重大日子,想到目前网上的资源针对Kettle实战博客太零散,对于初学者很碎片化,因此自己决定写下关于Kettle的实战博客100篇,初步设想是1天写1篇,借助于网上的资源和Kettle的官方文档,将自己的所思和所想都写下来.100天的时间来改变一下自己,也正好更新自己的技术栈.一举两得.因此,本系列的博客就以《Kettle实战100篇》来命名开头吧!!!因为我是纯粹的想学习Kettle这个ETL工具,并非是资深的ETL工程师(我的工作是Java开发工程师)，因此博客中的需求大部分都是我虚构的(大胆假设,小心求证)，大家如果有在看我博客中遇到问题的可以加我QQ(121462374 )或者微信(xiao934447)(交个朋友也行呀~~!)进行讨论.共同学习进步.  备注:虽然我是初次接触Kettle,但是在写的过程中,并非是按照Kettle的教程来排序,有些基础的概念在我学习的过程中我可能已经知道了,因此就不会单独再博客中说明.我所希望的这个博客系列主要是以实战+Kettle组件介绍说明为主.目前已更新的Kettle博客章节：  Kettle实战100篇 第1篇 介绍与安装  Kettle实战100篇 第2篇 调用RESTful接口导入JSON结果入库  Kettle实战100篇 第3篇 转换核心对象JSON input组件  Kettle实战100篇 第4篇 转换核心对象REST client组件  Kettle实战100篇 第5篇 转换核心对象生成记录组件  Kettle实战100篇 第6篇 转换核心对象字段选择组件  Kettle实战100篇 第7篇 转换核心对象插入更新组件  Kettle实战100篇 第8篇 Excel导入到Mysql数据库  Kettle实战100篇 第9篇 Mysql数据库数据导出到Excel  Kettle实战100篇 第10篇 JavaScript脚本中日志输出  Kettle实战100篇 第11篇 JavaScript表达式变量说明  Kettle实战100篇 第12篇 自定义开发Java工具类并在JavaScript脚本中运用  Kettle实战100篇 第13篇 MySQL数据导出Excel数据乱码  Kettle实战100篇 第14篇 参数与变量  Kettle实战100篇 第15篇 Mysql数据库表迁移  Kettle实战100篇 第16篇 JSON文件导入Mysql  Kettle实战100篇 第17篇 JSONPath组件介绍说明  Kettle实战100篇 第18篇 JavaScript脚本组件使用示例  Kettle实战100篇 第19篇 转换核心对象Microsoft Excel输出组件  Kettle实战100篇 第20篇 MySQL数据库导出到ElasticSearch  Kettle实战100篇 第21篇 JavaScript内置函数说明  Kettle实战100篇 第22篇 资源库的使用  Kettle实战100篇 第23篇 命令行介绍使用  Kettle实战100篇 第24篇 日志报表输出  Kettle实战100篇 第25篇 作业核心对象设置变量组件"
  },
  
  {
    "title": "Kettle实战100篇 第4篇 转换核心对象REST client组件",
    "url": "/posts/kettle-4/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-08 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第3篇 转换核心对象JSON input组件",
    "url": "/posts/kettle-3/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-08 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "Kettle实战100篇 第2篇 调用RESTful接口导入JSON结果入库",
    "url": "/posts/kettle-2/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-08 00:00:00 +0800",
    





    
    "snippet": "不管是通过Java或者是Python编码的方式调用RESTful接口将结果入库,都是有一定复杂度的,首先你要加载第三方REST组件,然后连接数据库,写SQL语句,最后插入的目标数据库中但我们有了Kettle这个工具之后,只需要使用她的图形化界面Spoon就可以很方便的完成接口调用及入库的操作简单的GET请求需求我们拥有接口api地址：http://xxx.domin.com/api请求方式G...",
    "content": "不管是通过Java或者是Python编码的方式调用RESTful接口将结果入库,都是有一定复杂度的,首先你要加载第三方REST组件,然后连接数据库,写SQL语句,最后插入的目标数据库中但我们有了Kettle这个工具之后,只需要使用她的图形化界面Spoon就可以很方便的完成接口调用及入库的操作简单的GET请求需求我们拥有接口api地址：http://xxx.domin.com/api请求方式Get，无参数传递,响应内容如下：我们需要将该JSON数据导入数据库中,如果region字段存在,则更新该数据实战首先需要在Spoon中新建一个转换,菜单选项:文件 -&gt; 新建 -&gt; 转换首先我们需要分析,我们这个转换操作需要哪些组件：  需要输入请求url  发送RESTful请求  入库  JSON解析定义变量既然我们的url是指定的,那么我们可以在输入对象树中选择一个生成记录的组件配置REST client组件设定好请求接口变量，接下来选择发送RESTFul的组件，因为我们是请求的接口,因此可以直接选择REST client组件因为我们在生产记录的组件中定义了接口的地址,因此我们这里可以选择从字段中获取地址,然后在URL field name中选择我们上个步骤中定义的变量名称然后选择请求类型GET,输入输出的结果变量名称result定义JSON输入流接下来,通过REST组件,我们其实已经拿到的接口响应的JSON结果,此时我们需要一个JSON的输入流组件来接收,因此我们需要用到JSON input组件JSON input组件我们需要设定两个关键的值  设置数据来源,因为我们是通过REST请求来获取的JSON,而并非是JSON文件,因此我们可以使用上个步骤中的输出字段result来作为我们的JSON输入源  设置输出隐射字段，我们得到了JSON的结果,通过接口的结果我们得知是一个JSON数组,因此我们需要设置字段名称,通过读取JSON的结果字段设置字段的映射在JSON input组件中,字段的路径规则是通过$.field来设置的，但从上图我们可以看到,貌似并没有按照此种方式来设置，而是中间多了一层[]中括号，这是因为我们的目标源返回的JSON是集合,而非对象返回集合的JSON实例：[{    \"id\":123,    \"title\":\"我是标题\"}]如果是以上这种方式,我们需要获取title的映射字段的话,那么我们在路径的表达式中应该写成$.[*].title的格式那假设我们的JSON结果是以下这种方式：{    \"id\":123,    \"title\":\"我是标题\"}我们需要获取title字段的映射只需要写$.title如果是多级层次对象,则通过.*的通配符一直匹配下去即可.字段选择此时,我们已经得到了JSON输入流的字段映射关系,我们可以选择一个字段选择组件进行字段匹配点击获取选择的字段按钮,可以迅速获取我们在JSON input组件中定义的映射字段获取字段后,我们可以为字段更改名称、长度、精度等数据入库通过以上步骤,我们已经选择了字段列表,此时,我们选择输出对象树中的插入/更新组件，将我们从接口中获取的JSON数据进行更新到数据库中插入/更新我们从字面意思即可得知,如果我们的数据库中存在记录行则进行插入操作,否则通过指定的字段进行更新.组件的选项卡意思也很清晰明了,先选择数据库表,如果我们没有建立数据库,则需要首先建立数据库连接,此处不再骜述用来查询的关键字：此表可以设置我们的更新字段,即我们数据根据此字段来查询的字段，如果存在即更新更新字段：点击获取和更新字段按钮,可以获取字段选择中我们设定好的字段列表，然后再进行选择执行通过以上的步骤,我们已经完成了整个ETL过程的创建，如下图：此时,我们点击工具栏的运行按钮，运行我们的ETL转换运行，查看控制台日志输出我们在查看我们的数据库,是否已经插入成功数据库中已经存在数据,说明我们的整个过程是成功POST带参数请求需求已知某POST接口http://test.com/api?page=0&amp;size=100发送JSON请求体:{}获取如下JSON结构：此时我们需要将content节点中的数据请求并入库实战我们有了简单的GET请求的经验,因此当我们在构建POST请求的ETL过程的时候就简单了很多,首先我们分析需求,同样是接口地址，请求参数，因此我们第一步也是定义变量定义变量同样的，限制条数为1条配置REST client组件因为是POST请求，因此我们在REST client组件中会和GET有一些区别，如下图：首先设定请求类型为POST，同时设置Application Type为JSON类型，设置Body field字段，该字段为我们在请求时候发送给接口的BODY内容，和我们写Java程序时赋予的application/json内容是一致的，因为我们在生成记录中已经定义了BODY字段，因此在这里只需要设置字段的名称即可第二步，我们在需求的时候有发现，POST请求还需要两个参数,分别是page和size字段，可以通过在REST client组件的Parameters选项卡中进行设定参数设置组件这里大家可能会产生疑问,为什么会有两列Parameter，应该如何设置，给大家说明一下：第一列相当于设置的是参数的值,因为我们在定义变量中已经设置的变量,因此这里实际相当于是引用关系第二列是参数的名称，也就是我们实际访问url的时候通过?paramName来访问的这个paramName参数名称定义JSON输入流定义JSON输入流和我们在上面GET请求时介绍的差不多,唯一的区别在于我们需要根据REST client组件响应给我们的JSON格式来判断,给定不同的字段映射关系因为我们需求的接口响应的JSON格式如下：{    \"content\":[{\"id\":\"12112122\"//....}],    \"first\":true,     //more}我们最终是要将content属性中的字段入库,加上我们的JSON是返回的是Object对象，因此我们的映射关系如下图：字段选择字段选择的步骤和GET请求相同数据入库数据入库同GET请求配置步骤执行通过以上步骤,我们已经完成了整个ETL过程的创建,如下图：此时,我们点击执行，查看我们的日志和数据库，如下图：通过控制台,我们已经看到是成功的，再看我们的数据库分页发送POST请求需求我们在上面已经完成了POST请求的Kettle转换,但是我们会有疑问,因为接口是分页请求,此时如果我们想轮训页码,将接口的数据全部导入到数据库应该如何做呢？可能某些人会说我们将页码大小参数size改大一点即可,加入我们的总记录行数是2W行，我们将size设置为2W，这样是否可行呢？答案肯定是不行的,因为我们都知道,在通过请求获取的数据都是存在内存中的，2W行数据一次查询出来有可能导致内存溢出的异常,因此并不推荐这么做.那么,我们应该如何处理呢?实战我们通过PostMan等工具或者Chrome浏览器看到的接口请求,当前传递page=0时，返回的数据其实是附带了总页码条数的,那么我们只需要固定轮训小于等于总页码条数，每次传递不同的页码值给参数即可,这个在我们的Java或者Python等面向对象的语言中是非常容易实现的，那么在Kettle中我们应该如何实现？此时我们需要使用到Kettle的作业，上面的POST请求实际上是一个Kettle转换,我们通过作业的方式,设定判断条件语句，对转换进行页码轮训，即可达到我们的目的.新建作业Kettle中的作业一般是以Start组件开始，并以成功组件结束选择菜单：文件 -&gt; 新建 -&gt; 作业设置变量我们既然需要轮询,因此我们需要把我们的相关参数设置在作业中,通过作业传递给子转换的方式,进行page页码轮询，因此我们需要把相关参数抽离出来：  page:页码，初始值为0(这里根据实际需求来设定,我这边访问的接口初始从0开始)  size:每页显示数据大小,初始值200  totalPage:总页码数,我们通过接口查询1次，是可以获取得到总页码数据的，此处为122页  url:POST接口请求地址  query:POST请求参数体最终设定好后，如下图：我们需要注意的是,需要指定变量的有效范围,因为参数值需要传递的子作业中,我选择的范围是在JVM中有效,从字面也是也不难理解,就是在JVM运行的时候,该参数值始终有效,和我们的Session概念差不多.条件此时,我们设定了初始变量,我们需要设定我们的执行条件(当前页码&lt;总页码)，因此，从作业的核心对象树条件树中选择检查字段的值组件,如下图：获取page源值,判断成功条件，即page&lt;totalPage值,执行子转换修改转换获取参数项我们通过条件检查的方式,设定了成功时需要执行子转换(POST带参数请求的转换)，因为我们把参数都提取在作业中定义,因此，我们的转换需要修改一下把生成记录组件替换为转换核心对象树中的作业-&gt; 获取变量 组件，如下图：而我们的获取变量 组件 如下图：类似于我们在该转换中声明一些临时的变量,只不过变量是通过父作业传递过来。在转换中我们只需要修改此参数的定义一处即可,后面的步骤无需更改.JavaScript脚本条件Kettle的作业执行已经执行成功了子转换,此时,我们需要根据page页码轮询,我们可以通过Javascript脚本来动态更改我们的page的值代码逻辑如下：var page=parent_job.getVariable('page');var totalPage=parent_job.getVariable('totalPage');if(page==totalPage){ false;}else{\tpage++;\tparent_job.setVariable('page',page);\ttrue;}通过parent_job内置对象的getVariable()方法和setVariable()方法分别获取变量和重新赋值变量即可完成此操作执行整个作业的创建就完成了,如下图：此时,我们执行作业，Kettle就会根据作业中的流程,将接口的全部数据导入到数据库中.整个ETL过程到此就完成了.附录我们在将RESTFul接口最终导入到数据库中的ETL过程中,我们使用了很多组件,关于各个组件的明细介绍可以参考以下链接进行查看:  生成记录组件  REST client请求RESTful API组件  JSON input组件  字段选择组件  插入/更新组件  作业之设置变量组件  作业之检查字段的值组件  作业之JavaScript脚本组件"
  },
  
  {
    "title": "Kettle实战100篇 第1篇 介绍与安装",
    "url": "/posts/kettle-1/",
    "categories": "Kettle实战",
    "tags": "",
    "date": "2019-08-08 00:00:00 +0800",
    





    
    "snippet": "简介Kettle是一款由纯Java语言开发的免费开源的ETL工具,ETL即是Extract-Transform-Load的缩写,用来描述将数据从来源端通过萃取(Extract)、转换(Transform)、加载(Load)到目标端的过程,通常用于数据清洗、数据迁移等.下载地址:https://sourceforge.net/projects/pentaho/files/GitHub地址：ht...",
    "content": "简介Kettle是一款由纯Java语言开发的免费开源的ETL工具,ETL即是Extract-Transform-Load的缩写,用来描述将数据从来源端通过萃取(Extract)、转换(Transform)、加载(Load)到目标端的过程,通常用于数据清洗、数据迁移等.下载地址:https://sourceforge.net/projects/pentaho/files/GitHub地址：https://github.com/pentaho/pentaho-kettleJava doc地址：https://javadoc.pentaho.com/文档地址:https://help.pentaho.com/转换组件文档：https://help.pentaho.com/Documentation/8.2/Products/Data_Integration/Transformation_Step_Reference作业组件文档：https://help.pentaho.com/Documentation/8.2/Products/Data_Integration/Job_Entry_Reference安装JDK安装由于Kettle是由Java语言开发,因此,我们在安装Kettle之前需要安装Java运行所需环境JDKwindow环境中的安装这里不再多做说明,只需要下载JDK的exe可运行文件,一直点击下一步即可安装,安装成功后再设置JAVA_HOME环境变量即可,非常简单在Linux环境中,我们首先需要下载JDK的安装文件,本篇博客中安装的版本为JDK1.8解压文件tar -xvf jdk-8u144-linux-x64.tar.gz -C /usr/local/java配置环境变量vim /etc/profile,编辑加入JDK路径export JAVA_HOME=/usr/local/java/jdk1.8.0_144export PATH=$JAVA_HOME/bin:$PATH编译source /etc/profile查看是否安装成功[root@izbp1ad1jbc6ftdure2mpnz ~]# java -versionjava version \"1.8.0_144\"Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)Kettle安装Kettle实战100篇系列博客下载的版本是当前最新版本Pentaho 8.3下载目录地址：https://sourceforge.net/projects/pentaho/files/Pentaho%208.3/client-tools/下的pdi-ce-8.3.0.0-371.zip目前我们都是在Windows环境中使用Kettle的Spoon图形化界面程序进行ETL的开发,Kettle是用Java开发的纯绿色版程序,因此我们只需要将下载的文件解压到指定目录即可,我本机解压目录D:\\Users\\xiaoymin\\Bin\\data-integration\\data-integration 8.3解压完成后,我们需要关注Kettle的几个关键目录和文件  Spoon:这是Kettle为我们提供的Spoon图形化界面启动程序,bat是在Windows环境下运行,sh则是在 类似Unix环境中运行，用于创建/编辑作业或者转换  Pan:我们通过Spoon创建了转换或者作业后,如果是保存在本地磁盘的话,会生成响应的文件,转换文件是以.ktr结尾，而Pan是转换的命令行执行程序,  Kitchen:作业文件以.kjb结尾,而Kitchen是作业的命令行执行程序  Carte:轻量级的HTTP服务器(依托于Jetty实现),后台的方式运行,监听HTTP请求来运行一个作业.Carte也可用于分布式和协调跨机器执行作业,即Kettle集群方式.  lib:该目录是Kettle依赖的第三方Jar包目录,如果我们在使用Kettle进行数据库导入的话,此时如果Kettle中没有该数据库的驱动Jar包时,我们需要将从网站上下载的驱动Jar放到该lib目录下,然后重启程序进行调试,否则会报错(驱动类不存在)  Encr:上面我们所说的创建数据库连接时,我们需要输入密码,但是我们的密码不能是明文,Encr工具为我们提供加密服务核心我们通过上面的步骤即可安装成功Kettle,此时我们可以运行Spoon程序创建转换或者作业,初始化界面如下:Kettle中两个核心的组件服务：转换和作业  转换：转换(transformation)是ETL解决方案中最主要的部分,它负责抽取、转换、加载各个阶段的数据操作处理,转换包括一个或多个步骤,如读取文件、请求REST接口、插入数据、过滤数据等等,各个步骤之间通过Hop连接,Hop代表的是一个单向的数据流通道.例如在上一个步骤中我们定义了变量user,那么我们在后面的步骤中则可以通过${user}的方式来获取变量的值,通过:文件 -&gt; 新建 -&gt; 转换用以创建转换  作业：作业(job)通常是一组转换的集合,比如一个条件的判断,参数的轮训执行转换,因为转换的执行只能执行一次,遇上分页接口的转换我们需要借助于作业的方式轮训执行转换以阶级数据的抽取工作,在作业中可以对转换的执行成功发送邮件服务等,通过:文件 -&gt; 新建 -&gt; 作业用以创建作业.牛刀小试由于本系列博客是以实战为主,因此很多Kettle的概念会以实战中的篇幅中介绍,不单独说明,当然,对于某些核心的组件会单独再博客中说明需求我们访问CSDN的博客RSS地址：https://blog.csdn.net/u010192145/rss/list,响应内容如下：目前我们需要通过网络访问该RSS地址,然后解析XML最终输出到Excel文件中,从XML中剥离出来id、标题、发布时间、作者、简介等字段这个过程涉及到了请求RESTful地址,数据解析,数据转换(输出到Excel),因此我们通过Kettle中的转换来实现此过程实战生成记录从Kettle的转换核心对象树中拖拽生成记录组件,定义url地址，如下图：REST client组件第二步是需要用到REST client组件,帮助我们发送地址请求获取得到XML的内容，如下图：GET  data from XML我们通过REST组件请求得到了XML内容,因此我们需要使用GET data from XML组件来接收,接收后定义输出映射字段Excel 输出通过上一个组件的字段映射定义,接下来我们就可以将请求得到的XML结果循环输出到Excel中了，选择对象树中的Excel 输出组件，设置相关属性，如下图：运行整个转换过程创建完后如下图：此时,我们点击Spoon界面的运行按钮,运行我们的转换，输出日志：此时,我们打开已经下载好的本地Excel文件,看是否将Xml的结果已经导入到本地至此,整个过程已经完成了,如果你是开发人员的话,通过Kettle来完成此操作会大大提升你的工作效率因为,假设您是一名Java开发人员,你需要用到的技术栈如下：  HTTP客户端请求技术,例如：httpClient或者OKHttp或者JDK原生的HttpConnection组件  Excel操作的相关技术,例如POI  XML操作的相关技术，例如Dom4j但是通过Kettle来操作的话,上面的技术栈我们就可以省略了(虽然我都会:),无奈~~~)看到这里,您是否想跃跃欲试呢?"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.9.5 发布，支持过滤请求参数",
    "url": "/posts/swagger-bootstrap-ui-1.9.5-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-07-31 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.9.5 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger...",
    "content": "swagger-bootstrap-ui 1.9.5 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/swagger-bootstrap-ui示例:https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性&amp;优化1、针对文件上传响应JSON内容时,内容不高亮的问题#IYXZB @Gitee2、文件上传响应内容显示异常Bug#IYO96 @Gitee3、针对中文请求头使用encodeURIComponent()函数进行编码处理#IYMUF @Gitee4、修复开启增强时空指针异常Bug#IYADU @Gitee5、针对@ResponseHeader注解未显示Bug#IY86A @Gitee6、DELETE请求针对Array类型的请求参数错误Bug#IY37Z @Gitee7、修复GET请求时CURL响应栏参数拼装错误#131 @GitHub8、修复非200状态码响应内容不格式化高亮的问题#130 @GitHub9、解决地址显示的BUG, 确保请求能够正确发送出去#PR108 @GitHub10、在使用动态扩展字段说明时,服务器上部署会造成空指针异常,该错误是由未对field名称进行非空判断导致#IYLVC @Gitee、#119 @GitHub11、可以自定义动态过滤请求参数,这在很多时候可以让我少写实体类，比如新增的时候不需要id，修改时又需要id，只需要在接口层使用增强注解@ApiOperationSupport的ignoreParameters属性即可,具体使用规则请参考文档12、优化增强排序接口注解@ApiSort无效果的问题13、响应类Model动态添加解释字段.请参考文档UI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.9.5&lt;/version&gt;&lt;/dependency&gt;Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.9.4 发布，扩展支持动态字段注释",
    "url": "/posts/swagger-bootstrap-ui-1.9.4-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-06-10 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.9.4 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger...",
    "content": "swagger-bootstrap-ui 1.9.4 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/swagger-bootstrap-ui示例:https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性&amp;优化1、最低需要JDK 1.8支持2、单独接口通过hash地址访问,方便开发人员之间快速复制传递接口信息,能准确定位到接口3、优化下载参数名称问题,忽略filename大小写敏感#IXA5C @Gitee4、优化BasicFilter过滤器正则匹配频率问题,decode函数调用替换为JDK 1.8版本中的java.util.Base645、tab操作项修改为点击事件显示,避免同调试按钮冲突导致误关选项卡#IXA5I @Gitee6、增加调试接口响应类型为Xml、Html、Text的支持#IWP49 @Gitee7、优化调试后header、raw、curl等选项卡高度太低的问题#IWLSU @Gitee8、主页简介description字段支持markdown格式#IVVRX @Gitee9、针对枚举类型的集合类型(List),在字段描述中显示枚举可用列表值#100 @GitHub10、重构原接口排序、tag排序规则,新增接口作者属性,可写每个接口的作者,方便开发者调试.参考文档11、针对Authorize授权的相关属性,不同分组相同的请求参数只需授权一次即可则全局通用#IXHBL @Gitee12、针对Map、JSONObject等动态类型可通过自定义注解@ApiOperationSupport或者@DynamicParameters来增加参数的字段说明,解决不想写实体类的烦恼,但是又无文档的困扰.参考文档13、优化自定义文档(markdown)界面效果,增加相关markdown语法样式(引用editormd.css)UI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.9.4&lt;/version&gt;&lt;/dependency&gt;Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）源码分析距离上一个版本也有挺长时间了,这段时间主要是对springfox的源码进行了一些研究和学习，并且记录了一些博客,该版本(1.9.4)的一些功能也在看源码的过程中对我有一些启发,对于Swagger的规范也多了一些了解对springfox源码有兴趣的朋友可以去我的博客查看,点击前往相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "springfox 源码分析(二十二) 总结",
    "url": "/posts/springfox-22/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-06-03 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "springfox 源码分析(二十一) 忽略参数Class类型",
    "url": "/posts/springfox-21/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-06-03 00:00:00 +0800",
    





    
    "snippet": "  我们在前面的源码过程中,了解了springfox的基本工作原理,接下来,我们可以通过使用springfox给我们提供的外部接口,来处理一些我们工作中碰到的问题,或者进行自定义扩展本篇主要介绍如何来忽略某些特定的参数Class类型先举一个例子,假如我们的接口是这样的：@PostMapping(\"/createOr33der\")@ApiOperation(value = \"创建订单\")pub...",
    "content": "  我们在前面的源码过程中,了解了springfox的基本工作原理,接下来,我们可以通过使用springfox给我们提供的外部接口,来处理一些我们工作中碰到的问题,或者进行自定义扩展本篇主要介绍如何来忽略某些特定的参数Class类型先举一个例子,假如我们的接口是这样的：@PostMapping(\"/createOr33der\")@ApiOperation(value = \"创建订单\")public Rest&lt;Order&gt; createOrdetr(@RequestBody Order order, HttpSession httpSession){    Rest&lt;Order&gt; r=new Rest&lt;&gt;();    r.setData(order);    return r;}我们在我们的方法上接收了一个HttpSession的参数对象,此时,我们来看我们的文档页面效果在我们的文档介绍页面中,多出了很多我们自认为不必要的参数,因为HttpSession对象我们并不需要传参处理,该对象我们是直接拿来使用对session进行操作的那么,针对这种情况,我们应该如何处理呢（即把HttpSession的参数处理掉,不显示）?目前有两种方法：  在方法的参数前,添加@ApiIgnore注解  在创建Docket对象时,指定忽略相关的Class第一种方式先来看第一种的代码处理方式：@PostMapping(\"/createOr33der\")@ApiOperation(value = \"创建订单\")public Rest&lt;Order&gt; createOrdetr(@RequestBody Order order,@ApiIgnore HttpSession httpSession){    Rest&lt;Order&gt; r=new Rest&lt;&gt;();    r.setData(order);    return r;}我们在HttpSession的参数前,添加@ApiIgnore注解，那么此时springfox会帮助我们忽略此参数@ApiIgnore的作用方法不仅仅在参数上,还可以作用于整个接口Controller，或者单个接口@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.METHOD, ElementType.TYPE, ElementType.PARAMETER})public @interface ApiIgnore {  /**   * A brief description of why this parameter/operation is ignored   * @return  the description of why it is ignored   */  String value() default \"\";}其作用范围是METHOD、TYPE、PARAMETER第二种方式虽然第一种方式达到了我们的目的,但是细心的朋友可能会发现,如果目前的接口方法中,存在大量的HttpSession参数，那么每个方法都需要更改一遍?那岂不是炸了所以针对这种情况,springfox在我们创建Docket对象时,提供了入口,我们在创建Docket对象时就可以默认传入需要忽略的类Class，这样我们就不需要每个接口都更改一遍了先来看Docket的部分源码/**   * Adds ignored controller method parameter types so that the framework does not generate swagger model or parameter   * information for these specific types.   * e.g. HttpServletRequest/HttpServletResponse which are already included in the pre-configured ignored types.   *   * @param classes the classes to ignore   * @return this Docket   * @see springfox.documentation.spi.service.contexts.Defaults#defaultIgnorableParameterTypes()   */public Docket ignoredParameterTypes(Class... classes) {    this.ignorableParameterTypes.addAll(Arrays.asList(classes));    return this;}传入Class的集合springfox框架默认忽略的类型在Default中private void initIgnorableTypes() {    ignored = newHashSet();    ignored.add(ServletRequest.class);    ignored.add(Class.class);    ignored.add(Void.class);    ignored.add(Void.TYPE);    ignored.add(HttpServletRequest.class);    ignored.add(HttpServletResponse.class);    ignored.add(HttpHeaders.class);    ignored.add(BindingResult.class);    ignored.add(ServletContext.class);    ignored.add(UriComponentsBuilder.class);    ignored.add(ApiIgnore.class); //Used to ignore parameters}此时,我们在创建Docket对象时,做一下更改,如下：@Bean(value = \"groupRestApi\")@Order(value = 1)public Docket groupRestApi() {    return new Docket(DocumentationType.SWAGGER_2)        .apiInfo(groupApiInfo())        .groupName(\"分组接口\")        .select()        .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.group\"))        .paths(PathSelectors.any())        .build()        .ignoredParameterTypes(HttpSession.class) //添加忽略类型        .extensions(Lists.newArrayList(new OrderExtensions(2))).securityContexts(Lists.newArrayList(securityContext(),securityContext1())).securitySchemes(Lists.&lt;SecurityScheme&gt;newArrayList(apiKey(),apiKey1()));}通过ignoredParameterTypes方法,传入HttpSession的class，告诉springfox框架该class需要忽略最终的效果如下："
  },
  
  {
    "title": "springfox 源码分析(二十) 自定义扩展实现Map、JSONObject等动态字段显示",
    "url": "/posts/springfox-20/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-06-03 00:00:00 +0800",
    





    
    "snippet": "待续…",
    "content": "待续…"
  },
  
  {
    "title": "springfox 源码分析(十九) guava库学习",
    "url": "/posts/springfox-19/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-06-02 00:00:00 +0800",
    





    
    "snippet": "我们在研究springfox的过程中，发现springfox大量使用了guava这个库的一些方法和类,针对我们在研究源码的学习过程中,将涉及到的guava库中的类进行归纳总结,后期在工作中我们也可以熟练运用guava库为我们提供的简介apiArrayListMultimap从字面意思来看map中包含了数组元素举一个简单的例子来帮助我们理解这个类我们在读书时,作为主体对象的我们(学生),都有一...",
    "content": "我们在研究springfox的过程中，发现springfox大量使用了guava这个库的一些方法和类,针对我们在研究源码的学习过程中,将涉及到的guava库中的类进行归纳总结,后期在工作中我们也可以熟练运用guava库为我们提供的简介apiArrayListMultimap从字面意思来看map中包含了数组元素举一个简单的例子来帮助我们理解这个类我们在读书时,作为主体对象的我们(学生),都有一个班级,即该学生是属于哪个班级的,现在拥有全校的学生列表集合,但是想通过班级名称来统计各个班级的人数情况,应该如何操作呢？如果在数据库中,一个SQL语句的分组函数即可搞定,但是在Java中却是异常繁杂.ArrayListMultimap就可以做到先来看我们的学生类：public class Student {    private String name;    private Integer age;    /***     * 班级     */    private String classRoom;    //getter setter}学生类拥有姓名、年龄、班级三个属性，此时我们通过ArrayListMultimap来解决上面我们所提的问题：List&lt;Student&gt; list= Lists.newArrayList();list.add(new Student(\"学生A\",12,\"班级1\"));list.add(new Student(\"学生B\",13,\"班级2\"));list.add(new Student(\"学生C\",12,\"班级1\"));list.add(new Student(\"学生D\",15,\"班级3\"));list.add(new Student(\"学生E\",12,\"班级1\"));list.add(new Student(\"学生F\",13,\"班级2\"));list.add(new Student(\"学生G\",11,\"班级1\"));list.add(new Student(\"学生H\",15,\"班级2\"));list.add(new Student(\"学生I\",11,\"班级3\"));list.add(new Student(\"学生J\",12,\"班级1\"));list.add(new Student(\"学生W\",16,\"班级1\"));list.add(new Student(\"学生Q\",13,\"班级4\"));//针对班级分组ArrayListMultimap&lt;String,Student&gt; arrayListMultimap=ArrayListMultimap.create();for (Student student:list){    arrayListMultimap.put(student.getClassRoom(),student);}Map&lt;String,Collection&lt;Student&gt;&gt; map=arrayListMultimap.asMap();for (String key:map.keySet()){    Collection&lt;Student&gt; students=map.get(key);    System.out.println(\"班级名称:\"+key+\",总共有学员:\"+students.size());    for (Student sd:students){        System.out.println(sd.toString());    }    System.out.println(\"\");}而此时,控制台的打印情况如下：班级名称:班级1,总共有学员:6班级：班级1,姓名：学生A,年龄:12班级：班级1,姓名：学生C,年龄:12班级：班级1,姓名：学生E,年龄:12班级：班级1,姓名：学生G,年龄:11班级：班级1,姓名：学生J,年龄:12班级：班级1,姓名：学生W,年龄:16班级名称:班级4,总共有学员:1班级：班级4,姓名：学生Q,年龄:13班级名称:班级2,总共有学员:3班级：班级2,姓名：学生B,年龄:13班级：班级2,姓名：学生F,年龄:13班级：班级2,姓名：学生H,年龄:15班级名称:班级3,总共有学员:2班级：班级3,姓名：学生D,年龄:15班级：班级3,姓名：学生I,年龄:11班级数量、班级针对的学生明细、学生根据班级统计情况都很方便的统计出来了.FluentIterableguava提供了FluentIterable对集合进行各种简化遍历的操作,这和Java8中的stream是很相似的.例如对一个集合中的元素进行过滤public static void main(String[] args) {    List&lt;Student&gt; list= Lists.newArrayList();    list.add(new Student(\"学生A\",12,\"班级1\"));    list.add(new Student(\"学生B\",13,\"班级2\"));    list.add(new Student(\"学生C\",12,\"班级1\"));    list.add(new Student(\"学生D\",15,\"班级3\"));    list.add(new Student(\"学生E\",12,\"班级1\"));    list.add(new Student(\"学生F\",13,\"班级2\"));    list.add(new Student(\"学生G\",11,\"班级1\"));    list.add(new Student(\"学生H\",15,\"班级2\"));    list.add(new Student(\"学生I\",11,\"班级3\"));    list.add(new Student(\"学生J\",12,\"班级1\"));    list.add(new Student(\"学生W\",16,\"班级1\"));    list.add(new Student(\"学生Q\",13,\"班级4\"));    //arrmapTest(list);    fluter(list);}static void fluter(List&lt;Student&gt; list){    //过滤    List&lt;Student&gt; studentList=FluentIterable.from(list).filter(new Predicate&lt;Student&gt;() {        @Override        public boolean apply(Student input) {            return input.getClassRoom().equals(\"班级1\");        }    }).toList();    for (Student sd:studentList){        System.out.println(sd.toString());    }}此时,我们筛选班级1的学生，最终输出：班级：班级1,姓名：学生A,年龄:12班级：班级1,姓名：学生C,年龄:12班级：班级1,姓名：学生E,年龄:12班级：班级1,姓名：学生G,年龄:11班级：班级1,姓名：学生J,年龄:12班级：班级1,姓名：学生W,年龄:16通过Java8 来操作List&lt;Student&gt; li=list.stream().filter(student -&gt; student.getClassRoom().equals(\"班级1\")).collect(Collectors.toList());for (Student sd:li){    System.out.println(sd.toString());}OptionalOptional操作是避免开发人员出现空指针操作而设计的,在Java8 中也有该对象的使用。"
  },
  
  {
    "title": "springfox 源码分析(十八) 自定义扩展实现分组的排序",
    "url": "/posts/springfox-18/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-06-02 00:00:00 +0800",
    





    
    "snippet": "既然我们对springfox提供的接口已经有了一个初步的了解,那么针对我们在分组接口文章中提的需求,如果自定义扩展实现分组的排序如何做呢？在swagger-bootstrap-ui以前的版本中,已经存在了增强功能,增强功能主要的方式是重写了springfox的接口,然后在我们自定义的ui中渲染即可.因为SwaggerResource.java中没有提供排序的字段属性,所以我们可以扩展该类,提...",
    "content": "既然我们对springfox提供的接口已经有了一个初步的了解,那么针对我们在分组接口文章中提的需求,如果自定义扩展实现分组的排序如何做呢？在swagger-bootstrap-ui以前的版本中,已经存在了增强功能,增强功能主要的方式是重写了springfox的接口,然后在我们自定义的ui中渲染即可.因为SwaggerResource.java中没有提供排序的字段属性,所以我们可以扩展该类,提供一个排序字段/*** * * @since:swagger-bootstrap-ui 1.9.4 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2019/06/02 16:24 */public class SwaggerResourceExt extends SwaggerResource {    private Integer order;    public Integer getOrder() {        return order;    }    public void setOrder(Integer order) {        this.order = order;    }}很简单,提供一个order属性,该类继承自springfox的SwaggerResource扩展了基础属性类,那么我们提供的方式也需要进行扩展@Component@Qualifier(\"swaggerResourcesExtProvider\")public class SwaggerResourcesExtProvider  {    private final String swagger1Url;    private final String swagger2Url;    @VisibleForTesting    boolean swagger1Available;    @VisibleForTesting    boolean swagger2Available;    private final DocumentationCache documentationCache;    @Autowired    public SwaggerResourcesExtProvider(Environment environment, DocumentationCache documentationCache) {        swagger1Url = environment.getProperty(\"springfox.documentation.swagger.v1.path\", \"/api-docs-ext\");        swagger2Url = environment.getProperty(\"springfox.documentation.swagger.v2.path\", \"/v2/api-docs-ext\");        swagger1Available = classByName(\"springfox.documentation.swagger1.web.Swagger1Controller\").isPresent();        swagger2Available = classByName(\"springfox.documentation.swagger2.web.Swagger2Controller\").isPresent();        this.documentationCache = documentationCache;    }    public List&lt;SwaggerResourceExt&gt; get() {        List&lt;SwaggerResourceExt&gt; resources = new ArrayList&lt;SwaggerResourceExt&gt;();        for (Map.Entry&lt;String, Documentation&gt; entry : documentationCache.all().entrySet()) {            String swaggerGroup = entry.getKey();            Documentation documentation=entry.getValue();            List&lt;VendorExtension&gt; vendorExtensions=documentation.getVendorExtensions();            if (swagger1Available) {                SwaggerResourceExt swaggerResource = resource(swaggerGroup, swagger1Url,vendorExtensions);                swaggerResource.setSwaggerVersion(\"1.2\");            }            if (swagger2Available) {                SwaggerResourceExt swaggerResource = resource(swaggerGroup, swagger2Url,vendorExtensions);                swaggerResource.setSwaggerVersion(\"2.0\");                resources.add(swaggerResource);            }        }        //根据自定义扩展属性order进行排序        Collections.sort(resources, new Comparator&lt;SwaggerResourceExt&gt;() {            @Override            public int compare(SwaggerResourceExt o1, SwaggerResourceExt o2) {                return o1.getOrder().compareTo(o2.getOrder());            }        });        return resources;    }    private SwaggerResourceExt resource(String swaggerGroup, String baseUrl,List&lt;VendorExtension&gt; vendorExtensions) {        SwaggerResourceExt swaggerResource = new SwaggerResourceExt();        swaggerResource.setName(swaggerGroup);        swaggerResource.setUrl(swaggerLocation(baseUrl, swaggerGroup));        swaggerResource.setOrder(0);        //判断是否不为空        if (vendorExtensions!=null&amp;&amp;!vendorExtensions.isEmpty()){            Optional&lt;VendorExtension&gt; ov= FluentIterable.from(vendorExtensions).filter(new Predicate&lt;VendorExtension&gt;() {                @Override                public boolean apply(VendorExtension input) {                    return input.getClass().isAssignableFrom(OrderExtensions.class);                }            }).first();            if (ov.isPresent()){                OrderExtensions orderExtensions=(OrderExtensions) ov.get();                swaggerResource.setOrder(orderExtensions.getValue());            }        }        return swaggerResource;    }    private String swaggerLocation(String swaggerUrl, String swaggerGroup) {        String base = Optional.of(swaggerUrl).get();        if (Docket.DEFAULT_GROUP_NAME.equals(swaggerGroup)) {            return base;        }        return base + \"?group=\" + swaggerGroup;    }}针对原springfox的方式进行扩展,主要逻辑  首先获取Documentation的Map集合对象,进行遍历  我们的接口参数是需要从外部由开发者自定义的传入的,那么此时我们可以利用Docket对象提供的扩展属性集合来操作,swagger-bootstrap-ui提供了OrderExtensions扩展,开发者创建Docket对象时进行参数传入即可  筛选Documentation的扩展属性集合,找到符合规范的扩展,如果未找到则默认排序值为0重写了获取SwaggerResource集合的工具类,接下来重写接口层@ApiIgnore@Controller@RequestMapping(\"/swagger-resources-ext\")public class SwaggerBootstrapUiResourceExtController {    private final SwaggerResourcesExtProvider swaggerResourcesExtProvider;    @Autowired    public SwaggerBootstrapUiResourceExtController(@Qualifier(\"swaggerResourcesExtProvider\") SwaggerResourcesExtProvider swaggerResources) {        this.swaggerResourcesExtProvider = swaggerResources;    }    @RequestMapping    @ResponseBody    public ResponseEntity&lt;List&lt;SwaggerResourceExt&gt;&gt; swaggerResources() {        return new ResponseEntity&lt;List&lt;SwaggerResourceExt&gt;&gt;(swaggerResourcesExtProvider.get(), HttpStatus.OK);    }}此时,提供一个类似springfox的分组接口,通过工具类提供,获取拿到分组信息有了以上的扩展实现,我们SwaggerConfiguration配置文件创建Docket对象时需要稍微做一个改动@Bean(value = \"defaultApi\")    public Docket defaultApi() {        ParameterBuilder parameterBuilder=new ParameterBuilder();        List&lt;Parameter&gt; parameters= Lists.newArrayList();        parameterBuilder.name(\"token\").description(\"token令牌\").modelRef(new ModelRef(\"String\"))                .parameterType(\"header\")                .required(true).build();        parameters.add(parameterBuilder.build());        Docket docket=new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .groupName(\"默认接口\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.controller\"))                //.apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class))                .paths(PathSelectors.any())                .build()            //添加扩展            .extensions(Lists.newArrayList(new OrderExtensions(1)))            .globalOperationParameters(parameters)                .securityContexts(Lists.newArrayList(securityContext())).securitySchemes(Lists.&lt;SecurityScheme&gt;newArrayList(apiKey()));        return docket;    }此时,我们使用extensions方法添加扩展,赋值OrderExtensions的排序order值此时我们访问接口/swagger-resoueces-ext返回：[    {        \"order\": 1,        \"name\": \"默认接口\",        \"url\": \"/v2/api-docs-ext?group=默认接口\",        \"swaggerVersion\": \"2.0\",        \"location\": \"/v2/api-docs-ext?group=默认接口\"    },    {        \"order\": 2,        \"name\": \"分组接口\",        \"url\": \"/v2/api-docs-ext?group=分组接口\",        \"swaggerVersion\": \"2.0\",        \"location\": \"/v2/api-docs-ext?group=分组接口\"    }]此时,我们在Ui端就可以自定义接口分组的排序了以上功能在swagger-bootstrap-ui1.9.4版本已经实现,开发者如果有排序的需求,可以使用此方法.注意：在使用此功能时,需要在Swagger的配置文件类上加上@EnableSwaggerBootstrapUI注解"
  },
  
  {
    "title": "springfox 源码分析(十七) Swagger2接口文档示例接口api-docs",
    "url": "/posts/springfox-17/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-06-01 00:00:00 +0800",
    





    
    "snippet": "前面已经获取得到了swagger的分组接口信息了,接下来就是根据分组名称获取每个分组的Swagger资源详细信息,在springfox中提供了/v2/api-docs接口来进行获取来看接口的源码@Controller@ApiIgnorepublic class Swagger2Controller {  public static final String DEFAULT_URL = \"/v...",
    "content": "前面已经获取得到了swagger的分组接口信息了,接下来就是根据分组名称获取每个分组的Swagger资源详细信息,在springfox中提供了/v2/api-docs接口来进行获取来看接口的源码@Controller@ApiIgnorepublic class Swagger2Controller {  public static final String DEFAULT_URL = \"/v2/api-docs\";  private static final Logger LOGGER = LoggerFactory.getLogger(Swagger2Controller.class);  private static final String HAL_MEDIA_TYPE = \"application/hal+json\";  private final String hostNameOverride;  private final DocumentationCache documentationCache;  private final ServiceModelToSwagger2Mapper mapper;  private final JsonSerializer jsonSerializer;  @Autowired  public Swagger2Controller(      Environment environment,      DocumentationCache documentationCache,      ServiceModelToSwagger2Mapper mapper,      JsonSerializer jsonSerializer) {    this.hostNameOverride =        environment.getProperty(            \"springfox.documentation.swagger.v2.host\",            \"DEFAULT\");    this.documentationCache = documentationCache;    this.mapper = mapper;    this.jsonSerializer = jsonSerializer;  }  @RequestMapping(      value = DEFAULT_URL,      method = RequestMethod.GET,      produces = { APPLICATION_JSON_VALUE, HAL_MEDIA_TYPE })  @PropertySourcedMapping(      value = \"${springfox.documentation.swagger.v2.path}\",      propertyKey = \"springfox.documentation.swagger.v2.path\")  @ResponseBody  public ResponseEntity&lt;Json&gt; getDocumentation(      @RequestParam(value = \"group\", required = false) String swaggerGroup,      HttpServletRequest servletRequest) {    String groupName = Optional.fromNullable(swaggerGroup).or(Docket.DEFAULT_GROUP_NAME);    Documentation documentation = documentationCache.documentationByGroup(groupName);    if (documentation == null) {      LOGGER.warn(\"Unable to find specification for group {}\", groupName);      return new ResponseEntity&lt;Json&gt;(HttpStatus.NOT_FOUND);    }    Swagger swagger = mapper.mapDocumentation(documentation);    UriComponents uriComponents = componentsFrom(servletRequest, swagger.getBasePath());    swagger.basePath(Strings.isNullOrEmpty(uriComponents.getPath()) ? \"/\" : uriComponents.getPath());    if (isNullOrEmpty(swagger.getHost())) {      swagger.host(hostName(uriComponents));    }    return new ResponseEntity&lt;Json&gt;(jsonSerializer.toJson(swagger), HttpStatus.OK);  }  private String hostName(UriComponents uriComponents) {    if (\"DEFAULT\".equals(hostNameOverride)) {      String host = uriComponents.getHost();      int port = uriComponents.getPort();      if (port &gt; -1) {        return String.format(\"%s:%d\", host, port);      }      return host;    }    return hostNameOverride;  }}该接口主要逻辑：  传入groupName分组名称参数,从文档缓存对象中获取Documentation文档对象  通过mapper提供的方法,将Documentation对象转换为标准的Swagger对象  JSON响应输出Swagger的标准对象主要包含信息我们在前面也介绍过public class Swagger {    protected String swagger = \"2.0\";    protected Info info;    protected String host;    protected String basePath;    protected List&lt;Tag&gt; tags;    protected List&lt;Scheme&gt; schemes;    protected List&lt;String&gt; consumes;    protected List&lt;String&gt; produces;    protected List&lt;SecurityRequirement&gt; security;    protected Map&lt;String, Path&gt; paths;    protected Map&lt;String, SecuritySchemeDefinition&gt; securityDefinitions;    protected Map&lt;String, Model&gt; definitions;    protected Map&lt;String, Parameter&gt; parameters;    protected Map&lt;String, Response&gt; responses;    protected ExternalDocs externalDocs;    protected Map&lt;String, Object&gt; vendorExtensions;}最终在ui端拿到Swagger的属性信息进行接口的信息渲染,开发人员即可进行接口的查看和调试."
  },
  
  {
    "title": "springfox 源码分析(十六) 分组接口swagger-resouces",
    "url": "/posts/springfox-16/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-06-01 00:00:00 +0800",
    





    
    "snippet": "通过前面的分析,我们最终得到了springfox的Documentation文档对象,将我们的RESTful接口最终转换为了文档对象,文档对象是包含了接口列表、分组信息等属性的在springfox中,为我们提供了springfox-swagger-ui来呈现最终的接口信息.在ui界面中有两个核心接口：  swagger-resources:swagger分组接口，创建多少Docket,就会有...",
    "content": "通过前面的分析,我们最终得到了springfox的Documentation文档对象,将我们的RESTful接口最终转换为了文档对象,文档对象是包含了接口列表、分组信息等属性的在springfox中,为我们提供了springfox-swagger-ui来呈现最终的接口信息.在ui界面中有两个核心接口：  swagger-resources:swagger分组接口，创建多少Docket,就会有多少分组信息  /v2/api-docs:Swagger接口示例信息,通过Documentation对象最终输出为Swagger标准信息先来看接口源码：@Controller@ApiIgnore@RequestMapping(\"/swagger-resources\")public class ApiResourceController {  @Autowired(required = false)  private SecurityConfiguration securityConfiguration;  @Autowired(required = false)  private UiConfiguration uiConfiguration;  private final SwaggerResourcesProvider swaggerResources;  @Autowired  public ApiResourceController(SwaggerResourcesProvider swaggerResources) {    this.swaggerResources = swaggerResources;  }  @RequestMapping(value = \"/configuration/security\")  @ResponseBody  public ResponseEntity&lt;SecurityConfiguration&gt; securityConfiguration() {    return new ResponseEntity&lt;SecurityConfiguration&gt;(        Optional.fromNullable(securityConfiguration).or(SecurityConfigurationBuilder.builder().build()), HttpStatus.OK);  }  @RequestMapping(value = \"/configuration/ui\")  @ResponseBody  public ResponseEntity&lt;UiConfiguration&gt; uiConfiguration() {    return new ResponseEntity&lt;UiConfiguration&gt;(        Optional.fromNullable(uiConfiguration).or(UiConfigurationBuilder.builder().build()), HttpStatus.OK);  }  @RequestMapping  @ResponseBody  public ResponseEntity&lt;List&lt;SwaggerResource&gt;&gt; swaggerResources() {    return new ResponseEntity&lt;List&lt;SwaggerResource&gt;&gt;(swaggerResources.get(), HttpStatus.OK);  }}通过swaggerResources.get()方法获取最终的信息SwaggerResourcesProvider是接口,在springfox中只有一个实现类InMemorySwaggerResourcesProvider@Componentpublic class InMemorySwaggerResourcesProvider implements SwaggerResourcesProvider {  private final String swagger1Url;  private final String swagger2Url;  @VisibleForTesting  boolean swagger1Available;  @VisibleForTesting  boolean swagger2Available;  private final DocumentationCache documentationCache;  @Autowired  public InMemorySwaggerResourcesProvider(      Environment environment,      DocumentationCache documentationCache) {    swagger1Url = environment.getProperty(\"springfox.documentation.swagger.v1.path\", \"/api-docs\");    swagger2Url = environment.getProperty(\"springfox.documentation.swagger.v2.path\", \"/v2/api-docs\");    swagger1Available = classByName(\"springfox.documentation.swagger1.web.Swagger1Controller\").isPresent();    swagger2Available = classByName(\"springfox.documentation.swagger2.web.Swagger2Controller\").isPresent();    this.documentationCache = documentationCache;  }  @Override  public List&lt;SwaggerResource&gt; get() {    List&lt;SwaggerResource&gt; resources = new ArrayList&lt;SwaggerResource&gt;();    for (Map.Entry&lt;String, Documentation&gt; entry : documentationCache.all().entrySet()) {      String swaggerGroup = entry.getKey();      if (swagger1Available) {        SwaggerResource swaggerResource = resource(swaggerGroup, swagger1Url);        swaggerResource.setSwaggerVersion(\"1.2\");        resources.add(swaggerResource);      }      if (swagger2Available) {        SwaggerResource swaggerResource = resource(swaggerGroup, swagger2Url);        swaggerResource.setSwaggerVersion(\"2.0\");        resources.add(swaggerResource);      }    }    Collections.sort(resources);    return resources;  }  private SwaggerResource resource(String swaggerGroup, String baseUrl) {    SwaggerResource swaggerResource = new SwaggerResource();    swaggerResource.setName(swaggerGroup);    swaggerResource.setUrl(swaggerLocation(baseUrl, swaggerGroup));    return swaggerResource;  }  private String swaggerLocation(String swaggerUrl, String swaggerGroup) {    String base = Optional.of(swaggerUrl).get();    if (Docket.DEFAULT_GROUP_NAME.equals(swaggerGroup)) {      return base;    }    return base + \"?group=\" + swaggerGroup;  }}通过遍历DocumentationCache中缓存的Documentation对象,得到接口文档信息的分组信息,响应SwaggerResource的集合信息SwaggerResource信息主要包含的字段信息：名称，url、swagger版本@JsonInclude(JsonInclude.Include.NON_NULL)public class SwaggerResource implements Comparable&lt;SwaggerResource&gt; {  private String name;  private String url;  private String swaggerVersion;  @Override  public int compareTo(SwaggerResource other) {    return ComparisonChain.start()        .compare(this.swaggerVersion, other.swaggerVersion)        .compare(this.name, other.name)        .result();  }}在开发swagger-bootstrap-ui的过程中,经常会碰到很多朋友提问,有什么方式能对文档的分组信息进行排序的吗？我们通过上面的源码可以看到,其实SwaggerResource实现了Comparable接口,但是他的排序规则是先根据swagger的版本进行排序，然后对名称进行排序,asc顺序排序那么我们如何实现我们自定义的排序方式呢?后面我会详细介绍."
  },
  
  {
    "title": "springfox 源码分析(十五) 归档得到Documentation文档对象",
    "url": "/posts/springfox-15/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-31 00:00:00 +0800",
    





    
    "snippet": "通过上篇的分析,我们已经得到了ApiListing的map集合，接下来最终做文档归档,得到Documentation对象/***   * 最终生成Documentation文档对象   * @param context   * @return   */  public Documentation scan(DocumentationContext context) {    //得到分组接口...",
    "content": "通过上篇的分析,我们已经得到了ApiListing的map集合，接下来最终做文档归档,得到Documentation对象/***   * 最终生成Documentation文档对象   * @param context   * @return   */  public Documentation scan(DocumentationContext context) {    //得到分组接口    ApiListingReferenceScanResult result = apiListingReferenceScanner.scan(context);    //拿到所有接口请求    //controller:methods-- 1:N的关系    ApiListingScanningContext listingContext = new ApiListingScanningContext(context,        result.getResourceGroupRequestMappings());    //核心操作,springfox的关键操作都在下面这个scan方法中,构造接口函数    Multimap&lt;String, ApiListing&gt; apiListings = apiListingScanner.scan(listingContext);    Set&lt;Tag&gt; tags = toTags(apiListings);    tags.addAll(context.getTags());    DocumentationBuilder group = new DocumentationBuilder()        .name(context.getGroupName())        .apiListingsByResourceGroupName(apiListings)        .produces(context.getProduces())        .consumes(context.getConsumes())        .host(context.getHost())        .schemes(context.getProtocols())        .basePath(context.getPathProvider().getApplicationBasePath())        .extensions(context.getVendorExtentions())        .tags(tags);    Set&lt;ApiListingReference&gt; apiReferenceSet = newTreeSet(listingReferencePathComparator());    apiReferenceSet.addAll(apiListingReferences(apiListings, context));    ResourceListing resourceListing = new ResourceListingBuilder()        .apiVersion(context.getApiInfo().getVersion())        .apis(from(apiReferenceSet).toSortedList(context.getListingReferenceOrdering()))        .securitySchemes(context.getSecuritySchemes())        .info(context.getApiInfo())        .build();    group.resourceListing(resourceListing);    return group.build();  }Documentation主要包含的信息  分组名称  接口列表  produces  consumes  基础路径  host  分组tags  扩展  schema-Models"
  },
  
  {
    "title": "springfox 源码分析(十四) 归档得到ApiListing接口集合",
    "url": "/posts/springfox-14/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-30 00:00:00 +0800",
    





    
    "snippet": "在前面我们拿到了接口的Model类型集合,然后还获取到了该接口的ApiDescription描述信息此时针对这些信息,进行接口的资源整合,最终构造ApiListing类/*** * 通过已经筛选过滤的接口集合以及context上下文对象来得到接口列表 * @param context * @return */public Multimap&lt;String, ApiListing&gt; ...",
    "content": "在前面我们拿到了接口的Model类型集合,然后还获取到了该接口的ApiDescription描述信息此时针对这些信息,进行接口的资源整合,最终构造ApiListing类/*** * 通过已经筛选过滤的接口集合以及context上下文对象来得到接口列表 * @param context * @return */public Multimap&lt;String, ApiListing&gt; scan(ApiListingScanningContext context) {  final Multimap&lt;String, ApiListing&gt; apiListingMap = LinkedListMultimap.create();  int position = 0;  // 从外部拿到已经筛选过滤后的接口信息  //controler:methods 1:N  Map&lt;ResourceGroup, List&lt;RequestMappingContext&gt;&gt; requestMappingsByResourceGroup      = context.getRequestMappingsByResourceGroup();  //收集接口详细信息  //由于ApiListingScannerPlugin在springfox中没有实现类,所以此处返回additional集合对象是空的  //additionalListings在此处是空集合，一个元素都没有  Collection&lt;ApiDescription&gt; additionalListings = pluginsManager.additionalListings(context);  //拿到所有的Controller分组信息  Set&lt;ResourceGroup&gt; allResourceGroups = FluentIterable.from(collectResourceGroups(additionalListings))          .append(requestMappingsByResourceGroup.keySet())          .toSet();  List&lt;SecurityReference&gt; securityReferences = newArrayList();  for (final ResourceGroup resourceGroup : sortedByName(allResourceGroups)) {    DocumentationContext documentationContext = context.getDocumentationContext();    Set&lt;String&gt; produces = new LinkedHashSet&lt;String&gt;(documentationContext.getProduces());    Set&lt;String&gt; consumes = new LinkedHashSet&lt;String&gt;(documentationContext.getConsumes());    String host = documentationContext.getHost();    Set&lt;String&gt; protocols = new LinkedHashSet&lt;String&gt;(documentationContext.getProtocols());    Set&lt;ApiDescription&gt; apiDescriptions = newHashSet();    Map&lt;String, Model&gt; models = new LinkedHashMap&lt;String, Model&gt;();    //得到该Controller下的所有接口    List&lt;RequestMappingContext&gt; requestMappings = nullToEmptyList(requestMappingsByResourceGroup.get(resourceGroup));    for (RequestMappingContext each : sortedByMethods(requestMappings)) {      //拿到该接口的所有Model      models.putAll(apiModelReader.read(each.withKnownModels(models)));      apiDescriptions.addAll(apiDescriptionReader.read(each));    }    //根据分组名称进行分组    List&lt;ApiDescription&gt; additional = from(additionalListings)        .filter(            and(                belongsTo(resourceGroup.getGroupName()),                onlySelectedApis(documentationContext)))        .toList();    apiDescriptions.addAll(additional);    List&lt;ApiDescription&gt; sortedApis = FluentIterable.from(apiDescriptions)        .toSortedList(documentationContext.getApiDescriptionOrdering());    String resourcePath = new ResourcePathProvider(resourceGroup)        .resourcePath()        .or(longestCommonPath(sortedApis))        .orNull();    PathProvider pathProvider = documentationContext.getPathProvider();    String basePath = pathProvider.getApplicationBasePath();    PathAdjuster adjuster = new PathMappingAdjuster(documentationContext);    ApiListingBuilder apiListingBuilder = new ApiListingBuilder(context.apiDescriptionOrdering())        .apiVersion(documentationContext.getApiInfo().getVersion())        .basePath(adjuster.adjustedPath(basePath))        .resourcePath(resourcePath)        .produces(produces)        .consumes(consumes)        .host(host)        .protocols(protocols)        .securityReferences(securityReferences)        .apis(sortedApis)        .models(models)        .position(position++)        .availableTags(documentationContext.getTags());    ApiListingContext apiListingContext = new ApiListingContext(        context.getDocumentationType(),        resourceGroup,        apiListingBuilder);    apiListingMap.put(resourceGroup.getGroupName(), pluginsManager.apiListing(apiListingContext));  }  return apiListingMap;}代码逻辑：  首先根据Controller分类获取得到所有接口上下文信息(RequestMappingContext)  遍历每个接口上下文信息,获取得到该接口的Models类型集合  遍历获取得到ApiDescription接口描述信息,接口描述信息包括：接口名称、路径、是否过时、参数、响应状态码、请求类型等等信息  通过以上这些信息构造ApiListingBuilder对象  调用ApiListingBuilderPlugin插件，构造赋值ApiListingBuilder对象的相关属性信息  添加到apiListingMap集合对象中ApiListingBuilderPlugin的 实现类目前有三个：  ApiListingReader:分组信息、描述信息  MediaTypeReader:赋值consumes、produces信息  SwaggerApiListingReader：@Api注解，分组tags信息赋值"
  },
  
  {
    "title": "springfox 源码分析(十三) 自定义扩展实现接口的排序",
    "url": "/posts/springfox-13/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-29 00:00:00 +0800",
    





    
    "snippet": "很多时候,Swagger定义的标准并不能满足我们实际的需求,比如拿分组后的接口来说,有适合我们希望我们的接口能够排序,假如我们当前有一个注册的需求实现,那么他的接口可能是这样的：1.获取验证码 -&gt; 2.校验用户名是否有效 -&gt; 3.注册验证 -&gt; 4.登录如果我们没有排序的情况下,上面的接口对于开发人员来说可能是杂乱无章的,对于初级的接口对接人员来说,排序更能让开发者把当...",
    "content": "很多时候,Swagger定义的标准并不能满足我们实际的需求,比如拿分组后的接口来说,有适合我们希望我们的接口能够排序,假如我们当前有一个注册的需求实现,那么他的接口可能是这样的：1.获取验证码 -&gt; 2.校验用户名是否有效 -&gt; 3.注册验证 -&gt; 4.登录如果我们没有排序的情况下,上面的接口对于开发人员来说可能是杂乱无章的,对于初级的接口对接人员来说,排序更能让开发者把当前的需求清晰明了的用代码来实现掉,为此，接口文档的作用也能最大化.那么,在swagger的标准中,那些允许我们自定义扩展,在Springfox中我们又如何来实现我们的自定义扩展呢?Swagger标准先来看Swagger定义的几个标准属性,可参考官方文档            swagger      string      Required. Specifies the Swagger Specification version being used. It can be used by the Swagger UI and other clients to interpret the API listing. The value MUST be \"2.0\".                  info      Info Object      Required. Provides metadata about the API. The metadata can be used by the clients if needed.              host      string      The host (name or ip) serving the API. This MUST be the host only and does not include the scheme nor sub-paths. It MAY include a port. If the host is not included, the host serving the documentation is to be used (including the port). The host does not support path templating.              basePath      string      The base path on which the API is served, which is relative to the host. If it is not included, the API is served directly under the host. The value MUST start with a leading slash (/). The basePath does not support path templating.              schemes      [string]      The transfer protocol of the API. Values MUST be from the list: \"http\", \"https\", \"ws\", \"wss\". If the schemes is not included, the default scheme to be used is the one used to access the Swagger definition itself.              consumes      [string]      A list of MIME types the APIs can consume. This is global to all APIs but can be overridden on specific API calls. Value MUST be as described under Mime Types.              produces      [string]      A list of MIME types the APIs can produce. This is global to all APIs but can be overridden on specific API calls. Value MUST be as described under Mime Types.              paths      Paths Object      Required. The available paths and operations for the API.              definitions      Definitions Object      An object to hold data types produced and consumed by operations.              parameters      Parameters Definitions Object      An object to hold parameters that can be used across operations. This property does not define global parameters for all operations.              responses      Responses Definitions Object      An object to hold responses that can be used across operations. This property does not define global responses for all operations.              securityDefinitions      Security Definitions Object      Security scheme definitions that can be used across the specification.              security      [Security Requirement Object]      A declaration of which security schemes are applied for the API as a whole. The list of values describes alternative security schemes that can be used (that is, there is a logical OR between the security requirements). Individual operations can override this definition.              tags      [Tag Object]      A list of tags used by the specification with additional metadata. The order of the tags can be used to reflect on their order by the parsing tools. Not all tags that are used by the Operation Objectmust be declared. The tags that are not declared may be organized randomly or based on the tools’ logic. Each tag name in the list MUST be unique.              externalDocs      External Documentation Object      Additional external documentation.      在上面定义的标准字段中,最后一个是扩展对象,我们在Java对象中io.swagger.models.Swagger中可以看到他的定义public class Swagger {    protected String swagger = \"2.0\";    protected Info info;    protected String host;    protected String basePath;    protected List&lt;Tag&gt; tags;    protected List&lt;Scheme&gt; schemes;    protected List&lt;String&gt; consumes;    protected List&lt;String&gt; produces;    protected List&lt;SecurityRequirement&gt; security;    protected Map&lt;String, Path&gt; paths;    protected Map&lt;String, SecuritySchemeDefinition&gt; securityDefinitions;    protected Map&lt;String, Model&gt; definitions;    protected Map&lt;String, Parameter&gt; parameters;    protected Map&lt;String, Response&gt; responses;    protected ExternalDocs externalDocs;    //扩展属性    protected Map&lt;String, Object&gt; vendorExtensions;    //setter and getter}所以从上面的接口定义来看,我们最终可以来一一查看Swagger支持哪些对象进行自定义扩展属性Swagger根对象扩展在Swagger的根对象中,我们看到他是有vendorExtensions扩展属性的支持的，是一个散列的数据结构类型，这意味着我们可以在Swagger的根对象中添加多个扩展属性扩展属性名称的规则必须是以x-来开头，所有的都是这个规则            Field Pattern      Type      Description                  ^x-      Any      Allows extensions to the Swagger Schema. The field name MUST begin with x-, for example, x-internal-id. The value can be null, a primitive, an array or an object. See Vendor Extensions for further details.      看到此处,以前在swagger-bootstrap-ui的1.8.5版本中添加的扩展属性都是不规范的,因为没有应用swagger的标准规则，在后期的版本中要重写该规则实现所以,我们在Swagger根路径扩展的规则最终生成的JSON格式可能是这样：{    \"swagger\": \"2.0\",    \"info\": {        \"description\": \"&lt;div style='font-size:14px;color:red;'&gt;swagger-bootstrap-ui-demo RESTful APIs&lt;/div&gt;\",        \"version\": \"1.0\",        \"title\": \"swagger-bootstrap-ui很棒~~~！！！\",        \"termsOfService\": \"http://www.group.com/\",        \"contact\": {            \"name\": \"group@qq.com\"        }    },    \"host\": \"127.0.0.1:8999\",    \"basePath\": \"/\",    \"tags\": [        {            \"name\": \"1.8.2版本\",            \"description\": \"Api 182 Controller\"        }    ],    \"paths\": {        \"/2/api/new187/postRequest\": {            \"post\": {                \"tags\": [                    \"api-1871-controller\"                ],                \"summary\": \"版本2-post请求参数Hidden属性是否生效\",                \"operationId\": \"postRequestUsingPOST_1\",                \"consumes\": [                    \"application/json\"                ],                \"produces\": [                    \"*/*\"                ],                \"parameters\": [                    {                        \"in\": \"body\",                        \"name\": \"model187\",                        \"description\": \"model187\",                        \"required\": true,                        \"schema\": {                            \"originalRef\": \"Model187\",                            \"$ref\": \"#/definitions/Model187\"                        }                    }                ],                \"responses\": {                    \"200\": {                        \"description\": \"OK\",                        \"schema\": {                            \"originalRef\": \"Rest«Model187»\",                            \"$ref\": \"#/definitions/Rest«Model187»\"                        }                    },                    \"201\": {                        \"description\": \"Created\"                    },                    \"401\": {                        \"description\": \"Unauthorized\"                    },                    \"403\": {                        \"description\": \"Forbidden\"                    },                    \"404\": {                        \"description\": \"Not Found\"                    }                },                \"security\": [                    {                        \"BearerToken\": [                            \"global\"                        ]                    },                    {                        \"BearerToken1\": [                            \"global\"                        ]                    }                ],                \"deprecated\": false            }        }    },    \"securityDefinitions\": {        \"BearerToken\": {            \"type\": \"apiKey\",            \"name\": \"Authorization\",            \"in\": \"header\"        }    },    \"definitions\": {        \"AInfoVo\": {            \"type\": \"object\",            \"required\": [                \"aId\",                \"bList\"            ],            \"properties\": {                \"aId\": {                    \"type\": \"string\",                    \"description\": \"A记录主键\"                },                \"bList\": {                    \"type\": \"object\",                    \"description\": \"B信息Map, key为BInfoVo的主键pkId\",                    \"additionalProperties\": {                        \"originalRef\": \"BInfoVo\",                        \"$ref\": \"#/definitions/BInfoVo\"                    }                }            },            \"title\": \"AInfoVo\",            \"description\": \"A信息\"        },        \"ActInteger\": {            \"type\": \"object\",            \"properties\": {                \"doub1\": {                    \"type\": \"number\",                    \"format\": \"double\",                    \"description\": \"double类型属性\"                },                \"float1\": {                    \"type\": \"number\",                    \"format\": \"float\",                    \"description\": \"float类型属性\"                },                \"name\": {                    \"type\": \"string\"                },                \"number\": {                    \"type\": \"integer\",                    \"format\": \"int64\",                    \"description\": \"Long类型\"                },                \"price\": {                    \"type\": \"number\",                    \"description\": \"BigDecimal类型属性\"                },                \"sort\": {                    \"type\": \"integer\",                    \"format\": \"int32\",                    \"description\": \"int类型\"                }            },            \"title\": \"ActInteger\"        },        \"Actor\": {            \"type\": \"object\",            \"properties\": {                \"address\": {                    \"type\": \"string\"                },                \"deepOne\": {                    \"originalRef\": \"DeepOne\",                    \"$ref\": \"#/definitions/DeepOne\"                },                \"recipt\": {                    \"originalRef\": \"Recipt\",                    \"$ref\": \"#/definitions/Recipt\"                },                \"sort\": {                    \"type\": \"integer\",                    \"format\": \"int32\"                }            },            \"title\": \"Actor\"        }    },    \"x-description\":\"Swagger扩展属性之一Description\"}x-description属性就是我们扩展的标准的扩展属性，我们在Java代码中也可以这么来实现：Swagger swagger = mapper.mapDocumentation(documentation);swagger.setVendorExtension(\"x-description\",\"Swagger扩展属性之一Description\");path接口扩展同上面的规则,path中定义的属性，我们同样可以扩展我们的规则,此时我们的需求,根据接口来排序就可以通过path增加扩展属性来实现,比如我们给path添加一个扩展属性x-orderpath的JSON结构就可能如下：\"/2/api/new187/postRequest\": {    \"post\": {        \"tags\": [            \"api-1871-controller\"        ],        \"summary\": \"版本2-post请求参数Hidden属性是否生效\",        \"operationId\": \"postRequestUsingPOST_1\",        \"consumes\": [            \"application/json\"        ],        \"produces\": [            \"*/*\"        ],        \"parameters\": [            {                \"in\": \"body\",                \"name\": \"model187\",                \"description\": \"model187\",                \"required\": true,                \"schema\": {                    \"originalRef\": \"Model187\",                    \"$ref\": \"#/definitions/Model187\"                }            }        ],        \"responses\": {            \"200\": {                \"description\": \"OK\",                \"schema\": {                    \"originalRef\": \"Rest«Model187»\",                    \"$ref\": \"#/definitions/Rest«Model187»\"                }            },            \"201\": {                \"description\": \"Created\"            },            \"401\": {                \"description\": \"Unauthorized\"            },            \"403\": {                \"description\": \"Forbidden\"            },            \"404\": {                \"description\": \"Not Found\"            }        },        \"security\": [            {                \"BearerToken\": [                    \"global\"                ]            },            {                \"BearerToken1\": [                    \"global\"                ]            }        ],        \"deprecated\": false,        \"x-order\":\"1\"    }}moreswagger在Open API的规范文档中声明的是任意对象都可以有对象扩展,只要符合扩展规则即可(即扩展属性名称以x-开头)Springfox实现我们知道了扩展规则的定义,那么在Springfox中我们如何自定义实现呢?在前面的文章中,我们介绍了springfox使用了Spring Plugin系统来增强整个框架的可扩展性,我想此时的你应该能明白了，如果要扩展path接口的属性,那么，其实我们只需要找到Springfox提供的Plugin接口，然后增加一个Plugin的接口实现，把我们的扩展属性增加进去即可接下来,我们实现上面path接口的自定义x-order的属性扩展实现.我们先来看Springfox将自己的Documentation对象转换为Swagger标准对象的代码@Overridepublic Swagger mapDocumentation(Documentation from) {    if ( from == null ) {        return null;    }    Swagger swagger = new Swagger();    swagger.setVendorExtensions( vendorExtensionsMapper.mapExtensions( from.getVendorExtensions() ) );    swagger.setSchemes( mapSchemes( from.getSchemes() ) );    //path转换    swagger.setPaths( mapApiListings( from.getApiListings() ) );    swagger.setHost( from.getHost() );    swagger.setDefinitions( modelMapper.modelsFromApiListings( from.getApiListings() ) );    swagger.setSecurityDefinitions( securityMapper.toSecuritySchemeDefinitions( from.getResourceListing() ) );    ApiInfo info = fromResourceListingInfo( from );    if ( info != null ) {        swagger.setInfo( mapApiInfo( info ) );    }    swagger.setBasePath( from.getBasePath() );    swagger.setTags( tagSetToTagList( from.getTags() ) );    List&lt;String&gt; list2 = from.getConsumes();    if ( list2 != null ) {        swagger.setConsumes( new ArrayList&lt;String&gt;( list2 ) );    }    else {        swagger.setConsumes( null );    }    List&lt;String&gt; list3 = from.getProduces();    if ( list3 != null ) {        swagger.setProduces( new ArrayList&lt;String&gt;( list3 ) );    }    else {        swagger.setProduces( null );    }    return swagger;}既然我们的目标是path,那么来看mapApiListings方法protected Map&lt;String, Path&gt; mapApiListings(Multimap&lt;String, ApiListing&gt; apiListings) {    Map&lt;String, Path&gt; paths = newTreeMap();    for (ApiListing each : apiListings.values()) {      for (ApiDescription api : each.getApis()) {        paths.put(api.getPath(), mapOperations(api, Optional.fromNullable(paths.get(api.getPath()))));      }    }    return paths;  }程序的逻辑是：  声明一个map数组,key是接口路径,value是path对象  遍历springfox中的ApiListing集合对象(类似于controller)  遍历ApiDescription结合对象（类似于接口method）  最终拿到apiDescription的接口地址,将operation对象转换为path继续来看mapOperations方法private Path mapOperations(ApiDescription api, Optional&lt;Path&gt; existingPath) {    Path path = existingPath.or(new Path());    for (springfox.documentation.service.Operation each : nullToEmptyList(api.getOperations())) {      Operation operation = mapOperation(each);      path.set(each.getMethod().toString().toLowerCase(), operation);    }    return path;  }            循环遍历所有的Operation,此处为什么有循环,因为我们同一个接口允许存在不同的请求方式(GET      POST      PUT      DELETE…),但是请求体可以相同      @Overrideprotected io.swagger.models.Operation mapOperation(Operation from) {    if ( from == null ) {        return null;    }    io.swagger.models.Operation operation = new io.swagger.models.Operation();    operation.setSecurity( mapAuthorizations( from.getSecurityReferences() ) );    operation.setVendorExtensions( vendorExtensionsMapper.mapExtensions( from.getVendorExtensions() ) );看到mapOperation方法时,我们终于看到了setVendorExtensions的操作,即赋值扩展属性那么来看扩展属性是如何来实现的@Mapperpublic class VendorExtensionsMapper {  public Map&lt;String, Object&gt; mapExtensions(List&lt;VendorExtension&gt; from) {    Map&lt;String, Object&gt; extensions = newTreeMap();    Iterable&lt;ListVendorExtension&gt; listExtensions = from(from)        .filter(ListVendorExtension.class);    for (ListVendorExtension each : listExtensions) {      extensions.put(each.getName(), each.getValue());    }    Iterable&lt;Map&lt;String, Object&gt;&gt; objectExtensions = from(from)        .filter(ObjectVendorExtension.class)        .transform(toExtensionMap());    for (Map&lt;String, Object&gt; each : objectExtensions) {      extensions.putAll(each);    }    Iterable&lt;StringVendorExtension&gt; propertyExtensions = from(from)        .filter(StringVendorExtension.class);    for (StringVendorExtension each : propertyExtensions) {      extensions.put(each.getName(), each.getValue());    }    return extensions;  }通过VendorExtensionsMapper中的扩展属性方法,我们看到,springfox目前做了限制,因为VendorExtension是接口,我们可以有我们自己的定义实现,但是springfox最终会对扩展接口进行filter过滤,从代码中我们看到,springfox目前只允许三种扩展实现分别是：  ListVendorExtension:列表的形式,该对象支持泛型，最终形式：”x-field”:[{field:value}]  ObjectVendorExtension:对象的扩展形式,最终的扩展形式是：”x-field”:[{field:value}]  StringVendorExtension:string类型的扩展实现，最终的扩展形式是”x-field”:”value”既然springfox给我们提供了默认的三种扩展实现,那么针对上面的我们需要扩展path的扩展属性,我们使用StringVendorExtension:string这种类型即可针对path的operation操作，我们在前面也介绍过,springfox最终使用的是OperationBuilderPlugin接口那么我们只需要写一个OperationBuilderPluginPlugin接口的实现即可@Component@Order(Ordered.HIGHEST_PRECEDENCE+100)public class OperationPositionBulderPlugin implements OperationBuilderPlugin {    @Override    public void apply(OperationContext context) {        context.operationBuilder().extensions(Lists.newArrayList(new StringVendorExtension(\"x-order\",\"1\")));    }    @Override    public boolean supports(DocumentationType delimiter) {        return true;    }}目前假设我们给所有的接口都赋予扩展属性x-order,默认值为”1”此时,我们来看/v2/api-docs接口响应的JSON示例上图中,我们其实可以看到我们的自定义扩展属性实现了然后我们在结合我们自定义的swagger-bootstrap-ui前端UI渲染程序,把order字段作为path接口的排序字段，在页面进行排序显示,这样我们就实现了我们的接口自定义排序规则了有可能细心的朋友会问,我们给的order值都是1,如果给与开发者在代码中给接口自定义的值呢此时，有两种方式  基于swagger-bootstrap-ui提供的注解@ApiOperationSort进行获取  基于swagger的默认注解@ApiOperation中的postion属性进行二次利用此时,我们的接口代码可能会如下：@PostMapping(\"/createOr33der\")@ApiOperation(value = \"创建订单\",position = 2)public Rest&lt;Order&gt; createOrdetr(@RequestBody Order order,HttpSession httpSession){    Rest&lt;Order&gt; r=new Rest&lt;&gt;();    r.setData(order);    return r;}@PostMapping(\"/createOrder\")@ApiOperationSort(3)@ApiOperation(value = \"hash测试\",nickname = \"test\")public Rest&lt;Order&gt; createOrder(@RequestBody Order order){    Rest&lt;Order&gt; r=new Rest&lt;&gt;();    r.setData(order);    return r;}两种方式,取第一种即可这时,我们更改一下上面我们的Plugin接口实现@Overridepublic void apply(OperationContext context) {    int position=Integer.MAX_VALUE;    //首先查找ApiOperation注解    Optional&lt;ApiOperation&gt; api=context.findAnnotation(ApiOperation.class);    if (api.isPresent()){        //判断postion是否有值        int posit=api.get().position();        if (posit!=0){            position=posit;        }else{            Optional&lt;ApiOperationSort&gt; apiOperationSortOptional=context.findAnnotation(ApiOperationSort.class);            if (apiOperationSortOptional.isPresent()){                position=apiOperationSortOptional.get().value();            }        }    }else{        Optional&lt;ApiOperationSort&gt; apiOperationSortOptional=context.findAnnotation(ApiOperationSort.class);        if (apiOperationSortOptional.isPresent()){            position=apiOperationSortOptional.get().value();        }    }    context.operationBuilder().extensions(Lists.newArrayList(new StringVendorExtension(\"x-order\",String.valueOf(position))));}此时,我们再来看JSON效果此时,我们看到，我们的自定义属性已经出现了,而且是根据开发者自定义的实现,此时我们的目的也达到了."
  },
  
  {
    "title": "springfox 源码分析(十二) 遍历接口获取ApiDescription集合",
    "url": "/posts/springfox-12/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-28 00:00:00 +0800",
    





    
    "snippet": "ApiDescription是springfox提供的接口描述信息类,在springfox 源码分析(十) 遍历接口获取Model对象中我们拿到了接口的类型Model集合信息，但除了Model信息,接口还有更多的信息基础信息主要包括：接口路径、consumes、produces、参数、请求类型、描述、说明、响应状态码、是否过时、扩展信息、分组因为我们的接口可以运行多个请求类型的存在,所以以上...",
    "content": "ApiDescription是springfox提供的接口描述信息类,在springfox 源码分析(十) 遍历接口获取Model对象中我们拿到了接口的类型Model集合信息，但除了Model信息,接口还有更多的信息基础信息主要包括：接口路径、consumes、produces、参数、请求类型、描述、说明、响应状态码、是否过时、扩展信息、分组因为我们的接口可以运行多个请求类型的存在,所以以上信息在springfox是通过Operation来声明的先来看ApiDescription的源码public class ApiDescription {  //分组名称  private final String groupName;  //路径  private final String path;  //描述  private final String description;  //操作信息集合  //一个接口有可能存在多个请求方法类型,即：GET、POST、PUT、DELETE等,所以这里也是1：N的映射关系  private final List&lt;Operation&gt; operations;  //是否隐藏  private final Boolean hidden;    //getter and setters....}在代码注释中,我也做了说明因为一个接口有可能存在多个请求方法类型,即：GET、POST、PUT、DELETE等,所以这里也是1：N的映射关系，即存在多个Operation集合Operation的属性public class Operation {  //请求接口  private final HttpMethod method;  //接口名称  private final String summary;  //接口描述信息  private final String notes;  private final ModelReference responseModel;  //唯一id  private final String uniqueId;  private final int position;  //tags  private final Set&lt;String&gt; tags;  private final Set&lt;String&gt; produces;  private final Set&lt;String&gt; consumes;  private final Set&lt;String&gt; protocol;  //是否隐藏  private final boolean isHidden;  private final Map&lt;String, List&lt;AuthorizationScope&gt;&gt; securityReferences;  //参数  private final List&lt;Parameter&gt; parameters;  //状态码  private final Set&lt;ResponseMessage&gt; responseMessages;  //是否过时  private final String deprecated;  //扩展信息  private final List&lt;VendorExtension&gt; vendorExtensions;  //setter and getter..   }在Operation中声明的属性中就是我们上面介绍的接口相关信息.初始化我们知道了接口的介绍信息,此时,来看springfox如何处理，将接口的上下文信息最终初始化转换为ApiDescriptionApiDescriptionReader.read方法/*** * 获取ApiDescription接口集合信息 * @param outerContext * @return */public List&lt;ApiDescription&gt; read(RequestMappingContext outerContext) {  PatternsRequestCondition patternsCondition = outerContext.getPatternsCondition();  ApiSelector selector = outerContext.getDocumentationContext().getApiSelector();  List&lt;ApiDescription&gt; apiDescriptionList = newArrayList();  for (String path : matchingPaths(selector, patternsCondition)) {    String methodName = outerContext.getName();    try {      RequestMappingContext operationContext = outerContext.copyPatternUsing(path);\t//根据接口上下文获取Operation集合      List&lt;Operation&gt; operations = operationReader.read(operationContext);      if (operations.size() &gt; 0) {        operationContext.apiDescriptionBuilder()            .groupName(outerContext.getGroupName())            .operations(operations)            .pathDecorator(pluginsManager.decorator(new PathContext(outerContext, from(operations).first())))            .path(path)            .description(methodName)            .hidden(false);        ApiDescription apiDescription = operationContext.apiDescriptionBuilder().build();        lookup.add(outerContext.key(), apiDescription);        apiDescriptionList.add(apiDescription);      }    } catch (Error e) {      String contentMsg = \"Skipping process path[\" + path + \"], method[\" + methodName + \"] as it has an error.\";      log.error(contentMsg, e);    }  }  return apiDescriptionList;}核心操作是通过operationReader.read操作,获取Operation集合public List&lt;Operation&gt; read(RequestMappingContext outerContext) {    List&lt;Operation&gt; operations = newArrayList();\t\t    Set&lt;RequestMethod&gt; requestMethods = outerContext.getMethodsCondition();    Set&lt;RequestMethod&gt; supportedMethods = supportedMethods(requestMethods);    //Setup response message list    Integer currentCount = 0;    //遍历获取当前支持的接口类型    for (RequestMethod httpRequestMethod : supportedMethods) {      OperationContext operationContext = new OperationContext(new OperationBuilder(nameGenerator),          httpRequestMethod,          outerContext,          currentCount);\t\t//调用OperationPlugin插件，构造Operation对象      Operation operation = pluginsManager.operation(operationContext);        //添加      if (!operation.isHidden()) {        operations.add(operation);        currentCount++;      }    }    Collections.sort(operations, outerContext.operationOrdering());    return operations;  }主要的逻辑如下：                              获取当前支持的接口类型,包括GET          POST、PUT、DELETE等                      通过调用OperationPlugin的插件对Operation中的每个属性进行赋值操作,包括参数类型、描述、响应状态码等等信息OperationPlugin插件包含了多个实现类型，这个可以参考前面介绍的springfox 源码分析(五) web配置类Plugin插件的使用既然Operation提供了扩展参数,那么我们后面是可以进行添加自定义扩展的下一篇会介绍如何添加springfox的接口扩展字段."
  },
  
  {
    "title": "springfox 源码分析(十一) 自定义添加Swagger Models功能实现",
    "url": "/posts/springfox-11/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-27 00:00:00 +0800",
    





    
    "snippet": "在springfox 源码分析(十) 遍历接口获取Model对象这一篇中,我们其实已经大致了解了Springfox针对接口中涉及到的Model类进行解析初始化的过程在默认OperationModelsProviderPlugin插件中,collectGlobalModels收集全局Models的方法会将我们外部传入的Model添加到Springfox的集合中去,并且最终我们会在Swagger...",
    "content": "在springfox 源码分析(十) 遍历接口获取Model对象这一篇中,我们其实已经大致了解了Springfox针对接口中涉及到的Model类进行解析初始化的过程在默认OperationModelsProviderPlugin插件中,collectGlobalModels收集全局Models的方法会将我们外部传入的Model添加到Springfox的集合中去,并且最终我们会在Swagger的标准属性定义definitions中发现她那么我们既然知道了springfox的原理,我们知道springfox默认只会把接口中涉及的参数类、返回类、注解中定义的类这三类model添加到框架中有时,如果我们在程序框架中定义了一些公共的属性Models,但是并没有在接口中使用,此时springfox默认是不会加入的,那么我们应该通过何种方式,才能再swagger的ui界面中看到后端自定义的Model呢我们通过源码环节知道OperationModelsProviderPlugin最终获取全局参数Models是通过DocumentationContext对象来获取的,而在springfox 源码分析(七) 文档初始化-DocumentationContext这一节时,我们已经介绍了DocumentationContext的初始化过程我们只需要使用springfox为我们提供的Docket对象的方法就可以实现我们的自定义Models目前Docket对象提供了添加Model的方法，源码如下：/**   * Method to add additional models that are not part of any annotation or are perhaps implicit   *   * @param first     - at least one is required   * @param remaining - possible collection of more   * @return on-going docket   * @since 2.4.0   */public Docket additionalModels(ResolvedType first, ResolvedType... remaining) {    additionalModels.add(first);    additionalModels.addAll(newHashSet(remaining));    return this;}这是唯一的方法入口,ResolvedType是springfox默认使用的jackson提供的类,他是一个静态类那么,我们如何将Type类型转化为ResolvedType类型jackson也提供了一个类来进行转换,那就是com.fasterxml.classmate.TypeResolver并且该类springfox已经帮助我们注入到了Spring的容器中,具体代码如下：@Configuration@ComponentScan(basePackages = {    \"springfox.documentation.schema\"})@EnablePluginRegistries({    ModelBuilderPlugin.class,    ModelPropertyBuilderPlugin.class,    TypeNameProviderPlugin.class,    SyntheticModelProviderPlugin.class})public class ModelsConfiguration {  @Bean  public TypeResolver typeResolver() {    return new TypeResolver();  }}所以,在我们的SwaggerConfiguration配置文件中,只需要将TypeResolver通过注解注入即可使用了第一种方式在SwaggerConfiguration中引入TypeResolver@EnableSwagger2@EnableSwaggerBootstrapUI@Import(BeanValidatorPluginsConfiguration.class)public class SwaggerConfiguration {    private final TypeResolver typeResolver;    @Autowired    public SwaggerConfiguration(TypeResolver typeResolver) {        this.typeResolver = typeResolver;    }        在创建Docket对象时,调用additionalModels的方法,代码如下：@Bean(value = \"groupRestApi\")    @Order(value = 1)    public Docket groupRestApi() {        List&lt;ResolvedType&gt; list=Lists.newArrayList();        SpringAddtionalModel springAddtionalModel= springAddtionalModelService.scan(\"com.swagger.bootstrap.ui.demo.extend\");        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(groupApiInfo())                .groupName(\"分组接口\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.group\"))                .paths(PathSelectors.any())                .build()            //添加自定义Model类型                .additionalModels(typeResolver.resolve(DeveloperApiInfo.class))                .ignoredParameterTypes(HttpSession.class).extensions(Lists.newArrayList(new OrderExtensions(2))).securityContexts(Lists.newArrayList(securityContext(),securityContext1())).securitySchemes(Lists.&lt;SecurityScheme&gt;newArrayList(apiKey(),apiKey1()));    }这样我们在界面上就可以看见我们默认添加的Model了，效果：如果我们只是需要添加一个类的情况下,使用这种方式是最简洁的,假如我们有很多类的情况下,我们希望能够提供根据路径包扫描的方式来获取ResolvedType,那该如何做呢?此时,你可以使用第二种方式第二种方式在swagger-bootstrap-ui的1.9.4版本中,为Java开发者提供了公共api方法在SwaggerConfiguration配置文件中,可以引入swagger-bootstrap-ui提供的工具类@Configuration@EnableSwagger2@EnableSwaggerBootstrapUI@Import(BeanValidatorPluginsConfiguration.class)public class SwaggerConfiguration {    @Autowired    SpringAddtionalModelService springAddtionalModelService;    }注意：@EnableSwaggerBootstrapUI注解必须在配置类上引入,否则可能引起错误.然后使用springAddtionalModelService提供的scan方法进行包路径扫描，包路径可以是多个,以逗号分隔@Bean(value = \"groupRestApi\")@Order(value = 1)public Docket groupRestApi() {    List&lt;ResolvedType&gt; list=Lists.newArrayList();\t//扫描    SpringAddtionalModel springAddtionalModel= springAddtionalModelService.scan(\"com.swagger.bootstrap.ui.demo.extend\");    return new Docket(DocumentationType.SWAGGER_2)        .apiInfo(groupApiInfo())        .groupName(\"分组接口\")        .select()        .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.group\"))        .paths(PathSelectors.any())        .build()        .additionalModels(springAddtionalModel.getFirst(),springAddtionalModel.getRemaining())        .ignoredParameterTypes(HttpSession.class).extensions(Lists.newArrayList(new OrderExtensions(2))).securityContexts(Lists.newArrayList(securityContext(),securityContext1())).securitySchemes(Lists.&lt;SecurityScheme&gt;newArrayList(apiKey(),apiKey1()));}springAddtionalModelService最终扫描包路径生成SpringAddtionalModel对象，该对象源码：public class SpringAddtionalModel {    /***     * 第一个Type     */    private ResolvedType first;    /***     * 剩余     */    private List&lt;ResolvedType&gt; remaining=new ArrayList&lt;&gt;();    public ResolvedType[] getRemaining() {        if (!remaining.isEmpty()){            return remaining.toArray(new ResolvedType[]{});        }        return new ResolvedType[]{};    }    public ResolvedType getFirst() {        return first;    }    public void setFirst(ResolvedType first) {        this.first = first;    }    public void add(ResolvedType type){        remaining.add(type);    }}注意有两个属性,first和remaining的集合这也是配合Docket对象提供的additionalModels方法进行的简单封装,开发者扫描包路径后,会得到first以及remaining的集合"
  },
  
  {
    "title": "springfox 源码分析(十) 遍历接口获取Model对象",
    "url": "/posts/springfox-10/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-26 00:00:00 +0800",
    





    
    "snippet": "在上一篇中,我们了解到了springfox通过groupName的过滤,拿到了所有的接口,并且通过guava库的ArrayListMultimap对接口的Controller进一步进行了分组,接下来就是解析每个接口的操作了这篇主要介绍springfox解析每个接口中涉及的Model类操作,这其中包含：  参数中是Java Bean的参数类型  接口返回非void、基础类型的类型  在@Api...",
    "content": "在上一篇中,我们了解到了springfox通过groupName的过滤,拿到了所有的接口,并且通过guava库的ArrayListMultimap对接口的Controller进一步进行了分组,接下来就是解析每个接口的操作了这篇主要介绍springfox解析每个接口中涉及的Model类操作,这其中包含：  参数中是Java Bean的参数类型  接口返回非void、基础类型的类型  在@ApiResponse注解中标注返回的class类型目前主要有以上这三种类型,通过解析拿到接口涉及的Model类型,然后添加到一个Set集合中,该Set集合就对应了Swagger标准属性的definitions属性先来看遍历接口的代码：for (final ResourceGroup resourceGroup : sortedByName(allResourceGroups)) {  DocumentationContext documentationContext = context.getDocumentationContext();  Set&lt;String&gt; produces = new LinkedHashSet&lt;String&gt;(documentationContext.getProduces());  Set&lt;String&gt; consumes = new LinkedHashSet&lt;String&gt;(documentationContext.getConsumes());  String host = documentationContext.getHost();  Set&lt;String&gt; protocols = new LinkedHashSet&lt;String&gt;(documentationContext.getProtocols());  Set&lt;ApiDescription&gt; apiDescriptions = newHashSet();  Map&lt;String, Model&gt; models = new LinkedHashMap&lt;String, Model&gt;();  //得到该Controller下的所有接口  List&lt;RequestMappingContext&gt; requestMappings = nullToEmptyList(requestMappingsByResourceGroup.get(resourceGroup));  for (RequestMappingContext each : sortedByMethods(requestMappings)) {    //拿到该接口的所有Model    models.putAll(apiModelReader.read(each.withKnownModels(models)));    apiDescriptions.addAll(apiDescriptionReader.read(each));  }遍历RequestMappingContext对象,在前面我也已经介绍过,该对象其实就是每个接口实例对象最主要的是来看apiModelReader.read方法each.withKnownModels方法是通过new关键字复制了一个新的RequestMappingContextpublic RequestMappingContext withKnownModels(Map&lt;String, Model&gt; knownModels) {    return new RequestMappingContext(documentationContext, handler,                                     operationModelContextsBuilder, requestMappingPattern, knownModels);}来看读取接口Models的源码：/***   * 读取该接口Model信息   * @param context   * @return   */public Map&lt;String, Model&gt; read(RequestMappingContext context) {    //忽略的class集合，如果没有额外设置,则得到的是Defaults类中的默认忽略类Class集合    Set&lt;Class&gt; ignorableTypes = newHashSet(context.getIgnorableParameterTypes());    Set&lt;ModelContext&gt; modelContexts = pluginsManager.modelContexts(context);    Map&lt;String, Model&gt; modelMap = newHashMap(context.getModelMap());    for (ModelContext each : modelContexts) {        markIgnorablesAsHasSeen(typeResolver, ignorableTypes, each);        Optional&lt;Model&gt; pModel = modelProvider.modelFor(each);        if (pModel.isPresent()) {            LOG.debug(\"Generated parameter model id: {}, name: {}, schema: {} models\",                      pModel.get().getId(),                      pModel.get().getName());            mergeModelMap(modelMap, pModel.get());        } else {            LOG.debug(\"Did not find any parameter models for {}\", each.getType());        }        populateDependencies(each, modelMap);    }    return modelMap;}初步通过源码得知,要想先得到Model,则需要先构造得到ModelContext  初始化外部涉及到的忽略类型Set集合  读取RequestMappingContext，拿到ModelContext的Set集合  context中的ModelMap在此处其实是空对象，对应的modelMap也是空对象,这个在上面的withKnownModels方法中我们可以观察到  遍历ModelContext的Set集合,通过modelProvider.modelFor的方法由ModelContext转换构造成目标Model对象ModelContext在初始化ModelContext集合之前,我们先来看看ModelContext的属性public class ModelContext {    //类型  private final Type type;    //是否返回类型  private final boolean returnType;    //分组名称  private final String groupName;    //文档类型  private final DocumentationType documentationType;  //父级  private final ModelContext parentContext;    //ResolvedType  private final Set&lt;ResolvedType&gt; seenTypes = newHashSet();    //model构造器  private final ModelBuilder modelBuilder;  private final AlternateTypeProvider alternateTypeProvider;    //名称策略  private final GenericTypeNamingStrategy genericNamingStrategy;    //忽略类型  private final ImmutableSet&lt;Class&gt; ignorableTypes;  private ModelContext(      String groupName,      Type type,      boolean returnType,      DocumentationType documentationType,      AlternateTypeProvider alternateTypeProvider,      GenericTypeNamingStrategy genericNamingStrategy,      ImmutableSet&lt;Class&gt; ignorableTypes) {    this.groupName = groupName;    this.documentationType = documentationType;    this.alternateTypeProvider = alternateTypeProvider;    this.genericNamingStrategy = genericNamingStrategy;    this.ignorableTypes = ignorableTypes;    this.parentContext = null;    this.type = type;    this.returnType = returnType;    this.modelBuilder = new ModelBuilder();  } //...   }参数对象全部是final关键字修饰初始化ModelContext Set集合先来看pluginsManager.modelContexts方法中的初始化操作public Set&lt;ModelContext&gt; modelContexts(RequestMappingContext context) {    DocumentationType documentationType = context.getDocumentationContext().getDocumentationType();    //构建该接口的ModelContext集合    for (OperationModelsProviderPlugin each : operationModelsProviders.getPluginsFor(documentationType)) {      each.apply(context);    }    return context.operationModelsBuilder().build();  }通过文档类型,获取Model的OperationModelsProviderPlugin插件实现类，然后调用apply方法初始化OperationModelsProviderPlugin主要有两个实现类，分别是：  OperationModelsProviderPlugin：处理返回类型、参数类型等  SwaggerOperationModelsProvider：处理swagger注解提供的值类型,主要包括@ApiResponse、@ApiOperationOperationModelsProviderPlugin先来看常规类型@Component@Order(Ordered.HIGHEST_PRECEDENCE)public class OperationModelsProvider implements OperationModelsProviderPlugin {  private static final Logger LOG = LoggerFactory.getLogger(OperationModelsProvider.class);  private final TypeResolver typeResolver;  @Autowired  public OperationModelsProvider(TypeResolver typeResolver) {    this.typeResolver = typeResolver;  }  @Override  public void apply(RequestMappingContext context) {    collectFromReturnType(context);    collectParameters(context);    collectGlobalModels(context);  }    }常规Model插件的apply方法主要有三个方法collectFromReturnType收集接口返回类型,跟踪源码;private void collectFromReturnType(RequestMappingContext context) {    ResolvedType modelType = context.getReturnType();    modelType = context.alternateFor(modelType);    LOG.debug(\"Adding return parameter of type {}\", resolvedTypeSignature(modelType).or(\"&lt;null&gt;\"));    context.operationModelsBuilder().addReturn(modelType);  }直接拿到接口的返回类型,这个返回类型在前面接口初始化时,已经初始化，getReturnType方法实际调用的是RequestHandler的方法public ResolvedType getReturnType() {    return handler.getReturnType();}我们在前面也介绍过，RequestHander因为是接口，在springfox中的实现类是WebMvcRequestHandler拿到返回类型,最终嗲用addReturn方法添加到context对象中的全局Set对象中collectParameters收集接口中的参数类型private void collectParameters(RequestMappingContext context) {    LOG.debug(\"Reading parameters models for handlerMethod |{}|\", context.getName());    List&lt;ResolvedMethodParameter&gt; parameterTypes = context.getParameters();    for (ResolvedMethodParameter parameterType : parameterTypes) {        if (parameterType.hasParameterAnnotation(RequestBody.class)            || parameterType.hasParameterAnnotation(RequestPart.class)) {          ResolvedType modelType = context.alternateFor(parameterType.getParameterType());          LOG.debug(\"Adding input parameter of type {}\", resolvedTypeSignature(modelType).or(\"&lt;null&gt;\"));          context.operationModelsBuilder().addInputParam(modelType);        }    }    LOG.debug(\"Finished reading parameters models for handlerMethod |{}|\", context.getName());  }接口参数类型中,springfox目前只解析两种  一种是实体类通过Spring的@RequestBody注解标注的,我们在使用Spring开发的时候如果使用该注解通常是使用的JSON作为接口的交互格式  通过Spring的@ReuqestPart注解标注的参数类型，@RequestPart注解是配合文件上传时附属参数类型使用的注解collectGlobalModels收集接口的全局Modelprivate void collectGlobalModels(RequestMappingContext context) {    for (ResolvedType each : context.getAdditionalModels()) {        context.operationModelsBuilder().addInputParam(each);        context.operationModelsBuilder().addReturn(each);    }}收集外部全局添加的Model,添加进入集合中SwaggerOperationModelsProvider基于Swagger相关注解赋值的类型Class解析@Component@Order(SwaggerPluginSupport.SWAGGER_PLUGIN_ORDER)public class SwaggerOperationModelsProvider implements OperationModelsProviderPlugin {  private static final Logger LOG = LoggerFactory.getLogger(SwaggerOperationModelsProvider.class);  private final TypeResolver typeResolver;  @Autowired  public SwaggerOperationModelsProvider(TypeResolver typeResolver) {    this.typeResolver = typeResolver;  }  @Override  public void apply(RequestMappingContext context) {    collectFromApiOperation(context);    collectApiResponses(context);  }}主要有两种类型：收集使用@ApiOperation注解时,使用主句的属性值收集@ApiResponse响应状态码涉及到的ModelcollectFromApiOperationprivate void collectFromApiOperation(RequestMappingContext context) {    ResolvedType returnType = context.getReturnType();    returnType = context.alternateFor(returnType);    Optional&lt;ResolvedType&gt; returnParameter = context.findAnnotation(ApiOperation.class)        .transform(resolvedTypeFromOperation(typeResolver, returnType));    if (returnParameter.isPresent() &amp;&amp; returnParameter.get() != returnType) {      LOG.debug(\"Adding return parameter of type {}\", resolvedTypeSignature(returnParameter.get()).or(\"&lt;null&gt;\"));      context.operationModelsBuilder().addReturn(returnParameter.get());    }  }查找注解,获取ResolvedType的值核心是拿到ApiOeration注解的response-class属性值@VisibleForTestingstatic ResolvedType getResolvedType(    ApiOperation annotation,    TypeResolver resolver,    ResolvedType defaultType) {    if (null != annotation) {        Class&lt;?&gt; response = annotation.response();        String responseContainer = annotation.responseContainer();        if (resolvedType(resolver, response, responseContainer).isPresent()) {            return resolvedType(resolver, response, responseContainer).get();        }    }    return defaultType;}collectApiResponses收集在接口上标注状态码涉及的Class类，ApiResponses是集合，最终遍历得到ApiResponseprivate void collectApiResponses(RequestMappingContext context) {  List&lt;ApiResponses&gt; allApiResponses = context.findAnnotations(ApiResponses.class);  LOG.debug(\"Reading parameters models for handlerMethod |{}|\", context.getName());  Set&lt;ResolvedType&gt; seenTypes = newHashSet();  for (ApiResponses apiResponses : allApiResponses) {    List&lt;ResolvedType&gt; modelTypes = toResolvedTypes(context).apply(apiResponses);    for (ResolvedType modelType : modelTypes) {      if (!seenTypes.contains(modelType)) {        seenTypes.add(modelType);        context.operationModelsBuilder().addReturn(modelType);      }    }  }}ModelContext初始化我们通过TypeResolved方法将基础的Class转换为ResolvedType此时ModelContext提供了几个方法将ResolvedType转换为ModelContext类型  returnValue:提供返回的class  inputParam:参数类的方法通过OperationModelContextsBuilder提供的默认参数,构造函数默认构造出ModelContext对象/**   * Convenience method to provide an new context for an input parameter   *   * @param group                 - group name of the docket   * @param type                  - type   * @param documentationType     - for documentation type   * @param alternateTypeProvider - alternate type provider   * @param genericNamingStrategy - how generic types should be named   * @param ignorableTypes        - types that can be ignored   * @return new context   */public static ModelContext inputParam(    String group,    Type type,    DocumentationType documentationType,    AlternateTypeProvider alternateTypeProvider,    GenericTypeNamingStrategy genericNamingStrategy,    ImmutableSet&lt;Class&gt; ignorableTypes) {    return new ModelContext(        group,        type,        false,        documentationType,        alternateTypeProvider,        genericNamingStrategy,        ignorableTypes);}ModelContext转化为ModelSet&lt;ModelContext&gt; modelContexts = pluginsManager.modelContexts(context);Map&lt;String, Model&gt; modelMap = newHashMap(context.getModelMap());for (ModelContext each : modelContexts) {    //添加基础忽略类型的ResolvedType类型    markIgnorablesAsHasSeen(typeResolver, ignorableTypes, each);    //通过modelProvider获取到Model类型,modelProvider是接口,有两个实现类    //DefaultModelProvider:默认装换    //CachingModelProvider:缓存    Optional&lt;Model&gt; pModel = modelProvider.modelFor(each);    if (pModel.isPresent()) {        LOG.debug(\"Generated parameter model id: {}, name: {}, schema: {} models\",                  pModel.get().getId(),                  pModel.get().getName());        mergeModelMap(modelMap, pModel.get());    } else {        LOG.debug(\"Did not find any parameter models for {}\", each.getType());    }    populateDependencies(each, modelMap);}通过modelProvider将ModelContext转换为Model类型modelProvider是接口,有两个实现类：  DefaultModelProvider:默认装换,每次都会将modelContext转换为model  CachingModelProvider:声明了一个guava的缓存池,先从缓存池获取,如果没有，则调用默认的处理器,转换为model，然后放入缓存池中此处modelProvider使用的是caching缓存配置初次通过modelFor获取是为空的,所以接下来看populateDependencies方法private void populateDependencies(ModelContext modelContext, Map&lt;String, Model&gt; modelMap) {    Map&lt;String, Model&gt; dependencies = modelProvider.dependencies(modelContext);    for (Model each : dependencies.values()) {        mergeModelMap(modelMap, each);    }}caching默认是依赖default的，此处dependencies实际是调用的default的@Overridepublic Map&lt;String, Model&gt; dependencies(ModelContext modelContext) {    Map&lt;String, Model&gt; models = newHashMap();    for (ResolvedType resolvedType : dependencyProvider.dependentModels(modelContext)) {        ModelContext parentContext = ModelContext.fromParent(modelContext, resolvedType);        Optional&lt;Model&gt; model = modelFor(parentContext).or(mapModel(parentContext, resolvedType));        if (model.isPresent()) {            models.put(model.get().getName(), model.get());        }    }    return models;}dependencyProvider和modelProvider是同一个策略，默认接口，有两个实现类,一个是cache，一个是default所以我们默认来看default的即可@Overridepublic Set&lt;ResolvedType&gt; dependentModels(ModelContext modelContext) {    return concat(from(resolvedDependencies(modelContext))                  .filter(ignorableTypes(modelContext))                  .filter(not(baseTypes(modelContext))),                  schemaPluginsManager.dependencies(modelContext))        .toSet();}在默认配置中,最终是通过schemaPluginsManager的方法来解决ModelContext的转换最终是通过SyntheticModelProviderPlugin来转换,但是springfox中他没有实现类,所以此处的Plugin是空的，不存在所以此处的dependentModels返回的Set集合是空的再来看resolvedDependencies的方法private List&lt;ResolvedType&gt; resolvedDependencies(ModelContext modelContext) {    ResolvedType resolvedType = modelContext.alternateFor(modelContext.resolvedType(typeResolver));    if (isBaseType(ModelContext.fromParent(modelContext, resolvedType))) {      LOG.debug(\"Marking base type {} as seen\", resolvedType.getSignature());      modelContext.seen(resolvedType);      return newArrayList();    }    List&lt;ResolvedType&gt; dependencies = newArrayList(resolvedTypeParameters(modelContext, resolvedType));    dependencies.addAll(resolvedArrayElementType(modelContext, resolvedType));    dependencies.addAll(resolvedMapType(modelContext, resolvedType));    dependencies.addAll(resolvedPropertiesAndFields(modelContext, resolvedType));    dependencies.addAll(resolvedSubclasses(resolvedType));    return dependencies;  }从代码中我们能看到：  首先因为ModelContext中属性是包含type的，所以默认拿到ResolvedType  通过拿到参数类型得到ResolvedType集合，如果有父类则递归调用.最终通过反射的方式拿到Model类型private Optional&lt;Model&gt; reflectionBasedModel(ModelContext modelContext, ResolvedType propertiesHost) {    ImmutableMap&lt;String, ModelProperty&gt; propertiesIndex        = uniqueIndex(properties(modelContext, propertiesHost), byPropertyName());    LOG.debug(\"Inferred {} properties. Properties found {}\", propertiesIndex.size(),              Joiner.on(\", \").join(propertiesIndex.keySet()));    Map&lt;String, ModelProperty&gt; properties = newTreeMap();    properties.putAll(propertiesIndex);    return Optional.of(modelBuilder(propertiesHost, properties, modelContext));}private Model modelBuilder(ResolvedType propertiesHost,                           Map&lt;String, ModelProperty&gt; properties,                           ModelContext modelContext) {    String typeName = typeNameExtractor.typeName(ModelContext.fromParent(modelContext, propertiesHost));    modelContext.getBuilder()        .id(typeName)        .type(propertiesHost)        .name(typeName)        .qualifiedType(simpleQualifiedTypeName(propertiesHost))        .properties(properties)        .description(\"\")        .baseModel(\"\")        .discriminator(\"\")        .subTypes(new ArrayList&lt;ModelReference&gt;());    return schemaPluginsManager.model(modelContext);}构造Model的基础属性，包括类型，名称、描述、属性等信息private List&lt;ModelProperty&gt; propertiesFor(ResolvedType type, ModelContext givenContext, String namePrefix) {    List&lt;ModelProperty&gt; properties = newArrayList();    BeanDescription beanDescription = beanDescription(type, givenContext);    Map&lt;String, BeanPropertyDefinition&gt; propertyLookup = uniqueIndex(beanDescription.findProperties(),        BeanPropertyDefinitions.beanPropertyByInternalName());    for (Map.Entry&lt;String, BeanPropertyDefinition&gt; each : propertyLookup.entrySet()) {      LOG.debug(\"Reading property {}\", each.getKey());      BeanPropertyDefinition jacksonProperty = each.getValue();      Optional&lt;AnnotatedMember&gt; annotatedMember          = Optional.fromNullable(safeGetPrimaryMember(jacksonProperty));      if (annotatedMember.isPresent()) {        properties.addAll(candidateProperties(type, annotatedMember.get(), jacksonProperty, givenContext, namePrefix));      }    }    return FluentIterable.from(properties).toSortedSet(byPropertyName()).asList();  }获取属性集合配置的代码总结通过源码的一些研究,springfox主要的处理流程：  收集该接口的参数类型Model  收集@ApiOperation注解的response类型Model  收集全局Model  收集接口返回类型Model  收集接口主键@ApiResponses状态码涉及的类型Model  在收集过程中使用了缓存策略,这样能提高解析效率"
  },
  
  {
    "title": "springfox 源码分析(九) 文档初始化-分组",
    "url": "/posts/springfox-9/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-25 00:00:00 +0800",
    





    
    "snippet": "在前面我们了解了DocumennationContext的初始化过程,包括一系列的默认属性的赋值,接下来,开始真正的文档解析操作我们的源码分析方式是按照springfox的文档初始化来进行归纳的,所以也是看到哪儿,就写到哪儿,当我们整个过程都研究完后,我会总结一篇文章来统一说明springfox的整个流程说明，或许以图文的方式来配合说明更能加深我们的印象.我们在前面的初始化过程中,sprin...",
    "content": "在前面我们了解了DocumennationContext的初始化过程,包括一系列的默认属性的赋值,接下来,开始真正的文档解析操作我们的源码分析方式是按照springfox的文档初始化来进行归纳的,所以也是看到哪儿,就写到哪儿,当我们整个过程都研究完后,我会总结一篇文章来统一说明springfox的整个流程说明，或许以图文的方式来配合说明更能加深我们的印象.我们在前面的初始化过程中,springfox将Spring环境中所有的接口都转换成了WebMvcRequestHandler,但是我们在外部创建Docket对象是对整个系统的接口文档来分组的,所以接下来需要对所有的接口进行分组(根据Docket对象传入的接口Selector来分).先来看scan方法 /***   * 最终生成Documentation文档对象   * @param context   * @return   */public Documentation scan(DocumentationContext context) {    //得到分组接口    ApiListingReferenceScanResult result = apiListingReferenceScanner.scan(context);\t//more...}通过DocumentationContext对象创建ApiListingReferenceScanResult对象而ApiListingReferenceScanResult类只有一个属性,那就是根据controller分组后的接口方法public class ApiListingReferenceScanResult {  //分组  private final Map&lt;ResourceGroup, List&lt;RequestMappingContext&gt;&gt; resourceGroupRequestMappings;  public ApiListingReferenceScanResult(Map&lt;ResourceGroup, List&lt;RequestMappingContext&gt;&gt; resourceGroupRequestMappings) {    this.resourceGroupRequestMappings = resourceGroupRequestMappings;  }  public Map&lt;ResourceGroup, List&lt;RequestMappingContext&gt;&gt; getResourceGroupRequestMappings() {\t\t\t        return resourceGroupRequestMappings;  }}继续来看apiListingReferenceScanner对象的scan方法public ApiListingReferenceScanResult scan(DocumentationContext context) {    LOG.info(\"Scanning for api listing references\");    ArrayListMultimap&lt;ResourceGroup, RequestMappingContext&gt; resourceGroupRequestMappings        = ArrayListMultimap.create();    //拿到外部的接口选择器    //通常我们在创建Docket对象时,会赋予接口选择器,一般是以包路径来区分    ApiSelector selector = context.getApiSelector();    //过滤筛选    //如果是以package路径来区分的,则会根据接口的Handler的包路径是否已packagePath开始来进行匹配    //如果是以注解的方式,则会判断handler是否包含annotation注解    Iterable&lt;RequestHandler&gt; matchingHandlers = from(context.getRequestHandlers())        .filter(selector.getRequestHandlerSelector());    //    for (RequestHandler handler : matchingHandlers) {      //接口分组      //我们在一个Controller中会存在1个或多个接口方法      //所以resourceGroup和RequestMapping的关系是1:N      ResourceGroup resourceGroup = new ResourceGroup(          handler.groupName(),          handler.declaringClass(),          0);      //构建RequestMappingContext对象      RequestMappingContext requestMappingContext          = new RequestMappingContext(context, handler);      resourceGroupRequestMappings.put(resourceGroup, requestMappingContext);    }    return new ApiListingReferenceScanResult(asMap(resourceGroupRequestMappings));  }从代码流程中,我们得知：  首先获取外部Docket对象的ApiSelector选择器，该选择器我们一般选择的是包路径  根据选择的规则进行接口过滤,此处会排除掉部分不符合规则的RequestHandler接口,通常是以package路径或者注解的方式，如果默认没有提供规则,那么springfox会根据在controller类上和方法上都没有标注@ApiIgnore注解的默认ApiSelctor来进行筛选  最后通过ArrayListMultimap来进行接口的归类操作  关于ArrayListMultimap的操作可参考springfox 源码分析(十九) guava库学习来了解"
  },
  
  {
    "title": "springfox 源码分析(八) 遍历接口获取Model对象",
    "url": "/posts/springfox-8/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-24 00:00:00 +0800",
    





    
    "snippet": "我们通过读DocumentationPluginsBootstrapper代码中的start方法,了解到springfox根据我们外部提供的Docket对象进行初始化时,会通过Docket对象构建DocumentationContext对象来进行初始化操作private DocumentationContext buildContext(DocumentationPlugin each) {...",
    "content": "我们通过读DocumentationPluginsBootstrapper代码中的start方法,了解到springfox根据我们外部提供的Docket对象进行初始化时,会通过Docket对象构建DocumentationContext对象来进行初始化操作private DocumentationContext buildContext(DocumentationPlugin each) {    return each.configure(defaultContextBuilder(each));}BuildContext方法是通过Docket对象来构建最终的DocumentaionContext对象所以我们在研究Documentation之前,先来看DocumentationContext对象主要是包含哪些属性和方法先来看DocumentationContext的源码：public class DocumentationContext {  //文档类型  private final DocumentationType documentationType;  //请求接口  private final List&lt;RequestHandler&gt; handlerMappings;  //接口信息，包括title、描述等信息  private final ApiInfo apiInfo;  //分组名称  private final String groupName;  //接口选择器  private final ApiSelector apiSelector;  private final AlternateTypeProvider alternateTypeProvider;  //忽略的参数类型  private final Set&lt;Class&gt; ignorableParameterTypes;  //请求方法对应的响应状态码信息  private final Map&lt;RequestMethod, List&lt;ResponseMessage&gt;&gt; globalResponseMessages;  //全局参数  private final List&lt;Parameter&gt; globalOperationParameters;  //分组策略  private final ResourceGroupingStrategy resourceGroupingStrategy;  //路径Provider  private final PathProvider pathProvider;  //安全信息  private final List&lt;SecurityContext&gt; securityContexts;  //安全Scheme  private final List&lt;? extends SecurityScheme&gt; securitySchemes;  //接口信息  private final Ordering&lt;ApiListingReference&gt; listingReferenceOrdering;  //接口描述  private final Ordering&lt;ApiDescription&gt; apiDescriptionOrdering;  //接口信息  private final Ordering&lt;Operation&gt; operationOrdering;  private final GenericTypeNamingStrategy genericsNamingStrategy;  private final Optional&lt;String&gt; pathMapping;  private final Set&lt;ResolvedType&gt; additionalModels;  //tag分组标签  private final Set&lt;Tag&gt; tags;  private Set&lt;String&gt; produces;  private Set&lt;String&gt; consumes;  //主机号  private String host;  //协议  private Set&lt;String&gt; protocols;  private boolean isUriTemplatesEnabled;  //扩展属性  private List&lt;VendorExtension&gt; vendorExtensions;  //getter and setter and constructor}我们姑且称他为文档上下文环境吧,springfox是通过文档上下文(DocumentationContext)最终构建真正的Documenation对象,然后缓存在内存中,最终通过接口/v2/api-docs将Documentation对象转换为标准的Swagger对象输出.DocumentationContextBuilder在springfox的源码中,大量的使用了Builder构造器来进行目标对象的构建,所以文档上下文也一样,最终通过DocumentaionContextBuilder来构造创建DocumentationPlugin中提供了根据DocumentationContextBuilder来创建DocumenationContext的方法public interface DocumentationPlugin extends Plugin&lt;DocumentationType&gt; {  /**   * Creates a documentation context based on a given DocumentationContextBuilder   *   * @param builder - @see springfox.documentation.spi.service.contexts.DocumentationContextBuilder   * @return context to use for building the documentation   */  DocumentationContext configure(DocumentationContextBuilder builder);    }源码根据DocumentaionPlugin对象来构建Builderpublic class DocumentationContextBuilder {  //安全参数  private final List&lt;SecurityContext&gt; securityContexts = newArrayList();  //忽律类型  private final Set&lt;Class&gt; ignorableParameterTypes = newHashSet();  //接口响应状态码  private final Map&lt;RequestMethod, List&lt;ResponseMessage&gt;&gt; responseMessageOverrides = newTreeMap();  //全局参数  private final List&lt;Parameter&gt; globalOperationParameters = newArrayList();  //类型规则  private final List&lt;AlternateTypeRule&gt; rules = newArrayList();  //默认接口状态响应吗  private final Map&lt;RequestMethod, List&lt;ResponseMessage&gt;&gt; defaultResponseMessages = newHashMap();  //protocols  private final Set&lt;String&gt; protocols = newHashSet();  private final Set&lt;String&gt; produces = newHashSet();  private final Set&lt;String&gt; consumes = newHashSet();  //扩展类型  private final Set&lt;ResolvedType&gt; additionalModels = newHashSet();  //分组tag  private final Set&lt;Tag&gt; tags = newTreeSet(Tags.tagComparator());  //扩展属性  private List&lt;VendorExtension&gt; vendorExtensions = new ArrayList&lt;VendorExtension&gt;();  //类型处理器  private TypeResolver typeResolver;  //接口集合  private List&lt;RequestHandler&gt; handlerMappings;  //接口信息  private ApiInfo apiInfo;  //分组名称  private String groupName;  //资源分组策略  private ResourceGroupingStrategy resourceGroupingStrategy;  //路径处理  private PathProvider pathProvider;  private List&lt;? extends SecurityScheme&gt; securitySchemes;  private Ordering&lt;ApiListingReference&gt; listingReferenceOrdering;  private Ordering&lt;ApiDescription&gt; apiDescriptionOrdering;  //swagger文档类型  private DocumentationType documentationType;  private Ordering&lt;Operation&gt; operationOrdering;  private boolean applyDefaultResponseMessages;  //接口选择器  private ApiSelector apiSelector = ApiSelector.DEFAULT;  //主机  private String host;  //默认类型名称策略  private GenericTypeNamingStrategy genericsNamingStrategy;  //接口路径映射  private Optional&lt;String&gt; pathMapping;    private boolean isUrlTemplatesEnabled;}DocumentationContextBuilder基本覆盖了DocumentationContext的所有属性,而DocumentationContextBuilder没有提供构造函数来实例化参数，只提供了一个构造函数(文档类型),其余参数都是通过Builder构造器模式来赋值属性,最终通过Builder()方法来构建输出DocumentaionContext构造函数public DocumentationContextBuilder(DocumentationType documentationType) {    this.documentationType = documentationType;}赋值属性public DocumentationContextBuilder requestHandlers(List&lt;RequestHandler&gt; handlerMappings) {    this.handlerMappings = handlerMappings;    return this;}//more...通过返回this对象的方式,提供了很多属性的赋值方法build构造public DocumentationContext build() {    Map&lt;RequestMethod, List&lt;ResponseMessage&gt;&gt; responseMessages = aggregateResponseMessages();    OrderComparator.sort(rules);    return new DocumentationContext(documentationType,        handlerMappings,        apiInfo,        groupName,        apiSelector,        ignorableParameterTypes,        responseMessages,        globalOperationParameters,        resourceGroupingStrategy,        pathProvider,        securityContexts,        securitySchemes,        rules,        listingReferenceOrdering,        apiDescriptionOrdering,        operationOrdering,        produces,        consumes,        host,        protocols,        genericsNamingStrategy,        pathMapping,        isUrlTemplatesEnabled,        additionalModels,        tags,        vendorExtensions);  }最终通过使用build()方法,调用DocumentationContext的构造函数,构建DocumentationContext对象构造所以,我们先来看DocumentationContextBuilder对象的创建,主要包含了那些参数、方法/***   * 构建文档builder   * @param plugin   * @return   */  private DocumentationContextBuilder defaultContextBuilder(DocumentationPlugin plugin) {    DocumentationType documentationType = plugin.getDocumentationType();    //获取RequestHandler    //疑问：handlerProviders在何时初始化    List&lt;RequestHandler&gt; requestHandlers = from(handlerProviders)        .transformAndConcat(handlers())        .toList();    List&lt;AlternateTypeRule&gt; rules = from(nullToEmptyList(typeConventions))          .transformAndConcat(toRules())          .toList();    return documentationPluginsManager        .createContextBuilder(documentationType, defaultConfiguration)        .rules(rules)        .requestHandlers(combiner().combine(requestHandlers));  }通过代码我们可以了解到：  首先获取所有的RequestHnadler，而RequestHandlerProvider的默认实现类是WebMvcRequestHandlerProvider,该实现类会接收Spring中的所有请求Mapping，最终转化为WebMvcRequestHandler,WebMvcRequestHandler是接口RequestHnadler的实现，这等于是拿到了所有的接口  获取AlternateTypeRule的规则列表  初始化创建Builder,赋值请求接口、rules了解了DocumentationContextBuilder的构造方式,在来看他的创建过程通过代码知道是通过DocumentationPluginsManager的createContextBuilder方法来构建public DocumentationContextBuilder createContextBuilder(    DocumentationType documentationType,    DefaultConfiguration defaultConfiguration) {    return defaultsProviders.getPluginFor(documentationType, defaultConfiguration)        .create(documentationType)        .withResourceGroupingStrategy(resourceGroupingStrategy(documentationType));}defaultsProviders是也是一个Plugin接口,但是我们在前面章节也介绍说过,他只有一个实现类DefaultConfiguration,但是该实现类并没有通过@Compoent注解注入到Spring的容器中,所以此处通过Plugin的实现给了一个默认值defaultConfiguration，其实,此处就是使用的defaultConfiguration那么该默认配置的create方法做了那些操作呢?,继续跟踪代码：public class DefaultConfiguration implements DefaultsProviderPlugin {    private final Defaults defaults;    private final TypeResolver typeResolver;    private final ServletContext servletContext;    public DefaultConfiguration(Defaults defaults,                                TypeResolver typeResolver,                                ServletContext servletContext) {        this.servletContext = servletContext;        this.defaults = defaults;        this.typeResolver = typeResolver;    }    @Override    public DocumentationContextBuilder create(DocumentationType documentationType) {        return new DocumentationContextBuilder(documentationType)            .operationOrdering(defaults.operationOrdering())            .apiDescriptionOrdering(defaults.apiDescriptionOrdering())            .apiListingReferenceOrdering(defaults.apiListingReferenceOrdering())            .additionalIgnorableTypes(defaults.defaultIgnorableParameterTypes())            .rules(defaults.defaultRules(typeResolver))            .defaultResponseMessages(defaults.defaultResponseMessages())            .pathProvider(new RelativePathProvider(servletContext))            .typeResolver(typeResolver)            .enableUrlTemplating(false)            .selector(ApiSelector.DEFAULT);    }}主要是给DocumentationContextBuilder赋值了默认的相关参数，主要包括：  默认忽略Class类型  默认响应状态码消息  类型解析器  接口选择器  接口排序  …通过上面源码我们知道：      首先defaultsProviders是也是一个Plugin接口,但是我们在前面章节也介绍说过,他只有一个实现类DefaultConfiguration,但是该实现类并没有通过@Compoent注解注入到Spring的容器中,所以此处通过Plugin的实现给了一个默认值defaultConfiguration，其实,此处就是使用的defaultConfiguration        defaultConfiguration是在DocumentationPluginsBootstrapper的构造函数中通过new的方式进行构造的        //通过DefaultConfiguration可以构建DocumentationContextBuilderthis.defaultConfiguration = new DefaultConfiguration(defaults, typeResolver, servletContext);        在此处的构建过程中，赋值了资源分组策略.赋值从源码过程中,我们已经了解到Builder赋值的参数主要包括：  Spring环境中的所有接口,最终是RequestHandler的集合，实际则是WebMvcRequestHandler的集合  赋值AlternateTypeRule规则集合  赋值分组策略属性(resourceGroupingStrategy),默认是ClassOrApiAnnotationResourceGrouping实现DocumentationContext获取到了DocumentationContextBuilder对象,此时在通过DocumentationPlugin的configure方法,构建DocumentationContext来看Docket的configure方法/**   * Builds the Docket by merging/overlaying user specified values.   * It is not necessary to call this method when defined as a spring bean.   * NOTE: Calling this method more than once has no effect.   *   * @see DocumentationPluginsBootstrapper   */  public DocumentationContext configure(DocumentationContextBuilder builder) {    return builder        .apiInfo(apiInfo)        .selector(apiSelector)        .applyDefaultResponseMessages(applyDefaultResponseMessages)        .additionalResponseMessages(responseMessages)        .additionalOperationParameters(globalOperationParameters)        .additionalIgnorableTypes(ignorableParameterTypes)        .ruleBuilders(ruleBuilders)        .groupName(groupName)        .pathProvider(pathProvider)        .securityContexts(securityContexts)        .securitySchemes(securitySchemes)        .apiListingReferenceOrdering(apiListingReferenceOrdering)        .apiDescriptionOrdering(apiDescriptionOrdering)        .operationOrdering(operationOrdering)        .produces(produces)        .consumes(consumes)        .host(host)        .protocols(protocols)        .genericsNaming(genericsNamingStrategy)        .pathMapping(pathMapping)        .enableUrlTemplating(enableUrlTemplating)        .additionalModels(additionalModels)        .tags(tags)        .vendorExtentions(vendorExtensions)        .build();  }针对Builder的一些列二次赋值,最终通过build方法构造我们的Docket对象是我们开发人员在外部通过Bean来创建的,来看Docket的部分代码：public class Docket implements DocumentationPlugin {  public static final String DEFAULT_GROUP_NAME = \"default\";  private final DocumentationType documentationType;  private final List&lt;SecurityContext&gt; securityContexts = newArrayList();  private final Map&lt;RequestMethod, List&lt;ResponseMessage&gt;&gt; responseMessages = newHashMap();  private final List&lt;Parameter&gt; globalOperationParameters = newArrayList();  private final List&lt;Function&lt;TypeResolver, AlternateTypeRule&gt;&gt; ruleBuilders = newArrayList();  private final Set&lt;Class&gt; ignorableParameterTypes = newHashSet();  private final Set&lt;String&gt; protocols = newHashSet();  private final Set&lt;String&gt; produces = newHashSet();  private final Set&lt;String&gt; consumes = newHashSet();  private final Set&lt;ResolvedType&gt; additionalModels = newHashSet();  private final Set&lt;Tag&gt; tags = newHashSet();  private PathProvider pathProvider;  private List&lt;? extends SecurityScheme&gt; securitySchemes;  private Ordering&lt;ApiListingReference&gt; apiListingReferenceOrdering;  private Ordering&lt;ApiDescription&gt; apiDescriptionOrdering;  private Ordering&lt;Operation&gt; operationOrdering;  private ApiInfo apiInfo = ApiInfo.DEFAULT;  private String groupName = DEFAULT_GROUP_NAME;  private boolean enabled = true;  private GenericTypeNamingStrategy genericsNamingStrategy = new DefaultGenericTypeNamingStrategy();  private boolean applyDefaultResponseMessages = true;  private String host = \"\";  private Optional&lt;String&gt; pathMapping = Optional.absent();  private ApiSelector apiSelector = ApiSelector.DEFAULT;  private boolean enableUrlTemplating = false;  private List&lt;VendorExtension&gt; vendorExtensions = newArrayList();}我们通过Docket来外部赋值的对象值,最终都会构建到DocumentationContext上下文中，我们先来看我们开发中一般创建Docket对象过程@Bean(value = \"defaultApi\")@Order(value = 4)public Docket defaultApi() {    ParameterBuilder parameterBuilder=new ParameterBuilder();    List&lt;Parameter&gt; parameters= Lists.newArrayList();    parameterBuilder.name(\"token\").description(\"token令牌\").modelRef(new ModelRef(\"String\"))        .parameterType(\"header\")        .required(true).build();    parameters.add(parameterBuilder.build());    Docket docket=new Docket(DocumentationType.SWAGGER_2)        .apiInfo(apiInfo())        .groupName(\"默认接口\")        .select()        .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.controller\"))        //.apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class))        .paths(PathSelectors.any())        .build().globalOperationParameters(parameters)        .securityContexts(Lists.newArrayList(securityContext())).securitySchemes(Lists.&lt;SecurityScheme&gt;newArrayList(apiKey()));    return docket;}一般创建Docket对象,主要的赋值参数：  分组名称  apiInfo信息  ApiSelector  全局参数  权限验证主要包含了以上的一些信息，整个文档上下文环境构造完成,我们也可以以Debug的方式来跟踪代码,如下图：除了默认的参数赋值外,接口、definitions、model等关键信息等都还没有初始化。"
  },
  
  {
    "title": "springfox 源码分析(七) 文档初始化",
    "url": "/posts/springfox-7/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-23 00:00:00 +0800",
    





    
    "snippet": "时间：2019-5-23 20:12:04地点：家中通过前面几篇文章对springfox的介绍,以及我们的学习准备工作,这篇我们将正式来探索springfox是如何初始化的  我们在学算法的时候,其中一个算法是快速排序,而快速排序讲究的是如果给定一个集合的元素&lt;2,那其实就不用排序了，那就是最快的,取集合中任意元素M,然后，比M小的，排左边,比M大的排右边,这样只需要排2次(递归调用最...",
    "content": "时间：2019-5-23 20:12:04地点：家中通过前面几篇文章对springfox的介绍,以及我们的学习准备工作,这篇我们将正式来探索springfox是如何初始化的  我们在学算法的时候,其中一个算法是快速排序,而快速排序讲究的是如果给定一个集合的元素&lt;2,那其实就不用排序了，那就是最快的,取集合中任意元素M,然后，比M小的，排左边,比M大的排右边,这样只需要排2次(递归调用最小次数)，这其中用到了分而治之的思想,这种思想我们在工作中也很适用,就拿学习源码来说吧,将一个看似很难的源码,分解成若干小块,每一个小块都逐一研究攻破,因为你不可能所有的都不懂,随着研究的过程中,自信心的增长,整个部分的源码最后你就会把他吃透.项目结构在这之前,我们先来看一下springfox的项目分层结构：这是springfox 2.9.2版本的源码结构,主要包含了6个模块：  springfox-core:springfox的核心包,里面基本封装的是一些实体类，core模块大量的运用了设计模式中的Builder构造器  springfox-schema:一系列方法实现类  springfox-spi:一系列的Plugin接口声明  springfox-spring-web:针对spring-web模块的核心操作,springfox的初始化代码也在此模块中  springfox-swagger2:对外使用类，注解,包括我们熟知的@EnableSwagger2注解  springfox-swagger-common:springfox的功能模块代码，Plugin接口的实现启动类启动类就是springfox的开始,从前面的篇幅我们也发现了,springfox没有给我们任何有益的提示,告诉我们他的启动类是那个,是具体在何时初始化的当然我也是很茫然,一个偶然的机会,只是在代码中多瞟了一眼,我突然就发现了她,她就如太阳一样,温暖着我的心,令我为止动容,她就是springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.java至于是如何发现她的,你们各自体会吧…首先来看DocumentationPluginsBootstrapper.java的部分源码：/** * After an application context refresh, builds and executes all DocumentationConfigurer instances found in the * application context. * * If no instances DocumentationConfigurer are found a default one is created and executed. */@Componentpublic class DocumentationPluginsBootstrapper implements SmartLifecycle {  private static final Logger log = LoggerFactory.getLogger(DocumentationPluginsBootstrapper.class);  private static final String SPRINGFOX_DOCUMENTATION_AUTO_STARTUP = \"springfox.documentation.auto-startup\";  //插件管理类,提供了一些列的Swagger相关参数的插件  private final DocumentationPluginsManager documentationPluginsManager;  //所有的请求接口结果  /***   * springfox.documentation.spring.web.plugins   */  private final List&lt;RequestHandlerProvider&gt; handlerProviders;}因为DocumentationPluginsBootstrapper类实现了Spring的SmartLifecycle接口,而我们都知道,在Spring的应用程序中,实现此接口后,并且通过@Component注入到容器的bean,在Spring容器初始化完成后,都会执行这个接口的start()方法.既然是Spring容器初始化完成后执行的操作,我想那就是springfox的初始化操作,没错了(PS:因为我也再找不到其他的启动类了。。。)。来看start方法@Overridepublic void start() {    if (initialized.compareAndSet(false, true)) {        log.info(\"Context refreshed\");        //此处拿到DocumentationPlugin插件        //因为Docket类是实现了DocumentationPlugin,我们在程序外部通过@Bean注解注入到Spring容器中,所以此处DocumentationPlugin的实例对象是Docket对象        //一个Docket代表的一个分组,多个则是多个文档分组        //调用guava的排序规则,根据groupName排序        //思考：在重构Swagger-ui的过程中,会有需求能否提供默认的排序规则,因为groupName排序对用户来说太死板,可以提供一个order参数值来进行默认排序,这样对用户更友好        List&lt;DocumentationPlugin&gt; plugins = pluginOrdering()            .sortedCopy(documentationPluginsManager.documentationPlugins());        log.info(\"Found {} custom documentation plugin(s)\", plugins.size());        //遍历Docket对象        for (DocumentationPlugin each : plugins) {            //获取文档类型,一般都是Swagger_2            DocumentationType documentationType = each.getDocumentationType();            if (each.isEnabled()) {                //如果启用,则开始扫描生成文档                scanDocumentation(buildContext(each));            } else {                log.info(\"Skipping initializing disabled plugin bean {} v{}\",                         documentationType.getName(), documentationType.getVersion());            }        }    }}从代码中,我们看到：  首先获取DocumentationPlugin的实现类列表,而DocumentaionPlugin我们在前面的章节也介绍过,他只有一个实现类,那就是Docket,而Docket类正是我们在使用Springfox的时候,通过编写SwaggerConfiguration配置文件,通过@Bean注解注入的对象,此处DocumentationPlugin的集合实际拿到的就是List&lt;Docket&gt;实例集合,我们在外部创建几个Docket,此处就会有几个DocumentationPlugin  通过循环外部创建的Docket实体bean,最终转换为Documentation文档对象我们找到了springfox的初始化方法,接下来,针对Springfox的各个操作步骤,我们逐一分析."
  },
  
  {
    "title": "springfox 源码分析(六) web配置类扫描包作用探索",
    "url": "/posts/springfox-6/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-23 00:00:00 +0800",
    





    
    "snippet": "时间：2019-5-23 18:46:50地点：家中我们在上一篇中,知道了springfox一系列Plugin接口的实现、作用而此时,我们联想到springfox为我们提供的Configuration配置类中使用了包路径扫描先来看OperationBuilderPlugin的实现类之一OperationDeprecatedReader的代码OperationDeprecatedReader....",
    "content": "时间：2019-5-23 18:46:50地点：家中我们在上一篇中,知道了springfox一系列Plugin接口的实现、作用而此时,我们联想到springfox为我们提供的Configuration配置类中使用了包路径扫描先来看OperationBuilderPlugin的实现类之一OperationDeprecatedReader的代码OperationDeprecatedReader.javapackage springfox.documentation.spring.web.readers.operation;import com.google.common.base.Optional;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spi.service.OperationBuilderPlugin;import springfox.documentation.spi.service.contexts.OperationContext;@Component@Order(Ordered.HIGHEST_PRECEDENCE)public class OperationDeprecatedReader implements OperationBuilderPlugin {  @Override  public void apply(OperationContext context) {    Optional&lt;Deprecated&gt; annotation = context.findAnnotation(Deprecated.class);    context.operationBuilder().deprecated(String.valueOf(annotation.isPresent()));  }  @Override  public boolean supports(DocumentationType delimiter) {    return true;  }}这是针对operation中接口是否过时进行处理的实现类实现类位于springfox.documentation.spring.web.readers.operation包下,并且通过@Component注解进行bean的实例注入此时,我们回过头来看SpringfoxWebMvcConfiguration的源码，源码中配置了springfox.documentation.spring.web.readers.operation扫描路径@Configuration@Import({ ModelsConfiguration.class })@ComponentScan(basePackages = {    \"springfox.documentation.spring.web.scanners\",    \"springfox.documentation.spring.web.readers.operation\",    \"springfox.documentation.spring.web.readers.parameter\",    \"springfox.documentation.spring.web.plugins\",    \"springfox.documentation.spring.web.paths\"})@EnablePluginRegistries({ DocumentationPlugin.class,    ApiListingBuilderPlugin.class,    OperationBuilderPlugin.class,    ParameterBuilderPlugin.class,    ExpandedParameterBuilderPlugin.class,    ResourceGroupingStrategy.class,    OperationModelsProviderPlugin.class,    DefaultsProviderPlugin.class,    PathDecorator.class,    ApiListingScannerPlugin.class})public class SpringfoxWebMvcConfiguration {    //more..}@ComponentScan注解此时配置了5个包路径，分别是：  springfox.documentation.spring.web.scanners  springfox.documentation.spring.web.readers.operation  springfox.documentation.spring.web.readers.parameter  springfox.documentation.spring.web.plugins  springfox.documentation.spring.web.paths源码看到这里,我们应该明白,包括Plugin的接口实现类,都会通过@ComponentScan配置的扫描包路径一并全部注入到Spring容器中而我们只需要在我们的springfox其他代码中通过@Autowired依赖注入即可进行相应的实体bean使用"
  },
  
  {
    "title": "springfox 源码分析(五) web配置类Plugin插件的使用",
    "url": "/posts/springfox-5/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-23 00:00:00 +0800",
    





    
    "snippet": "时间：2019-5-23 14:46:50地点：家中前言我们在上一篇文章,通过@EnableSwagger2注解,知道springfox使用开启Plugin注解的配置,注入了很多Plugin的配置类，结合我们第二篇针对Spring Plugin的使用文章介绍,该篇主要探索springfox中的各种不同Plugin的具体作用,以及声明了那些方法插件在SpringfoxWebMvcConfigu...",
    "content": "时间：2019-5-23 14:46:50地点：家中前言我们在上一篇文章,通过@EnableSwagger2注解,知道springfox使用开启Plugin注解的配置,注入了很多Plugin的配置类，结合我们第二篇针对Spring Plugin的使用文章介绍,该篇主要探索springfox中的各种不同Plugin的具体作用,以及声明了那些方法插件在SpringfoxWebMvcConfiguration配置中,主要涉及了以下Plugin  DocumentationPlugin  ApiListingBuilderPlugin  OperationBuilderPlugin  ParameterBuilderPlugin  ExpandedParameterBuilderPlugin  OperationModelsProviderPlugin  DefaultsProviderPlugin  PathDecorator  ApiListingScannerPlugin代码结构一览：plugin中声明的接口,都是为处理contexts上下文中的属性DocumentationPlugin先来看DocumentationPlugin的源码public interface DocumentationPlugin extends Plugin&lt;DocumentationType&gt; {  /**   * @return indicator to determine if the plugin is enabled   */  boolean isEnabled();  DocumentationType getDocumentationType();  /**   * Creates a documentation context based on a given DocumentationContextBuilder   *   * @param builder - @see springfox.documentation.spi.service.contexts.DocumentationContextBuilder   * @return context to use for building the documentation   */  DocumentationContext configure(DocumentationContextBuilder builder);  /**   * Gets the group name for the plugin. This is expected to be unique for each instance of the plugin   * @return group the plugin belongs to   */  String getGroupName();}此Plugin使用的分隔符类是DocumentationType,文档类型,在Springfox中声明了三个版本的文档类型，主要是：  SWAGGER_2:swagger的2.0版本  SWAGGER_12:Swagger的1.2版本  SPRING_WEB:springfox项目是由原spring-mvc-swagger项目演变而来,所以这是最早的一个版本DocumentationPlugin定义了三个方法：  是否启用  获取文档类型  通过文档上下文Builder构建文档上下文对象  获取分组名称那么,他的实现类是谁，我们通过IDEA的编辑器功能能轻松定位到,是Docket类来看类图：由于Docket对象是最终实现类,而我们开发者一般在使用时,都是通过创建Docket的实体对象来注入到Spring的容器中所以,我们创建几个Docket对象的Bean实例，那么通过PluginRetry&lt;DocumentationPlugin,DocumentationType&gt;的getPlugins()方法,最终就会获取到外部注入的Docket对象实例,然后再程序中就可以使用了ApiListingBuilderPlugin来看ApiListingBuilderPlugin的源码public interface ApiListingBuilderPlugin extends Plugin&lt;DocumentationType&gt; {  /**   * Implement this method to override the ApiListing using the ApiListingBuilder   *   * @param apiListingContext - context that can be used to override the model property attributes   * @see springfox.documentation.service.ApiListing   * @see springfox.documentation.builders.ApiListingBuilder   */  void apply(ApiListingContext apiListingContext);}实现ApiListingBuilderPlugin插件类需要实现apply方法,主要是处理ApiListingContext上下文的属性信息来看类图：从ApiListingBuilderPlugin类图中,我们可以看到,他有三个子类,分别是：  MediaTypeReader：获取接口的RequestMapping注解,赋值Produces和Consumes属性  ApiListingReader：针对controller名称的处理操作,最后赋值给ApiListingBuilder对象description属性  SwaggerApiListingReader:获取@Api注解,赋值tag及description属性这三个实现类都通过@Component注解注入到了Spring的容器中OperationBuilderPluginspringfox中的一些列插件Plugin最终的作用都是分别为定义传参的Context上下文进行一系列的赋值处理每个上下文中几乎都会存在该对象的Builder,最终通过各种不同的Plugin来分别进行赋值,这样整个程序架构会清晰很多Operation也不例外,先来看Operation的上下文类OperationContext.javapublic class OperationContext {    //builder函数  private final OperationBuilder operationBuilder;    //Spring中接口的请求方法类型枚举  private final RequestMethod requestMethod;    //请求接口上下文  private final RequestMappingContext requestContext;  private final int operationIndex;    //getter setter and constructor    }此时,我们来看OperationBuilderPlugin插件的源码：public interface OperationBuilderPlugin extends Plugin&lt;DocumentationType&gt; {  /**   * Implement this method to override the Operation using the OperationBuilder available in the context   *   * @param context - context that can be used to override the parameter attributes   * @see springfox.documentation.service.Operation   * @see springfox.documentation.builders.OperationBuilder   */  void apply(OperationContext context);}顶级Plugin声明接口,分层逐步给OperationContext对象赋值先来看部分类图：由于OperationBuilderPlugin实现类比较多,此处类图进列出其中四个实现类,我们通过文字来一一说明  DefaultOperationReader:请求方法、接口说明、唯一id值  MediaTypeReader:consumes、produces  OperationAuthReader:权限赋值  OperationDeprecatedReader；接口是否过时  OperationHiddenReader：是否隐藏  OperationHttpMethodReader:接口请求方法  OperationImplicitParameterReader:针对@ApiImplicitParam注解的接口进行读取赋值  OperationImplicitParametersReader:针对@ApiImplicitParams注解的接口进行读取赋值  OperationNicknameIntoUniqueIdReader:昵称属性,通过读取@ApiOperation注解中的nickname属性进行赋值  OperationNotesReader:接口说明  OperationParameterHeadersConditionReader:请求头  OperationParameterReader:后端配置的全局parameter以及接口的parameter参数进行读取赋值  OperationParameterRequestConditionReader:参数条件  OperationPositionReader:position属性  OperationResponseClassReader:响应类处理  OperationSummaryReader:接口名称  OperationTagsReader:tags  ResponseMessagesReader:响应状态码信息，先读取后端配置的全局,然后读取接口  SwaggerMediaTypeReader:consumes、produces  SwaggerOperationResponseClassReader:响应class类  SwaggerOperationTagsReader：接口的tags处理  SwaggerResponseMessageReader:状态码信息,针对@ApiResponse注解标注的接口  VendorExtensionsReader:扩展整个代码结构一览：ParameterBuilderPlugin针对参数处理的Plugin，先来看相关类图：总共有七个实现类，我们一一说明：  ApiParamParameterBuilder:针对接口使用@ApiParam注解的参数进行处理  ParameterDataTypeReader:参数的数据类型  ParameterDefaultReader:参数默认值  ParameterMultiplesReader:  ParameterNameReader:参数名称  ParameterRequiredReader:参数是否必须  ParameterTypeReader：参数类型，包括（form、header、query、formdata、body），默认是bodyExpandedParameterBuilderPlugin先来看类图关系从类图关系中,实现类主要有两个：  ExpandedParameterBuilder:实体类参数的默认属性赋值  SwaggerExpandedParameterBuilder:针对我们的类使用@ApiModelProperty注解的操作OperationModelsProviderPlugin来看类图关系  OperationModelsProvider:收集所有的参数Models,返回类型，全局Models  SwaggerOperationModelsProvider:接口返回类型已经使用@ApiResponse标注的返回类型DefaultsProviderPlugin来看DefaultsProviderPlugin的源码public interface DefaultsProviderPlugin extends Plugin&lt;DocumentationType&gt; {  /**   * Implement this method to override the @see  springfox.documentation.spi.service.contexts   * .DocumentationContextBuilder   *   * @param documentationType - creates a default DocumentationContextBuilder based on documentation type   * @return - returns the documentation context builder   */  DocumentationContextBuilder create(DocumentationType documentationType);}根据文档类型创建DocumentationContextBuilder对象而DefaultsProviderPlugin只有一个实现子类,那就是springfox.documentation.spring.web.plugins.DefaultConfigurationpublic class DefaultConfiguration implements DefaultsProviderPlugin {  private final Defaults defaults;  private final TypeResolver typeResolver;  private final ServletContext servletContext;  public DefaultConfiguration(Defaults defaults,                       TypeResolver typeResolver,                       ServletContext servletContext) {    this.servletContext = servletContext;    this.defaults = defaults;    this.typeResolver = typeResolver;  }  @Override  public DocumentationContextBuilder create(DocumentationType documentationType) {    return new DocumentationContextBuilder(documentationType)            .operationOrdering(defaults.operationOrdering())            .apiDescriptionOrdering(defaults.apiDescriptionOrdering())            .apiListingReferenceOrdering(defaults.apiListingReferenceOrdering())            .additionalIgnorableTypes(defaults.defaultIgnorableParameterTypes())            .rules(defaults.defaultRules(typeResolver))            .defaultResponseMessages(defaults.defaultResponseMessages())            .pathProvider(new RelativePathProvider(servletContext))            .typeResolver(typeResolver)            .enableUrlTemplating(false)            .selector(ApiSelector.DEFAULT);  }  @Override  public boolean supports(DocumentationType delimiter) {    return true;  }}给DocumentationContextBuilder创建一系列空对象默认值,方便后期其他Plugin进行赋值初始化Defaults和TypeResolver在前面的Configuration配置类中已经通过Bean注解进行了注入PathDecorator先来看类图：PathDecorator声明了一个Guava函数库中的Function函数接口Function@GwtCompatiblepublic interface Function&lt;F, T&gt; {  @Nullable  @CanIgnoreReturnValue // TODO(kevinb): remove this  T apply(@Nullable F input);  /**   * &lt;i&gt;May&lt;/i&gt; return {@code true} if {@object} is a {@code Function} that behaves identically to   * this function.   *   * &lt;p&gt;&lt;b&gt;Warning: do not depend&lt;/b&gt; on the behavior of this method.   *   * &lt;p&gt;Historically, {@code Function} instances in this library have implemented this method to   * recognize certain cases where distinct {@code Function} instances would in fact behave   * identically. However, as code migrates to {@code java.util.function}, that behavior will   * disappear. It is best not to depend on it.   */  @Override  boolean equals(@Nullable Object object);}传入输入参数,返回输出参数主要实现类：  OperationPathDecorator:basePath处理类  PathMappingDecorator:接口path处理  PathSanitizer:接口path-origin处理  QueryStringUriTemplateDecorator:接口参数处理ApiListingScannerPlugin来看源码public interface ApiListingScannerPlugin extends Plugin&lt;DocumentationType&gt; {  /**   * Implement this method to manually add ApiDescriptions   *   * @param context - Documentation context that can be used infer documentation context   * @see springfox.documentation.service.ApiDescription   * @return List of {@link ApiDescription}   */  List&lt;ApiDescription&gt; apply(DocumentationContext context);}该Plugin没有任何实现子类总结通过上面的Plugin,我们大致了解了Springfox中定义的Plugin接口,以及实现类,完事具备，此时只需要查看springfox的初始化代码部分了在下一篇文章中我们继续."
  },
  
  {
    "title": "springfox 源码分析(四) 配置类初始化",
    "url": "/posts/springfox-4/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-23 00:00:00 +0800",
    





    
    "snippet": "时间：2019-5-23 12:46:50地点：单位、家中@EnableSwagger2有了二三章的理解,此时我们再来看EnableSwagger2注解的内容@Retention(value = java.lang.annotation.RetentionPolicy.RUNTIME)@Target(value = { java.lang.annotation.ElementType.TYP...",
    "content": "时间：2019-5-23 12:46:50地点：单位、家中@EnableSwagger2有了二三章的理解,此时我们再来看EnableSwagger2注解的内容@Retention(value = java.lang.annotation.RetentionPolicy.RUNTIME)@Target(value = { java.lang.annotation.ElementType.TYPE })@Documented@Import({Swagger2DocumentationConfiguration.class})public @interface EnableSwagger2 {}Swagger2DocumentationConfiguration该注解没啥好说的,最终是导入Swagger2DocumentationConfiguration的配置类@Configuration@Import({ SpringfoxWebMvcConfiguration.class, SwaggerCommonConfiguration.class })@ComponentScan(basePackages = {    \"springfox.documentation.swagger2.mappers\"})@ConditionalOnWebApplicationpublic class Swagger2DocumentationConfiguration {此处的@ComponentScan注解,扫描了springfox.documentation.swagger2.mappers包路径Mappers该包路径下包含了众多运用MapStruct组件自动生成的Mapper实体类转换关系,通过扫描注解,自动注入到Spring的容器中关于MapStruct组件的使用,可参考:springfox 源码分析(二) 初探mapstruct主要包括如下：  LicenseMapper  ModelMapper  ParameterMapper  SecurityMapper  SerivceModelToSwagger2Mapper  VendorExtensionsMapper每个Mapper接口都有一个实现类MapperImpl，实现类通过@Component注解注入到Spring的容器中最重要的是SerivceModelToSwagger2Mapper这个Mapper该类的作用会聚合使用Model、Parameter、License等Mapper,将springfox中的对象转化为Swagger标准的对象，包括Swagger@Generated(    value = \"org.mapstruct.ap.MappingProcessor\",    date = \"2018-06-23T17:02:57-0500\",    comments = \"version: 1.2.0.Final, compiler: javac, environment: Java 1.8.0_151 (Oracle Corporation)\")@Componentpublic class ServiceModelToSwagger2MapperImpl extends ServiceModelToSwagger2Mapper {        @Autowired    private ModelMapper modelMapper;    @Autowired    private ParameterMapper parameterMapper;    @Autowired    private SecurityMapper securityMapper;    @Autowired    private LicenseMapper licenseMapper;    @Autowired    private VendorExtensionsMapper vendorExtensionsMapper;    @Override    public Swagger mapDocumentation(Documentation from) {        if ( from == null ) {            return null;        }        Swagger swagger = new Swagger();        swagger.setVendorExtensions( vendorExtensionsMapper.mapExtensions( from.getVendorExtensions() ) );        swagger.setSchemes( mapSchemes( from.getSchemes() ) );        swagger.setPaths( mapApiListings( from.getApiListings() ) );        swagger.setHost( from.getHost() );        swagger.setDefinitions( modelMapper.modelsFromApiListings( from.getApiListings() ) );        swagger.setSecurityDefinitions( securityMapper.toSecuritySchemeDefinitions( from.getResourceListing() ) );        ApiInfo info = fromResourceListingInfo( from );        if ( info != null ) {            swagger.setInfo( mapApiInfo( info ) );        }        swagger.setBasePath( from.getBasePath() );        swagger.setTags( tagSetToTagList( from.getTags() ) );        List&lt;String&gt; list2 = from.getConsumes();        if ( list2 != null ) {            swagger.setConsumes( new ArrayList&lt;String&gt;( list2 ) );        }        else {            swagger.setConsumes( null );        }        List&lt;String&gt; list3 = from.getProduces();        if ( list3 != null ) {            swagger.setProduces( new ArrayList&lt;String&gt;( list3 ) );        }        else {            swagger.setProduces( null );        }        return swagger;    }    //more...}各个Mapper组件的映射关系如下：            Mapper      目标类                         LicenseMapper      io.swagger.models.License      通过ApiInfo的属性Lincese构建目标类实体对象              ModelMapper      io.swagger.models.Model      将springfox.documentation.schema.Model转化成目标类              ParameterMapper      io.swagger.models.parameters.Parameter      将springfox.documentation.service.Parameter转化成目标类              SecurityMapper      io.swagger.models.auth.SecuritySchemeDefinition                     ServiceModelToSwagger2Mapper      io.swagger.models.Swagger      输出Swagger完整对象                                   SpringfoxWebMvcConfiguration在Swagger2DocumentationConfiguration源码中,我们看到该Configuration类还引入了SpringfoxWebMvcConfiguration,该类是注入Spring Rest接口相关的配置核心类先来看源码:@Configuration@Import({ ModelsConfiguration.class })@ComponentScan(basePackages = {    \"springfox.documentation.spring.web.scanners\",    \"springfox.documentation.spring.web.readers.operation\",    \"springfox.documentation.spring.web.readers.parameter\",    \"springfox.documentation.spring.web.plugins\",    \"springfox.documentation.spring.web.paths\"})@EnablePluginRegistries({ DocumentationPlugin.class,    ApiListingBuilderPlugin.class,    OperationBuilderPlugin.class,    ParameterBuilderPlugin.class,    ExpandedParameterBuilderPlugin.class,    ResourceGroupingStrategy.class,    OperationModelsProviderPlugin.class,    DefaultsProviderPlugin.class,    PathDecorator.class,    ApiListingScannerPlugin.class})public class SpringfoxWebMvcConfiguration {  @Bean  public Defaults defaults() {    return new Defaults();  }  @Bean  public DocumentationCache resourceGroupCache() {    return new DocumentationCache();  }  @Bean  public static ObjectMapperConfigurer objectMapperConfigurer() {    return new ObjectMapperConfigurer();  }  @Bean  public JsonSerializer jsonSerializer(List&lt;JacksonModuleRegistrar&gt; moduleRegistrars) {    return new JsonSerializer(moduleRegistrars);  }  @Bean  public DescriptionResolver descriptionResolver(Environment environment) {    return new DescriptionResolver(environment);  }  @Bean  public HandlerMethodResolver methodResolver(TypeResolver resolver) {    return new HandlerMethodResolver(resolver);  }}从源码中我们可以看到：  使用import导入ModelConfiguration配置类,该类  使用@ComponentScan注解扫描配置的package包路径,完成Spring的Bean实例注入  使用@EnablePluginRegistries插件机制来完成插件的动态实例Bean注入到Spring容器中,关于Spring Plugin的使用,不明白的可以参考下上一篇文章对Spring Plugin的说明  注入相关Bean的实例对象ModelsConfiguration从webmvc配置类导入的Models配置类,我们来看该类的源码@Configuration@ComponentScan(basePackages = {    \"springfox.documentation.schema\"})@EnablePluginRegistries({    ModelBuilderPlugin.class,    ModelPropertyBuilderPlugin.class,    TypeNameProviderPlugin.class,    SyntheticModelProviderPlugin.class})public class ModelsConfiguration {  @Bean  public TypeResolver typeResolver() {    return new TypeResolver();  }}该类的配置和SpringfoxWebMvcConfiguration配置类相似,作用都是扫描包路径,启用PluginRetry进行Spring的实体Bean动态注入SwaggerCommonConfigurationSwagger2DocumenationConfiguration导入的第二个配置类SwaggerCommonConfiguration来看代码:SwaggerCommonConfiguration.java@Configuration@ComponentScan(basePackages = {    \"springfox.documentation.swagger.schema\",    \"springfox.documentation.swagger.readers\",    \"springfox.documentation.swagger.web\"})public class SwaggerCommonConfiguration {}作用和以上类似总结通过@EnableSwagger2注解,我们看到了三个4个Configuration配置类的导入主要作用：  实体Bean的注入  Plugin插件的动态Bean注入  扫描springfox配置的各种package路径看到这里相信我们还是一头雾水,我们并没有发现springfox何时初始化接口类的.接下来,我们会针对上面Configuration涉及到的Plugin和@CompnentScan扫描package路径进行一一探索."
  },
  
  {
    "title": "springfox 源码分析(三) 初探Spring Plugin插件系统",
    "url": "/posts/springfox-3/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-22 00:00:00 +0800",
    





    
    "snippet": "时间：2019-5-22 12:46:50地点：单位、家中前言同MapStuct组件一样,因为springfox中运用到了Spring Plugin插件系统,我们对研究springfox源码之前,先来学习一下Spring Plugin插件的机制因为在工作中很少使用到Spring Plugin,所以学习记录下Spring PluginGithub:https://github.com/spri...",
    "content": "时间：2019-5-22 12:46:50地点：单位、家中前言同MapStuct组件一样,因为springfox中运用到了Spring Plugin插件系统,我们对研究springfox源码之前,先来学习一下Spring Plugin插件的机制因为在工作中很少使用到Spring Plugin,所以学习记录下Spring PluginGithub:https://github.com/spring-projects/spring-plugin可以说作为Spring项目中的Spring Plugin,确实相对小众,并没有像Spring其他的项目那么流行,甚至在其他流行的框架中,都很少见到他的身影.截止目前(2019-5-22 13:54:08)，Github 的Star为222,fork数66Spring Plugin是世界上最小规模的插件系统如今构建可扩展的体系结构是创建可维护应用程序的核心原则。 这就是像OSGi这样的完全成熟的插件环境如今如此受欢迎的原因。 不幸的是，OSGi的引入给项目带来了很多复杂性。Spring Plugin通过提供扩展核心系统功能的插件实现的核心灵活性，但不提供动态类加载或运行时安装和插件部署等核心OSGi功能，同时为插件开发提供了更实用的方法。 虽然Spring Plugin并不像OSGi那样强大，但它可以满足穷人构建模块化可扩展应用程序的要求。假如你希望构建一个可扩展的应用系统,你可能需要从以下几点进行考虑：  无论出于何种原因，您都无法将OSGi用作完全成熟的插件架构  提供专用的插件接口来满足可扩展性  通过简单地提供捆绑在JAR文件中并在类路径中可用的插件接口的实现来扩展核心系统  使用Spring来构建应用系统示例我们通过一个小示例,来对Spring Plugin系统有一个初步的了解Spring Plugin提供一个标准的Plugin&lt;S&gt;接口供开发人员继承使用声明自己的插件机制,然后通过@EnablePluginRegistries注解依赖注入到Spring的容器中,Spring容器会为我们自动匹配到插件的所有实现子对象,最终我们在代码中使用时,通过依赖注入注解，注入PluginRegistry&lt;T extends Plugin&lt;S&gt;, S&gt;对象拿到插件实例进行操作。Plugin&lt;S&gt;接口声明了一个接口实现,标注实现该插件是否支持，因为有可能存在多个接口实现的情况我们在使用时,可能这样调用：List&lt;Plugin&lt;S&gt;&gt; plugins=plugin.getPlugins();S delimiter;for(Plugin&lt;S&gt; p:plugins){    if(p.supports(delimiter)){        p.doSomeThing();//    }}从应用程序的扩展性来说,开发灵活的插件系统是我们每个开发人员都需考虑的假设目前我们有一个移动电话充值系统,在业务初期发展中,业务的目标是保证稳定性,拥有充值业务在maven配置中先来引入相关的jar包&lt;properties&gt;    &lt;logback.version&gt;1.2.3&lt;/logback.version&gt;    &lt;org.slf4j.version&gt;1.7.21&lt;/org.slf4j.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;4.8.2&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-core --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-core&lt;/artifactId&gt;        &lt;version&gt;4.0.9.RELEASE&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- https://mvnrepository.com/artifact/org.springframework.plugin/spring-plugin-core --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.plugin&lt;/groupId&gt;        &lt;artifactId&gt;spring-plugin-core&lt;/artifactId&gt;        &lt;version&gt;1.2.0.RELEASE&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;        &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;        &lt;version&gt;${org.slf4j.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;        &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;        &lt;version&gt;${org.slf4j.version}&lt;/version&gt;        &lt;scope&gt;runtime&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;        &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;        &lt;version&gt;${logback.version}&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;groupId&gt;javax.mail&lt;/groupId&gt;                &lt;artifactId&gt;mail&lt;/artifactId&gt;            &lt;/exclusion&gt;            &lt;exclusion&gt;                &lt;groupId&gt;javax.jms&lt;/groupId&gt;                &lt;artifactId&gt;jms&lt;/artifactId&gt;            &lt;/exclusion&gt;            &lt;exclusion&gt;                &lt;groupId&gt;com.sun.jdmk&lt;/groupId&gt;                &lt;artifactId&gt;jmxtools&lt;/artifactId&gt;            &lt;/exclusion&gt;            &lt;exclusion&gt;                &lt;groupId&gt;com.sun.jmx&lt;/groupId&gt;                &lt;artifactId&gt;jmxri&lt;/artifactId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;        &lt;scope&gt;runtime&lt;/scope&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;先来看我们的客户属性：MobileCustomer/*** * * @since:spring-plugin-demo 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2019/05/22 14:41 */public class MobileCustomer {    /***     * 电话号码     */    private String tel; \t//setter getter       /***     * 是否老用户     */    private boolean old=false;}声明我们的充值接口：/*** * 我们有电话增值业务,业务中有充值方法 * @since:spring-plugin-demo 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2019/05/22 14:42 */public interface MobileIncrementBusiness{    /***     * 电话充值     * @param mobileCustomer     * @param money 金额     */    void increment(MobileCustomer mobileCustomer, int money);}充值接口目前有一个接口,充值,根据客户和充值金额进行充值的方法接下来,我们来实现充值的业务逻辑,假设当前我们叫他V1版本/*** * 第一版本的充值系统 * @since:spring-plugin-demo 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2019/05/22 14:44 */public class MobileIncrementV1 implements MobileIncrementBusiness {    Logger logger= LoggerFactory.getLogger(MobileIncrementV1.class);    @Override    public void increment(MobileCustomer mobileCustomer, int money) {        logger.info(\"给{}充值电话费,充值金额:{}\",mobileCustomer.getTel(),money);        logger.info(\"充值完成.\");    }}此时，我们在系统中加入充值插件的配置@Configurationpublic class MobileConfig {    @Bean    public MobileIncrementV1 mobileIncrementV1(){        return new MobileIncrementV1();    }}我们在通过对外提供一个业务Service,来调用我们的充值方法/*** * * @since:spring-plugin-demo 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2019/05/22 15:00 */@Componentpublic class CustomerService {        @Autowired    MobileIncrementV1 mobileIncrementV1;    public void increments(MobileCustomer mobileCustomer,int money){        //对人员进行充值        mobileIncrementV1.increment(mobileCustomer,money);    }}通过CustomerService方法,就可以调用我们的充值插件进行话费的充值我们来模拟public class MobileTest {    public static void main(String[] args) {        AnnotationConfigApplicationContext context=                new AnnotationConfigApplicationContext(\"com.xiaominfo.cloud.plugin.phone\");        CustomerService customerService=context.getBean(CustomerService.class);        MobileCustomer mobileCustomer=new MobileCustomer(\"13567662664\");        mobileCustomer.setOld(true);        customerService.increments(mobileCustomer,120);    }}我们对电话13567662664进行充值120元控制台输出：2019-05-22 15:11:21,391 INFO (MobileIncrementV1.java:27)- 给13567662664充值电话费,充值金额:1202019-05-22 15:11:21,394 INFO (MobileIncrementV1.java:28)- 充值完成.插件的使用到这里就完成了,此时我们或许会有疑问？不是说满足应用程序的可扩展性吗?此处并未体现出来啊？假设随着电话公司的业务逐步扩大,此时,电话公司推出了老用户充话费折扣的活动，具体的规则是  当前电话号码必须是老用户(通过old字段来区分)  充值金额必须&gt;100  折扣金额为充值金额*10%,返冲到客户的手机上此时,针对该活动,我们为了满足以上业务,传统的做法是继续在MobileIncrementV1代码中添加业务逻辑代码会是这样：public class MobileIncrementV1 implements MobileIncrementBusiness {    Logger logger= LoggerFactory.getLogger(MobileIncrementV1.class);    @Override    public void increment(MobileCustomer mobileCustomer, int money) {        logger.info(\"给{}充值电话费,充值金额:{}\",mobileCustomer.getTel(),money);        logger.info(\"充值完成.\");        if (mobileCustomer.isOld()){            logger.info(\"老用户折扣\");            if (money&gt;100){                BigDecimal big=new BigDecimal(money).multiply(new BigDecimal(0.1));                logger.info(\"当前充值金额&gt;100元,返冲{}元\",big.intValue());            }        }    }    @Override    public boolean supports(MobileCustomer delimiter) {        return true;    }}改版后的业务逻辑,我们在V1中添加了业务逻辑,满足老客户是进行返冲运行后,控制台：2019-05-22 15:24:50,229 INFO (MobileIncrementV1.java:29)- 给13567662664充值电话费,充值金额:1202019-05-22 15:24:50,231 INFO (MobileIncrementV1.java:30)- 充值完成.2019-05-22 15:24:50,232 INFO (MobileIncrementV1.java:32)- 老用户折扣2019-05-22 15:24:50,236 INFO (MobileIncrementV1.java:35)- 当前充值金额&gt;100元,返冲12元程序没有任何问题,同时也满足了活动要求,但是这样做的缺陷也是明显的,主要如下  在V1充值系统中,业务已经稳定,此时,如果我们的返冲活动业务比较复杂的情况下,会出现测试不到的情况,新业务逻辑代码更新后,对非老用户的充值稳定性存在影响  如果我们的业务规则变化越来越多,此时我们的V1中的business方法会越来越臃肿,不利于维护  假如我们的活动是有时效性的情况下,在某一段时间,这段业务逻辑有空,而时效性失效后,这段业务逻辑是冗余的,但是它仍然存在于我们的主业务方法中.那么,针对以上问题,我们应该如何解决呢？Spring Plugin帮助我们解决了此问题,如果用Plugin的方式,我们应该如何做呢？首先,改进我们的增值业务MobileIncrementBusiness,改业务接口继承Plugin&lt;S&gt;,代码如下：public interface MobileIncrementBusiness extends Plugin&lt;MobileCustomer&gt;{    /***     * 电话充值     * @param mobileCustomer     * @param money 金额     */    void increment(MobileCustomer mobileCustomer, int money);}我们继承了Plugin的接口,所以我们的子类充值V1业务代码也需要实现Plugin的supports方法,代码如下：public class MobileIncrementV1 implements MobileIncrementBusiness {    Logger logger= LoggerFactory.getLogger(MobileIncrementV1.class);    @Override    public void increment(MobileCustomer mobileCustomer, int money) {        logger.info(\"给{}充值电话费,充值金额:{}\",mobileCustomer.getTel(),money);        logger.info(\"充值完成.\");    }    @Override    public boolean supports(MobileCustomer delimiter) {        return true;    }}此时,我们把老用户返冲的代码移除了,我们通过Plugin的方式来帮助我们我们新建老用户返冲的业务实现MobileIncrementDiscount：public class MobileIncrementDiscount implements MobileIncrementBusiness {    Logger logger= LoggerFactory.getLogger(MobileIncrementDiscount.class);    @Override    public void increment(MobileCustomer mobileCustomer, int money) {        if (supports(mobileCustomer)){            logger.info(\"老用户折扣\");            if (money&gt;100){                if (money&gt;100){                    BigDecimal big=new BigDecimal(money).multiply(new BigDecimal(0.1));                    logger.info(\"当前充值金额&gt;100元,返冲{}元\",big.intValue());                }            }        }    }    /***     * 来用户才满足     * @param delimiter     * @return     */    @Override    public boolean supports(MobileCustomer delimiter) {        return delimiter.isOld();    }}此时,我们启用Plugin插件系统,将我们的返冲实现业务注入到系统中@Configuration@EnablePluginRegistries({MobileIncrementBusiness.class})public class MobileConfig {    @Bean    public MobileIncrementV1 mobileIncrementV1(){        return new MobileIncrementV1();    }   @Bean    public MobileIncrementDiscount mobileIncrementDiscount(){        return new MobileIncrementDiscount();    }}最后，我们修改我们的CustomerService中的充值方法@Componentpublic class CustomerService {    @Autowired    private PluginRegistry&lt;MobileIncrementBusiness,MobileCustomer&gt; mobileCustomerPluginRegistry;      public void increments(MobileCustomer mobileCustomer,int money){        //获取插件        List&lt;MobileIncrementBusiness&gt; plugins=mobileCustomerPluginRegistry.getPlugins();        for (MobileIncrementBusiness incrementBusiness:plugins){            //对人员进行充值            incrementBusiness.increment(mobileCustomer,money);        }    }}此时,我们在来运行我们的Test测试AnnotationConfigApplicationContext context=new AnnotationConfigApplicationContext(\"com.xiaominfo.cloud.plugin.phone\");CustomerService customerService=context.getBean(CustomerService.class);MobileCustomer mobileCustomer=new MobileCustomer(\"13567662664\");mobileCustomer.setOld(true);customerService.increments(mobileCustomer,120);控制台输出：2019-05-22 15:42:01,743 INFO (MobileIncrementV1.java:29)- 给13567662664充值电话费,充值金额:1202019-05-22 15:42:01,745 INFO (MobileIncrementV1.java:30)- 充值完成.2019-05-22 15:42:01,746 INFO (MobileIncrementDiscount.java:28)- 老用户折扣2019-05-22 15:42:01,752 INFO (MobileIncrementDiscount.java:32)- 当前充值金额&gt;100元,返冲12元通过控制台,我们发现,和在v1业务中继续新增代码的方式,效果是完全相同的,但是对于整个系统的扩展性来说,是V1方式无法比例的，主要体现在以下几个方面:  通过插件的方式,不需要更改原来已经稳定的业务代码,对系统稳定性来说尤为重要(系统稳定是基础)  与业务解耦,如果业务发生变化(在某个周期内)，或者有新用户的活动,我们只需要构建我们的业务代码,核心框架层无需更改  程序架构更清晰,分层设计更明显.源码分析相信通过上面的示例,我们对Spring Plugin插件技术组件有一个初步的了解,接下来我们看看Spring Plugin的源码实现既然是号称世界上规模最小的插件系统,通过我们的使用来看,确实也够简单,所以Spring Plugin的代码量也是很精悍.通过GitHub下载下来的源码,总共也就三个包这对于我们学习他的源码、设计模式来说,反而是好事情.先来看Plugin涉及到的关键类图：我们最终使用插件时,通过PluginRegistry来获取已实现的插件bean实例，该插件提供了几个主要方法：  Optional getPluginFor(S delimiter):根据特定条件获取插件的Optional对象(第一个)  T getRequiredPluginFor(S delimiter)：根据条件获取插件对象,如果没有,则抛出异常  getPlugins():获取所有插件  contains(T):是否包含插件  …我们在使用Spring Plugin组件的时候,主要有以下几个步骤：  在我们的Configuration配置类上通过注解@EnablePluginRegistries注入相应的Plugin接口的class  在Configuration配置类中注入Plugin的实现类实体Bean  通过@Autowired注解,并使用PluginRegistry&lt;T extend Plugin&lt;S&gt;,S&gt;的方式拿到我们的plugin实例,然后再业务方法中进行使用.这里有两个关键点：1、@EnablePluginRegistries注解具体的作用2、PluginRegistry是接口,通过@Antowired注入,具体的实现类在哪儿?带着这两个疑问点,我们先来看@EnablePluginRegistries的代码：EnablePluginRegistries.java/** * 为开启使用Plugin插件的类型应用启用PluginRegistry的实例注入 * @see #value() * @author Oliver Gierke */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@Import(PluginRegistriesBeanDefinitionRegistrar.class)public @interface EnablePluginRegistries {\t/**\t* \t * The {@link Plugin} types to register {@link PluginRegistry} instances for. The registries will be named after the\t * uncapitalized plugin type extended with {@code Registry}. So for a plugin interface {@code SamplePlugin} the\t * exposed bean name will be {@code samplePluginRegistry}. This can be used on the client side to make sure you get\t * the right {@link PluginRegistry} injected by using the {@link Qualifier} annotation and referring to that bean\t * name. If the auto-generated bean name collides with one already in your application you can use the\t * {@link Qualifier} annotation right at the plugin interface to define a custom name.\t * \t * @return\t */\tClass&lt;? extends Plugin&lt;?&gt;&gt;[] value();}通过注释我们得知该注解的作用  注册PluginRegistry的实例Bean,并以此命名  导入PluginRegistriesBeanDefinitionRegistrar类进行实例Bean注入PluginRegistry的注入规则是,首字母变小写,例如SimplePluginRegistry的实例bean，在Spring容器中的beanName为simplePluginRegistry如果系统的命名和自动生成的名称相冲突,可以使用@Qualifier注解来强制命名匹配以解决此问题来看PluginRegistriesBeanDefinitionRegistrar.java代码：/** * {@link ImportBeanDefinitionRegistrar} to register {@link PluginRegistryFactoryBean} instances for type listed in * {@link EnablePluginRegistries}. Picks up {@link Qualifier} annotations used on the plugin interface and forwards them * to the bean definition for the factory. * 为pluginRegistry接口注入动态实例bean对象 * * @author Oliver Gierke */public class PluginRegistriesBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar {\tprivate static final Logger LOG = LoggerFactory.getLogger(PluginRegistriesBeanDefinitionRegistrar.class);\t/*\t * importingClassMetadata:此参数为通过@EnablePluginRegistries注解标注的类型注解元数据信息对象\t * registry:注入bean对象\t * \t */\t@Override\tpublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {        //获取当前enablePluginRegistries注解类信息\t\tMap&lt;String, Object&gt; annotationAttributes = importingClassMetadata\t\t\t\t.getAnnotationAttributes(EnablePluginRegistries.class.getName());\t\t//判断是否为空\t\tif (annotationAttributes == null) {\t\t\tLOG.info(\"No EnablePluginRegistries annotation found on type {}!\", importingClassMetadata.getClassName());\t\t\treturn;\t\t}\t\t//获取什么的类型集合        //例如我们在示例中使用的@EnablePluginRegistries({MobileIncrementBusiness.class})        //此处会拿到MobileIncrementBusiness.class这个type，types.length=1\t\tClass&lt;?&gt;[] types = (Class&lt;?&gt;[]) annotationAttributes.get(\"value\");        //循环遍历\t\tfor (Class&lt;?&gt; type : types) {            //获取PluginRegistryFactoryBean类的实体bean定义builder\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.rootBeanDefinition(PluginRegistryFactoryBean.class);\t\t\tbuilder.addPropertyValue(\"type\", type);\t\t\tRootBeanDefinition beanDefinition = (RootBeanDefinition) builder.getBeanDefinition();\t\t\tbeanDefinition.setTargetType(getTargetType(type));\t\t\tQualifier annotation = type.getAnnotation(Qualifier.class);\t\t\t// If the plugin interface has a Qualifier annotation, propagate that to the bean definition of the registry\t\t\tif (annotation != null) {\t\t\t\tAutowireCandidateQualifier qualifierMetadata = new AutowireCandidateQualifier(Qualifier.class);\t\t\t\tqualifierMetadata.setAttribute(AutowireCandidateQualifier.VALUE_KEY, annotation.value());\t\t\t\tbeanDefinition.addQualifier(qualifierMetadata);\t\t\t}\t\t\t//获取bean的默认名称\t\t\t// Default\t\t\tString beanName = annotation == null //\t\t\t\t\t? StringUtils.uncapitalize(type.getSimpleName() + \"Registry\") //\t\t\t\t\t: annotation.value();\t\t\t//动态注入\t\t\tregistry.registerBeanDefinition(beanName, builder.getBeanDefinition());\t\t}\t}\t/**\t * Returns the target type of the {@link PluginRegistry} for the given plugin type.\t *\t * @param pluginType must not be {@literal null}.\t * @return\t */\tprivate static ResolvableType getTargetType(Class&lt;?&gt; pluginClass) {\t\tAssert.notNull(pluginClass, \"Plugin type must not be null!\");\t\tResolvableType delimiterType = ResolvableType.forClass(Plugin.class, pluginClass).getGeneric(0);\t\tResolvableType pluginType = ResolvableType.forClass(pluginClass);\t\treturn ResolvableType.forClassWithGenerics(OrderAwarePluginRegistry.class, pluginType, delimiterType);\t}}通过以上代码，我们知道：  通过@EnablePluginRegistries会为我们动态注入PluginRetry的实体bean  PluginRegistryFactoryBean会产生一个目标bean的代理,此目标bean真是PluginRegistry接口的实例,首先找到容器中实现了Plugin插件接口的实体bean,最终得到一个List&lt;Plugin&gt;的集合  通过拿到该Plugins的结合，在通过OrderAwarePluginRegistry.create(List&lt;Plugin&lt;S&gt;&gt;)的方法来创建PluginRetry接口的默认实例  通过上面的类图其实我们知道,PluginRetry的接口拥有他的默认子类实现,为OrderAwarePluginRegistry回过头来看我们示例中的CustomerService的Plugin调用方式@Componentpublic class CustomerService {    @Autowired    private PluginRegistry&lt;MobileIncrementBusiness,MobileCustomer&gt; mobileCustomerPluginRegistry;}通过制定泛型T和delimiter的S,最终通过依赖注入匹配到PluginRegistry的实例bean我们可以通过调试来查看我们最终的mobileCustomerPluginRegistry是否和我们通过读源码的方式得到的一致:我们通过Debug断点来跟踪从上图中我们可以看到,PluginRegistry的最终实例是OrderAwarePluginRegistry实体对象整个过程也到此结束总结我们通过该篇文章的分析,了解到了Spring Plugin组件的工作方式,大致跟踪学习了Plugin的初始化过程不知道通过上面的介绍,你是否会在工作中更多的使用Spring Plugin组件的,至少从目前来看,他的使用还是很简单的,对于应用程序的可扩展性也是极强的.Springfox的源码中大量的使用了Spring Plugin的这种方式,相信通过这篇文章,能对后面我们研究学习Springfox的源码有一个很大的提升和帮助."
  },
  
  {
    "title": "springfox 源码分析(二) 初探mapstruct",
    "url": "/posts/springfox-2/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-22 00:00:00 +0800",
    





    
    "snippet": "时间：2019-5-22 12:40:21地点：单位前言在继续阅读学习springfox源码之前,我们需要先来学习一下mapstruct这个组件,只有在理解了mapstruct组件后,后面再看springfox的源码才不会有疑惑因为之前并没有接触过mapstruct这个组件,所以记录一下学习的过程.mapstruct官网地址：http://mapstruct.org/GitHub:https...",
    "content": "时间：2019-5-22 12:40:21地点：单位前言在继续阅读学习springfox源码之前,我们需要先来学习一下mapstruct这个组件,只有在理解了mapstruct组件后,后面再看springfox的源码才不会有疑惑因为之前并没有接触过mapstruct这个组件,所以记录一下学习的过程.mapstruct官网地址：http://mapstruct.org/GitHub:https://github.com/mapstruct/mapstruct文档：http://mapstruct.org/documentation/stable/reference/html/一言一概之:Java bean mappings, the easy way!简介通过上面的最简单的一句话,很清晰的描述了mapstruct的作用,主要用于Java Bean的映射,这有点类似mybatis中的对象关系映射,但此处的mappings并非mybatis那样MapStruct同时也是一个代码生成器，它基于约定优于配置方法极大地简化了Java bean类型之间映射的实现。通过MapStruct生成的映射代码使用普通方法调用，因此快速，类型安全且易于理解。作用我们为什么需要MapStruct组件？我们的应用程序通常会使用分层结构,分层时每层的对象会有不同的POJO对象(例如实体DO和业务DTO),实体DO定义了程序内部的逻辑属性,而DTO定义了外部业务逻辑关系通常我们在应用程序通过DTO接受进来外部参数时,需要将之转化为内部DO对象,供内部调用,此时MapStruct组件正为此而生.与其他映射框架相比，MapStruct在编译时生成bean映射，可确保高性能，允许快速的开发人员反馈和彻底的错误检查。示例先来看一组关于MapStruct的示例在maven中引入MapStruct框架的jar包&lt;properties&gt;    &lt;mapstruct.version&gt;1.2.0.Final&lt;/mapstruct.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;4.8.2&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;        &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt;        &lt;version&gt;${mapstruct.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;        &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt;        &lt;version&gt;${mapstruct.version}&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;            &lt;version&gt;3.5.1&lt;/version&gt; &lt;!-- or newer version --&gt;            &lt;configuration&gt;                &lt;source&gt;1.8&lt;/source&gt; &lt;!-- depending on your project --&gt;                &lt;target&gt;1.8&lt;/target&gt; &lt;!-- depending on your project --&gt;                &lt;annotationProcessorPaths&gt;                    &lt;path&gt;                        &lt;groupId&gt;org.mapstruct&lt;/groupId&gt;                        &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt;                        &lt;version&gt;${mapstruct.version}&lt;/version&gt;                    &lt;/path&gt;                    &lt;!-- other annotation processors --&gt;                &lt;/annotationProcessorPaths&gt;                &lt;compilerArgs&gt;                    &lt;compilerArg&gt;                        -Amapstruct.suppressGeneratorTimestamp=true                    &lt;/compilerArg&gt;                    &lt;compilerArg&gt;                        -Amapstruct.suppressGeneratorVersionInfoComment=true                    &lt;/compilerArg&gt;                &lt;/compilerArgs&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;假设我们拥有DO和业务DTO对象Car.java、CarDTO.javaCar.java:public class Car {    private String name;    private String make;    private int numberOfSeats; \t//getter and setter ,constructs   }CarDTO.javapublic class CarDTO {    private int seatCount;    //getter and setter ,constructs}按照传统的转换关系,如果我们不使用MapStruct框架的话,使用方式如下：Car car=new Car(\"c1\",\"m1\",12);CarDTO cd=new CarDTO();//赋值cd.setSeatCount(car.getNumberOfSeats())；按照以上的方式会有以下局限:  如果属性很多的话,需要写大量的赋值属性代码  代码极其繁琐如果使用MapStruct框架,我们可以先声明一个CarMapping接口/*** * * @since:spring-plugin-demo 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2019/05/21 21:40 */@Mapperpublic interface CarMapper {    CarMapper INSTANCE= Mappers.getMapper(CarMapper.class);    @Mapping(source = \"numberOfSeats\", target = \"seatCount\")    CarDTO carToCarDto(Car car);}我们将所有DO对象及DTO对象的映射关系都定义在Mapper接口中,然后通过@Mapper注解标注而此时我们使用的话也会有所变化： //givenCar car = new Car( \"Morris\", \"4make\", 13 );//whenCarDTO carDto = CarMapper.INSTANCE.carToCarDto( car );//thenSystem.out.println(carDto.getSeatCount());此时，我们程序在compile编译时,MapStruct框架会为我们自动生成CarMapper的实现类：此时在generated-source也会生成相应的java文件CarMapperImpl.java@Generated(    value = \"org.mapstruct.ap.MappingProcessor\",    date = \"2019-05-21T21:46:10+0800\",    comments = \"version: 1.2.0.Final, compiler: javac, environment: Java 1.8.0_111 (Oracle Corporation)\")public class CarMapperImpl implements CarMapper {    @Override    public CarDTO carToCarDto(Car car) {        if ( car == null ) {            return null;        }        CarDTO carDTO = new CarDTO();        carDTO.setSeatCount( car.getNumberOfSeats() );        return carDTO;    }}映射接口自动帮助我们实现了Java实体的转换总结了解了mapstruct的功能,我们在接下来学习springfox的源码时会轻松很多."
  },
  
  {
    "title": "springfox 源码分析(一) 程序入口",
    "url": "/posts/springfox-1/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-21 00:00:00 +0800",
    





    
    "snippet": "日期：2019-5-21 21:05:15地点：家中前言最近也是闲来无事,加上对swagger-bootstrap-ui也已经发布了将近26个稳定版本了,想到很多以后更有趣的功能,从Java底层扩展插件的方式开发出让国人拥有更棒的文档体验,所以决定研究一下springfox的源码，看能否对自己有一些启发.开发一些有趣的功能呢.关于springfox的使用这里不做过多的说明,可以自行搜索查看帮...",
    "content": "日期：2019-5-21 21:05:15地点：家中前言最近也是闲来无事,加上对swagger-bootstrap-ui也已经发布了将近26个稳定版本了,想到很多以后更有趣的功能,从Java底层扩展插件的方式开发出让国人拥有更棒的文档体验,所以决定研究一下springfox的源码，看能否对自己有一些启发.开发一些有趣的功能呢.关于springfox的使用这里不做过多的说明,可以自行搜索查看帮助文档，或者可以参考我提供的swagger-bootstrap-ui-demo进行swagger的集成示例.在读springfox的源码之前,我们需要知道他具体的作用是什么？我觉得有以下几点：  对Spring的RestController、Controller接口进行包装,封装输出为Swagger规范中的path  针对Rest接口涉及到的model进行解析,包括model的属性等  满足文档分组的要求,解析tags总结一句话就是：输出符合Swagger API规范的JSON格式Swagger 规范OpenAPI 2.0 规范可以参考官网地址:https://swagger.io/specification/v2/先来看我们的Swagger规范文件包含哪些元素{    \"swagger\": \"2.0\",    \"info\": {        \"description\": \"&lt;div style='font-size:14px;color:red;'&gt;swagger-bootstrap-ui-demo RESTful APIs&lt;/div&gt;\",        \"version\": \"1.0\",        \"title\": \"swagger-bootstrap-ui很棒~~~！！！\",        \"termsOfService\": \"http://www.group.com/\",        \"contact\": {            \"name\": \"group@qq.com\"        }    },    \"host\": \"127.0.0.1:8999\",    \"basePath\": \"/\",    \"tags\": [        {            \"name\": \"1.8.2版本\",            \"description\": \"Api 182 Controller\"        }    ],    \"paths\": {        \"/2/api/new187/postRequest\": {            \"post\": {                \"tags\": [                    \"api-1871-controller\"                ],                \"summary\": \"版本2-post请求参数Hidden属性是否生效\",                \"operationId\": \"postRequestUsingPOST_1\",                \"consumes\": [                    \"application/json\"                ],                \"produces\": [                    \"*/*\"                ],                \"parameters\": [                    {                        \"in\": \"body\",                        \"name\": \"model187\",                        \"description\": \"model187\",                        \"required\": true,                        \"schema\": {                            \"originalRef\": \"Model187\",                            \"$ref\": \"#/definitions/Model187\"                        }                    }                ],                \"responses\": {                    \"200\": {                        \"description\": \"OK\",                        \"schema\": {                            \"originalRef\": \"Rest«Model187»\",                            \"$ref\": \"#/definitions/Rest«Model187»\"                        }                    },                    \"201\": {                        \"description\": \"Created\"                    },                    \"401\": {                        \"description\": \"Unauthorized\"                    },                    \"403\": {                        \"description\": \"Forbidden\"                    },                    \"404\": {                        \"description\": \"Not Found\"                    }                },                \"security\": [                    {                        \"BearerToken\": [                            \"global\"                        ]                    },                    {                        \"BearerToken1\": [                            \"global\"                        ]                    }                ],                \"deprecated\": false            }        }    },    \"securityDefinitions\": {        \"BearerToken\": {            \"type\": \"apiKey\",            \"name\": \"Authorization\",            \"in\": \"header\"        }    },    \"definitions\": {        \"AInfoVo\": {            \"type\": \"object\",            \"required\": [                \"aId\",                \"bList\"            ],            \"properties\": {                \"aId\": {                    \"type\": \"string\",                    \"description\": \"A记录主键\"                },                \"bList\": {                    \"type\": \"object\",                    \"description\": \"B信息Map, key为BInfoVo的主键pkId\",                    \"additionalProperties\": {                        \"originalRef\": \"BInfoVo\",                        \"$ref\": \"#/definitions/BInfoVo\"                    }                }            },            \"title\": \"AInfoVo\",            \"description\": \"A信息\"        },        \"ActInteger\": {            \"type\": \"object\",            \"properties\": {                \"doub1\": {                    \"type\": \"number\",                    \"format\": \"double\",                    \"description\": \"double类型属性\"                },                \"float1\": {                    \"type\": \"number\",                    \"format\": \"float\",                    \"description\": \"float类型属性\"                },                \"name\": {                    \"type\": \"string\"                },                \"number\": {                    \"type\": \"integer\",                    \"format\": \"int64\",                    \"description\": \"Long类型\"                },                \"price\": {                    \"type\": \"number\",                    \"description\": \"BigDecimal类型属性\"                },                \"sort\": {                    \"type\": \"integer\",                    \"format\": \"int32\",                    \"description\": \"int类型\"                }            },            \"title\": \"ActInteger\"        },        \"Actor\": {            \"type\": \"object\",            \"properties\": {                \"address\": {                    \"type\": \"string\"                },                \"deepOne\": {                    \"originalRef\": \"DeepOne\",                    \"$ref\": \"#/definitions/DeepOne\"                },                \"recipt\": {                    \"originalRef\": \"Recipt\",                    \"$ref\": \"#/definitions/Recipt\"                },                \"sort\": {                    \"type\": \"integer\",                    \"format\": \"int32\"                }            },            \"title\": \"Actor\"        }    }}一个标准的Swagger接口规范可能类似上面的JSON文件,主要有以下属性:  swagger:当前swagger的版本号  info:文档的基础信息,包括描述信息,标题、作者、host等  tags：分组tag标志  paths:接口明细集合  securityDefinitions:权限信息  definitions：接口涉及到的Model类型定义使用我们对Swagger的规范定义有了一个初步的了解,所以,接下来,我们来查看springfox是如何来实现的我们在使用springfox-swagger的时候主要有两步：  创建Docket实例对象,并使用@Bean注解注入到Spring容器中  在Swagger的配置类上添加@EnableSwagger2注解开始我们从springfox的使用文档上来看,也仅仅知道告诉我们开发人员,需要从@EnableSwagger2这个注解入手,来跟踪springfox的创建流程但是我在看了该注解后,发现其实并不是这样,springfox源码中使用了大量的Spring的@Component注解进行实体bean的注入,所以要想找到各个类的依赖关系可以说是相当复杂,加上使用了Spring项目中并不怎么流行的spring-plugin组件,这更加增加了的阅读源码的难度，说实话,看过之后,已经留下了眼泪(这乱七八糟的什么玩意儿:( )…..@EnableSwagger2先来看EnableSwagger2注解的代码package springfox.documentation.swagger2.annotations;import org.springframework.context.annotation.Import;import springfox.documentation.swagger2.configuration.Swagger2DocumentationConfiguration;import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;/** * 配合Java配置注解@Configuration使用,启用Swagger的配置注解,使用@Import注解导入Swagger文档的Configuration配置初始化类 * @see springfox.documentation.spring.web.plugins.Docket */@Retention(value = java.lang.annotation.RetentionPolicy.RUNTIME)@Target(value = { java.lang.annotation.ElementType.TYPE })@Documented@Import({Swagger2DocumentationConfiguration.class})public @interface EnableSwagger2 {}@EnableSwagger2注解只干一件事,导入Swagger2DocumentationConfiguration配置类Swagger2DocumentationConfiguration继续看Swagger2DocumentationConfiguration的代码@Configuration@Import({ SpringfoxWebMvcConfiguration.class, SwaggerCommonConfiguration.class })@ComponentScan(basePackages = {    \"springfox.documentation.swagger2.mappers\"})@ConditionalOnWebApplicationpublic class Swagger2DocumentationConfiguration {  @Bean  public JacksonModuleRegistrar swagger2Module() {    return new Swagger2JacksonModule();  }  @Bean  public HandlerMapping swagger2ControllerMapping(      Environment environment,      DocumentationCache documentationCache,      ServiceModelToSwagger2Mapper mapper,      JsonSerializer jsonSerializer) {    return new PropertySourcedRequestMappingHandlerMapping(        environment,        new Swagger2Controller(environment, documentationCache, mapper, jsonSerializer));  }}从代码中,我们可以得知：  注入JacksonModuleRegistrar实体bean到Spring容器中  注入一个HandlerMapping实体Bean到Spring容器中,该接口就是我们经常所见的/v2/api-docs接口  扫描springfox.documentation.swagger2.mappers包路径，进行实体bean的注入工作  导入SpringfoxWebMvcConfiguration和SwaggerCommonConfiguration配置类既然知道了swagger提供接口代码所在,那么我就先来看看Swagger2Controller的风采@Controller@ApiIgnorepublic class Swagger2Controller {  public static final String DEFAULT_URL = \"/v2/api-docs\";  private static final Logger LOGGER = LoggerFactory.getLogger(Swagger2Controller.class);  private static final String HAL_MEDIA_TYPE = \"application/hal+json\";  private final String hostNameOverride;  private final DocumentationCache documentationCache;  private final ServiceModelToSwagger2Mapper mapper;  private final JsonSerializer jsonSerializer;  @Autowired  public Swagger2Controller(      Environment environment,      DocumentationCache documentationCache,      ServiceModelToSwagger2Mapper mapper,      JsonSerializer jsonSerializer) {    this.hostNameOverride =        environment.getProperty(            \"springfox.documentation.swagger.v2.host\",            \"DEFAULT\");    this.documentationCache = documentationCache;    this.mapper = mapper;    this.jsonSerializer = jsonSerializer;  }  @RequestMapping(      value = DEFAULT_URL,      method = RequestMethod.GET,      produces = { APPLICATION_JSON_VALUE, HAL_MEDIA_TYPE })  @PropertySourcedMapping(      value = \"${springfox.documentation.swagger.v2.path}\",      propertyKey = \"springfox.documentation.swagger.v2.path\")  @ResponseBody  public ResponseEntity&lt;Json&gt; getDocumentation(      @RequestParam(value = \"group\", required = false) String swaggerGroup,      HttpServletRequest servletRequest) {    String groupName = Optional.fromNullable(swaggerGroup).or(Docket.DEFAULT_GROUP_NAME);    Documentation documentation = documentationCache.documentationByGroup(groupName);    if (documentation == null) {      LOGGER.warn(\"Unable to find specification for group {}\", groupName);      return new ResponseEntity&lt;Json&gt;(HttpStatus.NOT_FOUND);    }    Swagger swagger = mapper.mapDocumentation(documentation);    UriComponents uriComponents = componentsFrom(servletRequest, swagger.getBasePath());    swagger.basePath(Strings.isNullOrEmpty(uriComponents.getPath()) ? \"/\" : uriComponents.getPath());    if (isNullOrEmpty(swagger.getHost())) {      swagger.host(hostName(uriComponents));    }    return new ResponseEntity&lt;Json&gt;(jsonSerializer.toJson(swagger), HttpStatus.OK);  }  private String hostName(UriComponents uriComponents) {    if (\"DEFAULT\".equals(hostNameOverride)) {      String host = uriComponents.getHost();      int port = uriComponents.getPort();      if (port &gt; -1) {        return String.format(\"%s:%d\", host, port);      }      return host;    }    return hostNameOverride;  }从接口代码中,我们得知:  springfox为我们提供了一个默认的接口/v2/api-docs  同时我们也应该知道,springfox的初始化工作不在这里,springfox在应用启动时已经初始化好相应的文档对象Documentation,而接口此处仅仅只是从缓存对象中获取而已SpringfoxWebMvcConfiguration通过名称,我们可能也猜到了一部分内容,这是和Spring的webmvc相关的配置类,来看具体代码：@Configuration@Import({ ModelsConfiguration.class })@ComponentScan(basePackages = {    \"springfox.documentation.spring.web.scanners\",    \"springfox.documentation.spring.web.readers.operation\",    \"springfox.documentation.spring.web.readers.parameter\",    \"springfox.documentation.spring.web.plugins\",    \"springfox.documentation.spring.web.paths\"})@EnablePluginRegistries({ DocumentationPlugin.class,    ApiListingBuilderPlugin.class,    OperationBuilderPlugin.class,    ParameterBuilderPlugin.class,    ExpandedParameterBuilderPlugin.class,    ResourceGroupingStrategy.class,    OperationModelsProviderPlugin.class,    DefaultsProviderPlugin.class,    PathDecorator.class,    ApiListingScannerPlugin.class})public class SpringfoxWebMvcConfiguration {  @Bean  public Defaults defaults() {    return new Defaults();  }  @Bean  public DocumentationCache resourceGroupCache() {    return new DocumentationCache();  }  @Bean  public static ObjectMapperConfigurer objectMapperConfigurer() {    return new ObjectMapperConfigurer();  }  @Bean  public JsonSerializer jsonSerializer(List&lt;JacksonModuleRegistrar&gt; moduleRegistrars) {    return new JsonSerializer(moduleRegistrars);  }  @Bean  public DescriptionResolver descriptionResolver(Environment environment) {    return new DescriptionResolver(environment);  }  @Bean  public HandlerMethodResolver methodResolver(TypeResolver resolver) {    return new HandlerMethodResolver(resolver);  }}从代码中能知道：  注入了文档缓存DocumentationCache实体bean  注入了JSON序列化实体bean  通过EnablePluginRegistries注解,开启Spring-Plugin组件的相关插件类,关于Spring-Plugin我们后面会说明  扫描相关package路径  导入ModelsConfiguration配置文件来看ModelsConfiguration配置类有做了那些操作呢@Configuration@ComponentScan(basePackages = {    \"springfox.documentation.schema\"})@EnablePluginRegistries({    ModelBuilderPlugin.class,    ModelPropertyBuilderPlugin.class,    TypeNameProviderPlugin.class,    SyntheticModelProviderPlugin.class})public class ModelsConfiguration {  @Bean  public TypeResolver typeResolver() {    return new TypeResolver();  }}和SpringfoxWebMvcConfiguration配置类行为相似，主要是:  扫描springfox.documentation.schema进行实体bean的注入或者初始化工作  通过EnablePluginRegistries插件开启注入相关插件的实体bean  注入TypeResolver实体bean到Spring容器中SwaggerCommonConfigurationSwagger的公共配置类@Configuration@ComponentScan(basePackages = {    \"springfox.documentation.swagger.schema\",    \"springfox.documentation.swagger.readers\",    \"springfox.documentation.swagger.web\"})public class SwaggerCommonConfiguration {}主要是进行backpage包的扫描,注入到Spring的容器中初始化相关的操作思维导图或许通过一张思维导图,我们能对本小结有一个初步的印象,对@EnableSwagger2注解的做作用有一个初步的了解总结就是两点：  扫描package  注入bean总结整个springfox的初始化工作如果我们从上面来看,那绝对是灾难.心中肯定会有诸多疑问：  我们通过在外部创建Docket对象,提供诸如扫描接口包路径的方式进行文档分组,springfox何时初始化？  分组的接口代码在哪儿?  初始化的入口在哪儿?这主要是因为Springfox使用Spring的@Component注解和ComponentScan扫描包导致的,让我们无从下手啊（累觉不爱）~~~~带着这些疑问,我们继续往下看~~！"
  },
  
  {
    "title": "springfox 源码系列",
    "url": "/posts/springfox-0/",
    "categories": "springfox",
    "tags": "",
    "date": "2019-05-20 00:00:00 +0800",
    





    
    "snippet": "最近闲来无事,之前在开发过程中一直在用到springfox来生成swagger的文档,但一直对springfox的源码尚未研究,所以决定对源码进行探究一番.在这个浮躁的社会中,我们唯一能做到的就是做好自己。springfox-swagger版本号：2.9.2Github:https://github.com/springfox/springfox官方文档：http://springfox.g...",
    "content": "最近闲来无事,之前在开发过程中一直在用到springfox来生成swagger的文档,但一直对springfox的源码尚未研究,所以决定对源码进行探究一番.在这个浮躁的社会中,我们唯一能做到的就是做好自己。springfox-swagger版本号：2.9.2Github:https://github.com/springfox/springfox官方文档：http://springfox.github.io/springfox/目前的章节：  springfox 源码分析(一) 程序入口  springfox 源码分析(二) 初探mapstruct  springfox 源码分析(三) 初探Spring Plugin插件系统  springfox 源码分析(四) 配置类初始化  springfox 源码分析(五) web配置类Plugin插件的使用  springfox 源码分析(六) web配置类扫描包作用探索  springfox 源码分析(七) 文档初始化-DocumentationContext  springfox 源码分析(八) 遍历接口获取Model对象  springfox 源码分析(九) 文档初始化-分组  springfox 源码分析(十) 遍历接口获取Model对象  springfox 源码分析(十一) 自定义添加Swagger Models功能实现  springfox 源码分析(十二) 遍历接口获取ApiDescription集合  springfox 源码分析(十三) 自定义扩展实现接口的排序  springfox 源码分析(十四) 归档得到ApiListing接口集合  springfox 源码分析(十五) 归档得到Documentation文档对象  springfox 源码分析(十六) 分组接口swagger-resouces  springfox 源码分析(十七) Swagger2接口文档示例接口api-docs  springfox 源码分析(十八) 自定义扩展实现分组的排序  springfox 源码分析(十九) guava库学习  springfox 源码分析(二十) 自定义扩展实现Map、JSONObject等动态字段显示  springfox 源码分析(二十一) 忽略参数Class类型  springfox 源码分析(二十二) 总结"
  },
  
  {
    "title": "mybatis 源码系列(八) Java基础之wait()、notify()、notifyAll()方法",
    "url": "/posts/mybatis-8/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-19 00:00:00 +0800",
    





    
    "snippet": "在研究mybatis的连接池数据源源码时,我们看到了wait()、notifyAll()方法的使用,工作中因为很少使用到这类方法的调用,所以，其中概念也有些模糊了,写一遍博客记录一下.在读取mybatis提供的PooledDataSource源码中,获取PooledConnection对象时如果最大活动连接数达到上限后,则调用wait()方法等待,当调用close关闭连接时,再调用notif...",
    "content": "在研究mybatis的连接池数据源源码时,我们看到了wait()、notifyAll()方法的使用,工作中因为很少使用到这类方法的调用,所以，其中概念也有些模糊了,写一遍博客记录一下.在读取mybatis提供的PooledDataSource源码中,获取PooledConnection对象时如果最大活动连接数达到上限后,则调用wait()方法等待,当调用close关闭连接时,再调用notify方法唤起等待的线程.先来看jdk中的注释/**     * Causes the current thread to wait until another thread invokes the     * {@link java.lang.Object#notify()} method or the     * {@link java.lang.Object#notifyAll()} method for this object.     * In other words, this method behaves exactly as if it simply     * performs the call {@code wait(0)}.     * &lt;p&gt;     * The current thread must own this object's monitor. The thread     * releases ownership of this monitor and waits until another thread     * notifies threads waiting on this object's monitor to wake up     * either through a call to the {@code notify} method or the     * {@code notifyAll} method. The thread then waits until it can     * re-obtain ownership of the monitor and resumes execution.     * &lt;p&gt;     * As in the one argument version, interrupts and spurious wakeups are     * possible, and this method should always be used in a loop:     * &lt;pre&gt;     *     synchronized (obj) {     *         while (&amp;lt;condition does not hold&amp;gt;)     *             obj.wait();     *         ... // Perform action appropriate to condition     *     }     * &lt;/pre&gt;     * This method should only be called by a thread that is the owner     * of this object's monitor. See the {@code notify} method for a     * description of the ways in which a thread can become the owner of     * a monitor.     *     * @throws  IllegalMonitorStateException  if the current thread is not     *               the owner of the object's monitor.     * @throws  InterruptedException if any thread interrupted the     *             current thread before or while the current thread     *             was waiting for a notification.  The &lt;i&gt;interrupted     *             status&lt;/i&gt; of the current thread is cleared when     *             this exception is thrown.     * @see        java.lang.Object#notify()     * @see        java.lang.Object#notifyAll()     */public final void wait() throws InterruptedException {    wait(0);}/**     * Wakes up a single thread that is waiting on this object's     * monitor. If any threads are waiting on this object, one of them     * is chosen to be awakened. The choice is arbitrary and occurs at     * the discretion of the implementation. A thread waits on an object's     * monitor by calling one of the {@code wait} methods.     * &lt;p&gt;     * The awakened thread will not be able to proceed until the current     * thread relinquishes the lock on this object. The awakened thread will     * compete in the usual manner with any other threads that might be     * actively competing to synchronize on this object; for example, the     * awakened thread enjoys no reliable privilege or disadvantage in being     * the next thread to lock this object.     * &lt;p&gt;     * This method should only be called by a thread that is the owner     * of this object's monitor. A thread becomes the owner of the     * object's monitor in one of three ways:     * &lt;ul&gt;     * &lt;li&gt;By executing a synchronized instance method of that object.     * &lt;li&gt;By executing the body of a {@code synchronized} statement     *     that synchronizes on the object.     * &lt;li&gt;For objects of type {@code Class,} by executing a     *     synchronized static method of that class.     * &lt;/ul&gt;     * &lt;p&gt;     * Only one thread at a time can own an object's monitor.     *     * @throws  IllegalMonitorStateException  if the current thread is not     *               the owner of this object's monitor.     * @see        java.lang.Object#notifyAll()     * @see        java.lang.Object#wait()     */public final native void notify();通过查看JDK的注释方法,我们应该知道：  不管是wait方法或者notify、notifyAll,调用方法必须在synchronized同步代码块中,也就是说当前线程必须拥有对象的监视器,这样做的原因是防止线程信号丢失,否则会抛出IllegalMonitorStateException异常。  调用wait()方法前的检查操作必须使用while循环，有时在没有调用notify()方法的情况下,线程会被重新激活等待，使用if会造成虚假唤醒的问题，而使用while循环可以确保条件被检查到  如果是一个线程的话,notify和notifyAll效果一样,如果是多个线程的情况下,notify只会随机唤醒其中一个线程,而notifyAll会唤醒所有线程,唤醒后的所有线程会竞争获取对象锁.  另外,尽量避免在同步块中获取锁,或者调用外部方法(因为你不知道这个方法会发生什么),尽量避免造成死锁  如果你不知道自己在做什么的话,或者对notify不是很清楚,请使用notifyAll代替为了达到上面的效果,可以写一个简单的阻塞队列实现BlockingQueue首先我们应该抽取相应的条件：  队列有大小,也就是说我们的队里中如果已满,则线程必须等待  如果队里已经消费,则需要唤醒等待的线程,可以重新加入数据BlockingQueue.java/*** * * @since:mybatis-advance 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2019/05/20 21:41 */public class BlockingQueue&lt;T&gt; {    /**     * 容量     */    private int capacity;    private Queue&lt;T&gt; queue=new LinkedList&lt;&gt;();    public BlockingQueue(int capacity) {        this.capacity = capacity;    }    /***     * 添加元素     * @param t     */    public void add(T t){        synchronized (this){            //如果队列已满,wait等待            while (queue.size()==capacity){                try {                    wait();                } catch (InterruptedException e) {                    e.printStackTrace();                }            }            queue.add(t);            //已经添加元素,唤醒消费线程            notifyAll();        }    }    /***     * 获取元素     * @return     */    public T get(){        T obj=null;        //获取对象锁        synchronized (this){            //如果当前队列中没有数据,则等待            while (queue.isEmpty()){                try {                    wait();                } catch (InterruptedException e) {                    e.printStackTrace();                }            }            obj=queue.remove();            //获取得到obj,唤醒其他线程            notifyAll();            return obj;        }    }}此时,如果我们用两个线程来测试一下：public static void main(String[] args) {        BlockingQueue&lt;String&gt; blockingQueue=new BlockingQueue&lt;&gt;(10);        Thread t=new Thread(new Runnable() {            @Override            public void run() {                //provider                while (true){                    blockingQueue.add(\"test\");                }            }        });        t.start();        Thread tc=new Thread(new Runnable() {            @Override            public void run() {                while (true){                    System.out.println(\"获取的数据:\"+blockingQueue.get());                }            }        });        tc.start();    }tc线程会一直输出,这是因为我们的add数据和get数据都是一对一的，而我们的容量是10，这不会造成阻塞,如果我们有多个生成者,而只有一个消费者呢,此时我们改一下代码public static void main(String[] args) {    BlockingQueue&lt;String&gt; blockingQueue=new BlockingQueue&lt;&gt;(10);    for (int i=0;i&lt;10;i++){        Provider p=new Provider(blockingQueue);        p.setName(\"线程\"+i);        p.start();    }    //创建2个消费线程    for (int i=0;i&lt;2;i++){        Consumer c=new Consumer(blockingQueue);        c.setName(\"消费线程\"+i);        c.start();    }}private static class Provider extends Thread{    private final BlockingQueue&lt;String&gt; blockingQueue;    public Provider(BlockingQueue&lt;String&gt; blockingQueue) {        this.blockingQueue=blockingQueue;    }    @Override    public void run() {        while (true){            blockingQueue.add(Thread.currentThread().getName()+\"--产生的数据\");        }    }}private static class Consumer extends Thread{    private final BlockingQueue&lt;String&gt; blockingQueue;    public Consumer(BlockingQueue&lt;String&gt; blockingQueue) {        this.blockingQueue = blockingQueue;    }    public void run(){        while (true){            System.out.println(Thread.currentThread().getName()+\"---------&gt;\"+blockingQueue.get());        }    }}"
  },
  
  {
    "title": "mybatis 源码系列(七) Java基础之数据库事务隔离级别",
    "url": "/posts/mybatis-7/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-18 00:00:00 +0800",
    





    
    "snippet": "正确设置数据库的事务访问级别,有助于我们的应用程序达到预期的效果在mybatis中,提供了事务隔离级别的枚举类：org.apache.ibatis.session.TransactionIsolationLevel.java来看具体代码：/** * @author Clinton Begin */public enum TransactionIsolationLevel {  NONE(Co...",
    "content": "正确设置数据库的事务访问级别,有助于我们的应用程序达到预期的效果在mybatis中,提供了事务隔离级别的枚举类：org.apache.ibatis.session.TransactionIsolationLevel.java来看具体代码：/** * @author Clinton Begin */public enum TransactionIsolationLevel {  NONE(Connection.TRANSACTION_NONE),  READ_COMMITTED(Connection.TRANSACTION_READ_COMMITTED),  READ_UNCOMMITTED(Connection.TRANSACTION_READ_UNCOMMITTED),  REPEATABLE_READ(Connection.TRANSACTION_REPEATABLE_READ),  SERIALIZABLE(Connection.TRANSACTION_SERIALIZABLE);  private final int level;  private TransactionIsolationLevel(int level) {    this.level = level;  }  public int getLevel() {    return level;  }}从代码中,我们看到,mybatis维护了一份Connection连接的事务隔离级别枚举类,作用仅仅是简化变量,方便程序调用.那么,其中几个事务隔离级别具体代表什么意思呢?            英文名称      中文说明                         READ_COMMITTED      禁止脏读,允许不可重复读和幻读,此级别仅禁止事务读取具有未提交更改的行。      2              READ_UNCOMMITTED      允许脏读,不可重复读和幻读,此级别允许在提交该行中的任何更改（“脏读”）之前，由另一个事务读取由一个事务更改的行,如果回滚任何更改，则第二个事务将检索到无效行。      1              REPEATABLE_READ      禁止脏读和不可重复读,允许幻读,此级别禁止事务读取具有未提交更改的行，并且还禁止一个事务读取行，第二个事务更改行，第一个事务重新读取行，第二次获取不同值的情况（ “不可重复读”）。      4              SERIALIZABLE      事务最高隔离级别,禁止脏读、幻读和不可重复读      8      看了Java中JDK的注释,我们首先需要明白何为脏读、不可重复读及幻读何为事务在理解事务隔离级别之前,我们需要知道事务是什么,有什么作用?当应用程序被许多用户访问获取数据信息时,或者一个用户发出了多次请求时,为使用户获取的数据是完整的是非常重要的事情,而如何保证数据完整性在数据库中称为事务为确保数据完整性,事务需要遵循四个条件：原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)、持久性(Durability),也就是我们通常所说的ACID可以查阅mariadb的数据库理论文档,充分了解事务  题外话,最近在写博客温习这些知识的期间,有些不明白的还是会在网上查询资料,加深自己的理解,但我发现国内的很多篇幅都介绍的很片面,所以我建议大家都读英文文章,特别是官方文档，就算是一个单词一个单词的啃,对自己理解这个知识点会深刻许多，再结合自己工作中学到的,会事半功倍.原子性(Atomicity)我们都知道,原子是原子是元素中的最小单元那么在事务中,我们把他理解为一个操作要么成功,要么失败,除了这两种,没有其他情况发生.原子性意味着整个交易必须完成。如果不是这种情况，则中止整个事务。 这可确保数据库永远不会留下部分完成的事务，从而导致数据完整性不佳。例如，如果您从一个银行帐户中删除资金，但第二个请求失败且系统无法将资金存入另一个银行，则两个请求都必须失败。 这笔钱不能简单地丢失，也不能从一个帐户中取出而不会进入另一个帐户。一致性(Consistency)一致性是指满足某些条件时数据所处的状态。这个我认为需要结合应用程序来说,因为数据库中的数据状态的变更,都是由我们的应用程序来修改的,数据状态从一个状态变为另外一个状态，这其中的过程是不可见的通过满足我们的业务需求条件,最终将数据的状态设置为我们的认为正确的状态,这就是数据一致性一致性是目的(我们希望看到的数据状态)，而AID是手段隔离性(Isolation)隔离意味着在第一个事务完成之前，另一个事务不能使用在处理一个事务期间使用的任何数据。例如，如果两个人将100美元存入另一个账户，余额为900美元，则第一笔交易必须加100美元至900美元，第二笔交易必须加100美元至1000美元。 如果第二笔交易在第一笔交易完成前读取900美元，那么这两笔交易似乎都会成功，但100美元将会丢失。 第二个事务必须等到它一个人访问数据。也就是事务之间是相互隔离的通过上面的例子,我们也有所了解到隔离性也是确保我们的数据状态的一致持久性(Durability)持久性是指一旦事务中的数据被提交，即使系统出现故障，其影响也将保持不变。 当交易正在进行时，效果并不持久。 如果数据库崩溃，备份将始终在事务开始之前将其还原到一致状态。 交易没有什么能够改变这个事实。我所理解的是事务持久性即事务一旦提交,那么所影响的记录行会持久化保存在我们的磁盘上,及时业务系统崩溃,也不会影响我们的数据(如果你说磁盘蹦了那我也只能漏出尴尬而不失礼貌的微笑了)事务隔离级别为了得到更详细的说明,我查看了mariadb的官方文档介绍READ UNCOMMITTED(读取未提交)SELECT语句以非锁定方式执行,但可能会使用行的早期版本。因此,使用此隔离级别,会导致非一致性.也叫”脏读”,就好像读取到了未提交的行一样.READ COMMITTED(读取提交)读取提交内容,关于一致性（非锁定）读取的类似Oracle的隔离级别：即使在同一事务中，每个一致性读取使之读取到的内容都是自己的新快照对于锁定读取（SELECT FOR FOR UPDATE或LOCK IN SHARE MODE），InnoDB仅锁定索引记录，允许在锁定记录旁边自由插入新记录，对于UPDATE和DELETE语句，锁定取决于语句是使用具有唯一搜索条件的唯一索引（例如WHERE id = 100）还是范围类型搜索条件（例如WHERE id&gt; 100）。对于具有唯一搜索条件的唯一索引，InnoDB仅锁定找到的索引记录，而不是之前的间隙。对于范围类型搜索，InnoDB使用间隙锁或下一键（间隙加索引记录）锁来锁定扫描的索引范围，以阻止其他会话插入范围所涵盖的间隙。这是必要的，因为必须阻止“幻像行”才能使MySQL复制和恢复正常工作REPEATABLE READ(可重读)这是InnoDB存储引擎的默认事务隔离级别,关于一致性读取,这和READ COMMITTED事务隔离级别有很大的不同,同一事务中的所有一致读取读取第一次读取建立的快照。此约定意味着如果在同一事务中发出多个普通（非锁定）SELECT语句，则这些SELECT语句也相互一致使用锁读取的SELECT语句（FOR UPDATE或LOCK IN SHARE MODE ），UPDATE和DELETE语句，锁定取决于语句是否使用具有唯一搜索条件的唯一索引，或范围类型的搜索条件。对于具有唯一搜索条件的唯一索引，InnoDB仅锁定找到的索引记录，而不是之前的间隙。对于其他搜索条件，InnoDB使用间隙锁或下一键（间隙加索引记录）锁来锁定扫描的索引范围，以阻止其他会话插入范围所覆盖的间隙。这对于并发操作数据库数据获取的数据一致性是有很大的帮助.SERIALIZABLE（可串行化)这个级别就像REPEATABLE READ，但InnoDB隐式地将所有普通SELECT语句转换为SELECT lock …如果禁用自动提交，则锁定共享模式。如果启用了自动提交，则SELECT是其自己的事务。因此，已知它是只读的，并且如果作为一致（非锁定）读取执行则可以序列化，并且不需要阻止其他事务。（这意味着如果其他事务已修改所选行，则强制普通SELECT阻止，您应禁用自动提交。）分布式XA事务始终应用是该隔离级别数据库模拟脏读顾名思义,在一个事务中读取到了不该读到的数据,举例来说明:目前我们有User信息表(id,age,name),假设当前有A、B两个事务对该User表进行操作我们要模拟脏读的场景,首先就需要先设置我们当前数据库连接的事务隔离级别,设置为允许脏读,通过上面的说明,需要设置为READ_UNCOMMITED隔离级别先来查看mariadb中的默认隔离级别，相关的命令可以查阅官方文档：mysql&gt; SELECT @@tx_isolation;+-----------------+| @@tx_isolation  |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.06 sec)mysql&gt;mysql中默认事务隔离借呗为可重复读先设置为READ_UNCOMMITTED级别mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;Query OK, 0 rows affected (0.04 sec)mysql&gt; SELECT @@tx_isolation;+------------------+| @@tx_isolation   |+------------------+| READ-UNCOMMITTED |+------------------+1 row in set (0.06 sec)mysql&gt; 先看A事务开启事务,查询User信息表:mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;+----+-----+-------+| id | age | name  |+----+-----+-------+|  1 |  33 | 23    ||  2 |  33 | abc   ||  3 |  12 | ab3ec ||  4 |  12 | ab3ec ||  5 |  12 | ab3ec |+----+-----+-------+5 rows in set (0.03 sec)此时,开启B事务,修改User表中id=1的name值,但是并不提交当前事务mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; update user set name='ccccccccccccc' where id=1;Query OK, 1 row affected (0.19 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from user;+----+-----+---------------+| id | age | name          |+----+-----+---------------+|  1 |  33 | ccccccccccccc ||  2 |  33 | abc           ||  3 |  12 | ab3ec         ||  4 |  12 | ab3ec         ||  5 |  12 | ab3ec         |+----+-----+---------------+5 rows in set (0.11 sec)我们在B事务中修改后,在查询User信息,发现id=1的name值已发生变化,此时我们在回到A事务中查询User信息表mysql&gt; select * from user;+----+-----+---------------+| id | age | name          |+----+-----+---------------+|  1 |  33 | ccccccccccccc ||  2 |  33 | abc           ||  3 |  12 | ab3ec         ||  4 |  12 | ab3ec         ||  5 |  12 | ab3ec         |+----+-----+---------------+5 rows in set (0.11 sec)A事务已经读取到了B事务对记录行的修改，但是B事务并未提交,这就是所谓的”脏读”了，此时我们回滚B事务mysql&gt; rollback;Query OK, 0 rows affected (0.10 sec)再A事务中再查询User信息记录行：mysql&gt; select * from user;+----+-----+-------+| id | age | name  |+----+-----+-------+|  1 |  33 | 23    ||  2 |  33 | abc   ||  3 |  12 | ab3ec ||  4 |  12 | ab3ec ||  5 |  12 | ab3ec |+----+-----+-------+5 rows in set (0.10 sec)发现id=1的User表name信息已经跟随B事务一起回滚掉了.由此我们应该想到,这不是明显不对嘛,我们都知道事务要么成功,要么失败,B事务还未提交的情况下,A事务已经能读取到B事务所做的修改操作,在显示中,加入银行也存在这种操作,那绝对是不允许的,所以在实际生产环境中,READ UNCOMMITTED这一事务隔离级别需要在特定的场合下使用,一般是不能使用的不可重复读在同一个事务之间,两次查询的结果不一致,这有可能是在两次查询之间,另外一个事务对结果记录行做了修改导致的.同样,我们使用A、B两个事务来进行模拟首先,将B事务设置为READ COMMITTED隔离级别：mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.04 sec)A、B事务同时开启事务，此时,查询User信息表的数据都是一致的mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select *from user;+----+-----+------------+| id | age | name       |+----+-----+------------+|  1 |  33 | bbbbbbbbbb ||  2 |  33 | abc        ||  3 |  12 | ab3ec      ||  4 |  12 | ab3ec      ||  5 |  12 | ab3ec      |+----+-----+------------+5 rows in set (0.05 sec)此时，A事务修改user表中id=1的name属性值,但并提交mysql&gt; update user set name='aaaaaaaaaaaaaaaaaa' where id=1;我们在B事务中进行查询mysql&gt; select *from user;+----+-----+------------+| id | age | name       |+----+-----+------------+|  1 |  33 | bbbbbbbbbb ||  2 |  33 | abc        ||  3 |  12 | ab3ec      ||  4 |  12 | ab3ec      ||  5 |  12 | ab3ec      |+----+-----+------------+5 rows in set (0.05 sec)发现数据并未产生变化，此时我们提交A事务mysql&gt; commit;Query OK, 0 rows affected (0.11 sec)再在B事务中查询User表信息mysql&gt; select *from user;+----+-----+--------------------+| id | age | name               |+----+-----+--------------------+|  1 |  33 | aaaaaaaaaaaaaaaaaa ||  2 |  33 | abc                ||  3 |  12 | ab3ec              ||  4 |  12 | ab3ec              ||  5 |  12 | ab3ec              |+----+-----+--------------------+5 rows in set (0.11 sec)此时，B事务已经读取到A事务提交的影响记录，id=1的name值已更改可重复读在上面说明中我们知道,同一事务中的所有一致读取读取第一次读取建立的快照同样是A、B两个事务首先将B事务设置为REPEATABLE READ事务隔离级别mysql&gt; select @@tx_isolation;+-----------------+| @@tx_isolation  |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.06 sec)A\\B开启事务,先查询user信息表mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;+----+-----+--------------------+| id | age | name               |+----+-----+--------------------+|  1 |  33 | aaaaaaaaaaaaaaaaaa ||  2 |  33 | abc                ||  3 |  12 | ab3ec              ||  4 |  12 | ab3ec              ||  5 |  12 | ab3ec              |+----+-----+--------------------+5 rows in set (0.09 sec)在B事务中,修改id=1的name值为123456,并提交B事务mysql&gt; update user set name='123456' where id=1;Query OK, 1 row affected (0.05 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from user;+----+-----+--------+| id | age | name   |+----+-----+--------+|  1 |  33 | 123456 ||  2 |  33 | abc    ||  3 |  12 | ab3ec  ||  4 |  12 | ab3ec  ||  5 |  12 | ab3ec  |+----+-----+--------+5 rows in set (0.10 sec)mysql&gt; commit;Query OK, 0 rows affected (0.16 sec)B事务未提交,在B事务查询,User信息变更,此时，我们在A事务中查询user表信息mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;+----+-----+--------------------+| id | age | name               |+----+-----+--------------------+|  1 |  33 | aaaaaaaaaaaaaaaaaa ||  2 |  33 | abc                ||  3 |  12 | ab3ec              ||  4 |  12 | ab3ec              ||  5 |  12 | ab3ec              |+----+-----+--------------------+5 rows in set (0.09 sec)mysql&gt; select * from user;+----+-----+--------------------+| id | age | name               |+----+-----+--------------------+|  1 |  33 | aaaaaaaaaaaaaaaaaa ||  2 |  33 | abc                ||  3 |  12 | ab3ec              ||  4 |  12 | ab3ec              ||  5 |  12 | ab3ec              |+----+-----+--------------------+5 rows in set (0.11 sec)两次读取到的记录是一样的,并未产生任何变化,这也就是和官方说明保持一致,同一事务中的所有一致性查询，都是回去的第一次查询快照.这也就是可重读.此时，我们在提交A事务，再查询User表，发现记录已变更mysql&gt; select * from user;+----+-----+--------+| id | age | name   |+----+-----+--------+|  1 |  33 | 123456 ||  2 |  33 | abc    ||  3 |  12 | ab3ec  ||  4 |  12 | ab3ec  ||  5 |  12 | ab3ec  |+----+-----+--------+5 rows in set (0.13 sec)幻读同一个事务两次查询的数据记录行不一致,导致产生的幻影同样是基于REPEATABLE READ的事务隔离级别开启A\\B事务,查询我们的User表信息mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;+----+-----+--------+| id | age | name   |+----+-----+--------+|  1 |  33 | 123456 ||  2 |  33 | abc    ||  3 |  12 | ab3ec  ||  4 |  12 | ab3ec  ||  5 |  12 | ab3ec  |+----+-----+--------+5 rows in set (0.09 sec)我们在B事务中新增一条数据，并提交mysql&gt; insert into user(id,age,name) values(6,44,'add');Query OK, 1 row affected (0.06 sec)mysql&gt; commit;Query OK, 0 rows affected (0.10 sec)此时，A事务中查询User信息表mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;+----+-----+--------+| id | age | name   |+----+-----+--------+|  1 |  33 | 123456 ||  2 |  33 | abc    ||  3 |  12 | ab3ec  ||  4 |  12 | ab3ec  ||  5 |  12 | ab3ec  |+----+-----+--------+5 rows in set (0.09 sec)我们发现A事务中并未读取到B事务提交的新记录行数,这就是幻读.提交A事务,在进行读取mysql&gt; commit;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from user;+----+-----+--------+| id | age | name   |+----+-----+--------+|  1 |  33 | 123456 ||  2 |  33 | abc    ||  3 |  12 | ab3ec  ||  4 |  12 | ab3ec  ||  5 |  12 | ab3ec  ||  6 |  44 | add    |+----+-----+--------+6 rows in set (0.11 sec)mysql&gt; 此时已经读取到新的记录行了.可重复读隔离级别只允许读取已提交记录，而且在一个事务两次读取一个记录期间，其他事务部的更新该记录。但该事务不要求与其他事务可串行化总结或许根据事务隔离级别的字面意思，做一个简单的总结READ UNCOMMITTED:意思是一个事务可以读取另外一个事务(未提交)所做的操作,那么此操作给开发者所造成的影响即有可能是脏读、不可重复读、和幻读READ COMMITTED:意思是只能读取已提交的内容,这就避免的脏读的出现,但是在一个事务操作期间,另外一个事务对记录行产生了的变化,这就导致了可以不可重复读(A事务两次读取数据不一样)和幻读REPEATABLE READ:意思是可重复读，此级别是和READ COMMITTED一致性读取有相似点,却也有不同点,首先是不允许脏读，读取的内容都是已提交的。其二从字面意思来看也能理解,允许重复读，所以它是禁止不可重复读的,当然，幻读允许存在SERIALIZABLE:可串行化,我是这么理解的，串行化的操作既是一个操作连接着一个操作，就是事情总有先后,所以当一个事务正在操作的时候,其他事务必须等待，等操作的事务操作完成后,其他事务即可以进行操作,我们都知道事务是原子性的,所以该级别的隔离级别不允许脏读、不可重复读、和幻读.我们在理解了以上的基础概念后,后面再来读mybatis的事务相关代码,会让我们更轻松.最后我不能保证我所说的都一定是正确的,但我会确保每一个词,每一个用意都是根据自身的理解结合官方文档所总结的,如果其中任然有纰漏,欢迎同行中的朋友加以指正,我会虚心接受学习."
  },
  
  {
    "title": "mybatis 源码系列(六) 设计模式",
    "url": "/posts/mybatis-6/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-17 00:00:00 +0800",
    





    
    "snippet": "以前我们在学习Java的时候,都会将Java中的设计模式,记忆中用的比较多的好像有23种吧,但是这些设计模式其实自己在工作中除了那么几种几乎很少用到.不过最近在看mybatis的源码,看到了很多设计模式的应用,因此,想把这些在mybatis中运用的设计模式都记录下来,加深自己的印象和理解,后面也可以在工作中更多的去使用它写代码是们艺术活  你是否会看某些代码而入迷呢?Builder模式提供一...",
    "content": "以前我们在学习Java的时候,都会将Java中的设计模式,记忆中用的比较多的好像有23种吧,但是这些设计模式其实自己在工作中除了那么几种几乎很少用到.不过最近在看mybatis的源码,看到了很多设计模式的应用,因此,想把这些在mybatis中运用的设计模式都记录下来,加深自己的印象和理解,后面也可以在工作中更多的去使用它写代码是们艺术活  你是否会看某些代码而入迷呢?Builder模式提供一个Builder建造器,通过隐藏目标对象的复杂属性，而是通过Bulder来一步一步赋值目标对象属性,最终Builder构建目标对象,这个在mybatis中的Envionment类中的Builder已使用先来看org.apache.ibatis.mapping.Envionment.java/** * 环境对象 * @author Clinton Begin */public final class Environment {  /***   * 环境id,例如：dev、prod   */  private final String id;  /***   * 事务工厂   */  private final TransactionFactory transactionFactory;  /***   * 数据库连接数据源对象   */  private final DataSource dataSource; //getter and setters and  constructs           /***   * Builder构造器   * 比如   * new Builder(\"dev\").dataSource(ds).transactionFactory(tf).build();   */  public static class Builder {      private String id;      private TransactionFactory transactionFactory;      private DataSource dataSource;    public Builder(String id) {      this.id = id;    }    public Builder transactionFactory(TransactionFactory transactionFactory) {      this.transactionFactory = transactionFactory;      return this;    }    public Builder dataSource(DataSource dataSource) {      this.dataSource = dataSource;      return this;    }    public String id() {      return this.id;    }    public Environment build() {      return new Environment(this.id, this.transactionFactory, this.dataSource);    }  }    }通过上面的Builder，我们就可以使用这一的代码来构建我们的Environment对象//属性之数据源DataSource dataSource=null;//属性之事务管理器TransactionFactory transactionFactory=null;//基于Builder来构建Environment environment=new Environment.Builder(\"dev\").dataSource(dataSource).transactionFactory(transactionFactory).build();//根据构造函数来构建Environment environment1=new Environment(\"prod\",transactionFactory,dataSource);这只是提供了一种快捷的创建对象的方式,最终build()方法也是调用目标对象的构造函数来进行构建,根据开发者喜欢可以自行使用."
  },
  
  {
    "title": "mybatis 源码系列(五) 数据源DataSource",
    "url": "/posts/mybatis-5/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-16 00:00:00 +0800",
    





    
    "snippet": "在第四章节中,我们分析里数据库驱动Driver的加载方式,其中有提到mybatis的数据源，我们都知道,Java中的SQL规范java.sql.DataSource是一个接口,而我们在生产环境中一般都是基于数据库的连接池技术来获取数据库连接以操作数据库的.通常为我们所知的主流数据源主要有：druid、c3p0、dbcp,HikariCP等等这些都是帮助我们实现的在数据库连接池技术上非常好的技...",
    "content": "在第四章节中,我们分析里数据库驱动Driver的加载方式,其中有提到mybatis的数据源，我们都知道,Java中的SQL规范java.sql.DataSource是一个接口,而我们在生产环境中一般都是基于数据库的连接池技术来获取数据库连接以操作数据库的.通常为我们所知的主流数据源主要有：druid、c3p0、dbcp,HikariCP等等这些都是帮助我们实现的在数据库连接池技术上非常好的技术中间件,我们只需要引入相关的Jar包即可引用类型而这一节我们主要研究mybatis给我们提供的默认数据源mybatis中的数据源主要位于org.apache.ibatis.datasource包下,主要有三种  UnpooledDataSource：非数据库连接池的数据源,每次获取数据库Connection对象都会创建,不会使用数据库连接池  PooledDataSource：数据库连接池数据源  JndiDataSource:通过容器获取数据源先来看整个类图关系数据源工厂先来看mybatis中的数据源工厂父类,DataSourceFactory.java/** * @author Clinton Begin */public interface DataSourceFactory {  /***   * 设置数据源属性   * @param props   */  void setProperties(Properties props);  /***   * 获取当前数据源实例   * @return   */  DataSource getDataSource();}数据源工厂中主要提供了两个方法：  设置数据源属性  获取数据源有此两个方法,我们来看它的具体实现UnpooledDataSourceFactory非数据库连接池的数据源工厂，UnpooledDataSourceFactory.java/** * @author Clinton Begin */public class UnpooledDataSourceFactory implements DataSourceFactory {  private static final String DRIVER_PROPERTY_PREFIX = \"driver.\";  private static final int DRIVER_PROPERTY_PREFIX_LENGTH = DRIVER_PROPERTY_PREFIX.length();  /****   * 声明数据源   */  protected DataSource dataSource;  /****   * 构造函数   */  public UnpooledDataSourceFactory() {    this.dataSource = new UnpooledDataSource();  }  @Override  public void setProperties(Properties properties) {    Properties driverProperties = new Properties();      //通过反射,获取dataSource的元数据对象,此处dataSource目标是UnpooledDataSource      //关于元数据对象,我们在后面章节研究,此处不做深究    MetaObject metaDataSource = SystemMetaObject.forObject(dataSource);    for (Object key : properties.keySet()) {      String propertyName = (String) key;      if (propertyName.startsWith(DRIVER_PROPERTY_PREFIX)) {        String value = properties.getProperty(propertyName);        driverProperties.setProperty(propertyName.substring(DRIVER_PROPERTY_PREFIX_LENGTH), value);      } else if (metaDataSource.hasSetter(propertyName)) {        String value = (String) properties.get(propertyName);        Object convertedValue = convertValue(metaDataSource, propertyName, value);        metaDataSource.setValue(propertyName, convertedValue);      } else {        throw new DataSourceException(\"Unknown DataSource property: \" + propertyName);      }    }    if (driverProperties.size() &gt; 0) {      metaDataSource.setValue(\"driverProperties\", driverProperties);    }  }  @Override  public DataSource getDataSource() {    return dataSource;  }    //other...}从数据工厂的源码中我们看到,非数据库连接池的数据源最终返回的是UnpooledDataSourcesetProperties方法的主要逻辑：  声明驱动属性配置,从源配置中赋值驱动属性  通过反射获取UnpooledDataSource的元数据对象,对齐属性进行赋值  关于mybatis的元数据对象MetaObject我们不在这章深究,只需要知道这么回事即可,知道他的作用(动态根据Properties对象赋值目标对象UnpooledDataSource的属性)所以通过源码,我们在使用非绑定数据源的方式如下：//创建数据源工厂UnpooledDataSourceFactory unpooledDataSourceFactory=new UnpooledDataSourceFactory();String driver=\"com.mysql.cj.jdbc.Driver\";String url=\"jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true\";String username=\"root\";String password=\"123456\";//赋值propertiesProperties properties=new Properties();properties.setProperty(\"driver\",driver);properties.setProperty(\"url\",url);properties.setProperty(\"username\",username);properties.setProperty(\"password\",password);unpooledDataSourceFactory.setProperties(properties);//如果使用的是UnpooledDataSource数据源,则以上properties属性赋值需要使用UnpooledDataSource的属性值//获取数据源DataSource dataSource=unpooledDataSourceFactory.getDataSource();通过以上代码的方式,我们就能拿到DataSource的实例,从而获取数据库连接Connection对象UnpooledDataSource此时,我们来看UnpooledDataSource的具体实现UnpooledDataSource主要包含的属性            属性      说明                  driverClassLoader      当前驱动类的ClassLoader实例              driverProperties      驱动类的属性              registeredDrivers      注册驱动类              driver      数据库驱动              url      数据库连接地址              username      用户名              password      密码              autoCommit      是否自动提交              defaultTransactionIsolationLevel      事务隔离级别      非数据池的获取数据库连接方式很简单,代码如下：@Overridepublic Connection getConnection() throws SQLException {    return doGetConnection(username, password);}/***   * 获取数据连接对象   * @param properties   * @return   * @throws SQLException   */private Connection doGetConnection(Properties properties) throws SQLException {    //初始化Driver驱动    initializeDriver();    //获取连接    Connection connection = DriverManager.getConnection(url, properties);    //配置连接属性,主要是是否自动提交和事务隔离级别    configureConnection(connection);    return connection;}/****   * 配置Connection连接对象的属性   * @param conn   * @throws SQLException   */private void configureConnection(Connection conn) throws SQLException {    //是否自动提交    if (autoCommit != null &amp;&amp; autoCommit != conn.getAutoCommit()) {        conn.setAutoCommit(autoCommit);    }    //设置事务级别    if (defaultTransactionIsolationLevel != null) {        conn.setTransactionIsolation(defaultTransactionIsolationLevel);    }}获取数据库连接Connection对象的方式是每次都通过DriverManager来获取连接,不做连接池、缓存等处理.PooledDataSourceFactory通过上面的程序类图,我们其实已经知道,PooledDataSourceFactory其实是继承自UnPooledDataSourceFactory来看代码：public class PooledDataSourceFactory extends UnpooledDataSourceFactory {  public PooledDataSourceFactory() {      //dataSource数据源此处为PooledDataSource    this.dataSource = new PooledDataSource();  }}PooledDataSource源码来看使用连接池的数据源/** * 这是一个简单，同步，线程安全的数据库连接池。 * * @author Clinton Begin */public class PooledDataSource implements DataSource {  private static final Log log = LogFactory.getLog(PooledDataSource.class);  /***   * 连接池状态   */  private final PoolState state = new PoolState(this);  private final UnpooledDataSource dataSource;  // OPTIONAL CONFIGURATION FIELDS  /***   * 连接池活动最大连接数   */  protected int poolMaximumActiveConnections = 10;  /***   * 连接池最大空闲连接数量   */  protected int poolMaximumIdleConnections = 5;  /***   * 最大checkout时间,默认20秒   */  protected int poolMaximumCheckoutTime = 20000;  /***   * 等待时间   */  protected int poolTimeToWait = 20000;  /***   * 连接池本地最大死的连接差值   */  protected int poolMaximumLocalBadConnectionTolerance = 3;  protected String poolPingQuery = \"NO PING QUERY SET\";  /***   * 是否启用ping操作   */  protected boolean poolPingEnabled;  protected int poolPingConnectionsNotUsedFor;  /***   * 连接执行类别代码   */  private int expectedConnectionTypeCode;  public PooledDataSource() {    dataSource = new UnpooledDataSource();  }  public PooledDataSource(UnpooledDataSource dataSource) {    this.dataSource = dataSource;  }    //other}从源码中我们看到：  连接池数据源中以UnPooledDataSource为基础,构造函数传入的也是非连接池数据源  添加了连接池的相关基础属性,主要包含活动连接数、空闲连接数、等待时间等待来看连接池获取数据源的方式：/***   * 获取数据库连接   * @return   * @throws SQLException   */@Overridepublic Connection getConnection() throws SQLException {    return popConnection(dataSource.getUsername(), dataSource.getPassword()).getProxyConnection();}/**** 获取连接池的代理连接对象PooledConnection**/private PooledConnection popConnection(String username, String password) throws SQLException {    boolean countedWait = false;    PooledConnection conn = null;    long t = System.currentTimeMillis();    int localBadConnectionCount = 0;    while (conn == null) {      synchronized (state) {        //空閑连接不为空        if (!state.idleConnections.isEmpty()) {          // Pool has available connection          //空空闲连接集合中获取一个连接,并移除空闲连接集合          conn = state.idleConnections.remove(0);          if (log.isDebugEnabled()) {            log.debug(\"Checked out connection \" + conn.getRealHashCode() + \" from pool.\");          }        } else {          //空闲连接集合数为空          // Pool does not have available connection          if (state.activeConnections.size() &lt; poolMaximumActiveConnections) {            //激活连接数小于最大活动连接数,则创建一个连接(从DataSource数据源中获取一个新的连接)            // Can create new connection            conn = new PooledConnection(dataSource.getConnection(), this);            if (log.isDebugEnabled()) {              log.debug(\"Created connection \" + conn.getRealHashCode() + \".\");            }          } else {            //无法创建新的数据库连接            // Cannot create new connection            PooledConnection oldestActiveConnection = state.activeConnections.get(0);            long longestCheckoutTime = oldestActiveConnection.getCheckoutTime();            //当前连接的检查时间大于连接池默认check时间            if (longestCheckoutTime &gt; poolMaximumCheckoutTime) {              // Can claim overdue connection              //当前连接为逾期连接              //逾期连接数量+1              state.claimedOverdueConnectionCount++;              //累计连接时间++              state.accumulatedCheckoutTimeOfOverdueConnections += longestCheckoutTime;              //累计check时间++              state.accumulatedCheckoutTime += longestCheckoutTime;              //把当前连接数从活动连接集合中移除              state.activeConnections.remove(oldestActiveConnection);              //判断是否非自动提交              if (!oldestActiveConnection.getRealConnection().getAutoCommit()) {                try {                  //如果当前数据库连接不是自动提交,则回滚事务                  oldestActiveConnection.getRealConnection().rollback();                } catch (SQLException e) {                  /*                     Just log a message for debug and continue to execute the following                     statement like nothing happend.                     Wrap the bad connection with a new PooledConnection, this will help                     to not intterupt current executing thread and give current thread a                     chance to join the next competion for another valid/good database                     connection. At the end of this loop, bad {@link @conn} will be set as null.                   */                  log.debug(\"Bad connection. Could not roll back\");                }                }              conn = new PooledConnection(oldestActiveConnection.getRealConnection(), this);              conn.setCreatedTimestamp(oldestActiveConnection.getCreatedTimestamp());              conn.setLastUsedTimestamp(oldestActiveConnection.getLastUsedTimestamp());              //老的连接置为不可用              oldestActiveConnection.invalidate();              if (log.isDebugEnabled()) {                log.debug(\"Claimed overdue connection \" + conn.getRealHashCode() + \".\");              }            } else {              //等待              // Must wait              try {                if (!countedWait) {                  //等待数量+1                  state.hadToWaitCount++;                  //等待标志位置为true                  countedWait = true;                }                if (log.isDebugEnabled()) {                  log.debug(\"Waiting as long as \" + poolTimeToWait + \" milliseconds for connection.\");                }                long wt = System.currentTimeMillis();                //object的wait方法                state.wait(poolTimeToWait);                //累计等待时间                state.accumulatedWaitTime += System.currentTimeMillis() - wt;              } catch (InterruptedException e) {                break;              }            }          }        }        if (conn != null) {          // ping to server and check the connection is valid or not          if (conn.isValid()) {            //当前PoolConnection对象连接可用            //判断真实Connection是否自动提交,如果为false,则回滚当前事务.            if (!conn.getRealConnection().getAutoCommit()) {              conn.getRealConnection().rollback();            }            //设置当前连接hash            conn.setConnectionTypeCode(assembleConnectionTypeCode(dataSource.getUrl(), username, password));            conn.setCheckoutTimestamp(System.currentTimeMillis());            conn.setLastUsedTimestamp(System.currentTimeMillis());            //添加到活动连接集合中            state.activeConnections.add(conn);            //请求数+1            state.requestCount++;            //累计请求时间            state.accumulatedRequestTime += System.currentTimeMillis() - t;          } else {            if (log.isDebugEnabled()) {              log.debug(\"A bad connection (\" + conn.getRealHashCode() + \") was returned from the pool, getting another connection.\");            }            state.badConnectionCount++;            localBadConnectionCount++;            conn = null;            if (localBadConnectionCount &gt; (poolMaximumIdleConnections + poolMaximumLocalBadConnectionTolerance)) {              if (log.isDebugEnabled()) {                log.debug(\"PooledDataSource: Could not get a good connection to the database.\");              }              throw new SQLException(\"PooledDataSource: Could not get a good connection to the database.\");            }          }        }      }    }    if (conn == null) {      if (log.isDebugEnabled()) {        log.debug(\"PooledDataSource: Unknown severe error condition.  The connection pool returned a null connection.\");      }      throw new SQLException(\"PooledDataSource: Unknown severe error condition.  The connection pool returned a null connection.\");    }    return conn;  }流程图通过获取此链接的方式,整理流程图如下：逻辑从上面获取连接对象的代码中,程序执行逻辑如下：  首先获取的代理数据库连接PooledConnection,该对象通过维护真是Connection,并通过JDK的动态代理产生真实的数据库Connection连接对象  循环获取PooledConnection，知道获取得到为止  首先拿到连接池状态锁，判断空闲连接池是否为空，如果不为空,获取第一个空闲连接(同时remove从空闲池集合中remove第一个),并返回  如果空闲连接池为空,判断当前激活连接池大小是否小于连接池最大连接数,如果小于则new一个新的PooledConnection代理连接对象  如果连接池最大连接数已满,获取第一个连接池代理对象,判断该代理对象是否预期(连接池预期时间默认20秒),如果当前连接已预期,从活动连接池中移除该连接,回滚当前连接事务，使用当前代理对象的Connection，作为创建新的PooledConnection对象的参数，老的连接置为不可用  如果第一个池对象并未预期,则等待，根据连接池的等待时间进行等待  拿到PooledConnection对象后,对当前连接判断是否有效,有效的方法验证主要包括当前连接是否关闭，如果只想query操作,并执行,执行拿到结果则当前连接为可用连接  拿到真实Connection对象,判断是否自动提交,如果为false,则回滚当前Connection的事务，最后将该连接加入到连接池活动连接集合中返回  当我们得到PooledConnection后，因为最终要返回的是Connection对象,随意调用池代理连接的getProxyConnect()方法获取代理对象  获取代理对象时,首先判断当前Connection的方法，如果是调用close()方法,则首先会进入释放连接的逻辑，从当前活动连接池中移除该对象,判断空闲池空间足够,如果可用,加入空闲连接池,调用notifyAll(),唤醒wait线程,如果空闲连接池已满,则真实调用Connection的close()方法,并在之前回滚事务,关闭该连接JndiDataSourceFactory关于Jndi数据源,工作中几乎没有用到过,印象中是通过J2EE容器来创建数据源,为此我还是特地搜索学习记录一下首先,什么是JNDI？  JNDI(Java Naming and Directory Interface)是Java技术中指定的API，它为使用Java编程语言编写的应用程序提供命名和目录功能.它专为使用Java对象模型的Java平台而设计。使用JNDI，基于Java技术的应用程序可以存储和检索任何类型的命名Java对象,此外，JNDI还提供了执行标准目录操作的方法，例如将属性与对象相关联以及使用其属性搜索对象  JNDI也是独立于任何特定命名或目录服务实现而定义的,它使应用程序能够使用通用API访问不同的，可能是多个命名和目录服务,可以在此通用API后面无缝插入不同的命名和目录服务提供程序。这使基于Java技术的应用程序能够利用各种现有命名和目录服务中的信息,例如LDAP，NDS，DNS和NIS（YP），以及使应用程序能够与传统软件和系统共存  使用JNDI作为工具，您可以构建新的功能强大且可移植的应用程序，这些应用程序不仅可以利用Java的对象模型，而且还可以与部署它们的环境良好集成。  通过在网络范围内共享有关用户，机器，网络，服务和应用程序的各种信息，JNDI在Intranet和Internet中发挥着至关重要的作用可以看官网解释,我们知道Jndi是Java为我们提供的标准的Api,用于提供命名或目录服务这就好比我们将我们的数据源写在外部的配置文件中同等道理,我们在Jndi配置了一个数据源,命名为com/mybatis/prodDataSource,而开发无需要知道该数据源地址，用户名密码等，甚至连接池也不用关心,只需要使用Jndi提供的api,就能初始化拿到数据源的Connection连接,进行数据库的操作。这样做的好处：  开发在不同的环境(dev、prod)中可以使用相同的JNDI命名,这样在部署时,不用为了环境的不同,而变更相关的应用程序配置  可以最小化需要知道访问生产数据库的凭据的人数。只有Java EE应用服务器需要知道您是否使用JNDI当然,随着Spring Boot应用框架给我们提供的各环境部署的策略,目前Jndi这些技术已经很少有人使用了."
  },
  
  {
    "title": "mybatis 源码系列(四) 数据库驱动Driver加载方式",
    "url": "/posts/mybatis-4/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-14 00:00:00 +0800",
    





    
    "snippet": "不管是mysql或者oracle等等数据库的连接,在我们Java程序中,都需要将相应的数据库驱动jar包加入到Java应用程序中那么通过mybatis的两个DataSource数据源实现方式来看,我们的数据库驱动是如何加载的呢？先来看mybatis的UnpooledDataSource.java数据源/** * @author Clinton Begin * @author Eduardo ...",
    "content": "不管是mysql或者oracle等等数据库的连接,在我们Java程序中,都需要将相应的数据库驱动jar包加入到Java应用程序中那么通过mybatis的两个DataSource数据源实现方式来看,我们的数据库驱动是如何加载的呢？先来看mybatis的UnpooledDataSource.java数据源/** * @author Clinton Begin * @author Eduardo Macarron */public class UnpooledDataSource implements DataSource {    private ClassLoader driverClassLoader;  private Properties driverProperties;  private static Map&lt;String, Driver&gt; registeredDrivers = new ConcurrentHashMap&lt;String, Driver&gt;();  /***   * 驱动类   */  private String driver;  /***   * 数据库连接url   */  private String url;  //用户名  private String username;  //密码  private String password;  //是否自动提交  private Boolean autoCommit;  //默认事务隔离级别  private Integer defaultTransactionIsolationLevel;  static {    //加载数据库驱动    //遍历获取依据注册的驱动类,并将该驱动类实例加入到当前数据源的缓存map中    Enumeration&lt;Driver&gt; drivers = DriverManager.getDrivers();    while (drivers.hasMoreElements()) {      Driver driver = drivers.nextElement();      registeredDrivers.put(driver.getClass().getName(), driver);    }  } public UnpooledDataSource() {  }    //.....}按照mybatis的数据源实现方式,那么我们使用数据库的方式如下：//创建数据源工厂UnpooledDataSourceFactory unpooledDataSourceFactory=new UnpooledDataSourceFactory();String driver=\"com.mysql.cj.jdbc.Driver\";String url=\"jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true\";String username=\"root\";String password=\"123456\";//赋值propertiesProperties properties=new Properties();properties.setProperty(\"driver\",driver);properties.setProperty(\"url\",url);properties.setProperty(\"username\",username);properties.setProperty(\"password\",password);unpooledDataSourceFactory.setProperties(properties);//如果使用的是UnpooledDataSource数据源,则以上properties属性赋值需要使用UnpooledDataSource的属性值//获取数据源DataSource dataSource=unpooledDataSourceFactory.getDataSource();Connection connection=dataSource.getConnection();String sql=\"select * from user\";PreparedStatement pstm=connection.prepareStatement(sql);ResultSet rs=pstm.executeQuery();while (rs.next()){    String id=rs.getString(\"id\");    int age=rs.getInt(\"age\");    String name=rs.getString(\"name\");    System.out.println(\"id:\"+id+\",age:\"+age+\",name:\"+name);}rs.close();pstm.close();connection.close();这样我们会在控制台中打印当前user表的相关信息,看到这里,这在以前我会可能到此为止了,但是既然是源码研究,那么在阅读代码的时候就会产生疑问疑问点：static {    //加载数据库驱动    //遍历获取依据注册的驱动类,并将该驱动类实例加入到当前数据源的缓存map中    Enumeration&lt;Driver&gt; drivers = DriverManager.getDrivers();    while (drivers.hasMoreElements()) {      Driver driver = drivers.nextElement();      registeredDrivers.put(driver.getClass().getName(), driver);    }  }在以上static块中,通过使用DriverManager.getDrivers()就能在Java程序中获取得到我们当前以及注册的数据库驱动Driver类,那么这些Driver类是何时注册的呢？我们只能查看DriverManger.getDrivers()方法一探究竟.@CallerSensitivepublic static java.util.Enumeration&lt;Driver&gt; getDrivers() {    java.util.Vector&lt;Driver&gt; result = new java.util.Vector&lt;&gt;();    Class&lt;?&gt; callerClass = Reflection.getCallerClass();\t//从registeredDrivers方法遍历得到Driver的Vector集合    // Walk through the loaded registeredDrivers.    for(DriverInfo aDriver : registeredDrivers) {        // If the caller does not have permission to load the driver then        // skip it.        if(isDriverAllowed(aDriver.driver, callerClass)) {            result.addElement(aDriver.driver);        } else {            println(\"    skipping: \" + aDriver.getClass().getName());        }    }    return (result.elements());}从registeredDrivers方法遍历得到Driver的Vector集合，所以,此段代码说明registeredDrivers一定是在某处已经初始化过,我们在代码上并没有其他调用,此时只能是DriverManager中存在static代码块先来看部分代码：public class DriverManager {    // List of registered JDBC drivers    private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;();    private static volatile int loginTimeout = 0;    private static volatile java.io.PrintWriter logWriter = null;    private static volatile java.io.PrintStream logStream = null;    // Used in println() to synchronize logWriter    private final static  Object logSync = new Object();    /* Prevent the DriverManager class from being instantiated. */    private DriverManager(){}    /**     * Load the initial JDBC drivers by checking the System property     * jdbc.properties and then use the {@code ServiceLoader} mechanism     */    static {        loadInitialDrivers();        println(\"JDBC DriverManager initialized\");    }}果然,在static块中,存在loadInitialDrivers方法,顾名思义,这就是我们要找的驱动加载方法了.继续看下去.private static void loadInitialDrivers() {    String drivers;    try {        drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() {            public String run() {                return System.getProperty(\"jdbc.drivers\");            }        });    } catch (Exception ex) {        drivers = null;    }    // If the driver is packaged as a Service Provider, load it.    // Get all the drivers through the classloader    // exposed as a java.sql.Driver.class service.    // ServiceLoader.load() replaces the sun.misc.Providers()    AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() {        public Void run() {            ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);            Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();            /* Load these drivers, so that they can be instantiated.                 * It may be the case that the driver class may not be there                 * i.e. there may be a packaged driver with the service class                 * as implementation of java.sql.Driver but the actual class                 * may be missing. In that case a java.util.ServiceConfigurationError                 * will be thrown at runtime by the VM trying to locate                 * and load the service.                 *                 * Adding a try catch block to catch those runtime errors                 * if driver not available in classpath but it's                 * packaged as service and that service is there in classpath.                 */            try{                while(driversIterator.hasNext()) {                    driversIterator.next();                }            } catch(Throwable t) {                // Do nothing            }            return null;        }    });}从代码中我们看到通过ServiceLoader.load(Driver.class);ServiceLoader是实现了Iterable迭代器的，来看类图只提供了一个构造函数,根据Class和ClassLoader来构造ServiceLoader//初始化ServiceLoader方法public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) {        ClassLoader cl = Thread.currentThread().getContextClassLoader();        return ServiceLoader.load(service, cl);} public void reload() {     //情况     providers.clear();     lookupIterator = new LazyIterator(service, loader); }private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) {    //Class 非空校验,如果为空 则抛出空指针异常.    service = Objects.requireNonNull(svc, \"Service interface cannot be null\");    //判断当前ClassLoader是否为空,如果为空,则使用系统默认ClassLoader    loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl;    acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null;    reload();}关于AccessController涉及到的方法,这里不做过多研究说明.看了ServiceLoader的源码结构，在来看遍历try{    while(driversIterator.hasNext()) {        driversIterator.next();    }} catch(Throwable t) {    // Do nothing}此处的hasNext()方法实际调用的是ServiceLoader中的内部类LazyIterator中的hasNext()方法来看LazyIterator类private class LazyIterator        implements Iterator&lt;S&gt;    {        Class&lt;S&gt; service;        ClassLoader loader;        Enumeration&lt;URL&gt; configs = null;        Iterator&lt;String&gt; pending = null;        String nextName = null;        private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) {            this.service = service;            this.loader = loader;        }        private boolean hasNextService() {            if (nextName != null) {                return true;            }            if (configs == null) {                try {                \t//获取资源路径名称因为传递过来的类是java.sql.Driver                \t//所以此处fullName的全称是:META-INF/services/java.sql.Driver                    String fullName = PREFIX + service.getName();                    if (loader == null)                        configs = ClassLoader.getSystemResources(fullName);                    else                        configs = loader.getResources(fullName);                } catch (IOException x) {                    fail(service, \"Error locating configuration files\", x);                }            }            while ((pending == null) || !pending.hasNext()) {                if (!configs.hasMoreElements()) {                    return false;                }                pending = parse(service, configs.nextElement());            }            nextName = pending.next();            return true;        }        private S nextService() {            if (!hasNextService())                throw new NoSuchElementException();            String cn = nextName;            nextName = null;            Class&lt;?&gt; c = null;            try {                c = Class.forName(cn, false, loader);            } catch (ClassNotFoundException x) {                fail(service,                     \"Provider \" + cn + \" not found\");            }            if (!service.isAssignableFrom(c)) {                fail(service,                     \"Provider \" + cn  + \" not a subtype\");            }            try {            \t//从配置文件类中读取到驱动类Driver,通过反射调用产生Driver类的实例            \t                S p = service.cast(c.newInstance());                providers.put(cn, p);                return p;            } catch (Throwable x) {                fail(service,                     \"Provider \" + cn + \" could not be instantiated\",                     x);            }            throw new Error();          // This cannot happen        }        public boolean hasNext() {            if (acc == null) {                return hasNextService();            } else {                PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() {                    public Boolean run() { return hasNextService(); }                };                return AccessController.doPrivileged(action, acc);            }        }        public S next() {            if (acc == null) {                return nextService();            } else {                PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() {                    public S run() { return nextService(); }                };                return AccessController.doPrivileged(action, acc);            }        }        public void remove() {            throw new UnsupportedOperationException();        }    }通过hasNextService()方法,我们看到回去加载当前的资源获取资源路径名称因为传递过来的类是java.sql.Driver所以此处fullName的全称是:META-INF/services/java.sql.Driver此时我们去查看mariadb的驱动及mysql的驱动jar包,看是否存在该文件        果然存在,代码看到这里,是否也能有个大概了呢?看mysql的驱动代码package com.mysql.cj.jdbc;import java.sql.SQLException;/** * The Java SQL framework allows for multiple database drivers. Each driver should supply a class that implements the Driver interface *  * &lt;p&gt; * The DriverManager will try to load as many drivers as it can find and then for any given connection request, it will ask each driver in turn to try to * connect to the target URL. *  * &lt;p&gt; * It is strongly recommended that each Driver class should be small and standalone so that the Driver class can be loaded and queried without bringing in vast * quantities of supporting code. *  * &lt;p&gt; * When a Driver class is loaded, it should create an instance of itself and register it with the DriverManager. This means that a user can load and register a * driver by doing Class.forName(\"foo.bah.Driver\") */public class Driver extends NonRegisteringDriver implements java.sql.Driver {    //    // Register ourselves with the DriverManager    //    static {        try {            //注册驱动            java.sql.DriverManager.registerDriver(new Driver());        } catch (SQLException E) {            throw new RuntimeException(\"Can't register driver!\");        }    }    /**     * Construct a new driver and register it with DriverManager     *      * @throws SQLException     *             if a database error occurs.     */    public Driver() throws SQLException {        // Required for Class.forName().newInstance()    }}看DriverManager.registerDriver方法public static synchronized void registerDriver(java.sql.Driver driver,            DriverAction da)        throws SQLException {    /* Register the driver if it has not already been added to our list */    if(driver != null) {        //registeredDrivers        registeredDrivers.addIfAbsent(new DriverInfo(driver, da));    } else {        // This is for compatibility with the original DriverManager        throw new NullPointerException();    }    println(\"registerDriver: \" + driver);}registeredDrivers集合在此处得到初始化我们回过头来再看LazyIterator迭代器中的方法private S nextService() {    if (!hasNextService())        throw new NoSuchElementException();    String cn = nextName;    nextName = null;    Class&lt;?&gt; c = null;    try {        c = Class.forName(cn, false, loader);    } catch (ClassNotFoundException x) {        fail(service,             \"Provider \" + cn + \" not found\");    }    if (!service.isAssignableFrom(c)) {        fail(service,             \"Provider \" + cn  + \" not a subtype\");    }    try {        //从配置文件类中读取到驱动类Driver,通过反射调用产生Driver类的实例        S p = service.cast(c.newInstance());        providers.put(cn, p);        return p;    } catch (Throwable x) {        fail(service,             \"Provider \" + cn + \" could not be instantiated\",             x);    }    throw new Error();          // This cannot happen}从配置文件类中读取到驱动类Driver,通过Class.forName方法将该类加载到JVM中,此时会调用执行Driver类中的static方法块,将Driver类驱动注册到DriverManager中。整个过程到此完结。"
  },
  
  {
    "title": "mybatis 源码系列(三) 配置之环境变量Environment",
    "url": "/posts/mybatis-3/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-13 00:00:00 +0800",
    





    
    "snippet": "通过初始化的章节,我们知道了mybatis的核心配置类Configuration，那么,接下来我们逐一查看该配置的属性简介本章主要是查看Environment环境变量在Configuration.java中/** * @author Clinton Begin */public class Configuration {  /***   * 环境   * 一般在程序开发和上线部署时,数据源会...",
    "content": "通过初始化的章节,我们知道了mybatis的核心配置类Configuration，那么,接下来我们逐一查看该配置的属性简介本章主要是查看Environment环境变量在Configuration.java中/** * @author Clinton Begin */public class Configuration {  /***   * 环境   * 一般在程序开发和上线部署时,数据源会有所不同,例如:dev(开发),prod(生产)   * 所以我们在不同的环境中,需要构建不同的environment对象   */  protected Environment environment;    //other field       /***   * 根据环境参数构造   * @param environment   */  public Configuration(Environment environment) {    this();    this.environment = environment;  }}其中在Configuration的构造函数中,就有通过Environment来构建对象实例的构造方法.所以,本章节开始来研究Environment的详细属性字段类图研究每个类之前,我们先来看该类的相关类图属性从类图中,我们得知Environment有三个属性：  id:当前环境变量的id，例如dev、prod等等  transactionFactory:当前环境中的事务管理器  dataSource:当前环境中的数据源使用看完了类图,我们在来看环境变量的使用方法，主要有两种方式  基于Xml的配置方式,配置Environment的xml节点信息  基于Java Bean的方式手动创建基于Xml&lt;environments default=\"development\"&gt;    &lt;environment id=\"development\"&gt;        &lt;transactionManager type=\"JDBC\"/&gt;        &lt;dataSource type=\"POOLED\"&gt;            &lt;property name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/&gt;            &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/test?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;amp;allowMultiQueries=true\"/&gt;            &lt;property name=\"username\" value=\"root\"/&gt;            &lt;property name=\"password\" value=\"123456\"/&gt;        &lt;/dataSource&gt;    &lt;/environment&gt;&lt;/environments&gt;基于Java Bean的方式既然我们通过类图知道的Environment的相关属性和构造方法,那么通过Java的方式也是很简单,代码如下："
  },
  
  {
    "title": "mybatis 源码系列(二) 配置类Configuration",
    "url": "/posts/mybatis-2/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-12 00:00:00 +0800",
    





    
    "snippet": "我们在第一章初始化中知道了mybatis的核心配置类为org.apache.ibatis.session.Configuration.java先来看Configuration.java的类图看到类图,瞬间就懵逼了,这属性也太多了吧…..不过想到mybatis的功能如此强大,那如此多的属性也是可以理解的，我会逐一探索.构造函数通过类图我们发现,Configuration主要提供了两个构造函数：...",
    "content": "我们在第一章初始化中知道了mybatis的核心配置类为org.apache.ibatis.session.Configuration.java先来看Configuration.java的类图看到类图,瞬间就懵逼了,这属性也太多了吧…..不过想到mybatis的功能如此强大,那如此多的属性也是可以理解的，我会逐一探索.构造函数通过类图我们发现,Configuration主要提供了两个构造函数：  空构造,不传任意参数  根据Environment环境变量来构造空构造先来看空构造的代码/***   * 空构造,初始化mybatis的相关处理类方法   */  public Configuration() {    typeAliasRegistry.registerAlias(\"JDBC\", JdbcTransactionFactory.class);    typeAliasRegistry.registerAlias(\"MANAGED\", ManagedTransactionFactory.class);    typeAliasRegistry.registerAlias(\"JNDI\", JndiDataSourceFactory.class);    typeAliasRegistry.registerAlias(\"POOLED\", PooledDataSourceFactory.class);    typeAliasRegistry.registerAlias(\"UNPOOLED\", UnpooledDataSourceFactory.class);    typeAliasRegistry.registerAlias(\"PERPETUAL\", PerpetualCache.class);    typeAliasRegistry.registerAlias(\"FIFO\", FifoCache.class);    typeAliasRegistry.registerAlias(\"LRU\", LruCache.class);    typeAliasRegistry.registerAlias(\"SOFT\", SoftCache.class);    typeAliasRegistry.registerAlias(\"WEAK\", WeakCache.class);    typeAliasRegistry.registerAlias(\"DB_VENDOR\", VendorDatabaseIdProvider.class);    typeAliasRegistry.registerAlias(\"XML\", XMLLanguageDriver.class);    typeAliasRegistry.registerAlias(\"RAW\", RawLanguageDriver.class);    typeAliasRegistry.registerAlias(\"SLF4J\", Slf4jImpl.class);    typeAliasRegistry.registerAlias(\"COMMONS_LOGGING\", JakartaCommonsLoggingImpl.class);    typeAliasRegistry.registerAlias(\"LOG4J\", Log4jImpl.class);    typeAliasRegistry.registerAlias(\"LOG4J2\", Log4j2Impl.class);    typeAliasRegistry.registerAlias(\"JDK_LOGGING\", Jdk14LoggingImpl.class);    typeAliasRegistry.registerAlias(\"STDOUT_LOGGING\", StdOutImpl.class);    typeAliasRegistry.registerAlias(\"NO_LOGGING\", NoLoggingImpl.class);    typeAliasRegistry.registerAlias(\"CGLIB\", CglibProxyFactory.class);    typeAliasRegistry.registerAlias(\"JAVASSIST\", JavassistProxyFactory.class);    languageRegistry.setDefaultDriverClass(XMLLanguageDriver.class);    languageRegistry.register(RawLanguageDriver.class);  }空构造中注册了大量内置的mybatis核心逻辑处理类，这些类的作用我们会在后面章节逐一研究,这里不做说明根据Environment来看构造函数/***   * 根据环境参数构造   * @param environment   */  public Configuration(Environment environment) {    this();    this.environment = environment;  }首先调用空构造,其次,赋值Environment属性如果不看其中具体的属性，从目标两个构造函数来看,Configuration配置类似乎也是很简单的.关于Configuration的属性,我们会在后面逐一研究攻破."
  },
  
  {
    "title": "mybatis 源码系列(一) 初始化",
    "url": "/posts/mybatis-1/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-11 00:00:00 +0800",
    





    
    "snippet": "通过阅读mybatis的官方文档,我们知道了初始化mybatis的方法有以下两种方法:  通过XML文件构建SqlSessionFactory对象,最终创建SqlSession使用对象实例  通过Java创建Configuration对象来构建SqlSessionFactory对象类图我们先来看mybatis的初始化相关的几个基础类图几个关键类说明：  SqlSessionFactoryBu...",
    "content": "通过阅读mybatis的官方文档,我们知道了初始化mybatis的方法有以下两种方法:  通过XML文件构建SqlSessionFactory对象,最终创建SqlSession使用对象实例  通过Java创建Configuration对象来构建SqlSessionFactory对象类图我们先来看mybatis的初始化相关的几个基础类图几个关键类说明：  SqlSessionFactoryBuilder:创建SqlSessionFactory对象的唯一类.  SqlSessionFactory:创建SqlSession对象实例的工厂类,一旦被创建就应该在应用的运行期间一直存在,没有任何理由丢弃它或重新创建另一个实例,可以和应用中的DataSource等同处理,一个数据源对应一个SqlSessionFactory对象.  SqlSession:通过SqlSession对象进行对数据库的操作访问,该类为线程不安全,所以,每次对数据库的操作都需要重新创建SqlSession对象实例,不可将SqlSession对象实例置为全局变量基于Xml基于Xml文件来创建SqlSessionFactory对象的方式,通过阅读源码我们知道以下两种  提供根据读取XML的InputStream流对象来构建  根据读取Xml的Reader流对象来构建.SqlSessionFactoryBuilder.java:public class SqlSessionFactoryBuilder {  /***   * 根据reader对象来构建   * @param reader   * @return   */  public SqlSessionFactory build(Reader reader) {    return build(reader, null, null);  }      /****   * 指定参数构建   * @param reader   * @param environment   * @param properties   * @return   */  public SqlSessionFactory build(Reader reader, String environment, Properties properties) {    try {      XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties);      return build(parser.parse());    } catch (Exception e) {      throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e);    } finally {      ErrorContext.instance().reset();      try {        reader.close();      } catch (IOException e) {        // Intentionally ignore. Prefer previous error.      }    }  }      //other constucts    /***   * 根据input流来构建   * @param inputStream   * @return   */  public SqlSessionFactory build(InputStream inputStream) {    return build(inputStream, null, null);  }    /***   * 指定参数构建   * @param inputStream   * @param environment   * @param properties   * @return   */  public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {    try {      XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);      return build(parser.parse());    } catch (Exception e) {      throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e);    } finally {      ErrorContext.instance().reset();      try {        inputStream.close();      } catch (IOException e) {        // Intentionally ignore. Prefer previous error.      }    }  }}除了根据Reader和InputStream，还可以指定相关的environment和properties属性此时,初始化的代码:String resource = \"org/mybatis/example/mybatis-config.xml\";InputStream inputStream = Resources.getResourceAsStream(resource);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);非XML非XML的方式是开发者在外部首先初始化创建好相应的Configuration对象实例,然后调用SqlSessionFactoryBuilder的build(Configuration confg)方法来进行创建/***   * 最终通过Configuration对象构建SqlSessionFactory的方法,前面的各种构造函数都是通过读取流Xml对象,最终转换为Configuration对象   * 调用build(config)来构建SqlSessionFactory   * @param config   * @return   */public SqlSessionFactory build(Configuration config) {    return new DefaultSqlSessionFactory(config);}最终初始化代码应该是这样:Configuration configuration = new Configuration(environment);//other init operate...SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration);Configuration通过以上两种初始化的方式,我们大致了解到,mybatis的配置核心类Configuration,该类是mybatis的配置核心.不管是创建SqlSession或者SqlSessionFactory，都需要基于Configuration来操作."
  },
  
  {
    "title": "mybatis 源码系列",
    "url": "/posts/mybatis-toc/",
    "categories": "mybatis",
    "tags": "",
    "date": "2019-05-10 00:00:00 +0800",
    





    
    "snippet": "最近闲来无事,之前在开发过程中一直在使用mybatis这个技术框架,但是一直没有认真的好好读一下mybatis的源码,所以,决定把mybatis的源码通读一遍,在对mybatis的基础使用上,巩固自己的技术积累,也想通过这个优秀的开源ORM框架中学到一些程序设计理念.并且通过博客记录的方式,加深自己的印象.在这个浮躁的社会中,我们唯一能做到的就是做好自己。mybatis版本号：3.5.0-S...",
    "content": "最近闲来无事,之前在开发过程中一直在使用mybatis这个技术框架,但是一直没有认真的好好读一下mybatis的源码,所以,决定把mybatis的源码通读一遍,在对mybatis的基础使用上,巩固自己的技术积累,也想通过这个优秀的开源ORM框架中学到一些程序设计理念.并且通过博客记录的方式,加深自己的印象.在这个浮躁的社会中,我们唯一能做到的就是做好自己。mybatis版本号：3.5.0-SNAPSHOTGithub:https://github.com/mybatis/mybatis-3中文文档：http://www.mybatis.org/mybatis-3/zh/index.html笔者下载的是最新的mybatis的仓库代码,借助mybatis的中文文档来研读mybatis3的源码目前的章节：  mybatis 源码系列(一) 初始化  mybatis 源码系列(二) 配置类Configuration  mybatis 源码系列(三) 配置之环境变量Environment  mybatis 源码系列(四) Java基础之数据库驱动Driver加载方式  mybatis 源码系列(五) 数据源DataSource  mybatis 源码系列(六) 设计模式  mybatis 源码系列(七) Java基础之数据库事务隔离级别  mybatis 源码系列(八) Java基础之wait()、notify()、notifyAll()方法"
  },
  
  {
    "title": "免费给网站配置SSL证书(https)",
    "url": "/posts/website-ssl/",
    "categories": "Blog",
    "tags": "",
    "date": "2019-05-07 00:00:00 +0800",
    





    
    "snippet": "这几天一直在看小程序的开发指南,其中读到小程序调用的RESTful Api接口的网站都必须是HTTPS的,为了后面学习小程序开发先给我的swagger-bootstrap-ui的文档地址配置一个SSL证书.就权当练习吧.证书申请关于SSL证书的申请,网上提供了很多教程,包括免费的等等,但其实都过于复杂,直接通过阿里云就可以免费申请SSL的证书证书购买步骤：登录阿里云控制台-&gt; SSL证...",
    "content": "这几天一直在看小程序的开发指南,其中读到小程序调用的RESTful Api接口的网站都必须是HTTPS的,为了后面学习小程序开发先给我的swagger-bootstrap-ui的文档地址配置一个SSL证书.就权当练习吧.证书申请关于SSL证书的申请,网上提供了很多教程,包括免费的等等,但其实都过于复杂,直接通过阿里云就可以免费申请SSL的证书证书购买步骤：登录阿里云控制台-&gt; SSL证书 -&gt; 购买证书证书签发免费的证书购买成功后,在证书控制台,未签发控制台上会看到证书,点击申请,填写相关信息填写域名相关信息点击下一步,验证，提交审核等操作即可证书下载在证书签发动作完成后,等大概几分钟,在已签发中可以看到我们的站点签发信息,点击下载,下载我们当前站点的SSL证书Nginx 配置SSL安装nginx的安装很简单,可以通过yum安装,如下yum install nginx通过命令启动nginxservice nginx start配置将我们下载的文件上传的服务器,主要包括两个文件(key和pem)配置我们的nginx,如下：server {        listen       80;        server_name  doc.xiaominfo.com;        # http默认重定向到https        return    301 https://$server_name$request_uri;}server{        listen 443 ssl;        server_name  doc.xiaominfo.com;        # 证书目录        ssl_certificate  /mnt/ssl/doc/doc.xiaominfo.com.pem;        ssl_certificate_key /mnt/ssl/doc/doc.xiaominfo.com.key;                ssl_session_timeout 5m;        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;        ssl_prefer_server_ciphers on;        client_max_body_size 100m;        location / {            root /mnt/application/swagger-bootstrap-ui-doc;        }}最后最后,需要在阿里云控制台中的安全组中开启SSL的端口号443大功告成~~~！！！"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.9.3 发布，i18n及自定义文档支持",
    "url": "/posts/swagger-bootstrap-ui-1.9.3-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-04-23 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.9.3 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger...",
    "content": "swagger-bootstrap-ui 1.9.3 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿文档：http://doc.xiaominfo.com效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlGitee:https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI示例:https://gitee.com/xiaoym/swagger-bootstrap-ui-demo特性&amp;优化1、增加i18n国际化支持(中文、English)，可参考文档2、优化调试框请求参数类型,添加数据类型issue #IVF2L @Gitee3、接口描述支持Html渲染issue #IVBWM @Gitee4、允许添加自定义文档(以markdown的形式)issue #IUWN9 @Gitee,可参考文档5、优化非200状态码调试栏显示高度过低的情况.6、分组tag名称很长时超出bug,增加菜单title鼠标悬浮显示分组tag名称issue #IVE0S @Gitee7、初始化请求异常处理,弹出友好提示信息.8、接口任何信息变更和新增接口一样,添加new的icon图表样式,代表当前接口信息已产生变化.            9、Swagger Models中的属性类显示readOnly      example属性issue #77 @GitHub      Bug修复1、解决多个api文档切换时,Authorize的参数没有变更的bugissue #IV3OZ @Gitee2、解决Basic认证出现的空指针异常以及账户密码为空的时候，页面崩溃的情况issue #78 @GitHubUI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.9.3&lt;/version&gt;&lt;/dependency&gt;Star &amp; Issue感谢各位朋友的支持,前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.9.2 发布，提供前后端分离解决方案",
    "url": "/posts/swagger-bootstrap-ui-1.9.2-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-04-08 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.9.2 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿GitHub  Gitee  文档  示例代码  在线体验主要更新如下：特性&amp;优化1、增加地址栏参数访问,快速个性化设置功能，可参考文档2、修改SecurityConfiguration中关于Environment的注入方式,改...",
    "content": "swagger-bootstrap-ui 1.9.2 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿GitHub  Gitee  文档  示例代码  在线体验主要更新如下：特性&amp;优化1、增加地址栏参数访问,快速个性化设置功能，可参考文档2、修改SecurityConfiguration中关于Environment的注入方式,改为属性注解注入,提供默认无参构造,避免某些情况下使用SpringAop导致异常issue #ITI1C @Gitee3、针对存在format属性字段类型,显示format属性，使参数更加清晰明了(例如：Integer-int32,Integer-int64,string-date)issue #ITIPQ @Gitee4、针对body类型的Array类型请求,给与默认参数值issue #ITVZ2 @Gitee5、优化新接口图标太大的问题,解决下拉框选择分组后,title标题属性不切换的问题.issue #IUGWF @Gitee6、当请求参数太多(&gt;5)时,调试栏显示折叠栏,点击发送后可自动折叠参数7、图片预览显示高度自适应issue #72 @GitHub8、针对@RequestBody类型的参数类型枚举的支持issue #73 @GitHub9、提供前后端分离的文档预览解决方案,具体参考文档Bug修复1、修复请求示例中支持readOnly属性issue #IS28O @Gitee2、修复响应返回数据的Map类型数据无法展开显示issue #IUAXW @Gitee3、修复点击复制文档，复制的md文件中，没有接口名称issue #71 @GitHubUI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.9.2&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html项目文档：http://www.xiaominfo.com/swagger-bootstrap-ui/代码集成示例SpringBoot在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demoSpring Mvc在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo/tree/master/swagger-bootstrap-ui-demo-mvcStar &amp; Issue前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.9.1 发布，优化大数据响应接口",
    "url": "/posts/swagger-bootstrap-ui-1.9.1-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-03-11 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.9.1 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿GitHub  Gitee  文档  示例代码  在线体验主要更新如下：特性&amp;优化1、优化大数据响应接口,UI渲染卡顿,导致浏览器崩溃2、ApiInfo.description支持htmlissue #65 @GitHub3、合...",
    "content": "swagger-bootstrap-ui 1.9.1 发布了。swagger-bootstrap-ui是 Swagger 的增强UI 实现，使文档更友好一点儿GitHub  Gitee  文档  示例代码  在线体验主要更新如下：特性&amp;优化1、优化大数据响应接口,UI渲染卡顿,导致浏览器崩溃2、ApiInfo.description支持htmlissue #65 @GitHub3、合并pr#61，优化array子类型为基础类型时schema显示为空的情况4、响应数据编辑器增加换行模式,针对响应某个字段特别长时,自动换行.Bug修复1、关闭默认响应状态后，自定义了@ApiResposes后，字段属性说明不显示issue #IRV1I @Gitee2、example不显示,支持readOnly属性issue #IS28O @Gitee3、修复Authorize缓存bugissue #ITAST @GiteeUI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html项目文档：http://www.xiaominfo.com/swagger-bootstrap-ui/代码集成示例SpringBoot在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demoSpring Mvc在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo/tree/master/swagger-bootstrap-ui-demo-mvcStar &amp; Issue前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.9.0 发布，提供Swagger资源保护",
    "url": "/posts/swagger-bootstrap-ui-1.9.0-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-02-25 00:00:00 +0800",
    





    
    "snippet": "SwaggerBootstrapUi 1.9.0 发布了。SwaggerBootstrapUi是 Swagger 的增强UI 实现，使文档更友好一点儿GitHub  Gitee  文档  示例代码  在线体验主要更新如下：特性&amp;优化1、优化未给与tags分组时,Ui默认赋值default.2、针对使用SwaggerBootstrapUi的增强排序功能时导致升级Springfox-Sw...",
    "content": "SwaggerBootstrapUi 1.9.0 发布了。SwaggerBootstrapUi是 Swagger 的增强UI 实现，使文档更友好一点儿GitHub  Gitee  文档  示例代码  在线体验主要更新如下：特性&amp;优化1、优化未给与tags分组时,Ui默认赋值default.2、针对使用SwaggerBootstrapUi的增强排序功能时导致升级Springfox-Swagger必须升级到2.9.2引起的jar包冲突版本问题，Ui做向下兼容处理,Springfox-Swagger版本最低兼容2.7.0(相对稳定版本,亲测可用)3、个性化新增配置，是否开启缓存已打开的api文档,感谢@web-xiaxia提交的pr            4、优化application/octet-stream下载出现的参数(header      query)问题      5、优化图片验证码显示问题,可参考文档文件下载及图片预览6、新增权限特性属性swagger.production，开启此属性后会屏蔽swagger所有访问资源,可用于生产环境中部署屏蔽文档输出.保护文档安全,可参考文档访问权限控制7、针对Swagger资源请求,提供Basic认证功能,可用于保护Swagger文档页面.可参考Basic详情8、优化文件上传参数类型File的支持.可参考文档文件上传9、优化响应数据右侧存在字段说明Span元素重叠,并增加Toggle开关显示关闭右侧字段说明10、优化离线文档预览,超出UI默认接口数量(100个)时,自动显示markdown源文件代码,供开发者自动复制到第三方转换软件查看,不再提供预览效果Bug修复1、启用UI增强时,获取不到WebApplicationContext对象造成空指针异常2、修复SpringMvc启用增强失败的Bug3、修改对象属性设置example导致解析Model失败的bugissue #IROVN @Gitee4、修复搜索后,相关个性化状态设置不显示的bugissue #IRE8W @Gitee5、修复 请求响应实体类内有Map类型参数无法正常显示 issue #IR61U @GiteeUI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.9.0&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html项目文档：http://www.xiaominfo.com/swagger-bootstrap-ui/代码集成示例SpringBoot在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demoSpring Mvc在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo/tree/master/swagger-bootstrap-ui-demo-mvcStar &amp; Issue前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.9 发布，Swagger增强UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.9-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2019-01-11 00:00:00 +0800",
    





    
    "snippet": "Swagger-Bootstrap-Ui 1.8.9 发布了。Swagger-Bootstrap-Ui是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿Swagger-Bootstrap-Ui 1.8.9 主要更新如下：特性&amp;优化1、主页面添加页面不缓存元素,防止版本升级缓存造成新功能加载失败.2、响应示例说...",
    "content": "Swagger-Bootstrap-Ui 1.8.9 发布了。Swagger-Bootstrap-Ui是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿Swagger-Bootstrap-Ui 1.8.9 主要更新如下：特性&amp;优化1、主页面添加页面不缓存元素,防止版本升级缓存造成新功能加载失败.2、响应示例说明、调试响应内容行添加description说明字段,免去切换到文档说明看字段说明的麻烦,非常感谢@wanyaxing提交的PR3、新增个性化配置-开启RequestMapping接口类型重复地址过滤,默认只显示POST类型的接口地址(针对RequestMapping的接口请求类型,在不指定参数类型的情况下,如果不过滤,默认会显示7个类型的接口地址参数,如果开启此配置,默认展示一个Post类型的接口地址)4、针对application/octet-stream类型的接口提供下载调试.Bug修复1、启用UI增强时,获取不到WebApplicationContext对象造成空指针异常2、修复list套list的返回值会不显示issue #55 @GitHub3、接口请求参数同全局参数配置名称存在冲突的情况下,根据名称匹配导致参数丢失,匹配规则为参数名称、参数类型同时比较issue #IQV1U @Gitee4、服务端响应HTML标签数据时,响应内容显示异常issue #IQ9LG @Gitee5、修复参数格式问题issue #IPXX7 @Gitee6、针对多响应码返回不同schema类型,离线文档(markdown)未展示完整的bugissue #IPPHJ @GiteeUI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.9&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html代码集成示例SpringBoot在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demoSpring Mvc在线demo地址：https://gitee.com/xiaoym/swagger-bootstrap-ui-demo/tree/master/swagger-bootstrap-ui-demo-mvcStar &amp; Issue前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.8 发布，Swagger增强UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.8-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-12-17 00:00:00 +0800",
    





    
    "snippet": "Swagger-Bootstrap-Ui 1.8.8 发布了。Swagger-Bootstrap-Ui是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿Swagger-Bootstrap-Ui 1.8.8 主要更新如下：特性&amp;优化1、顶部标题可自定义,去除原默认显示swagger-bootstrap-ui的固...",
    "content": "Swagger-Bootstrap-Ui 1.8.8 发布了。Swagger-Bootstrap-Ui是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿Swagger-Bootstrap-Ui 1.8.8 主要更新如下：特性&amp;优化1、顶部标题可自定义,去除原默认显示swagger-bootstrap-ui的固定标题,title规则为获取分组对象apiInfo中的第一个title属性2、个性化配置中新增是否开启请求参数缓存策略,默认为true，当设置为false时,请求的参数不会再本地产生缓存,下次打开接口调试时需要自己重新输入相关接口参数3、分组加载由同步改为异步加载4、新增接口高亮显示,当后端新增接口后,UI会自动标识该接口为新接口,直到该接口被点击为止.5、当服务器正在重启或者宕机时,接口发生异常,给出友好提示,告知接口对接人员.6、请求参数必填排序,require=true排最前7、后端接口方法上针对@Deprecated标注的接口,UI以中横线标注区分8、针对不同状态响应码,返回内容均有Schema的情况下，UI以tab方式将所有状态码的schema内容呈现9、优化接口数量过多的情况下,离线文档会导致文档页假死Bug修复1、修复针对Delete请求,使用@RequestBody注解出现400错误 issue IPLJT @Gitee2、修复响应状态码HTML标签非转义输出 issue #47 @GitHub3、不能正确解析response内非$ref的schema内容 issue #43 @GithubUI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.8&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlStar &amp; Issue前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.7 发布，Swagger增强UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.7-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-11-12 00:00:00 +0800",
    





    
    "snippet": "Swagger-Bootstrap-Ui 1.8.7 发布了。Swagger-Bootstrap-Ui是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿从1.0到更新至今,Swagger-Bootstrap-Ui也新增了很多小特性,为使更多人了解她,我重写了一份关于Swagger-Bootstrap-Ui的文档说明....",
    "content": "Swagger-Bootstrap-Ui 1.8.7 发布了。Swagger-Bootstrap-Ui是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿从1.0到更新至今,Swagger-Bootstrap-Ui也新增了很多小特性,为使更多人了解她,我重写了一份关于Swagger-Bootstrap-Ui的文档说明.希望越来越多使用她的用户都能体验到她带来的便利.详情可关注README.MDSwagger-Bootstrap-Ui 1.8.7 主要更新如下：特性&amp;优化1、优化调试框响应内容高度,根据响应内容自动设置响应高度,不再设固定高度.2、Authorize功能提供注销功能,清空当前缓存在浏览器的相关Auth信息.3、新增Swagger Models菜单项功能,以TreeTable的方式展示当前Swagger分组实例文档中所有相关的Models属性说明.4、个性化配置项新增是否显示tag分组description属性的选择项,勾选后,会和swagger官方文档一样显示description属性,默认为false不显示.5、引入async.js异步组件库,优化文档解析效率,解析渲染速度提升5倍以上.6、优化接口的id生成策略,使用MD5针对接口地址和mehtod方式生成接口id,调试参数全局缓存localStorage对象中,方便下次刷新访问调试.7、响应状态栏增加全屏icon,点击全屏icon可全屏查看响应内容.8、解决离线文档再开启UI增强功能后不排序的问题9、调试框根据Swagger接口参数显示当前接口的Content-Type类型,在某些特殊情况下可更改默认定义Content-Type请求头类型,如果使用UI提供的全局参数功能,自定义了Content-Type的请求头,则默认以全局参数中的Content-Type为主.10、增加对JSR-303 annotations 注解的支持(部分)Bug修复1、针对SpringCloud通过网关构建Swagger分组获取不到Documentation对象的情况,根据default再获取一次2、修复UI增强关于使用@Api注解tags属性不赋值,使用value，增强排序失败的问题.3、修复针对@RequestMapping注解无value属性,UI增强出现数组越界的问题4、修复针对扩展Spring的RequestMappingHandlerMapping自定义实现方式,获取不到扩展接口url地址信息,导致UI增强排序失败的问题.UI效果展示项目地址Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.7&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.htmlStar &amp; Issue或许她不是最漂亮的SwaggerUi，但绝对是目前最实用的SwaggerUi前往https://gitee.com/xiaoym/swagger-bootstrap-ui点个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.6 发布，Swagger增强UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.6-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-10-31 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.8.6 发布了。swagger-bootstrap-ui 是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.6 主要更新如下：特性增加            1、请求参数类型(header      body      q...",
    "content": "swagger-bootstrap-ui 1.8.6 发布了。swagger-bootstrap-ui 是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.6 主要更新如下：特性增加            1、请求参数类型(header      body      query)等以不同颜色着色区分      2、调试栏针对必须项(require=true)时,文本框着红色以区分3、调试页输入框可通过tab键自动切换上下级输入框.Bug修复1、修复Spring使用cglib生成的代理类,导致class无法获取Spring的相关注解,导致接口增强排序失败2、针对basePath属性不是根路径“/”，导致接口排序比对失败，无法排序的问题3、修复针对SpringCloud通过zuul路由组件加载swagger接口存在basePath属性,增强接口缺失basePath属性的bug,导致增强接口请求失败的问题4、修复Spring的请求地址仅支持value属性，不支持path属性的bug5、针对请求头Content-Type中多余空格问题,部分接口调用失败的问题6、修复针对参数、参数说明太长,导致table换行，样式失效问题.7、修复针对header、path等参数外，传参只包含body类型无请求json示例的问题.8、修复针对请求参数存在多个数组,增加按钮无效的BUG.9、优化离线文档相关的显示格式问题.包括JSON显示格式错乱、添加请求JSON示例、文档开始说明等信息UI效果展示Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.6&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~还未给swagger-bootstrap-ui点过赞的朋友，前往https://gitee.com/xiaoym/swagger-bootstrap-ui给个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.5 发布，Swagger增强UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.5-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-10-16 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.8.5 发布了。swagger-bootstrap-ui 是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui在1.8.5以后,她不在是一个纯webjar的UI工具了,她增强了swagger的一些功能支持,例如tags、接口的排序,一...",
    "content": "swagger-bootstrap-ui 1.8.5 发布了。swagger-bootstrap-ui 是 Swagger 的增强UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui在1.8.5以后,她不在是一个纯webjar的UI工具了,她增强了swagger的一些功能支持,例如tags、接口的排序,一些个性化的支持,目前只增强接口排序后续更多关于swagger的增强功能需求非常欢迎大家提issue反馈,让这款UI更加丰富强大.swagger-bootstrap-ui 1.8.5 主要更新如下：1、fixed formdata类型参数针对array数组类型无增加按钮2、fixed 响应内容高度占比,参数过多的情况无法显示3、多选项卡文档介绍、在线调试position位置引起的不适改动,由竖变横.4、增强排序功能，添加个性化配置管理功能,可开启个性化配置5、关于个性化增强功能,目前已经实现了tags、和接口api方法的排序,使用方式：在原EnableSwagger2注解上增加@EnableSwaggerBootstrapUi注解@Configuration@EnableSwagger2@EnableSwaggerBootstrapUIpublic class SwaggerConfiguration { \t//more...   }针对tags分组排序，UI的排序规则是顺序排序，最小值1，最大值也是默认值Integer.Max_VALUE;如果不使用SwaggerBootstrapUi的增强功能,则无需开启@EnableSwaggerBootstrapUi注解tags的排序规则分两种：a、一种是判断Swagger的@Api注解的position属性是否不等于0（默认值为0），如果该值不为空,则获取此值,根据该值排序b、如果postion=0（不写的情况下）,判断是否存在注解@ApiSort的值，如果有值，则获取此值,根据该值排序c、所以排序的取值规则是：position&gt;@ApiSort接口api的排序规则：a、判断@ApiOperation注解上的postion属性是否不等于0（默认值为0），如果该值不为空,则获取此值,根据该值排序//postion属性赋值@ApiOperation(httpMethod = \"POST\",position = 2,value = \"Test2Model测试数组参数，多个\",response=Test2Model.class)@ApiResponses({    @ApiResponse(code = 200, message = \"非HTTP状态码，返回值JSON code字段值，描述：成功\")})@ApiImplicitParams({    @ApiImplicitParam(name = \"ids\",paramType =\"form\",value = \"参数\",allowMultiple = true, required = true)})b、如果postion=0（不写的情况下）,判断是否存在注解@ApiOperationSort的值，如果有值，则获取此值,根据该值排序c、所以排序的取值规则是：position&gt;@ApiOperationSort注意：注解@EnableSwaggerBootstrapUi、@ApiSort、@ApiOperationSort是本UI工具包提供的Java注解,排序功能的使用需要在启用原EnableSwagger2注解上增加@EnableSwaggerBootstrapUi注解方可生效6、默认去除接口api地址的线上,默认只显示方法类型、方法说明两个属性,当然,新版本增加的个性化的配置功能，如果你觉得api地址显示任然有需要,可在个性化配置中开启该功能，个性化配置属性存储在localStorage对象中.只需要配置一次接口.            7、fixed 构建curl功能中写死http,根据window.location.href动态判断(http      https)的情况      8、如果请求参数是json参数body类型，文档说明中添加请求示例json展示,方便查看9、请求示例、响应示例json自动适配高度10、选中接口api菜单时,菜单显示激活色,显示背景颜色background-color: #eee;11、fixed 离线文档markdown格式错乱问题(table标题换行导致显示异常)12、离线文档已预览html的方式展现,复制文档功能依然是复制markdown语法13、请求参数及响应参数说明改为多行显示,超出长度不以省略号显示,防止出现浮层一直显示的bugMaven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.5&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~还未给swagger-bootstrap-ui点过赞的朋友，前往https://gitee.com/xiaoym/swagger-bootstrap-ui给个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.4 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.4-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-09-25 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.8.4 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.4 主要更新如下：1、fixed key-value表单请求 @RequestParam映射无效,在线调试bug...",
    "content": "swagger-bootstrap-ui 1.8.4 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.4 主要更新如下：1、fixed key-value表单请求 @RequestParam映射无效,在线调试bugissue #IMXOV @Gitee、issue #30 @GitHub2、fixed 树形model默认展开issue #IMXH5 @Gitee3、fixed 两个list里放同一个bean，一个显示一个不显示issue #IMXOY @Gitee4、fixed 同时传输文本信息和文件时，值重复issue #IMXDT @Gitee5、fixed issue #IN03Q6、fixed 响应类 3层嵌套解析不出来issue #IMXOF @Gitee7、fixed 全局参数设置接口中已有变量,会导致在线调试里面出现2个参数,不方便调试(如果后端swagger配置文件中使用globalParameter设置全局参数，并且赋予默认值，则以后端全局参数值为准)issue #IMXVD @Gitee8、fixed [“text/plain”] controller接收问题issue #IN0PC @Gitee9、优化调试页响应高度，ace-editor响应高度10、默认在Swagger-bootstrap-ui的请求,UI会增加一个默认的请求头Request-Origion:SwaggerBootstrapUi11、fixed Authorize默认tab不选中的bug12、fixed curl响应参数,针对中文urlencode处理Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.4&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~还未给swagger-bootstrap-ui点过赞的朋友，前往https://gitee.com/xiaoym/swagger-bootstrap-ui给个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.3 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.3-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-09-17 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.8.3 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.3 主要更新如下：1、新增tab选项卡,各个api接口详情通过新开选项卡来展现2、去除原schema表格形式展示...",
    "content": "swagger-bootstrap-ui 1.8.3 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.3 主要更新如下：1、新增tab选项卡,各个api接口详情通过新开选项卡来展现2、去除原schema表格形式展示，请求参数、响应参数改由treetable组件(树组件)展示3、fixed 请求参数有array类型,显示为schema类型的bug4、fixed springcloud zuul 整合ui情况下 地址多个/ISSUE #IMF0L @Gitee5、响应内容去除cookies选项卡，响应示例、响应内容使用ace-editor展示响应内容，方便复制6、优化(全局参数&amp;Authorize)加入浏览器缓存问题,使用localStorage对象全局存储issue #IMH77 @Gitee7、fixed 泛型数据接口返回list类型时，不能解析issue #26 @GitHub8、fixed 模型内部包含模型没有展示issue #25 @GitHub9、优化请求参数是否必填样式,如果该参数必填,则以红色标注显示issue #22 @Github10、fixed DELETE请求不能正确处理Query参数 issue #19 @GitHub11、fixed 请参数类型为 formData 的参数，填写了参数值还是提示 参数不能为空issue #24 @GitHub、issue #IMMMJ @Gitee12、优化离线文档多行，换行、多空格显示问题预览效果如下：Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.3&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~还未给swagger-bootstrap-ui点过赞的朋友，前往https://gitee.com/xiaoym/swagger-bootstrap-ui给个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui详解",
    "url": "/posts/swagger-bootstrap-ui-description/",
    "categories": "Blog",
    "tags": "",
    "date": "2018-08-29 00:00:00 +0800",
    





    
    "snippet": "项目背景大概是在2017年4月份,我们团队整个开发方式都决定使用前后端分离的方式来合作开发,前后端分离当时整个技术方案也是由我来负责整理，探索，如何让整个团队更高效的开发，完成自己的本职工作.从一开始的jsonp，到后面nginx反向代理，这里面我也收获了很多东西，也写了一些相关的博客总结，但最让人头疼的还是前后端如何针对接口来对接，当时找了很多解决方案，一开始使用的是叫apidocs的，有...",
    "content": "项目背景大概是在2017年4月份,我们团队整个开发方式都决定使用前后端分离的方式来合作开发,前后端分离当时整个技术方案也是由我来负责整理，探索，如何让整个团队更高效的开发，完成自己的本职工作.从一开始的jsonp，到后面nginx反向代理，这里面我也收获了很多东西，也写了一些相关的博客总结，但最让人头疼的还是前后端如何针对接口来对接，当时找了很多解决方案，一开始使用的是叫apidocs的，有些类似于写java的注释，使用起来还是不错的，不过没有在线生成的，文档写完后需要单独命令来生成一个文档，挺麻烦，后来就放弃了最终就考虑使用swagger来做文档的这块，但swagger大家都知道，swagger的ui虽然能把文档说清楚，但是不怎么好用，可能不适合我们国人的眼光吧，至少我是这么认为的，所以当时也就想看看swagger的生成方式，swagger-bootstrap-ui就因此诞生了这里谈谈swagger，虽然很多人喷他，不好用，基于注解，代码入侵很强，等等 很多原因。但总体来看，swagger发展至今，包括在各个语言，nodeJs、.net、java、php等等，它可以说是一个有些接口规范的东西，从开始，到一步步规范，其实是一个很艰难的过程，任何事物，都不是尽善尽美的，swagger也是一样，至少它给这么多语言提供了一种文档生成的解决方案，其价值就远超它本身的缺点在Java里面，是springfox实现了swagger的接口方式，其他语言也类似.鄙人一直觉得如果前面有人开发出来这个东西，而且用户范围，稳定性都相对较高的情况下，这个东西一定是有他的意义存在的，站在巨人的肩膀上，做正确的事，一直是我认为符合实际情况的,起码你不用自己填坑，因为，做开源，一个想法在当时，可能比较新颖，关注度很高，但是我想，大部分人都逃离不了惰性，缺少的是持之以恒，特别是在中国，很多开源其实都是个人在做（包括我自己的这个swagger-bootstrap-ui），意识上，相对国外还是比较薄弱的,而且还有精力，锲而不舍，任重而道远矣~！所以，swagger-bootstrap-ui仅仅只是一个ui包，里面不包括任何Java代码，基于swagger，希望为swagger的生态发展做一份贡献。swagger-bootstrap-ui开源至今也有一年4月有余了，为自己一直坚持下来打call，也会一直坚持下去，继续维护它，东西虽小,但坚持下去总会有收获.详细说明接下来会从各个不同的方面说一下swagger-bootstrap-ui界面风格使用过swagger-bootstrap-ui的朋友应该都知道，它是基于左右菜单式的布局方式,这和目前大部分后台管理系统有些类似，使用这种风格的原因,我想应该是更符合国人的操作习惯吧.相比较swagger-ui的上下依次铺开的结构，我想这种方式更适合接口对接人员.功能说明swagger-bootstrap-ui在原有UI的基础上,扩展了一些功能，主要包括：离线文档(markdown)、全局参数、检索、主页介绍核心功能核心功能主要通过两块，一是文档说明，二是调试，使用的bootstrap的标签页来切分展示扩展功能swagger-bootstrap-ui在原有的文档说明、在线调试的基础上,扩展了一些功能，方便接口对接人调试使用离线文档(markdown)通过swagger响应的接口文档，动态自动生成一份markdwon的接口文档说明，开发者可以保存后，使用其他的markdown转换软件，转换成pdf、word、html等离线文件，发送给别人搜索右上角的搜索按钮，可以输入关键字进行模糊搜索，搜索范围包括：简介、方法类型、接口名称、接口描述、tags等多种不同维度搜索，帮助你快速定位到接口的文档说明全局参数设置该功能是在还没有支持全局参数时临时配置的功能，如果后端swagger有配置全局参数，该功能可以无视AuthorizeAuthorize 功能是后端配置类似JWT等权限配置而设置的,可以全局配置token等参数UI功能增强swagger-bootstrap-ui自1.8.5版本以后,增加了后端Java代码的支持功能,主要目的是辅助Java开发者在使用springfox-swagger的同时,扩展一些增强功能，帮助开发者拥有更好的文档体验.目前主要增强功能：  tags分组标签排序  api接口排序使用swagger-bootstrap-ui提供的增强功能,需要在源Spring的config配置文件中开启,在原EnableSwagger2注解上增加@EnableSwaggerBootstrapUi注解，示例代码如下：@Configuration@EnableSwagger2@EnableSwaggerBootstrapUIpublic class SwaggerConfiguration { \t//more...   }针对tags分组排序，UI的排序规则是顺序排序，最小值1，最大值也是默认值Integer.Max_VALUE;如果不使用SwaggerBootstrapUi的增强功能,则无需开启@EnableSwaggerBootstrapUi注解tags的排序规则分两种：a、一种是判断Swagger的@Api注解的position属性是否不等于0（默认值为0），如果该值不为空,则获取此值,根据该值排序b、如果postion=0（不写的情况下）,判断是否存在注解@ApiSort的值，如果有值，则获取此值,根据该值排序c、所以排序的取值规则是：position&gt;@ApiSort接口api的排序规则：a、判断@ApiOperation注解上的postion属性是否不等于0（默认值为0），如果该值不为空,则获取此值,根据该值排序//postion属性赋值@ApiOperation(httpMethod = \"POST\",position = 2,value = \"Test2Model测试数组参数，多个\",response=Test2Model.class)@ApiResponses({    @ApiResponse(code = 200, message = \"非HTTP状态码，返回值JSON code字段值，描述：成功\")})@ApiImplicitParams({    @ApiImplicitParam(name = \"ids\",paramType =\"form\",value = \"参数\",allowMultiple = true, required = true)})b、如果postion=0（不写的情况下）,判断是否存在注解@ApiOperationSort的值，如果有值，则获取此值,根据该值排序c、所以排序的取值规则是：position&gt;@ApiOperationSort注意：注解@EnableSwaggerBootstrapUi、@ApiSort、@ApiOperationSort是本UI工具包提供的Java注解,排序功能的使用需要在启用原EnableSwagger2注解上增加@EnableSwaggerBootstrapUi注解方可生效代码说明希望这份代码说明能帮助更多的人理解swaggerswagger接口说明在说swagger-bootstrap-ui的代码之前,先看swagger提供的2个接口，swagger-bootstrap-ui包也是根据这2个接口来动态生成文档的分组接口：/swagger-resources详情实例接口：/v2/api-docsswagger分组swagger的分组接口是用过后端配置不同的扫描包，将后端的接口，按配置的扫描包基础属性响应给前端，看看分组接口响应的json内容：[    {        \"name\": \"分组接口\",        \"url\": \"/v2/api-docs?group=分组接口\",        \"swaggerVersion\": \"2.0\",        \"location\": \"/v2/api-docs?group=分组接口\"    },    {        \"name\": \"默认接口\",        \"url\": \"/v2/api-docs?group=默认接口\",        \"swaggerVersion\": \"2.0\",        \"location\": \"/v2/api-docs?group=默认接口\"    }]在springfox-swagger有些较低的版本中，并没有location属性，高版本会有该属性            属性      说明                  name      分组名称              url      接口url              swaggerVersion      版本号              location      接口location，同url属性      分组的后端Java配置代码如下：@Bean(value = \"defaultApi\")public Docket defaultApi() {    ParameterBuilder parameterBuilder=new ParameterBuilder();    List&lt;Parameter&gt; parameters= Lists.newArrayList();    parameterBuilder.name(\"token\").description(\"token令牌\").modelRef(new ModelRef(\"String\"))        .parameterType(\"header\").defaultValue(\"abc\")        .required(true).build();    parameters.add(parameterBuilder.build());    return new Docket(DocumentationType.SWAGGER_2)        .apiInfo(apiInfo())        .groupName(\"默认接口\")        .select()        .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.controller\"))        .paths(PathSelectors.any())        .build().globalOperationParameters(parameters)        .securityContexts(Lists.newArrayList(securityContext(),securityContext1())).securitySchemes(Lists.&lt;SecurityScheme&gt;newArrayList(apiKey(),apiKey1()));}@Bean(value = \"groupRestApi\")public Docket groupRestApi() {    return new Docket(DocumentationType.SWAGGER_2)        .apiInfo(groupApiInfo())        .groupName(\"分组接口\")        .select()        .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.group\"))        .paths(PathSelectors.any())        .build().securityContexts(Lists.newArrayList(securityContext(),securityContext1())).securitySchemes(Lists.&lt;SecurityScheme&gt;newArrayList(apiKey(),apiKey1()));}以上详细配置可参考码云swagger-bootstrap-ui-demo在线SwaggerConfiguration.java此处groupName即分组名称，basePackage即我们写的接口基础package包路径.详情实例接口详情实例接口是根据分组名称,动态获取该组下配置的basePackage所有的接口描述信息响应json如下：            属性      说明                  info      定义的该分组一些基础信息,包括标题、简介、联系人等              tags      该属性是分组属性，与后端的@Api注解对应              paths      接口示例数组，每个实例包含了接口的入参、出参、响应码等基础信息              securityDefinitions      权限配置验证，一般JWT等配置的权限配置会在该节点属性出现              definitions      该属性定义了所有响应的类属性说明      swagger-bootstrap-ui说明有了以上swagger的两个接口，就可以根据这2个接口来生成页面了，这里有一个前提，为什么可以根据这个来生成，因为swagger给出的两个接口地址是固定的，所以写这套UI也能得到通用.swagger-bootstrap-ui主要使用到的前端技术栈主要包括：            属性      说明                  jquery      http://jquery.com/              bootstrap      http://getbootstrap.com              layer      http://layer.layui.com/              jsonviews      https://github.com/yesmeck/jquery-jsonview              clipboard      https://github.com/zenorocha/clipboard.js              axios.min.js      https://github.com/axios/axios              marked      https://github.com/markedjs/marked              art-template      https://github.com/aui/art-template      这里主要说一些swagger-bootstrap-ui的一些思路，源码的话大家可以去码云或者GitHub上去看1、构建SwaggerBootstrapUi主对象，类似Java后端面向对象的方式来写，定义一些基础属性,这样也方便后期扩展var SwaggerBootstrapUi=function () {    //swagger请求api地址    this.url=\"swagger-resources\";    //文档id    this.docId=\"content\";    //tabid    this.tabId=\"tabUl\";    this.tabContentId=\"tabContent\";    this.searchEleId=\"spanSearch\";    this.searchTxtEleId=\"searchTxt\";    this.menuId=\"menu\";    this.searchMenuId=\"searchMenu\";    //实例分组    this.instances=new Array();    //当前分组实例    this.currentInstance=null;    //动态tab    this.globalTabId=\"sbu-dynamic-tab\";    this.globalTabs=new Array();    this.tabsLiContent=null;    this.tabsPostProcessors=null;}包括swagger的响应的属性，也重新在js中定义函数，使用面向对象的方式来操作2、初始化工作，sbu的入口即main方法,类似于SpringBoot的main方法，读源码的朋友可以从这个方法进入/***     * swagger-bootstrap-ui的main方法,初始化文档所有功能,类似于SpringBoot的main方法     */SwaggerBootstrapUi.prototype.main=function () {    var that=this;    that.initWindowWidthAndHeight();    that.windowResize();    //加载分组接口    that.analysisGroup();    //创建分组元素    that.createGroupElement();    //搜索    that.searchEvents();}3、数据和页面分离，使用art-template模板渲染,这样保持js的独立性FAQSpringBoot访问doc.html页面404默认情况下并不需要添加此配置即可访问很多朋友在使用SpringBoot集成swagger-bootstrap-ui后，都无法访问doc.html界面，此时，你可能需要实现SpringBoot的WebMvcConfigurer接口，添加相关的ResourceHandler,代码如下：@SpringBootApplicationpublic class SwaggerBootstrapUiDemoApplication  implements WebMvcConfigurer{\t@Override\tpublic void addResourceHandlers(ResourceHandlerRegistry registry) {\t\tregistry.addResourceHandler(\"doc.html\").addResourceLocations(\"classpath*:/META-INF/resources/\");\t\tregistry.addResourceHandler(\"/webjars/**\").addResourceLocations(\"classpath*:/META-INF/resources/webjars/\");\t}}同理，在使用SpringMvc或者shiro等权限框架时，如果页面无法访问，配置doc.html属性即可离线文档markdown格式错乱即使文档格式错乱，但是在相关markdown转换软件中依然是可以正常使用的，该功能使用art-template来渲染，多少会出现一些空格、换行之类的问题markdown软件推荐使用Typora,我一直在用，相当好用，适合不会排版word的程序员们使用该UI后后端报错，官方的不报错？该UI仅仅只是UI包，里面不包含任何Java后端代码，你自己想想这个东西为何会让后端代码报错?后端的问题需要具体分析，和本UI包无任何关系.总结写下这篇说明，也是希望更多的朋友少些疑惑，swagger在Java后端里面使用不难，甚至可以说简单，希望本篇文章能帮助到你最后贴一下软件的仓库地址，哈哈~~~码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGitHub:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线效果体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html还没有给swagger-bootstrap-ui点赞的朋友，赶紧去点个赞吧~~~"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.2 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.2-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-08-26 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.8.2 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.2 主要更新如下：1、fixed 关于@ApiModelProperty的value不支持\\n issue #I...",
    "content": "swagger-bootstrap-ui 1.8.2 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.2 主要更新如下：1、fixed 关于@ApiModelProperty的value不支持\\n issue #IM7XC @GITEE2、fixed 关于在线调试界面显示的优化,调试栏新增参数类型列,区分数据参数请求类型 issue #IM7TV @GITEE3、fixed 在springcloud下 整合到zuul时 测试路径不正确issue #IM69X @GITEE4、属性介绍说明，表格栏统一使用中文5、fixed 发布到tomcat非root目下时路径被多层嵌套curl路径正确 ui内部测试路径多层issue #IM69H @GITEE6、fixed List和String[]类型解析不正确，应该为array，实际为String并且不能增加[issue #IM2ZI @GITEE](https://gitee.com/xiaoym/swagger-bootstrap-ui/issues/IM2ZI)7、fixed 类型及引用类在出现array类型时不一致的问题issue #7 @GitHub8、fixed DELETE请求无法正确处理请求头issue #16 @GitHub9、fixed 在线调试-参数名称更改不生效 issue #IMBN3 @GITEE10、fixed 升级到1.8.1后,火狐浏览器无法显示文档issue #IM37D @GITEE11、fixed 关于请求是form表单，但是业务参数是body(json体的)请求异常issue #IM2YE @GITEE12、fixed 入参中的对象被处理成stringissue #ILU3S @GITEE13、fixed UI 样式建议(采纳大部分建议，非常感谢@永夜 提出的建议)issue #IMCET @GitEE14、fixed 当请求，出现param参数时，与body参数时，传到服务器无效params没有传,同issue #IM2YE issue #IM72N @GITEE15、优化，返回raw文本标签页添加复制文本功能,方便开发者调用，复制按钮增加icon16、fixed 文件上传的bugissue #IM4RG @GITEEMaven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.2&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~还未给swagger-bootstrap-ui点过赞的朋友，前往https://gitee.com/xiaoym/swagger-bootstrap-ui给个Star吧~~ ：）相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.1 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.1-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-08-14 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.8.1 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.1 主要更新如下：1、fixed 针对basePath属性,调试接口重复添加basePath路径,接口报404错...",
    "content": "swagger-bootstrap-ui 1.8.1 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.1 主要更新如下：1、fixed 针对basePath属性,调试接口重复添加basePath路径,接口报404错误(重大bug,建议升级)2、fixed 针对@ApiModelProperty注解,针对example属性值,array类型值带单引号,文档无法显示bug3、fixed 针对404 异常,header-curl tab选项卡切换bug4、fixed curl -X 参数bug,显示缺少”/”根路径5、fixed 左侧接口列表滚条无法完全滚动到底部6、fixed 窗口大小改变后，界面混乱7、优化菜单做成接口方法类型和接口类型左对齐8、fixed 左侧接口列表滚条无法完全滚动到底部9、优化 针对枚举类型,参数说明显示可用值列表10、表单类型显示header、可提交header信息11、fixed 基础类型响应数据为空的情况Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.1&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI在线体验：http://swagger-bootstrap-ui.xiaominfo.com/doc.html欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.8.0 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.8.0-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-08-10 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.8.0 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.0 主要更新如下：1、fixed 请求参数出现重复问题,去重2、fixed 无法显示spring cloud 子...",
    "content": "swagger-bootstrap-ui 1.8.0 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.8.0 主要更新如下：1、fixed 请求参数出现重复问题,去重2、fixed 无法显示spring cloud 子项目路径,针对basePath不为空,或者不为”/”根路径的情况,相关api地址加上basePath前缀3、调整菜单url各方法配色、接口配色,文档介绍、调试返回响应数据json配色4、响应模块添加http响应码、接口耗时、大小,参数栏添加全选按钮,调试页面针对响应内容tab选项卡去除灰色背景色,为默认白色底色5、调试响应模块增加raw、curl两个子tab选项卡,实现curl功能,方便远程调试6、针对接口二进制返回,提供下载按钮,可点击弹出下载功能7、fixed 针对图片返回时报DApiUI is not defined错误8、文档doc.html页面title根据用户自定义title显示9、发送中增加loading效果10、调整菜单顶部分组接口位置,移动到最左侧,添加可隐藏/显示MENU元素11、fixed 针对schema类型的参数,显示类型为string类型,按schema类型展示12、文件上传支持文件多选Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.8.0&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7.9 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7.9-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-08-06 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.7.9 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7.9 主要更新如下：            1、fixed 针对Integer、double、float等类型参数...",
    "content": "swagger-bootstrap-ui 1.7.9 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7.9 主要更新如下：            1、fixed 针对Integer、double、float等类型参数,有format参数则显示format属性,以区分准确类型,如：int64      int32等      2、fixed 滚动条出现底部部分内容不显示bug3、优化菜单接口根据不同接口类型,颜色调整4、优化文档响应数据jsonview字体,优化间距,更显紧促,优化菜单,接口及接口类型加粗5、add 顶部加搜索功能、可根据api地址、api介绍、api类型、分组名称实现模糊搜索,默认搜索当前已加载的分组api,如果其他分组未加载则搜索不到.6、add 针对Security-JWT等权限验证,显示Authorize菜单授权7、add 左侧菜单栏可自由拖动长度大小Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.7.9&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7.8 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7.8-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-08-03 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.7.8 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7.8 主要更新如下：1、fixed 针对@RequestBody注解实体类属性required的值一直显示默认fa...",
    "content": "swagger-bootstrap-ui 1.7.8 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7.8 主要更新如下：1、fixed 针对@RequestBody注解实体类属性required的值一直显示默认false问题2、fixed 针对文件上传,使用allowMultiple = true,上传按钮不显示bug,推荐使用@ApiImplicitParam注解,并且指定dataType = “MultipartFile”3、分组接口移动至顶部,菜单列表添加icon图标,移除简介页的软件介绍信息,丰富简介页信息,新增各类型接口统计信息,菜单简介名称更名为主页4、增加调试参数记忆功能,下次点击该接口时,上次输入的参数会保存继续可使用5、优化 针对@RequestBody注解,参数使用默认description的问题,将使用@ApiModel注解实体类上的description属性Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.7.8&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI欢迎提BUG、Pull Request给我，共同来完善这个小工具~~~~相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7.7 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7.7-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-07-25 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.7.7 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿该版本基本是fixed版本，修复了很多bug，针对全局参数这种新特性，影响比较大,建议升级swagger-bootstrap-ui 1.7.7 主要更新如下：1、...",
    "content": "swagger-bootstrap-ui 1.7.7 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿该版本基本是fixed版本，修复了很多bug，针对全局参数这种新特性，影响比较大,建议升级swagger-bootstrap-ui 1.7.7 主要更新如下：1、fixed 对象ref应用本身，JS 出现死循环了么，栈内存溢出BUG2、优化递归查找ref方法,fixed ref自身引用,相互引用的情况下,文档出不来bug3、响应json属性太多，文档太长,不利于查看,使用jsonview插件格式化,可收缩,便于查看4、fixed 对象属性值存在required属性时,值显示不对bug5、兼容firefox,文档菜单换行显示异常问题6、新增枚举请求参数类型支持,调试页面枚举类型为下拉框7、fixed 请求swagger-resources接口响应为string类型，文档无法展示,格式化json展示文档8、fixed 全局参数重新赋值无效9、fixed 针对@ApiOperation注解自定义tags接口无法显示bugMaven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.7.7&lt;/version&gt;&lt;/dependency&gt;码云：https://gitee.com/xiaoym/swagger-bootstrap-uiGITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI欢迎提BUG给我~~~~相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7.6 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7.6-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-07-18 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.7.6 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿该版本基本是fixed版本，修复了很多bug，针对全局参数这种新特性，影响比较大,建议升级swagger-bootstrap-ui 1.7.6 主要更新如下：1、...",
    "content": "swagger-bootstrap-ui 1.7.6 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿该版本基本是fixed版本，修复了很多bug，针对全局参数这种新特性，影响比较大,建议升级swagger-bootstrap-ui 1.7.6 主要更新如下：1、fixed 全局默认参数，设置值无效问题2、add 简介页添加basePath属性3、fixed 响应类型是Ref引用属性，在响应json中未列出属性4、fixed 默认值未显示,swagger 2.9.2版本响应json的默认值为x-example属性5、fixed tags存在大写的情况不显示接口 bug,在swagger2.9.2版本测试时，swagger又将后台的tags改为区分大小写了，所以建议升级swagger版本到最新6、fixed 相同url地址，不同method类型，接口未展示bug7、fixed 请求参数为ref引用类型时，文档列出请求类型和schema类型一致，显示schema类型8、tip:推荐使用chrome浏览器，别的浏览器可能有js、css兼容问题，文档效果未到最佳9、tip：建议swagger版本升级到2.9.2&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 --&gt;&lt;dependency&gt;    &lt;groupId&gt;io.springfox&lt;/groupId&gt;    &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;    &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.7.6&lt;/version&gt;&lt;/dependency&gt;欢迎提BUG给我~~~~相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7.5 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7.5-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-07-16 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.7.5 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本版本,swagger-bootstrap-ui核心JS组件进行重构,新版本中，文档呈现将剔除原table的展现方式,以markdown格式展现swagger-b...",
    "content": "swagger-bootstrap-ui 1.7.5 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本版本,swagger-bootstrap-ui核心JS组件进行重构,新版本中，文档呈现将剔除原table的展现方式,以markdown格式展现swagger-bootstrap-ui 1.7.5 主要更新如下：      重构DApiUI.js功能,新版本使用SwaggerBootstrapUi.js，方便后期扩展,同时删除无效js、css、html文件,新版本jar包由原760kb缩小至295kb        重构文档页面，剔除原来table展现方式，新版本使用markdown格式展现文档,单个文档页可复制        新增全局参数配置功能，针对请求参数有全局参数情况下，方便在线调试            支持离线文档格式,生成markdown格式文档,供开发者对外生成静态文档        通过markdown转换工具Typora预览效果        Typora导出pdf预览效果            添加clipboard插件,离线文档可复制功能        正式发布版去除console打印调试信息        fixed 调试页面去除url根路径/,项目名称非ROOT，或分布式情况下路径不对，多一个”/”的问题        fixed RequestBody 接收实体对象，对象属性中有List属性时,参数显示array，需解析对象属性显示，方便查看        fixed 对象属性展示为string，属性未显示        tip:推荐使用chrome浏览器，别的浏览器可能有js、css兼容问题，文档效果未到最佳  Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.7.5&lt;/version&gt;&lt;/dependency&gt;相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "记录解决微信amr文件转mp3格式的过程",
    "url": "/posts/wechat-amr-mp3-convert/",
    "categories": "Blog",
    "tags": "",
    "date": "2018-06-26 00:00:00 +0800",
    





    
    "snippet": "我们在做微信语音上传功能开发时,因为微信的原因，音频文件在微信服务端只能存储3天,所以,我们需要根据微信的serverId，使用微信公众平台的接口将音频文件下载下来,存储到我们本地的服务器由于微信的音频文件格式是amr格式，该格式在HTML5页面是不支持播放的,此时,我们需要将amr格式装换为mp3格式利用jave的工具包可以实现次目的，由于jave并未上传中央仓库,官网下载地址：http:...",
    "content": "我们在做微信语音上传功能开发时,因为微信的原因，音频文件在微信服务端只能存储3天,所以,我们需要根据微信的serverId，使用微信公众平台的接口将音频文件下载下来,存储到我们本地的服务器由于微信的音频文件格式是amr格式，该格式在HTML5页面是不支持播放的,此时,我们需要将amr格式装换为mp3格式利用jave的工具包可以实现次目的，由于jave并未上传中央仓库,官网下载地址：http://www.sauronsoftware.it/projects/jave/download.php此次使用jave的工具包主要碰到两个问题：  抛异常 it.sauronsoftware.jave.EncoderException:   Duration: N/A, bitrate: N/A  抛异常it.sauronsoftware.jave.EncoderException:   Stream mapping:使用搜索帮助，主要发现两篇有价值的博文：      java amr格式转mp3格式(完美解决Linux下转换0K问题)        解決linux AMR轉MP3出現轉碼成功卻無法播放的問題  结合以上两篇博客的解决方案,主要做如下步骤：1.下载jave的最新src代码(该库09年已停止维护)，导入maven工程2.下载最新的ffmpeg程序,ffmpeg下载地址,替换jave中默认的ffmpeg程序3.重新打包,mavn install最终控制台调试 打印log如下：Java代码使用示例：TemplateDownloadMaterial tm=weixinService.downloadTempMaterial(media,file.getAbsolutePath());if (tm!=null&amp;&amp;tm.getFile()!=null){\t//判断是否是amr格式    //tm.getFile 文件为微信下载下来的amr格式文件\tif (tm.getFile().getName().endsWith(\"amr\")){\t\tString fileName=tm.getFile().getName();\t\tString newName=fileName.substring(0,fileName.lastIndexOf(\".\"));\t\tFile dest=new File(tm.getFile().getParent()+File.separator+newName+\".mp3\");\t\tAudioUtils.getAmrConversionMp3(tm.getFile().getAbsolutePath(),dest.getAbsolutePath());\t\tlog(\"转换音频mp3成功\");\t\ttm.getFile().deleteOnExit();\t\ttm.setFile(dest);\t}}修改后的jave源码地址：https://github.com/xiaoymin/jave下载后 ，mvn install后可以执行使用"
  },
  
  {
    "title": "oss-server 1.1 版本发布 小型对象存储系统",
    "url": "/posts/oss-server-1.1-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-06-25 00:00:00 +0800",
    





    
    "snippet": "oss-server 1.1正式发布了,oss-server是针对项目开发时提供的小型对象存储系统,开发者在针对文件上传时业务剥离,同时方便文件迁移，为满足单个项目，多个系统的情况下，提供统一的oss服务本次更新主要做以下内容升级：      添加可能恶意文件格式拦截过滤,包括(sh、php、jsp、exe、dll、asp等文件)，可在application.properties配置文件配置...",
    "content": "oss-server 1.1正式发布了,oss-server是针对项目开发时提供的小型对象存储系统,开发者在针对文件上传时业务剥离,同时方便文件迁移，为满足单个项目，多个系统的情况下，提供统一的oss服务本次更新主要做以下内容升级：      添加可能恶意文件格式拦截过滤,包括(sh、php、jsp、exe、dll、asp等文件)，可在application.properties配置文件配置    ## 过滤上传文件格式,大小写忽略material.excludeFileTypes=sh,jsp,php,exe,asp,dll            上传文件mode权限去除X执行权限,只读权限        上传文件列表信息查看、excel导出功能            主页面新增近一周上传数据分析图表报告展示            base64上传文件添加module字段，可分模块存储        接口返回新增字段：文件原始名、文件类型、文件长度(long类型,例如：102400)、文件长度(字符串类型,例如:100kb)    接口返回格式如下：    {    \"code\": 8200,    \"message\": \"Success\",    \"data\": [        {            \"id\": \"c9b26d0a31154e3496fa5b5eb3fd0f48\",            \"url\": \"http://192.168.0.7/xq_website/201806/21/c9b26d0a31154e3496fa5b5eb3fd0f48.png\",            \"store\": \"/xq_website/201806/21/c9b26d0a31154e3496fa5b5eb3fd0f48.png\",            \"objType\": \"png\",            \"originalName\": \"QQ截图20180606083705.png\",            \"byteLength\": 120010,            \"byteToStr\": \"117.2KB\"        }    ]}            修复上传文件存储数据库值user_id bug        修复文件夹浏览文件，文件访问地址依然是配置文件路径的bug，根据基本信息配置信息读取        增加oss-server-sdk-java组件        增加oss-server-spring-boot-starter组件  关于更多oss-server的信息,请仔细阅读帮助文档：http://oss-server.mydoc.io/如果您有任何问题,或者建议,欢迎提issue欢迎大家拍砖~~~如果项目对您有帮助,请前往项目地址给个Star ！！！！相关链接  oss-server 的详细介绍：点击查看  oss-server 的下载地址：点击下载"
  },
  
  {
    "title": "oss-server 1.0 版本发布 小型对象存储系统",
    "url": "/posts/oss-server-1.0-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-06-19 00:00:00 +0800",
    





    
    "snippet": "oss-server 1.0正式发布了,oss-server是针对项目开发时提供的小型对象存储系统,开发者在针对文件上传时业务剥离,同时方便文件迁移，为满足单个项目，多个系统的情况下，提供统一的oss服务本次更新：1、重构界面,调整登录页、首页等页面2、引入sqlite3嵌入式数据库，辅助存储相关系统相关信息3、增加主面板功能、基本信息、权限管理(开发者管理、应用管理)等功能4、修改上传相关...",
    "content": "oss-server 1.0正式发布了,oss-server是针对项目开发时提供的小型对象存储系统,开发者在针对文件上传时业务剥离,同时方便文件迁移，为满足单个项目，多个系统的情况下，提供统一的oss服务本次更新：1、重构界面,调整登录页、首页等页面2、引入sqlite3嵌入式数据库，辅助存储相关系统相关信息3、增加主面板功能、基本信息、权限管理(开发者管理、应用管理)等功能4、修改上传相关接口,增加开发者权限验证,上传需提供开发者appid及appsecret5、完善oss-server帮助文档,在线访问地址：http://oss-server.mydoc.io/6、引入druid、mybatis-plus等数据库技术中间件关于更多oss-server的信息,请仔细阅读帮助文档：http://oss-server.mydoc.io/如果您有任何问题,或者建议,欢迎提issue欢迎大家拍砖~~~如果项目对您有帮助,请前往项目地址给个Star ！！！！相关链接  oss-server 的详细介绍：点击查看  oss-server 的下载地址：点击下载"
  },
  
  {
    "title": "个人开源：oss-server 简单对象存储系统",
    "url": "/posts/oss-server-open/",
    "categories": "开源",
    "tags": "",
    "date": "2018-06-13 00:00:00 +0800",
    





    
    "snippet": "oss-server项目介绍oss-server是针对项目开发时提供的小型对象存储系统,开发者在针对文件上传时业务剥离,同时方便文件迁移，为满足单个项目，多个系统的情况下，提供统一的oss服务oss-server主要提供功能：  1、上传功能  2、文件在线管理功能(包括文件的预览、内部上传、删除、更名)  3、权限管理(上传api权限用户维护、oss-server登录系统维护)oss-se...",
    "content": "oss-server项目介绍oss-server是针对项目开发时提供的小型对象存储系统,开发者在针对文件上传时业务剥离,同时方便文件迁移，为满足单个项目，多个系统的情况下，提供统一的oss服务oss-server主要提供功能：  1、上传功能  2、文件在线管理功能(包括文件的预览、内部上传、删除、更名)  3、权限管理(上传api权限用户维护、oss-server登录系统维护)oss-server使用tomcat+nginx的方式，tomcat提供上传对象存储的能力，nginx提供在线访问的能力oss不提供文件相关日志存储功能，是纯技术中间件server端主要配置(application.properties)如下：#素材存储路径 -- 以/结尾material.root=/home/material/#素材下载路径根目录,该目录是nginx读取目录,可以使用域名material.invokingRoot=http://192.168.0.7/使用以上配置，服务端nginx配置如下：server{        listen          80;        server_name 192.168.0.7;        charset utf-8;        location / {           root /home/material/;        }    }该配置只是简单配置nginx访问路径,server_name可以是域名.管理员预览输入访问路径：http://ip:port/输入application.properties配置文件中的用户名密码:#验证用户名 密码oss.security.userName=adminoss.security.password=adminA123oss-server提供以下两种提交方式base64字符串格式提交该方式是后端需要将文件转换成base64字符串,提交给oss-server，该方式oss-server提供了java版的sdk，具体可参看oss-server-sdk-java程序请求接口：/oss/material/uploadByBinary接口类型：post请求类型：application/json;请求参数：{    \"project\": \"\",    \"files\": [        {            \"original_name\": \"test.png\",            \"file\": \"文件流base64字符串\",            \"media_type\": \"png\"        }    ]}字段说明：            参数      说明                  project      项目名称，oss-server会根据该名称创建项目目录,方便后续程序迁移              files      上传文件数组              original_name      文件原始名称              file      文件流base64字符串              media_type      文件格式类型      响应json{    \"code\": \"8200\",    \"message\": \"Success\",    \"data\": [{        \"id\": \"1a4c705d260647cc9be951ead3a449e6\",        \"url\": \"http://192.168.0.7/province_IIII/201805/30/1a4c705d260647cc9be951ead3a449e6.jpg\",        \"store\": \"/province_IIII/201805/30/1a4c705d260647cc9be951ead3a449e6.jpg\"    }]}响应参数说明            参数      说明                  code      错误码,8200为成功              message      错误信息              data      上传成功后文件返回信息              id      文件唯一标识              url      文件在线访问url              store      文件静态存储路径      form表单直接提交该方式前端可直接通过form提交上传,后端不需要提供中转请求接口：/oss/material/{project}/uploadMaterial接口类型：post请求参数：            参数      说明                  project      项目名称，oss-server会根据该名称创建项目目录,方便后续程序迁移              module      模块名称，可为空,很多情况下,我们希望分模块来存储我们的上传资源，这个时候，可以使用该module字段，例如：/product/wechat,此时,oss生成的全路径是：{project}/product/wechat/...              file      上传文件名称，可以是数组多个文件      响应json{    \"code\": \"8200\",    \"message\": \"Success\",    \"data\": [{        \"id\": \"1a4c705d260647cc9be951ead3a449e6\",        \"url\": \"http://192.168.0.7/province_IIII/201805/30/1a4c705d260647cc9be951ead3a449e6.jpg\",        \"store\": \"/province_IIII/201805/30/1a4c705d260647cc9be951ead3a449e6.jpg\"    }]}form表单代码示例如下&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"&gt;&lt;html&gt;&lt;head&gt;    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/&gt;    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"/&gt;    &lt;title&gt;Title&lt;/title&gt;    &lt;script src=\"https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=\"http://192.168.0.7:18000/oss/material/province_III/uploadMaterial\" method=\"post\" enctype=\"multipart/form-data\" target=\"uploadIFrame\"&gt;    &lt;input type=\"file\" name=\"file\" value=\"选择文件\"/&gt;    &lt;input type=\"submit\" value=\"提交\"/&gt;&lt;/form&gt;&lt;iframe name=\"uploadIFrame\" style=\"width: 500px;height: 500px;border: 1px solid gray;\"&gt;&lt;/iframe&gt;&lt;/body&gt;&lt;/html&gt;软件架构后端框架：SpringBoot 2.0.2.RELEASE后端模块：freemarker前端框架：layer+Bootstrap安装教程1、下载源码：git clone https://gitee.com/xiaoym/oss-server.git2、修改application.properties配置文件,主要修改以下oss对外域名路径已经上传存储路径#素材存储路径 -- 以/结尾material.root=/home/material/#素材下载路径根目录material.invokingRoot=http://192.168.0.7/3、打包：mvn package4、运行jar包：java -jar oss-server-0.0.1-SNAPSHOT.jar参与贡献  Fork 本项目  新建 Feat_xxx 分支  提交代码  新建 Pull Request项目地址如果项目对您有帮助,请前往项目地址给个Star ！！！！码云：https://gitee.com/xiaoym/oss-serverGitHub:https://github.com/xiaoymin/oss-server"
  },
  
  {
    "title": "地球坐标系,了解一下?",
    "url": "/posts/coordinate_system_stu/",
    "categories": "Blog",
    "tags": "",
    "date": "2018-06-06 00:00:00 +0800",
    





    
    "snippet": "大地坐标系(WGS-84)WGS84:World Geodetic System 1984，是为GPS全球定位系统使用而建立的坐标系统。通过遍布世界的卫星观测站观测到的坐标建立，其初次WGS84的精度为1-2m，在1994年1月2号，通过10个观测站在GPS测量方法上改正，得到了WGS84（G730），G表示由GPS测量得到，730表示为GPS时间第730个周。1996年，National ...",
    "content": "大地坐标系(WGS-84)WGS84:World Geodetic System 1984，是为GPS全球定位系统使用而建立的坐标系统。通过遍布世界的卫星观测站观测到的坐标建立，其初次WGS84的精度为1-2m，在1994年1月2号，通过10个观测站在GPS测量方法上改正，得到了WGS84（G730），G表示由GPS测量得到，730表示为GPS时间第730个周。1996年，National Imagery and Mapping Agency (NIMA) 为美国国防部 (U.S.Departemt of Defense, DoD)做了一个新的坐标系统。这样实现了新的WGS版本：WGS（G873）。其因为加入了USNO站和北京站的改正，其东部方向加入了31-39cm 的改正。所有的其他坐标都有在1分米之内的修正。第三次精化：WGS84（G1150），于2002年1月20日启用。用来表述地球上点的位置的一种地区坐标系统。它采用一个十分近似于地球自然形状的参考椭球作为描述和推算地面点位置和相互关系的基准面。一个大地坐标系统必须明确定义其三个坐标轴的方向和其中心的位置。通常人们用旋转椭球的短轴与某一规定的起始子午面分别平行干地球某时刻的平均自转轴和相应的真起始子午面来确定坐标轴的方向。若使参考椭球中心与地球平均质心重合，则定义和建立了地心大地坐标系。它是航天与远程武器和空间科学中各种定位测控测轨的依据。若椭球表面与一个或几个国家的局部大地水准面吻合最好，则建立了一个国家或区域的局部大地坐标系。大地坐标系中点的位置是以其大地坐标表示的，大地坐标均以椭球面的法线来定义。其中，过某点的椭球面法线与椭球赤道面的交角为大地纬度；包含该法线和大地子午面与起始大地子午面的二面角为该点的大地经度；沿法线至椭球面的距离为该点的大地高。大地纬度、大地经度和大地高分别用大写英文字母B、L、H表示。国内的互联网公司，都不会使用GPS坐标，因为这不符合国家政策。所以大家都会使用GCJ-02坐标系。火星坐标系(GCJ-02)GCJ-02（俗称火星坐标系、国测局坐标，官方称地形图非线性保密处理算法[14]）是一种基于WGS-84制定的大地测量系统，由中国国测局制定，国家科学技术进步奖一等奖得主李成名开发。[15][16]此坐标系所采用的混淆算法[17]会在经纬度中加入看似随机的偏移，号称可以促进国家安全。[13][18]使用GCJ-02记录下的地点在GCJ-02的地图中会显示在正确的位置，然而换成WGS-84的地图或地点记录就可能造成100—700米不等的偏移。据测量，[2]Google.com的地图与真实坐标相差约50—500米，[8][a]而中国区的Google.cn地图则与卫星不带偏差。[b]雅虎地图显示的街道图也与卫星偏差不大。[c]MapQuest地图与众包测绘、不受限制的OpenStreetMap重合。[d]虽然GCJ-02坐标系统本身保密，但是目前已有C#[19]、C、Go、Java、JavaScript、PHP[20]、Python[21]、R[13]、Ruby[22][23]等多种语言的开源转换实现。这些实现似乎都基于某份泄露出的WGS到GCJ加偏代码实现。 [24]除了直接获取加偏算法，也有人通过对谷歌中国地图与卫星间的偏移做回归近似处理。[25]Wu Yongzheng使用傅里叶变换解出了与泄露代码类似的高频结构。[26]根据泄露代码注释[19]，GCJ-02在加偏时使用的是SK-42参考系统的椭球体参数。百度坐标系(BD-09)百度坐标对火星坐标系进行了一次加密,形成了百度坐标系.目前使用百度坐标系的地图商:  百度Baidu地图国家大地坐标(CGCS2000)2000国家大地坐标系，是我国当前最新的国家大地坐标系，英文名称为China Geodetic Coordinate System 2000，英文缩写为CGCS2000。2000国家大地坐标系的原点为包括海洋和大气的整个地球的质量中心；2000国家大地坐标系的Z轴由原点指向历元2000.0的地球参考极的方向，该历元的指向由国际时间局给定的历元为1984.0的初始指向推算，定向的时间演化保证相对于地壳不产生残余的全球旋转，X轴由原点指向格林尼治参考子午线与地球赤道面（历元2000.0）的交点，Y轴与Z轴、X轴构成右手正交坐标系。采用广义相对论意义下的尺度。国家大地坐标系是测制国家基本比例尺地图的基础。根据《中华人民共和国测绘法》规定，中国建立全国统一的大地坐标系统。建国以来，中国于上世纪50年代和80年代分别建立了1954年北京坐标系和1980西安坐标系，测制了各种比例尺地形图，在国民经济、社会发展和科学研究中发挥了重要作用，限于当时的技术条件，中国大地坐标系基本上是依赖于传统技术手段实现的。54坐标系采用的是克拉索夫斯基椭球体。该椭球在计算和定位的过程中，没有采用中国的数据，该系统在中国范围内符合得不好，不能满足高精度定位以及地球科学、空间科学和战略武器发展的需要。上世纪70年代，中国大地测量工作者经过二十多年的艰巨努力，终于完成了全国一、二等天文大地网的布测。经过整体平差，采用1975年IUGG第十六届大会推荐的参考椭球参数，中国建立了1980西安坐标系，1980西安坐标系在中国经济建设、国防建设和科学研究中发挥了巨大作用。随着社会的进步，国民经济建设、国防建设和社会发展、科学研究等对国家大地坐标系提出了新的要求，迫切需要采用原点位于地球质量中心的坐标系统（以下简称地心坐标系）作为国家大地坐标系。采用地心坐标系，有利于采用现代空间技术对坐标系进行维护和快速更新，测定高精度大地控制点三维坐标，并提高测图工作效率。2008年3月，由国土资源部正式上报国务院《关于中国采用2000国家大地坐标系的请示》，并于2008年4月获得国务院批准。自2008年7月1日起，中国将全面启用2000国家大地坐标系，国家测绘局授权组织实施。[1] 1954年北京坐标系和1980西安坐标系由于其成果受技术条件制约，精度偏低、无法满足新技术的要求。空间技术的发展成熟与广泛应用迫切要求国家提供高精度、地心、动态、实用、统一的大地坐标系作为各项社会经济活动的基础性保障。从技术和应用方面来看，现行坐标系具有一定的局限性，已不适应发展的需要。主要表现在以下几点：1.二维坐标系统。1980西安坐标系是经典大地测量成果的归算及其应用，它的表现形式为平面的二维坐标。用现行坐标系只能提供点位平面坐标，而且表示两点之间的距离精确度也比用现代手段测得的低10倍左右。高精度、三维与低精度、二维之间的矛盾是无法协调的。比如将卫星导航技术获得的高精度的点的三维坐标表示在现有地图上，不仅会造成点位信息的损失（三维空间信息只表示为二维平面位置），同时也将造成精度上的损失。2.参考椭球参数。随着科学技术的发展，国际上对参考椭球的参数已进行了多次更新和改善。1980西安坐标系所采用的IAG1975椭球，其长半轴要比国际公认的WGS84椭球长半轴的值大3米左右，而这可能引起地表长度误差达10倍左右。3.随着经济建设的发展和科技的进步，维持非地心坐标系下的实际点位坐标不变的难度加大，维持非地心坐标系的技术也逐步被新技术所取代。4.椭球短半轴指向。1980西安坐标系采用指向JYD1968.0极原点，与国际上通用的地面坐标系如ITRS，或与GPS定位中采用的WGS84等椭球短轴的指向（BIH1984.0）不同。天文大地控制网是现行坐标系的具体实现，也是国家大地基准服务于用户最根本最实际的途径。面对空间技术、信息技术及其应用技术的迅猛发展和广泛普及，在创建数字地球、数字中国的过程中，需要一个以全球参考基准框架为背景的、全国统一的、协调一致的坐标系统来处理国家、区域、海洋与全球化的资源、环境、社会和信息等问题。单纯采用参心、二维、低精度、静态的大地坐标系统和相应的基础设施作为我国现行应用的测绘基准，必然会带来愈来愈多不协调问题，产生众多矛盾，制约高新技术的应用。若仍采用现行的二维、非地心的坐标系，不仅制约了地理空间信息的精确表达和各种先进的空间技术的广泛应用，无法全面满足当今气象、地震、水利、交通等部门对高精度测绘地理信息服务的要求，而且也不利于与国际上民航与海图的有效衔接，因此采用地心坐标系已势在必行。地图厂商百度地图百度地图使用的是BD-09坐标系，即他自己的百度坐标系,在百度地图拾取的坐标都是BD-09坐标Google地图Google地图国外使用的是WGS-84坐标系,国际标准Google国内地图(.cn域名下)使用的是GCJ-02坐标系,即火星坐标高德地图高德地图(AMap)使用的是GCJ-02坐标系,即火星坐标腾讯地图使用的是GCJ-02坐标系,即火星坐标天地图天地图坐标全部统一为cgcs2000，国家大地坐标，在ArcGIS中的reproject打开想要转换的坐标系即可转换工具  GitHub开源-coordtransform(提供了百度坐标（BD09）、国测局坐标（火星坐标，GCJ02）、和WGS84坐标系之间的转换)  GPS坐标互转：WGS-84(GPS)、GCJ-02(Google地图)、BD-09(百度地图)  wgs84, gcj02, bd09 三种坐标的互相转换参考文章  高德地图API-从零开始学高德JS API(六)–坐标转换  地图API-为何您的坐标不准?如何纠偏  ​"
  },
  
  {
    "title": "postgresql 安装|重置密码|备份数据|导入数据",
    "url": "/posts/postgres-operation/",
    "categories": "数据库",
    "tags": "",
    "date": "2018-05-31 00:00:00 +0800",
    





    
    "snippet": "安装本机在Centos 7环境下安装postgresql使用如下图安装方式安装完成,安装指南重置密码完成安装后,并不知道postgresql的密码，在服务器终端通过ps命令可以查到postgres的进程，如下：[root@ZABBIX-SERVER 9.5]# ps -ef|grep postgresroot     24737 24564  0 13:40 pts/1    00:00:0...",
    "content": "安装本机在Centos 7环境下安装postgresql使用如下图安装方式安装完成,安装指南重置密码完成安装后,并不知道postgresql的密码，在服务器终端通过ps命令可以查到postgres的进程，如下：[root@ZABBIX-SERVER 9.5]# ps -ef|grep postgresroot     24737 24564  0 13:40 pts/1    00:00:00 su postgrespostgres 24738 24737  0 13:40 pts/1    00:00:00 bashpostgres 24902     1  0 13:43 pts/1    00:00:00 /usr/pgsql-9.5/bin/postgres -D /var/lib/pgsql/9.5/datapostgres 24903 24902  0 13:43 ?        00:00:00 postgres: logger process   postgres 24905 24902  0 13:43 ?        00:00:00 postgres: checkpointer process   postgres 24906 24902  0 13:43 ?        00:00:00 postgres: writer process   postgres 24907 24902  0 13:43 ?        00:00:00 postgres: wal writer process   postgres 24908 24902  0 13:43 ?        00:00:00 postgres: autovacuum launcher process   postgres 24909 24902  0 13:43 ?        00:00:00 postgres: stats collector process   root     26244 24816  0 13:50 pts/3    00:00:00 grep --color=auto postgres[root@ZABBIX-SERVER 9.5]# 通过ps命令,postgres默认安装路径在/usr/pgsql-9.5/目录下，配置文件在/var/lib/pgsql/9.5/data中，该目录也是数据库存储目录编辑pg_hba.conf文件vim /var/lib/pgsql/9.5/data/pg_hda.conf将原来所有方式修改为trust，如下：# \"local\" is for Unix domain socket connections onlylocal   all             all                                     md5# IPv4 local connections:host    all             all             127.0.0.1/32            trusthost    all             all             0.0.0.0/0               trust# IPv6 local connections:host    all             all             ::1/128                 trust修改完成后重启su postgrescd /usr/pgsql-9.5/bin./pg_ctl restart -D /var/lib/pgsql/9.5/data等待服务器进程关闭 .... 完成服务器进程已经关闭正在启动服务器进程bash-4.2$ &lt; 2018-05-31 13:43:30.580 CST &gt;日志:  无法绑定 IPv6 套接字: 无法指定被请求的地址&lt; 2018-05-31 13:43:30.580 CST &gt;提示:  是否有其它 postmaster 已经在端口 5432 上运行了? 如果没有, 请等待几秒钟后然后再重试.&lt; 2018-05-31 13:43:30.601 CST &gt;日志:  日志输出重定向到日志收集进程&lt; 2018-05-31 13:43:30.601 CST &gt;提示:  后续的日志输出将出现在目录 \"pg_log\"中.重启完成后,使用postgres登录[root@ZABBIX-SERVER 9.5]# psql --username=postgres用户 postgres 的口令：psql (9.5.13)输入 \"help\" 来获取帮助信息.postgres=# ^C在该会话中执行修改密码命令：ALTER USER postgres WITH PASSWORD '新密码'; 操作完成的，执行：\\q命令回车退出。 最后,恢复pg_hba.conf设置为md5并重启服务重启数据库./usr/pgsql-9.5/bin/pg_ctl restart -D /var/lib/pgsql/9.5/data创建数据库创建用户数据库，如testdb：postgres=# CREATE DATABASE testdb OWNER dbuser;将testdb数据库的所有权限都赋予dbuser：postgres=# GRANT ALL PRIVILEGES ON DATABASE testdb TO dbuser;删除数据库例如删除testdb：postgres=# DROP DATABASE testdb;备份数据使用如下命令：pg_dump -h 127.0.0.1 -U postgres databasename &gt; db_backup_date.sql-h:目标主机-U：用户名称导入数据库使用如下命令：psql -U postgres -d databasename -f back_db_conf0529.sql -U：用户名称-d：数据库名称-f：导入数据库文件相关操作查看数据库postgres=# \\l               //\\加上字母l,相当于mysql的，mysql&gt; show databases;                                         资料库列表       名称        |  拥有者  | 字元编码 |  校对规则   |    Ctype    |       存取权限        -------------------+----------+----------+-------------+-------------+----------------------- ots_am_bdp_conf   | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |  ots_app_conf      | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |  ots_business_test | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |  postgres          | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 |  template0         | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 | =c/postgres          +                   |          |          |             |             | postgres=CTc/postgres template1         | postgres | UTF8     | zh_CN.UTF-8 | zh_CN.UTF-8 | =c/postgres          +                   |          |          |             |             | postgres=CTc/postgres(6 行记录)postgres=# postgres=# select pg_database_size('ots_business_test');   //查看ots_business_test数据库的大小   pg_database_size ------------------        399552276(1 行记录)postgres=# select pg_database.datname, pg_database_size(pg_database.datname) AS size from pg_database;  //查看所有数据库的大小        datname      |   size    -------------------+----------- template1         |   6865412 template0         |   6857220 postgres          |   7089940 ots_business_test | 399552276 ots_am_bdp_conf   |  12939028 ots_app_conf      |   8359700(6 行记录)postgres=# select pg_size_pretty(pg_database_size('ots_app_conf'));   //以KB，MB，GB的方式来查看数据库大小   pg_size_pretty ---------------- 8164 kB(1 行记录)查看多表postgres=# select * from pg_tables;  //查询所有的表,相当于mysql的show tables;     schemaname     |        tablename        | tableowner | tablespace | hasindexes | hasrules | hastriggers --------------------+-------------------------+------------+------------+------------+----------+------------- pg_catalog         | pg_statistic            | postgres   |            | t          | f        | f pg_catalog         | pg_cast                 | postgres   |            | t          | f        | f pg_catalog         | pg_authid               | postgres   | pg_global  | t          | f        | f //more...postgres=# \\d pg_cast;   //相当于mysql的，mysql&gt; desc pg_cast;    资料表 \"pg_catalog.pg_cast\"    栏位     |  型别  | 修饰词 -------------+--------+-------- castsource  | oid    | 非空 casttarget  | oid    | 非空 castfunc    | oid    | 非空 castcontext | \"char\" | 非空 castmethod  | \"char\" | 非空索引：    \"pg_cast_oid_index\" UNIQUE, btree (oid)    \"pg_cast_source_target_index\" UNIQUE, btree (castsource, casttarget)postgres=# select pg_relation_size('pg_cast');    //查看表大小   pg_relation_size ------------------            16384(1 行记录)postgres=# select pg_size_pretty(pg_relation_size('pg_cast'));   //以KB，MB，GB的方式来查看表大小   pg_size_pretty ---------------- 16 kB(1 行记录)postgres=# select pg_size_pretty(pg_total_relation_size('pg_cast'));  //查看表的总大小，包括索引大小  pg_size_pretty ---------------- 80 kB(1 行记录)查看索引postgres=&gt; \\di                      //相当于mysql的，mysql&gt; show index from test;                  List of relations   Schema |     Name      | Type  |  Owner  | Table  --------+---------------+-------+---------+-------   public | playboy_id_pk | index | playboy | test  (1 row)    postgres=&gt; select pg_size_pretty(pg_relation_size('playboy_id_pk'));    //查看索大小   pg_size_pretty  ----------------   8192 bytes  (1 row)  查看表空间，以及大小postgres=&gt; select spcname from pg_tablespace;         //查看所有表空间    spcname  ------------   pg_default   pg_global  (2 rows)    postgres=&gt; select pg_size_pretty(pg_tablespace_size('pg_default'));   //查看表空间大小   pg_size_pretty  ----------------   14 MB  (1 row)  "
  },
  
  {
    "title": "Lucene(7.3.1)学习笔记-Document类源码解析",
    "url": "/posts/lucene_document_source/",
    "categories": "Java",
    "tags": "",
    "date": "2018-05-24 00:00:00 +0800",
    





    
    "snippet": "本笔记针对Lucene版本为7.3.1介绍Document对象是Lucene中搜索和索引的最小单元,一个文档对象，包含多个属性字段集合列表，每个字段对象都包含名称及字段值.Documet类图结构Document类实现了Iterable接口，接收IndexableField泛型类型每个Document对象维护一个fields集合列表，Java代码如下：private final List&lt...",
    "content": "本笔记针对Lucene版本为7.3.1介绍Document对象是Lucene中搜索和索引的最小单元,一个文档对象，包含多个属性字段集合列表，每个字段对象都包含名称及字段值.Documet类图结构Document类实现了Iterable接口，接收IndexableField泛型类型每个Document对象维护一个fields集合列表，Java代码如下：private final List&lt;IndexableField&gt; fields = new ArrayList&lt;&gt;();构造函数/** Constructs a new document with no fields. */public Document() {}方法            返回类型      方法      描述                  void      add(IndexableField field)      添加字段到文档中.              void      clear()      清除文档中所有字段.              String      get(String name)      返回字段string值，如果字段拥有相同的name，则返回最先添加的字段，否则返回null.              BytesRef      getBinaryValue(String name)      返回最先添加的字段name二进制值.              BytesRef[]      getBinaryValues(String name)      返回字段name的二进制值数组.              IndexableField      getField(String name)      返回字段.              List&lt;IndexableField&gt;      getFields()      返回只读字段List集合.              IndexableField[]      getFields(String name)      返回name匹配的字段数组.              String[]      getValues(String name)      返回name匹配的字段值数组.              Iterator&lt;IndexableField&gt;      iterator()                     void      removeField(String name)      移除第一个匹配name的字段.              void      removeFields(String name)      移除所有name匹配的字段.              String      toString()      打印文档字段列表.      IndexableField索引的单个字段，该类是接口，主要包括方法：名称、索引类型、等类图如下：子类实现:  TextField  StringField  IntPoint  LongPoint  FloatPoint  DoublePoint  SortedDocValuesField  SortedSetDocValuesField  NumericDocValuesField  SortedNumericDocValuesField  StoredField"
  },
  
  {
    "title": "Mariadb创建索引",
    "url": "/posts/mariadb-create-index/",
    "categories": "数据库",
    "tags": "",
    "date": "2018-05-18 00:00:00 +0800",
    





    
    "snippet": "英文原文地址：创建索引创建索引语法CREATE [OR REPLACE] [ONLINE|OFFLINE] [UNIQUE|FULLTEXT|SPATIAL] INDEX   [IF NOT EXISTS] index_name    [index_type]    ON tbl_name (index_col_name,...)    [WAIT n | NOWAIT]    [index...",
    "content": "英文原文地址：创建索引创建索引语法CREATE [OR REPLACE] [ONLINE|OFFLINE] [UNIQUE|FULLTEXT|SPATIAL] INDEX   [IF NOT EXISTS] index_name    [index_type]    ON tbl_name (index_col_name,...)    [WAIT n | NOWAIT]    [index_option]    [algorithm_option | lock_option] ...index_col_name:    col_name [(length)] [ASC | DESC]index_type:    USING {BTREE | HASH | RTREE}index_option:    KEY_BLOCK_SIZE [=] value  | index_type  | WITH PARSER parser_name  | COMMENT 'string'algorithm_option:    ALGORITHM [=] {DEFAULT|INPLACE|COPY}lock_option:    LOCK [=] {DEFAULT|NONE|SHARED|EXCLUSIVE}描述创建索引映射到ALTAL TABLE语句以创建索引。参阅Alter Table表。创建索引不能用于创建主键；而是使用ALTER TABLE语法代替。如果另外一个数据库连接正在使用该表,则该表元数据锁是激活的,该连接所执行的语句需要等待指导该锁释放,对非事务性表也是如此.另一个快捷方式，删除索引，允许移除索引。对于用作索引名称的有效标识符，请参见标识符名称注意，KEYAB块大小在创建索引中被忽略，尽管它包含在StEdio CREATE表的输出中。MariaDb 10.0ONLINE and OFFLINE 从句已经被移除,不在支持MariaDb 5.5注释“字符串”索引选项允许多达1024个字符的注释。MariaDb 5.3语句支持进度报告唯一/全文/空间索引请参见唯一索引、空间索引和全文索引的详细信息。索引类型有关每个存储引擎的允许索引类型的详细信息，请参见存储引擎索引类型。OR REPLACEMariaDb 10.1.4OR REPLACE从句添加支持如果使用了该索引，并且该索引已经存在，而不是返回一个错误，那么现有索引将被删除，并由新定义的索引代替。IF NOT EXISTS如果使用IF NOT EXISTS语句创建索引,则只会在该索引不存在的情况才创建该索引,如果该索引存在,将会触发警告.WAIT/NOWAIT设置锁等待超时。参考WAIT AND NOWAIT。示例创建一个唯一索引：CREATE UNIQUE INDEX HomePhone ON Employees(Home_Phone);OR REPLACE 和IF NOT EXISTS ：CREATE INDEX xi ON xx5 (x);Query OK, 0 rows affected (0.03 sec)CREATE INDEX xi ON xx5 (x);ERROR 1061 (42000): Duplicate key name 'xi'CREATE OR REPLACE INDEX xi ON xx5 (x);Query OK, 0 rows affected (0.03 sec)CREATE INDEX IF NOT EXISTS xi ON xx5 (x);Query OK, 0 rows affected, 1 warning (0.00 sec)SHOW WARNINGS;+-------+------+-------------------------+| Level | Code | Message                 |+-------+------+-------------------------+| Note  | 1061 | Duplicate key name 'xi' |+-------+------+-------------------------+另外参阅  标识符名称  开始使用索引  什么是索引?  修改表  删除索引  空间索引  全文索引使用场景在目前开发的丽水实时客流量大屏系统中,针对高速卡口车流数据报表,接口响应速度异常缓慢,接口初次使用Chrome浏览器的Network查看是16s的响应时间查看到该接口api/carSourceTopFive 查看Java代码逻辑，Java代码如下：public List&lt;HighwayCarInfo&gt; queryCurrentAllCarInfoByHour(String time, String stationName) {        List&lt;HighwayCarInfo&gt; highwayCarInfoList=Lists.newArrayList();        Map params=Maps.newHashMap();        if (StringUtils.isNotBlank(time)){            params.put(\"time\",time);        }        if(StringUtils.isNotBlank(stationName)){            params.put(\"siteName\",stationName);        }        boolean lastRecord=true;        int current_page=1;        int page_size=1000;        do{            Pagination&lt;HighwayCarInfo&gt; mapPagination=cloudQueryRunner.queryListByExample(HighwayCarInfo.class,\"highway_car_info\",params,current_page,page_size);            if(mapPagination!=null&amp;&amp;mapPagination.getCount()&gt;0){                if(mapPagination.getData().size()&lt;page_size){                    lastRecord=false;                }else{                    current_page++;                }                highwayCarInfoList.addAll(mapPagination.getData());            }else{                lastRecord=false;            }        }while (lastRecord);        return highwayCarInfoList;    }最终得出结果是查询highway_car_info表，使用time及siteName两个字段进行匹配查询得到调试SQL，在数据库中执行select * from resource_lishui_lishui_daping_highway_car_info where time='2018051814'etc….查询耗时10s。。最终对表highway_car_info的time字段创建索引使用explain语句查看SQL的执行计划explain select * from resource_lishui_lishui_daping_highway_car_info where time='2018051814'得到结果：            id      select_type      table      type      possible_keys      key      key_len      ref      rows      Extra                  1      SIMPLE      resource_lishui_lishui_daping_highway_car_info      ref      IDX_HIGYWAY_TIME      IDX_HIGYWAY_TIME      768      const      1151      Using index condition      "
  },
  
  {
    "title": "个人开源作品:依赖hugo+markdown搭建github博客",
    "url": "/posts/hugo-blog/",
    "categories": "开源",
    "tags": "",
    "date": "2018-04-29 00:00:00 +0800",
    





    
    "snippet": "hugo-blog是作者整理最近两年的技术积累,以博客的方式整理、归类发布出来，希望能帮助到一些开发者Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。官网网站：http://gohugo.io/commands/hugo/中文参考：http://www.gohugo.org/hugo-blog在线访问地址：https://xiaoymin.github.io/h...",
    "content": "hugo-blog是作者整理最近两年的技术积累,以博客的方式整理、归类发布出来，希望能帮助到一些开发者Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。官网网站：http://gohugo.io/commands/hugo/中文参考：http://www.gohugo.org/hugo-blog在线访问地址：https://xiaoymin.github.io/hugo-blog使用步骤：1、首先，需要安装hugo，可以去官网下载2、下载git仓库地址git clone https://github.com/xiaoymin/hugo-blog.git3、运行调试(windows):cd %blog_dir%hugo server --theme=hyde --buildDrafts4、Browser online access: http://localhost:1313/相关链接  hugo-blog 的详细介绍：点击查看  hugo-blog 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7.3 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7.3-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-04-28 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.7.3 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7.3更新如下：1、添加patch、head、trace等http其他方法2、响应参数解析集合类型不展示属性bug3...",
    "content": "swagger-bootstrap-ui 1.7.3 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7.3更新如下：1、添加patch、head、trace等http其他方法2、响应参数解析集合类型不展示属性bug3、响应参数、请求参数使用treegrid-table组件相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "前端技术大发展的背景下，谈谈前后端分离的发展与实践，以及后端研发思想的转变",
    "url": "/posts/front-back-summary/",
    "categories": "Blog",
    "tags": "",
    "date": "2018-04-22 00:00:00 +0800",
    





    
    "snippet": "说在前面的话随着前端NodeJs技术的火爆,现在的前端已经非以前传统意义上的前端了,各种前端框架(Vue、React、Angular……)井喷式发展,配合NodeJs服务端渲染引擎,目前前端能完成的工作不仅仅局限于CSS，JS等方面，很多系统的业务逻辑都可以放在前端来完成，例如我司的游管家那可能有些人会说,前端这么火,NodeJs发展这么迅猛,后端是不是以后都没事情干了，其实不然,拿Java...",
    "content": "说在前面的话随着前端NodeJs技术的火爆,现在的前端已经非以前传统意义上的前端了,各种前端框架(Vue、React、Angular……)井喷式发展,配合NodeJs服务端渲染引擎,目前前端能完成的工作不仅仅局限于CSS，JS等方面，很多系统的业务逻辑都可以放在前端来完成，例如我司的游管家那可能有些人会说,前端这么火,NodeJs发展这么迅猛,后端是不是以后都没事情干了，其实不然,拿Java来说，经过这么多年发展,已经相当稳定,完善的生态圈也非最近今年发展起来的NodeJs可比，我们常常说闻道有先后，术业有专攻,用在这里最合适不过了，集群、分布式、高可用等等技术还是需要后端架构师来思考的事情目前前端同后端的合作方式是前后端分离，通过Nginx+Tomcat的组合部署(还可加nodejs中间件)方式能有效的进行解耦，并且前后端分离为项目以后的架构扩展、微服务化、组件化都打下重要基础,所以这在以后是一个发展的必然趋势,我们需要去适应,做出改变！！！早期的开发方式早期的开发方式如下图：这也是我前面工作1-3年的开发方式,我们没有前端帮我们写JS函数功能,所有的页面表单验证,数据渲染,数据接口编写都是我们后端全部实现,看上去更像是一个全栈工程师,从需求分析、搭建整个技术架构、数据库表设计、功能设计、编码开发，再到最终部署上线,我们无所不在,这可能也是目前很多小公司仍然在沿用的开发方式,很多后端同学担负起了项目的方方面面以我目前的经验来看,这样的开发方式对我个人的成长是有益无害的,因为你只有在了解了前端的JS/CSS/HTML的情况下,然后再谈目前的前后端分离,会让你的工作事半功倍,在写后端接口前,你脑子里浮现的是整个功能的交互页面,最终呈现的是前后端合作开发好后的的终端结果,这大大缩减了前后端的沟通交流前后端分离的探索jsonp可能由于我在前面三年积累了丰富的前端经验,在上家公司主要负责开发官网、微信、后台等相关系统的接口，前期我们的开发方式虽然也是前后端分离的方式,但大都使用jsonp跨域接口调用的方式来达到分离效果,后端所有的接口都是可跨域调用的jsonp形式,抛开需要登录的授权之外的接口，前端在开发的时候本地无需开启服务即可调用服务端接口，然后渲染数据，完成页面交互渲染效果jsonp的优点  不像XMLHttpRequest对象实现的Ajax请求那样受到同源策略的限制  兼容性更好,在更低版本的ie浏览器中都能兼容,这里区别于cors跨域类型jsonp的原理其实很简单，当然,这也涉及到前端的知识,简单点说就是js端的function函数执行正常的后端响应数据,例如：{    \"code\":\"8200\",    \"data\":{        \"id\":\"100\",        \"name\":\"Test\"        //more......    }}jsonp需要的返回格式：callback({    \"code\":\"8200\",    \"data\":{        \"id\":\"100\",        \"name\":\"Test\"        //more......    }});前端在页面定义callback回调函数,callback函数接收后端响应回来的data-json数据,后端响应后执行callback函数达到调用前端业务逻辑的目的,渲染页面nginx+ajax这种配合开发方式也是适合前端还没有引入Node等一站式开发解决方案的情况下引入的,纯粹的HTML+CSS+JS同后端对接，绑定业务接口,渲染数据我们在使用JSONP开发的时候,前端都是需要在页面端写死HOST+IP接口地址,存在很重大一个弊端就是前端需要些config文件，来配置我们后端的接口请求地址，如果前端工程师规范意识强一点，会通用到一个配置文件里，但是如果没有这方面的意识的话，就会出现代码里硬编码的情况，不利于服务器迁移，代码更新，接口变动等操作为规避上面碰到的问题,使用nginx的反向代理功能,将后端服务器代理下来,前端在开发的时候本地开启nginx服务，即解决了jsonp跨域问题,同时也解决了无需写死后端的服务ip+端口地址，利于后端在部署时整合代码,减少不必要的错误node随着NodeJs的火热,前端已经可以本地开启服务写接口的情况下,就类似服务端开启tomcat一样,在这样的情况下，前端框架VUE、React等都在此基础上,提供了一套完整的技术解决方案，这和上面说到的开启nginx服务架构有点类似这样做的意义：真正的解放了前后端，专注各自擅长的领域技术架构如下：前端node服务直接访问后端Java Restful Api接口服务，Api接口最终访问数据库完成数据查询最终返回node层，node渲染响应数据到前端如果存在会话信息同步等问题，可以使用中间件,例如redis缓存数据库,解决前端node和后端Api信息同步问题，传参可以通过JWT等方式完成接口权限验证不管是jsonp还是ajax+nginx这两种方式,node作为中间件都可以轻松切换处理,而且node作为中间层,还可以将多个后端接口组合成一整个数据集,最终以同步的方式渲染前端,这也利于做SEO优化,也是前面两种方式无法做到的关于前后端分离,详细可阅读前后端分离的思考与实践,该文章详细的列述了关于前后端分离的实际经验谈谈接口随着前后端的分离,后端工程师不需要编写页面，不需要写JS,只需要提供接口即可,可是就是仅仅这一个接口，对于很多后端开发工程师而言，在实际开发，同前端对接的过程中,依然问题重重很多后端同学说我只负责写接口,其他我一概不管,这样造成的后果就是1、接口结构无序、杂乱无章2、接口和实际业务场景不相匹配、不可用3、频繁的同前端沟通，简单的事情复杂化,前后端都很恼火4、事情没做好后端在编写接口前,首先是对业务的理解,在对业务未理解透彻之前,编码都是无意义的,作为后端来说,需要锻炼自己对整个系统全局考虑的能力,接口之间并非是毫无关联的,我们在写第一个接口之间,其他接口之间的业务逻辑也许考虑到，这在后端团队合作开发不同功能的情况下显得尤为重要.后端在开发接口时,我觉得主要从以下几个方面需要注意：  接口url 定义  接口类型、参数  全局错误码定义  接口json格式  接口文档编写接口url定义对于后端开发人员来说,接口前端入参,最终组合查询数据库资源，经过一系列相关业务场景下的计算，响应给前端json数据，每一层url的path定义需要清晰明了，这和后端在使用AOP定义事务管理同理，后端service需要满足一定的命名规范，这样方便统一管理，而且有这层规范后,后续的前后端对接会轻松很多为了在许多API和长时间内提供一致的开发人员体验，API使用的所有名称应为：  简单  直觉  一致这包括接口，资源，集合，方法和消息的名称。由于许多开发人员不是英文母语人士，因此这些命名约定的目标之一是确保大多数开发人员能够轻松了解API。 它通过鼓励在命名方法和资源时使用简单，一致和小的词汇表来实现。  API中使用的名称应该是正确的美国英语。例如，许可证（而不是许可证），颜色（而不是颜色）。  可以简单地使用常用的简短形式或长字的缩写。例如，API优于应用程序编程接口。  尽可能使用直观，熟悉的术语。例如，当描述删除（和销毁）资源时，删除是优先于擦除。  对同一概念使用相同的名称或术语，包括跨API共享的概念。  避免名称重载。为不同的概念使用不同的名称。  仔细考虑使用可能与常用编程语言中的关键字冲突的名称。可以使用这些名称，但在API审查期间可能会触发额外的审查。谨慎和谨慎地使用它们。接口类型、参数关于接口的请求类型，目前比较常用的：GET、POST、PUT、DELETE、PATCH  GET（SELECT）：从服务器取出资源（一项或多项）。  POST（CREATE）：在服务器新建一个资源。  PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。  PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。  DELETE（DELETE）：从服务器删除资源。后端可根据不同的业务场景定义不同的接口类型在定义接口参数之时,目前我们常用的几种提交方式表单提交，application/x-www-form-urlencoded表单提交主要针对key-value的提交形式如下Java片段：@PostMapping(\"/queryAll\")public RestfulMessage queryAll(RuleCheckLogs ruleCheckLogs, @RequestParam(value = \"current_page\",defaultValue = \"1\")Integer current_page            , @RequestParam(value = \"page_size\",defaultValue = \"10\")Integer page_size            , @RequestParam(value = \"tableName\",required = false) String tableName){        RestfulMessage restfulMessage=new RestfulMessage();        try{            assertArgumentNotEmpty(ruleCheckLogs.getProjectId(),\"质检方案id不能为空\"); restfulMessage.setData(qcRuleCheckLogsService.queryRuleLogsByPage(ruleCheckLogs,tableName,current_page,page_size));        }catch (Exception e){            restfulMessage=wrapperException(e);        }        return restfulMessage;}文件流提交json提交,application/jsonjson提交方式在SpringMVC或Spring Boot中主要有两种,一种是以@RequestBody注解接收方式，另外一种是以HttpEntity&lt;String&gt; requestEntity字节接收Java代码示例：@PostMapping(\"/mergeModelEntitys\")public RestfulMessage mergeModelEntitys(HttpEntity&lt;String&gt; requestEntity){    RestfulMessage restfulMessage=new RestfulMessage();    try{        JsonObject paramsJson = paramJson(requestEntity);        assertJsonNotEmpty(paramsJson,\"请求参数不能为空\");        //more...    }catch (Exception e){        restfulMessage=wrapperException(e);    }    return restfulMessage;}全局错误码定义错误码的定义同HTTP请求状态码一样,对接者能通过系统定义的错误码,快速了解接口返回错误信息，方便排查错误原因{    \"code\": \"8200\",    \"message\": \"Success\",    \"data\": {        \"total_page\": 1,        \"current_page\": 1,        \"page_size\": 10,        \"count\": 5,        \"data\": [            {                \"id\": \"a29ab07f1d374c22a72e884d4e822b29\",                //......            }//....        ]    }}接口json格式后端响应json给前端需要注意以下几点：1、json格式需固定例如如下图形如上图所示,横向是时间,纵向是value值我们给出的json结构应该如此：[    {        \"date\":\"2018-01\",        \"value\":100    },    {        \"date\":\"2018-02\",        \"value\":200    }    //more...]在工作中,我们经常碰见这样的数据格式：[    \"2018-01\":{    \tvalue:100    },    \"2018-02\":{    \tvalue:200    }    //more...]这里所说的json格式固定主要针对此种情况,后端给到前端的接口格式必须是固定的，所有动态数据值都需相应的key与之对应2、所有返回接口数据需直接可用,越简单越好后端提供给前端的接口数据,最终交给前端的工作，只需要让前端渲染数据即可,越简单越好，不因掺杂过多的业务逻辑让前端处理，所有复杂的业务逻辑，能合并规避掉的都需后端处理掉.接口文档编写接口文档编写是前后端对接重要依据，后端写明接口文档，前端根据接口文档对接文档形势目前主要分几种：1、依赖swagger框架，自动生成接口文档（swagger只能生成基于key-value详细参数方式，针对json格式，无法说明具体请求内容）2、手动编写说明文档，推荐markdown编写接口对接万事俱备,只欠东风,虽然上面我们准备了所有我们该准备的，接口定义完美无缺,接口文档也已说明，但在对接时任然可能出现问题，此时我想我们还需注意的细节1、后端接口需自行进行Junit单元测试Spring目前集成Junit框架可方便进行单元测试，包括对业务bean的方法测试，以及针对api的mock测试@RunWith(SpringRunner.class)@SpringBootTestpublic class QcWebApplicationTests {\t@Autowired\tprivate WebApplicationContext context;\tprivate MockMvc mvc;\t@Autowired\tQcFieldService qcFieldService;\t@Before\tpublic void setUp() throws Exception {        //初始化mock对象\t\tmvc = MockMvcBuilders.webAppContextSetup(context).build();\t}\t@Test\tpublic void queryByDsId(){\t\ttry {            //针对mock-接口Controller层测试\t\t\tmvc.perform(MockMvcRequestBuilders.post(\"/qc/entity/queryByDsId\")                    .contentType(MediaType.APPLICATION_JSON_UTF8)                    .param(\"dsId\", \"7d4c101498c742368ef7232f492b95bc\")                    .accept(MediaType.APPLICATION_JSON))                    .andExpect(MockMvcResultMatchers.status().isOk())                    .andDo(MockMvcResultHandlers.print());\t\t} catch (Exception e) {\t\t\te.printStackTrace();\t\t}\t}        @Test    public void testUpdateField(){\t\tQcField qcField=new QcField();\t\tqcField.setId(\"513ee55f5dc2498cb69b14b558bc73e6\");\t\tqcField.setShortName(\"密码\");        //业务bean-service方法测试\t\tqcFieldService.updateBatchFields(Lists.newArrayList(qcField));\t}2、使用工具测试，推荐PostMan作为接口调试神器,Postman大名想必大家都已知道作为后端来说,我们需要学会查看chrome推荐给我们的审查元素的功能，可参看Chrome开发工具介绍chrome提供了一个可以copy当前接口的url功能，最终生成curl命令行最终通过Copy as cURL(bash)功能可生成curl命令curl 'http://demo.com/qc/ds/getAll' -H 'Origin: http://demo.com' -H 'Accept-Encoding: gzip, deflate' -H 'Accept-Language: zh-CN,zh;q=0.9' -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36' -H 'Content-Type: application/x-www-form-urlencoded' -H 'Accept: application/json, text/plain, */*' -H 'Referer: http://demo.com/index.html' -H 'Connection: keep-alive' --data 'current_page=1&amp;page_size=6&amp;' --compressed以上命令可以在Linux等各终端直接执行curl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。postman提供导入curl命令行3、前后端需心平气和沟通，勿推卸责任，前后端开发人员水平不尽相同,作为同事,需要的是团结合作，努力将事情做好,而非相互推卸结语前后端分离,简化了我们的开发方式,不同人专注于不同的领域,技术价值最大化,大大提高工作效率,我们在掌握这些技能的同时,也需要加强自身的发展,以适应当前的技术发展趋势,不管是前端还是后端,多了解一些，总是没错的,古人云：技多不压身，我想也正是此理！！！"
  },
  
  {
    "title": "在Spring Boot中使用swagger-bootstrap-ui",
    "url": "/posts/swagger-bootstarp-ui-with-spring-boot/",
    "categories": "Spring",
    "tags": "",
    "date": "2018-01-31 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui是基于swagger接口api实现的一套UI,因swagger原生ui是上下结构的，在浏览接口时不是很清晰,所以，swagger-bootstrap-ui是基于左右菜单风格的方式,适用与我们在开发后台系统左右结构这种风格类似,方便与接口浏览GITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI码云...",
    "content": "swagger-bootstrap-ui是基于swagger接口api实现的一套UI,因swagger原生ui是上下结构的，在浏览接口时不是很清晰,所以，swagger-bootstrap-ui是基于左右菜单风格的方式,适用与我们在开发后台系统左右结构这种风格类似,方便与接口浏览GITHUB:https://github.com/xiaoymin/Swagger-Bootstrap-UI码云:https://gitee.com/xiaoym/swagger-bootstrap-ui欢迎大家Watch,Fork,Star界面预览：引入swagger在pom.xml文件中引入swagger以及ui的jar包依赖&lt;dependency&gt;  &lt;groupId&gt;io.springfox&lt;/groupId&gt;  &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;  &lt;version&gt;2.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--引入ui包--&gt;&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;  &lt;version&gt;1.7&lt;/version&gt;&lt;/dependency&gt;配置configuration配置swagger的启用配置文件，关键注解@EnableSwagger2一下配置是支持接口分组的配置，如果没有分组配置,只需要创建一个Docket即可@Configuration@EnableSwagger2public class SwaggerConfiguration {    @Bean    public Docket createRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .groupName(\"资源管理\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.lishiots.dc.baseinfo.ctl\"))                .paths(PathSelectors.any())                .build();    }    @Bean    public Docket createMonitorRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .groupName(\"实时监测\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.lishiots.dc.monitor.ctl\"))                .paths(PathSelectors.any())                .build();    }    @Bean    public Docket createActivitiRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .groupName(\"工作流引擎\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.lishiots.dc.activiti.ctl\"))                .paths(PathSelectors.any())                .build();    }    @Bean    public Docket createBaseRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .groupName(\"kernel模块\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.lishiots.dc.kernel.ctl\"))                .paths(PathSelectors.any())                .build();    }    @Bean    public Docket createComplaintRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .groupName(\"投诉管理\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.lishiots.dc.complaint.ctl\"))                .paths(PathSelectors.any())                .build();    }    private ApiInfo apiInfo() {        return new ApiInfoBuilder()                .title(\"swagger RESTful APIs\")                .description(\"swagger RESTful APIs\")                .termsOfServiceUrl(\"http://www.test.com/\")                .contact(\"xiaoymin@foxmail.com\")                .version(\"1.0\")                .build();    }}Controller层使用swagger注解ctl代码层：@Api(tags = \"banner管理\")@RestController@RequestMapping(\"/api/bannerInfo\")public class BannerCtl {    @Autowired    private BannerInfoService service;        @PostMapping(\"/query\")    @ApiOperation(value = \"查询banner\",notes = \"查询banner\")    public Pagination&lt;BannerInfo&gt; bannerInfoQuery(){        Pagination&lt;BannerInfo&gt; pagination = service.bannerInfoQuery();        return pagination;    }}接口访问在浏览器输入：http://${host}:${port}/doc.html"
  },
  
  {
    "title": "mysql数据库只读用户创建",
    "url": "/posts/mysql-user-onlyread/",
    "categories": "数据库",
    "tags": "",
    "date": "2018-01-30 00:00:00 +0800",
    





    
    "snippet": "登录mysql[root@s91 ~]# mysql -u root -p1234Welcome to the MariaDB monitor.  Commands end with ; or \\g.Your MariaDB connection id is 106959398Server version: 10.1.25-MariaDB MariaDB ServerCopyright (c...",
    "content": "登录mysql[root@s91 ~]# mysql -u root -p1234Welcome to the MariaDB monitor.  Commands end with ; or \\g.Your MariaDB connection id is 106959398Server version: 10.1.25-MariaDB MariaDB ServerCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.MariaDB [(none)]&gt; show databases;+------------------------------+| Database                     |+------------------------------+| test         || mysql        |创建用户MariaDB [(none)]&gt; create user test identified by 'test123';Query OK, 0 rows affected (0.01 sec)MariaDB [(none)]&gt; 授权MariaDB [cloud-lishui_daping]&gt; grant select on `cloud-test`.* to test@\"%\" identified by \"test1234\";Query OK, 0 rows affected (0.02 sec)MariaDB [cloud-lishui_daping]&gt; 特别注意是如果数据库 有-，需要用倒引号引起来，否则会报语法错误"
  },
  
  {
    "title": "在Linux操作系统上部署VUE开发的node应用",
    "url": "/posts/vue-node-app-linux/",
    "categories": "Linux",
    "tags": "",
    "date": "2018-01-26 00:00:00 +0800",
    





    
    "snippet": "Linux 服务器CentOS Linux release 7.3.1611 (Core) 配置node环境查看node是否安装[root@localhost ~]# nodebash: node: 未找到命令...从以上命令看出,node环境没有安装,需要安装node基础环境首先去node官网下载node的安装包英文官网访问太慢可以访问中文官网阿里云镜像：https://npm.taoba...",
    "content": "Linux 服务器CentOS Linux release 7.3.1611 (Core) 配置node环境查看node是否安装[root@localhost ~]# nodebash: node: 未找到命令...从以上命令看出,node环境没有安装,需要安装node基础环境首先去node官网下载node的安装包英文官网访问太慢可以访问中文官网阿里云镜像：https://npm.taobao.org/mirrors/node/本次下载的node版本是：node-v6.11.3-linux-x64.tar.xz解压# 解压[root@localhost ~]# tar -xvf node-v6.11.3-linux-x64.tar.xz[root@localhost ~]# mv node-v6.11.3-linux-x64 /usr/local/node## 配置环境变量[root@localhost ~]# vim /etc/profile[root@localhost ~]# node配置环境变量[root@localhost ~]# vim /etc/profileexport NODE_HOME=/usr/local/nodeexport PATH=$NODE_HOME/bin:$PATH[root@localhost local]# source /etc/profile[root@localhost local]# node -vv6.11.3 部署该项目是依赖nuxt开发,参考文章：nuxt commands章节官网说明中可以在项目中的package.json文件中查看package.json配置文件如下：{  \"name\": \"off\",  \"version\": \"1.0.0\",  \"description\": \"off\",  \"author\": \"jzc\",  \"private\": true,   \"config\": {        \"nuxt\": {            \"host\": \"127.0.0.1\",            \"port\": \"18010\"        }    },  \"scripts\": {    \"dev\": \"nuxt\",    \"build\": \"nuxt build\",    \"start\": \"nuxt start\",    \"generate\": \"nuxt generate\",    \"lint\": \"eslint --ext .js,.vue --ignore-path .gitignore .\",    \"precommit\": \"npm run lint\"  },  \"dependencies\": {    \"animejs\": \"^2.2.0\",    \"less\": \"^2.7.3\",    \"less-loader\": \"^4.0.5\",    \"nuxt\": \"^1.0.0\",    \"vue-awesome-swiper\": \"^3.1.2\"  },  \"devDependencies\": {    \"babel-eslint\": \"^8.2.1\",    \"eslint\": \"^4.15.0\",    \"eslint-friendly-formatter\": \"^3.0.0\",    \"eslint-loader\": \"^1.7.1\",    \"eslint-plugin-vue\": \"^4.0.0\"  }}先执行build操作[root@localhost ~] npm run build&gt; off@1.0.0 build /mnt/lishi/website&gt; nuxt build  ████████████████████ 100% Build completed in 14.168s WARNING  Compiled with 1 warnings                                                                                                                                                     10:50:26 warning  asset size limit: The following asset(s) exceed the recommended size limit (300 kB).This can impact web performance.Assets:   img/banner.c8fa5d3.png (679 kB)  img/cs.7924e8d.png (816 kB)  img/video.f81e697.png (356 kB)  img/OTS.426eca7.png (475 kB)  img/bender.0761e66.png (639 kB)  img/introduce.7c0f1a1.png (421 kB)  img/control.f36ce27.png (479 kB)Hash: 711ed163bda0e68a99b7Version: webpack 3.10.0Time: 14173ms                                            Asset       Size  Chunks                    Chunk Names                          img/ambient.f5922ac.png    2.62 kB          [emitted]                      img/administration_hover.875f478.png    2.58 kB          [emitted]                                 img/zhengshu4.9846a5d.png    26.7 kB          [emitted]                                img/experience.9e12d2c.png    1.47 kB          [emitted]                                    img/ticket.978864e.png     1.3 kB          [emitted]                                   img/service.a5b3c65.png    1.83 kB          [emitted]                                   img/iPhoneX.248a9cc.png    23.5 kB          [emitted]                               img/jingguanjia.8afc7c3.png    3.45 kB          [emitted]                          img/contentServiceBg.c9eb329.png     233 kB          [emitted]                                   img/tourist.5a236ea.png    3.16 kB          [emitted]                                 img/zhengshu3.07ef39a.png    37.1 kB          [emitted]                                img/youguanjia.09f7ff1.png    2.89 kB          [emitted]                         img/emergencyHandling.900bb3c.png    1.37 kB          [emitted]                                         img/b.d3ce94c.jpg    39.1 kB          [emitted]                          img/experience_hover.58b2c47.png    1.47 kB          [emitted]                                img/parkingLot.8c62aba.png    2.25 kB          [emitted]                                 img/marketing.1fb5e28.png    1.77 kB          [emitted]                                      img/roam.9faa35b.png    2.91 kB          [emitted]                                  img/evaluate.ea2bdeb.png    2.18 kB          [emitted]                                    img/QRCode.0a50fbd.png    11.5 kB          [emitted]                              img/scenicSpotBg.a5b307c.png     184 kB          [emitted]                                img/government.d086f44.png    1.78 kB          [emitted]                                       img/web.315c435.png    3.28 kB          [emitted]                                         img/c.238373a.jpg    20.7 kB          [emitted]                                    img/server.41de726.png    2.15 kB          [emitted]                            img/serviceContent.5d5f7c6.png    2.29 kB          [emitted]                                   img/levelBg.0562974.png    4.65 kB          [emitted]                                img/enterprise.56dae04.png    3.22 kB          [emitted]                          img/evaluationSystem.730526f.png    3.46 kB          [emitted]                                  img/shujujia.bb08350.png    3.01 kB          [emitted]                                 img/keepWatch.c55759f.png    1.91 kB          [emitted]                              img/server_hover.fdef7a3.png    2.31 kB          [emitted]                                    img/banner.c8fa5d3.png     679 kB          [emitted]  [big]                                 img/cs.7924e8d.png     816 kB          [emitted]  [big]                              img/video.f81e697.png     356 kB          [emitted]  [big]                          img/zhengshu2.4a19c1d.png    10.7 kB          [emitted]                                         img/a.2ba6f0c.jpg    26.4 kB          [emitted]                              img/scenicSpotBg.9804948.png    4.74 kB          [emitted]                                 img/marketing.35166b4.png    1.21 kB          [emitted]                                   img/monitor.8af33d3.png    2.65 kB          [emitted]                                    img/WeChat.896ae2d.png    2.36 kB          [emitted]                                      img/Wifi.f7571ea.png    2.61 kB          [emitted]                            img/administration.fc3f856.png    2.52 kB          [emitted]                                 img/broadcast.3372863.png     2.3 kB          [emitted]                           img/onlineRetailers.2b9a700.png    2.22 kB          [emitted]                                 img/marketing.ae28534.png    2.59 kB          [emitted]                               img/body2-item3.3b33ea4.png    3.44 kB          [emitted]                                 img/zhengshu5.907473c.png    47.8 kB          [emitted]                               img/body2-item1.cffdfb7.png    3.49 kB          [emitted]                               img/body2-item2.8b4ef31.png    3.66 kB          [emitted]                                       img/OTS.426eca7.png     475 kB          [emitted]  [big]                         img/recreation.417f692.png    3.04 kB          [emitted]                                      img/logo.ae9fae7.png    10.1 kB          [emitted]                                   img/release.f878c29.png     2.5 kB          [emitted]                                    img/bender.0761e66.png     639 kB          [emitted]  [big]                         img/enterprise.b12daef.png    2.11 kB          [emitted]                               img/marketingBg.0831255.png     2.6 kB          [emitted]                                     img/level.c7b1a8d.png    3.84 kB          [emitted]                                        img/VR.e0368e4.png    2.08 kB          [emitted]                                 img/zhengshu1.4a19c1d.png    10.7 kB          [emitted]                                 img/introduce.7c0f1a1.png     421 kB          [emitted]  [big]                            img/control.f36ce27.png     479 kB          [emitted]  [big]                         img/scenicSpot.775e2d1.png    4.05 kB          [emitted]                                img/body3-back.d346a0b.png     270 kB          [emitted]                        img/vehiclesAndVessels.28c0194.png    2.41 kB          [emitted]                                img/streetLamp.27a4c2e.png    2.06 kB          [emitted]                                  img/analysis.3d36965.png    2.16 kB          [emitted]                                   img/support.18f87fd.png    1.68 kB          [emitted]                           img/onlineRetailers.94150fa.png    1.74 kB          [emitted]                              img/enterpriseBg.4d6b672.png    4.81 kB          [emitted]                                     img/voice.aeb96b7.png    1.56 kB          [emitted]                           img/marketing_hover.a87ef11.png    3.12 kB          [emitted]                                  img/serverBg.95d78c4.png     213 kB          [emitted]         pages/product/jingguanjia.6d096988929c96b79c84.js    36.3 kB       0  [emitted]         pages/product/jingguanjia      pages/aboutUS/index.b87dc531e556bf7861ed.js    45.4 kB       1  [emitted]         pages/aboutUS/index pages/product/youguanjia.8b2dc5016946854c880d.js    19.9 kB       2  [emitted]         pages/product/youguanjia              pages/index.cfc2a9df7c5b2fea91db.js    38.1 kB       3  [emitted]         pages/index   pages/product/shujujia.88e3f673ff804d0569bd.js    19.5 kB       4  [emitted]         pages/product/shujujia         pages/News/index.cc009a13f2a811d4f9c5.js    32.6 kB       5  [emitted]         pages/News/index          layouts/default.7dd836b9fa5dbc88593f.js    1.41 kB       6  [emitted]         layouts/default                   vendor.258d4bae08c591e6eccc.js     284 kB       7  [emitted]         vendor                      app.b0507b107754ae5b2939.js    29.8 kB       8  [emitted]         app                 manifest.711ed163bda0e68a99b7.js    1.79 kB       9  [emitted]         manifest                                         LICENSES  697 bytes          [emitted]          + 3 hidden assetsWARNING in asset size limit: The following asset(s) exceed the recommended size limit (300 kB).This can impact web performance.Assets:   img/banner.c8fa5d3.png (679 kB)  img/cs.7924e8d.png (816 kB)  img/video.f81e697.png (356 kB)  img/OTS.426eca7.png (475 kB)  img/bender.0761e66.png (639 kB)  img/introduce.7c0f1a1.png (421 kB)  img/control.f36ce27.png (479 kB)Hash: a096aa98f9ed65c1ec48Version: webpack 3.10.0Time: 2641ms             Asset    Size  Chunks             Chunk Namesserver-bundle.json  507 kB          [emitted]最终后台启动[root@localhost ~] npm run start &amp;&gt; off@1.0.0 start /mnt/lishi/website&gt; nuxt start OPEN  http://iZbp10yas4kb5a9dudjbw2Z:18010其他node程序最终启动成功,可以通过ps命令查找进程[root@localhost ~] ps -ef|grep nodelishi    10155 10145  0 11:19 pts/1    00:00:03 node /mnt/project/website/node_modules/.bin/nuxt startroot     13134 10274  0 13:43 pts/1    00:00:00 grep --color=auto node[root@localhost ~] 通过端口查找：[root@localhost ~] netstat -anp|grep 8083(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp        0      0 0.0.0.0:8083            0.0.0.0:*               LISTEN      27562/java          [root@localhost ~] netstat -anp|grep 18010(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp        0      0 127.0.0.1:18010         0.0.0.0:*               LISTEN      10155/node          lishi@iZbp10yas4kb5a9dudjbw2Z:/usr/local/nginx/conf/vhost&gt; 通过上面列出来的进程信息,18010端口是node开启的服务器,8083是后台Java开启的tomcat服务比较之后，会发现一个是127.0.0.1，一个是0.0.0.0重点说明 0.0.0.0 是对外开放，通过服务域名、ip可以访问的端口127.0.0.1 只能对本机 localhost访问，也是保护此端口安全性所以最终node启用的服务 最后我只能改由nginx代理才能出去，这个怎么解决尚未有解决方案pm2pm2 是一个带有负载均衡功能的Node应用的进程管理器.当你要把你的独立代码利用全部的服务器上的所有CPU,并保证进程永远都活着,0秒的重载, PM2是完美的PM2是node进程管理工具，可以利用它来简化很多node应用管理的繁琐任务，如性能监控、自动重启、负载均衡等，而且使用非常简单。安装lishi@iZbp10yas4kb5a9dudjbw2Z:/mnt/lishi/website&gt; npm install -g pm2/usr/local/node-v9.0.0/bin/pm2 -&gt; /usr/local/node-v9.0.0/lib/node_modules/pm2/bin/pm2/usr/local/node-v9.0.0/bin/pm2-dev -&gt; /usr/local/node-v9.0.0/lib/node_modules/pm2/bin/pm2-dev/usr/local/node-v9.0.0/bin/pm2-docker -&gt; /usr/local/node-v9.0.0/lib/node_modules/pm2/bin/pm2-docker/usr/local/node-v9.0.0/bin/pm2-runtime -&gt; /usr/local/node-v9.0.0/lib/node_modules/pm2/bin/pm2-runtimenpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.1.3 (node_modules/pm2/node_modules/fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.1.3: wanted {\"os\":\"darwin\",\"arch\":\"any\"} (current: {\"os\":\"linux\",\"arch\":\"x64\"})+ pm2@2.9.3added 252 packages in 119.179slishi@iZbp10yas4kb5a9dudjbw2Z:/mnt/lishi/website&gt; pm2 list&gt;&gt;&gt;&gt; In-memory PM2 is out-of-date, do:&gt;&gt;&gt;&gt; $ pm2 updateIn memory PM2 version: 2.7.0Local PM2 version: 2.9.3┌──────────┬────┬──────┬─────┬────────┬─────────┬────────┬─────┬─────┬──────┬──────────┐│ App name │ id │ mode │ pid │ status │ restart │ uptime │ cpu │ mem │ user │ watching │└──────────┴────┴──────┴─────┴────────┴─────────┴────────┴─────┴─────┴──────┴──────────┘ Use `pm2 show &lt;id|name&gt;` to get more details about an appnuxt.js的项目启动命令，先执行npm run build,在执行npm run start,pm2也支持参数的传递，也有大神说pm2启动nuxt只需要执行pm2 start npm -- run start,到目前为止，表示项目没有这样启动成功过。所以我们要知道package.json这个文件，当我们执行npm run dev的时候，其实使用npm去启动了./node_modules/nuxt/bin/nuxt这个文件。当我们cd到我们的项目目录之后，我们最终可以执行如下命令来启动：pm2 start ./node_modules/nuxt/bin/nuxt -- start以上命令启动是默认端口3000，如果我们要自定义端口 需要执行参数lishi@iZbp10yas4kb5a9dudjbw2Z:/mnt/lishi/website&gt; netstat -anp|grep nux(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp        0      0 127.0.0.1:3000          0.0.0.0:*               LISTEN      3804/nuxt           查看帮助文档：lishi@iZbp10yas4kb5a9dudjbw2Z:/mnt/lishi/website&gt; ./node_modules/nuxt/bin/nuxt --help    Description      Starts the application in development mode (hot-code reloading, error      reporting, etc)    Usage      $ nuxt dev &lt;dir&gt; -p &lt;port number&gt; -H &lt;hostname&gt;    Options      --port, -p          A port number on which to start the application      --hostname, -H      Hostname on which to start the application      --spa               Launch in SPA mode      --universal         Launch in Universal mode (default)      --config-file, -c   Path to Nuxt.js config file (default: nuxt.config.js)      --help, -h          Displays this message  "
  },
  
  {
    "title": "Spring Boot 任务task源码分析",
    "url": "/posts/spring-boot-task-sources/",
    "categories": "Spring",
    "tags": "",
    "date": "2018-01-26 00:00:00 +0800",
    





    
    "snippet": "EnableScheduling注解在Spring Boot中添加任务job时,已提供很好的支持,只需在SpringBoot启动类加@EnableScheduling注解即可如：package com.lishiots.lshui;import org.springframework.boot.SpringApplication;import org.springframework.boot...",
    "content": "EnableScheduling注解在Spring Boot中添加任务job时,已提供很好的支持,只需在SpringBoot启动类加@EnableScheduling注解即可如：package com.lishiots.lshui;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.scheduling.annotation.EnableScheduling;@SpringBootApplication@EnableSchedulingpublic class ApiApplication {\tpublic static void main(String[] args) {\t\tSpringApplication.run(ApiApplication.class, args);\t}}EnableScheduling注解源码：1、导入SchedulingConfiguration配置2、注入ScheduledAnnotationBeanPostProcessorBean实例/* * Copyright 2002-2016 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * *      http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.springframework.scheduling.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import java.util.concurrent.Executor;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;import org.springframework.scheduling.Trigger;import org.springframework.scheduling.config.ScheduledTaskRegistrar;/** * Enables Spring's scheduled task execution capability, similar to * functionality found in Spring's {@code &lt;task:*&gt;} XML namespace. To be used * on @{@link Configuration} classes as follows: * * &lt;pre class=\"code\"&gt; * &amp;#064;Configuration * &amp;#064;EnableScheduling * public class AppConfig { * *     // various &amp;#064;Bean definitions * }&lt;/pre&gt; * * This enables detection of @{@link Scheduled} annotations on any Spring-managed * bean in the container. For example, given a class {@code MyTask} * * &lt;pre class=\"code\"&gt; * package com.myco.tasks; * * public class MyTask { * *     &amp;#064;Scheduled(fixedRate=1000) *     public void work() { *         // task execution logic *     } * }&lt;/pre&gt; * * the following configuration would ensure that {@code MyTask.work()} is called * once every 1000 ms: * * &lt;pre class=\"code\"&gt; * &amp;#064;Configuration * &amp;#064;EnableScheduling * public class AppConfig { * *     &amp;#064;Bean *     public MyTask task() { *         return new MyTask(); *     } * }&lt;/pre&gt; * * Alternatively, if {@code MyTask} were annotated with {@code @Component}, the * following configuration would ensure that its {@code @Scheduled} method is * invoked at the desired interval: * * &lt;pre class=\"code\"&gt; * &amp;#064;Configuration * &amp;#064;EnableScheduling * &amp;#064;ComponentScan(basePackages=\"com.myco.tasks\") * public class AppConfig { * }&lt;/pre&gt; * * Methods annotated with {@code @Scheduled} may even be declared directly within * {@code @Configuration} classes: * * &lt;pre class=\"code\"&gt; * &amp;#064;Configuration * &amp;#064;EnableScheduling * public class AppConfig { * *     &amp;#064;Scheduled(fixedRate=1000) *     public void work() { *         // task execution logic *     } * }&lt;/pre&gt; * * &lt;p&gt;By default, will be searching for an associated scheduler definition: either * a unique {@link org.springframework.scheduling.TaskScheduler} bean in the context, * or a {@code TaskScheduler} bean named \"taskScheduler\" otherwise; the same lookup * will also be performed for a {@link java.util.concurrent.ScheduledExecutorService} * bean. If neither of the two is resolvable, a local single-threaded default * scheduler will be created and used within the registrar. * * &lt;p&gt;When more control is desired, a {@code @Configuration} class may implement * {@link SchedulingConfigurer}. This allows access to the underlying * {@link ScheduledTaskRegistrar} instance. For example, the following example * demonstrates how to customize the {@link Executor} used to execute scheduled * tasks: * * &lt;pre class=\"code\"&gt; * &amp;#064;Configuration * &amp;#064;EnableScheduling * public class AppConfig implements SchedulingConfigurer { * *     &amp;#064;Override *     public void configureTasks(ScheduledTaskRegistrar taskRegistrar) { *         taskRegistrar.setScheduler(taskExecutor()); *     } * *     &amp;#064;Bean(destroyMethod=\"shutdown\") *     public Executor taskExecutor() { *         return Executors.newScheduledThreadPool(100); *     } * }&lt;/pre&gt; * * &lt;p&gt;Note in the example above the use of {@code @Bean(destroyMethod=\"shutdown\")}. * This ensures that the task executor is properly shut down when the Spring * application context itself is closed. * * &lt;p&gt;Implementing {@code SchedulingConfigurer} also allows for fine-grained * control over task registration via the {@code ScheduledTaskRegistrar}. * For example, the following configures the execution of a particular bean * method per a custom {@code Trigger} implementation: * * &lt;pre class=\"code\"&gt; * &amp;#064;Configuration * &amp;#064;EnableScheduling * public class AppConfig implements SchedulingConfigurer { * *     &amp;#064;Override *     public void configureTasks(ScheduledTaskRegistrar taskRegistrar) { *         taskRegistrar.setScheduler(taskScheduler()); *         taskRegistrar.addTriggerTask( *             new Runnable() { *                 public void run() { *                     myTask().work(); *                 } *             }, *             new CustomTrigger() *         ); *     } * *     &amp;#064;Bean(destroyMethod=\"shutdown\") *     public Executor taskScheduler() { *         return Executors.newScheduledThreadPool(42); *     } * *     &amp;#064;Bean *     public MyTask myTask() { *         return new MyTask(); *     } * }&lt;/pre&gt; * * &lt;p&gt;For reference, the example above can be compared to the following Spring XML * configuration: * * &lt;pre class=\"code\"&gt; * {@code * &lt;beans&gt; * *     &lt;task:annotation-driven scheduler=\"taskScheduler\"/&gt; * *     &lt;task:scheduler id=\"taskScheduler\" pool-size=\"42\"/&gt; * *     &lt;task:scheduled-tasks scheduler=\"taskScheduler\"&gt; *         &lt;task:scheduled ref=\"myTask\" method=\"work\" fixed-rate=\"1000\"/&gt; *     &lt;/task:scheduled-tasks&gt; * *     &lt;bean id=\"myTask\" class=\"com.foo.MyTask\"/&gt; * * &lt;/beans&gt; * }&lt;/pre&gt; * * The examples are equivalent save that in XML a &lt;em&gt;fixed-rate&lt;/em&gt; period is used * instead of a custom &lt;em&gt;{@code Trigger}&lt;/em&gt; implementation; this is because the * {@code task:} namespace {@code scheduled} cannot easily expose such support. This is * but one demonstration how the code-based approach allows for maximum configurability * through direct access to actual componentry.&lt;p&gt; * * @author Chris Beams * @author Juergen Hoeller * @since 3.1 * @see Scheduled * @see SchedulingConfiguration * @see SchedulingConfigurer * @see ScheduledTaskRegistrar * @see Trigger * @see ScheduledAnnotationBeanPostProcessor */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(SchedulingConfiguration.class)@Documentedpublic @interface EnableScheduling {}##Scheduled注解job类只需在方法上加@Scheduled注解即可,支持cron表达式例如：/*** * * @since:screen-api 1.0 * @author &lt;a href=\"mailto:xiaoymin@foxmail.com\"&gt;xiaoymin@foxmail.com&lt;/a&gt;  * 2018/01/22 13:44 */@Componentpublic class JgJob {    private static final Logger logger = LoggerFactory.getLogger(JgJob.class);    @Autowired    JgService jgService;    @Scheduled(cron = \"0 0/2 * * * ?\")    public void jgFlowJob(){        logger.info(\"同步极光数据任务开始...\");        logger.info(new DateTime().toString(\"yyyy-MM-dd HH:mm:ss\"));        String date=DateTime.now().toString(\"yyyyMMddHHmm\");        jgService.syncJgTouristFlow(date);        logger.info(\"同步极光数据任务结束...\");    }  }查看Scheduled注解源码：  使用该注解标注的方法将会被执行，指定cron或者fxedDelay或者fixedRate属性  该注解标注必须无参数,如果有返回参数,将会被忽略  通过类ScheduledAnnotationBeanPostProcessor注入/** * An annotation that marks a method to be scheduled. Exactly one of * the {@link #cron()}, {@link #fixedDelay()}, or {@link #fixedRate()} * attributes must be specified. * * &lt;p&gt;The annotated method must expect no arguments. It will typically have * a {@code void} return type; if not, the returned value will be ignored * when called through the scheduler. * * &lt;p&gt;Processing of {@code @Scheduled} annotations is performed by * registering a {@link ScheduledAnnotationBeanPostProcessor}. This can be * done manually or, more conveniently, through the {@code &lt;task:annotation-driven/&gt;} * element or @{@link EnableScheduling} annotation. * * &lt;p&gt;This annotation may be used as a &lt;em&gt;meta-annotation&lt;/em&gt; to create custom * &lt;em&gt;composed annotations&lt;/em&gt; with attribute overrides. * * @author Mark Fisher * @author Dave Syer * @author Chris Beams * @since 3.0 * @see EnableScheduling * @see ScheduledAnnotationBeanPostProcessor * @see Schedules */@Target({ElementType.METHOD, ElementType.ANNOTATION_TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(Schedules.class)public @interface Scheduled { .... }##SchedulingConfiguration/** * {@code @Configuration} class that registers a {@link ScheduledAnnotationBeanPostProcessor} * bean capable of processing Spring's @{@link Scheduled} annotation. * * &lt;p&gt;This configuration class is automatically imported when using the * {@link EnableScheduling @EnableScheduling} annotation. See * {@code @EnableScheduling}'s javadoc for complete usage details. * * @author Chris Beams * @since 3.1 * @see EnableScheduling * @see ScheduledAnnotationBeanPostProcessor */@Configuration@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public class SchedulingConfiguration {\t@Bean(name = TaskManagementConfigUtils.SCHEDULED_ANNOTATION_PROCESSOR_BEAN_NAME)\t@Role(BeanDefinition.ROLE_INFRASTRUCTURE)\tpublic ScheduledAnnotationBeanPostProcessor scheduledAnnotationProcessor() {\t\treturn new ScheduledAnnotationBeanPostProcessor();\t}}ScheduledAnnotationBeanPostProcessor/* * Copyright 2002-2017 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * *      http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.springframework.scheduling.annotation;import java.lang.reflect.Method;import java.util.Collection;import java.util.Collections;import java.util.IdentityHashMap;import java.util.LinkedHashSet;import java.util.Map;import java.util.Set;import java.util.TimeZone;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ScheduledExecutorService;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.springframework.aop.support.AopUtils;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.BeanFactoryAware;import org.springframework.beans.factory.BeanNameAware;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.ListableBeanFactory;import org.springframework.beans.factory.NoSuchBeanDefinitionException;import org.springframework.beans.factory.NoUniqueBeanDefinitionException;import org.springframework.beans.factory.SmartInitializingSingleton;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.beans.factory.config.ConfigurableBeanFactory;import org.springframework.beans.factory.config.DestructionAwareBeanPostProcessor;import org.springframework.beans.factory.config.NamedBeanHolder;import org.springframework.beans.factory.support.MergedBeanDefinitionPostProcessor;import org.springframework.beans.factory.support.RootBeanDefinition;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.context.ApplicationListener;import org.springframework.context.EmbeddedValueResolverAware;import org.springframework.context.event.ContextRefreshedEvent;import org.springframework.core.MethodIntrospector;import org.springframework.core.Ordered;import org.springframework.core.annotation.AnnotatedElementUtils;import org.springframework.scheduling.TaskScheduler;import org.springframework.scheduling.Trigger;import org.springframework.scheduling.config.CronTask;import org.springframework.scheduling.config.IntervalTask;import org.springframework.scheduling.config.ScheduledTask;import org.springframework.scheduling.config.ScheduledTaskRegistrar;import org.springframework.scheduling.support.CronTrigger;import org.springframework.scheduling.support.ScheduledMethodRunnable;import org.springframework.util.Assert;import org.springframework.util.StringUtils;import org.springframework.util.StringValueResolver;/** * Bean post-processor that registers methods annotated with @{@link Scheduled} * to be invoked by a {@link org.springframework.scheduling.TaskScheduler} according * to the \"fixedRate\", \"fixedDelay\", or \"cron\" expression provided via the annotation. * * &lt;p&gt;This post-processor is automatically registered by Spring's * {@code &lt;task:annotation-driven&gt;} XML element, and also by the * {@link EnableScheduling @EnableScheduling} annotation. * * &lt;p&gt;Autodetects any {@link SchedulingConfigurer} instances in the container, * allowing for customization of the scheduler to be used or for fine-grained * control over task registration (e.g. registration of {@link Trigger} tasks. * See the @{@link EnableScheduling} javadocs for complete usage details. * * @author Mark Fisher * @author Juergen Hoeller * @author Chris Beams * @author Elizabeth Chatman * @since 3.0 * @see Scheduled * @see EnableScheduling * @see SchedulingConfigurer * @see org.springframework.scheduling.TaskScheduler * @see org.springframework.scheduling.config.ScheduledTaskRegistrar * @see AsyncAnnotationBeanPostProcessor */public class ScheduledAnnotationBeanPostProcessor\t\timplements MergedBeanDefinitionPostProcessor, DestructionAwareBeanPostProcessor,\t\tOrdered, EmbeddedValueResolverAware, BeanNameAware, BeanFactoryAware, ApplicationContextAware,\t\tSmartInitializingSingleton, ApplicationListener&lt;ContextRefreshedEvent&gt;, DisposableBean {\t/**\t * The default name of the {@link TaskScheduler} bean to pick up: \"taskScheduler\".\t * &lt;p&gt;Note that the initial lookup happens by type; this is just the fallback\t * in case of multiple scheduler beans found in the context.\t * @since 4.2\t */\tpublic static final String DEFAULT_TASK_SCHEDULER_BEAN_NAME = \"taskScheduler\";\tprotected final Log logger = LogFactory.getLog(getClass());\tprivate Object scheduler;\tprivate StringValueResolver embeddedValueResolver;\tprivate String beanName;\tprivate BeanFactory beanFactory;\tprivate ApplicationContext applicationContext;\tprivate final ScheduledTaskRegistrar registrar = new ScheduledTaskRegistrar();\tprivate final Set&lt;Class&lt;?&gt;&gt; nonAnnotatedClasses =\t\t\tCollections.newSetFromMap(new ConcurrentHashMap&lt;Class&lt;?&gt;, Boolean&gt;(64));\tprivate final Map&lt;Object, Set&lt;ScheduledTask&gt;&gt; scheduledTasks =\t\t\tnew IdentityHashMap&lt;Object, Set&lt;ScheduledTask&gt;&gt;(16);\t@Override\tpublic int getOrder() {\t\treturn LOWEST_PRECEDENCE;\t}\t/**\t * Set the {@link org.springframework.scheduling.TaskScheduler} that will invoke\t * the scheduled methods, or a {@link java.util.concurrent.ScheduledExecutorService}\t * to be wrapped as a TaskScheduler.\t * &lt;p&gt;If not specified, default scheduler resolution will apply: searching for a\t * unique {@link TaskScheduler} bean in the context, or for a {@link TaskScheduler}\t * bean named \"taskScheduler\" otherwise; the same lookup will also be performed for\t * a {@link ScheduledExecutorService} bean. If neither of the two is resolvable,\t * a local single-threaded default scheduler will be created within the registrar.\t * @see #DEFAULT_TASK_SCHEDULER_BEAN_NAME\t */\tpublic void setScheduler(Object scheduler) {\t\tthis.scheduler = scheduler;\t}\t@Override\tpublic void setEmbeddedValueResolver(StringValueResolver resolver) {\t\tthis.embeddedValueResolver = resolver;\t}\t@Override\tpublic void setBeanName(String beanName) {\t\tthis.beanName = beanName;\t}\t/**\t * Making a {@link BeanFactory} available is optional; if not set,\t * {@link SchedulingConfigurer} beans won't get autodetected and\t * a {@link #setScheduler scheduler} has to be explicitly configured.\t */\t@Override\tpublic void setBeanFactory(BeanFactory beanFactory) {\t\tthis.beanFactory = beanFactory;\t}\t/**\t * Setting an {@link ApplicationContext} is optional: If set, registered\t * tasks will be activated in the {@link ContextRefreshedEvent} phase;\t * if not set, it will happen at {@link #afterSingletonsInstantiated} time.\t */\t@Override\tpublic void setApplicationContext(ApplicationContext applicationContext) {\t\tthis.applicationContext = applicationContext;\t\tif (this.beanFactory == null) {\t\t\tthis.beanFactory = applicationContext;\t\t}\t}\t@Override\tpublic void afterSingletonsInstantiated() {\t\t// Remove resolved singleton classes from cache\t\tthis.nonAnnotatedClasses.clear();\t\tif (this.applicationContext == null) {\t\t\t// Not running in an ApplicationContext -&gt; register tasks early...\t\t\tfinishRegistration();\t\t}\t}\t@Override\tpublic void onApplicationEvent(ContextRefreshedEvent event) {\t\tif (event.getApplicationContext() == this.applicationContext) {\t\t\t// Running in an ApplicationContext -&gt; register tasks this late...\t\t\t// giving other ContextRefreshedEvent listeners a chance to perform\t\t\t// their work at the same time (e.g. Spring Batch's job registration).\t\t\tfinishRegistration();\t\t}\t}\tprivate void finishRegistration() {\t\tif (this.scheduler != null) {\t\t\tthis.registrar.setScheduler(this.scheduler);\t\t}\t\tif (this.beanFactory instanceof ListableBeanFactory) {\t\t\tMap&lt;String, SchedulingConfigurer&gt; configurers =\t\t\t\t\t((ListableBeanFactory) this.beanFactory).getBeansOfType(SchedulingConfigurer.class);\t\t\tfor (SchedulingConfigurer configurer : configurers.values()) {\t\t\t\tconfigurer.configureTasks(this.registrar);\t\t\t}\t\t}\t\tif (this.registrar.hasTasks() &amp;&amp; this.registrar.getScheduler() == null) {\t\t\tAssert.state(this.beanFactory != null, \"BeanFactory must be set to find scheduler by type\");\t\t\ttry {\t\t\t\t// Search for TaskScheduler bean...\t\t\t\tthis.registrar.setTaskScheduler(resolveSchedulerBean(TaskScheduler.class, false));\t\t\t}\t\t\tcatch (NoUniqueBeanDefinitionException ex) {\t\t\t\tlogger.debug(\"Could not find unique TaskScheduler bean\", ex);\t\t\t\ttry {\t\t\t\t\tthis.registrar.setTaskScheduler(resolveSchedulerBean(TaskScheduler.class, true));\t\t\t\t}\t\t\t\tcatch (NoSuchBeanDefinitionException ex2) {\t\t\t\t\tif (logger.isInfoEnabled()) {\t\t\t\t\t\tlogger.info(\"More than one TaskScheduler bean exists within the context, and \" +\t\t\t\t\t\t\t\t\"none is named 'taskScheduler'. Mark one of them as primary or name it 'taskScheduler' \" +\t\t\t\t\t\t\t\t\"(possibly as an alias); or implement the SchedulingConfigurer interface and call \" +\t\t\t\t\t\t\t\t\"ScheduledTaskRegistrar#setScheduler explicitly within the configureTasks() callback: \" +\t\t\t\t\t\t\t\tex.getBeanNamesFound());\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t\tcatch (NoSuchBeanDefinitionException ex) {\t\t\t\tlogger.debug(\"Could not find default TaskScheduler bean\", ex);\t\t\t\t// Search for ScheduledExecutorService bean next...\t\t\t\ttry {\t\t\t\t\tthis.registrar.setScheduler(resolveSchedulerBean(ScheduledExecutorService.class, false));\t\t\t\t}\t\t\t\tcatch (NoUniqueBeanDefinitionException ex2) {\t\t\t\t\tlogger.debug(\"Could not find unique ScheduledExecutorService bean\", ex2);\t\t\t\t\ttry {\t\t\t\t\t\tthis.registrar.setScheduler(resolveSchedulerBean(ScheduledExecutorService.class, true));\t\t\t\t\t}\t\t\t\t\tcatch (NoSuchBeanDefinitionException ex3) {\t\t\t\t\t\tif (logger.isInfoEnabled()) {\t\t\t\t\t\t\tlogger.info(\"More than one ScheduledExecutorService bean exists within the context, and \" +\t\t\t\t\t\t\t\t\t\"none is named 'taskScheduler'. Mark one of them as primary or name it 'taskScheduler' \" +\t\t\t\t\t\t\t\t\t\"(possibly as an alias); or implement the SchedulingConfigurer interface and call \" +\t\t\t\t\t\t\t\t\t\"ScheduledTaskRegistrar#setScheduler explicitly within the configureTasks() callback: \" +\t\t\t\t\t\t\t\t\tex2.getBeanNamesFound());\t\t\t\t\t\t}\t\t\t\t\t}\t\t\t\t}\t\t\t\tcatch (NoSuchBeanDefinitionException ex2) {\t\t\t\t\tlogger.debug(\"Could not find default ScheduledExecutorService bean\", ex2);\t\t\t\t\t// Giving up -&gt; falling back to default scheduler within the registrar...\t\t\t\t\tlogger.info(\"No TaskScheduler/ScheduledExecutorService bean found for scheduled processing\");\t\t\t\t}\t\t\t}\t\t}\t\tthis.registrar.afterPropertiesSet();\t}\tprivate &lt;T&gt; T resolveSchedulerBean(Class&lt;T&gt; schedulerType, boolean byName) {\t\tif (byName) {\t\t\tT scheduler = this.beanFactory.getBean(DEFAULT_TASK_SCHEDULER_BEAN_NAME, schedulerType);\t\t\tif (this.beanFactory instanceof ConfigurableBeanFactory) {\t\t\t\t((ConfigurableBeanFactory) this.beanFactory).registerDependentBean(\t\t\t\t\t\tDEFAULT_TASK_SCHEDULER_BEAN_NAME, this.beanName);\t\t\t}\t\t\treturn scheduler;\t\t}\t\telse if (this.beanFactory instanceof AutowireCapableBeanFactory) {\t\t\tNamedBeanHolder&lt;T&gt; holder = ((AutowireCapableBeanFactory) this.beanFactory).resolveNamedBean(schedulerType);\t\t\tif (this.beanFactory instanceof ConfigurableBeanFactory) {\t\t\t\t((ConfigurableBeanFactory) this.beanFactory).registerDependentBean(\t\t\t\t\t\tholder.getBeanName(), this.beanName);\t\t\t}\t\t\treturn holder.getBeanInstance();\t\t}\t\telse {\t\t\treturn this.beanFactory.getBean(schedulerType);\t\t}\t}\t@Override\tpublic void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName) {\t}\t@Override\tpublic Object postProcessBeforeInitialization(Object bean, String beanName) {\t\treturn bean;\t}\t@Override\tpublic Object postProcessAfterInitialization(final Object bean, String beanName) {\t\tClass&lt;?&gt; targetClass = AopUtils.getTargetClass(bean);\t\tif (!this.nonAnnotatedClasses.contains(targetClass)) {\t\t\tMap&lt;Method, Set&lt;Scheduled&gt;&gt; annotatedMethods = MethodIntrospector.selectMethods(targetClass,\t\t\t\t\tnew MethodIntrospector.MetadataLookup&lt;Set&lt;Scheduled&gt;&gt;() {\t\t\t\t\t\t@Override\t\t\t\t\t\tpublic Set&lt;Scheduled&gt; inspect(Method method) {\t\t\t\t\t\t\tSet&lt;Scheduled&gt; scheduledMethods = AnnotatedElementUtils.getMergedRepeatableAnnotations(\t\t\t\t\t\t\t\t\tmethod, Scheduled.class, Schedules.class);\t\t\t\t\t\t\treturn (!scheduledMethods.isEmpty() ? scheduledMethods : null);\t\t\t\t\t\t}\t\t\t\t\t});\t\t\tif (annotatedMethods.isEmpty()) {\t\t\t\tthis.nonAnnotatedClasses.add(targetClass);\t\t\t\tif (logger.isTraceEnabled()) {\t\t\t\t\tlogger.trace(\"No @Scheduled annotations found on bean class: \" + bean.getClass());\t\t\t\t}\t\t\t}\t\t\telse {\t\t\t\t// Non-empty set of methods\t\t\t\tfor (Map.Entry&lt;Method, Set&lt;Scheduled&gt;&gt; entry : annotatedMethods.entrySet()) {\t\t\t\t\tMethod method = entry.getKey();\t\t\t\t\tfor (Scheduled scheduled : entry.getValue()) {\t\t\t\t\t\tprocessScheduled(scheduled, method, bean);\t\t\t\t\t}\t\t\t\t}\t\t\t\tif (logger.isDebugEnabled()) {\t\t\t\t\tlogger.debug(annotatedMethods.size() + \" @Scheduled methods processed on bean '\" + beanName +\t\t\t\t\t\t\t\"': \" + annotatedMethods);\t\t\t\t}\t\t\t}\t\t}\t\treturn bean;\t}\tprotected void processScheduled(Scheduled scheduled, Method method, Object bean) {\t\ttry {\t\t\tAssert.isTrue(method.getParameterTypes().length == 0,\t\t\t\t\t\"Only no-arg methods may be annotated with @Scheduled\");\t\t\tMethod invocableMethod = AopUtils.selectInvocableMethod(method, bean.getClass());\t\t\tRunnable runnable = new ScheduledMethodRunnable(bean, invocableMethod);\t\t\tboolean processedSchedule = false;\t\t\tString errorMessage =\t\t\t\t\t\"Exactly one of the 'cron', 'fixedDelay(String)', or 'fixedRate(String)' attributes is required\";\t\t\tSet&lt;ScheduledTask&gt; tasks = new LinkedHashSet&lt;ScheduledTask&gt;(4);\t\t\t// Determine initial delay\t\t\tlong initialDelay = scheduled.initialDelay();\t\t\tString initialDelayString = scheduled.initialDelayString();\t\t\tif (StringUtils.hasText(initialDelayString)) {\t\t\t\tAssert.isTrue(initialDelay &lt; 0, \"Specify 'initialDelay' or 'initialDelayString', not both\");\t\t\t\tif (this.embeddedValueResolver != null) {\t\t\t\t\tinitialDelayString = this.embeddedValueResolver.resolveStringValue(initialDelayString);\t\t\t\t}\t\t\t\ttry {\t\t\t\t\tinitialDelay = Long.parseLong(initialDelayString);\t\t\t\t}\t\t\t\tcatch (NumberFormatException ex) {\t\t\t\t\tthrow new IllegalArgumentException(\t\t\t\t\t\t\t\"Invalid initialDelayString value \\\"\" + initialDelayString + \"\\\" - cannot parse into integer\");\t\t\t\t}\t\t\t}\t\t\t// Check cron expression\t\t\tString cron = scheduled.cron();\t\t\tif (StringUtils.hasText(cron)) {\t\t\t\tAssert.isTrue(initialDelay == -1, \"'initialDelay' not supported for cron triggers\");\t\t\t\tprocessedSchedule = true;\t\t\t\tString zone = scheduled.zone();\t\t\t\tif (this.embeddedValueResolver != null) {\t\t\t\t\tcron = this.embeddedValueResolver.resolveStringValue(cron);\t\t\t\t\tzone = this.embeddedValueResolver.resolveStringValue(zone);\t\t\t\t}\t\t\t\tTimeZone timeZone;\t\t\t\tif (StringUtils.hasText(zone)) {\t\t\t\t\ttimeZone = StringUtils.parseTimeZoneString(zone);\t\t\t\t}\t\t\t\telse {\t\t\t\t\ttimeZone = TimeZone.getDefault();\t\t\t\t}\t\t\t\ttasks.add(this.registrar.scheduleCronTask(new CronTask(runnable, new CronTrigger(cron, timeZone))));\t\t\t}\t\t\t// At this point we don't need to differentiate between initial delay set or not anymore\t\t\tif (initialDelay &lt; 0) {\t\t\t\tinitialDelay = 0;\t\t\t}\t\t\t// Check fixed delay\t\t\tlong fixedDelay = scheduled.fixedDelay();\t\t\tif (fixedDelay &gt;= 0) {\t\t\t\tAssert.isTrue(!processedSchedule, errorMessage);\t\t\t\tprocessedSchedule = true;\t\t\t\ttasks.add(this.registrar.scheduleFixedDelayTask(new IntervalTask(runnable, fixedDelay, initialDelay)));\t\t\t}\t\t\tString fixedDelayString = scheduled.fixedDelayString();\t\t\tif (StringUtils.hasText(fixedDelayString)) {\t\t\t\tAssert.isTrue(!processedSchedule, errorMessage);\t\t\t\tprocessedSchedule = true;\t\t\t\tif (this.embeddedValueResolver != null) {\t\t\t\t\tfixedDelayString = this.embeddedValueResolver.resolveStringValue(fixedDelayString);\t\t\t\t}\t\t\t\ttry {\t\t\t\t\tfixedDelay = Long.parseLong(fixedDelayString);\t\t\t\t}\t\t\t\tcatch (NumberFormatException ex) {\t\t\t\t\tthrow new IllegalArgumentException(\t\t\t\t\t\t\t\"Invalid fixedDelayString value \\\"\" + fixedDelayString + \"\\\" - cannot parse into integer\");\t\t\t\t}\t\t\t\ttasks.add(this.registrar.scheduleFixedDelayTask(new IntervalTask(runnable, fixedDelay, initialDelay)));\t\t\t}\t\t\t// Check fixed rate\t\t\tlong fixedRate = scheduled.fixedRate();\t\t\tif (fixedRate &gt;= 0) {\t\t\t\tAssert.isTrue(!processedSchedule, errorMessage);\t\t\t\tprocessedSchedule = true;\t\t\t\ttasks.add(this.registrar.scheduleFixedRateTask(new IntervalTask(runnable, fixedRate, initialDelay)));\t\t\t}\t\t\tString fixedRateString = scheduled.fixedRateString();\t\t\tif (StringUtils.hasText(fixedRateString)) {\t\t\t\tAssert.isTrue(!processedSchedule, errorMessage);\t\t\t\tprocessedSchedule = true;\t\t\t\tif (this.embeddedValueResolver != null) {\t\t\t\t\tfixedRateString = this.embeddedValueResolver.resolveStringValue(fixedRateString);\t\t\t\t}\t\t\t\ttry {\t\t\t\t\tfixedRate = Long.parseLong(fixedRateString);\t\t\t\t}\t\t\t\tcatch (NumberFormatException ex) {\t\t\t\t\tthrow new IllegalArgumentException(\t\t\t\t\t\t\t\"Invalid fixedRateString value \\\"\" + fixedRateString + \"\\\" - cannot parse into integer\");\t\t\t\t}\t\t\t\ttasks.add(this.registrar.scheduleFixedRateTask(new IntervalTask(runnable, fixedRate, initialDelay)));\t\t\t}\t\t\t// Check whether we had any attribute set\t\t\tAssert.isTrue(processedSchedule, errorMessage);\t\t\t// Finally register the scheduled tasks\t\t\tsynchronized (this.scheduledTasks) {\t\t\t\tSet&lt;ScheduledTask&gt; registeredTasks = this.scheduledTasks.get(bean);\t\t\t\tif (registeredTasks == null) {\t\t\t\t\tregisteredTasks = new LinkedHashSet&lt;ScheduledTask&gt;(4);\t\t\t\t\tthis.scheduledTasks.put(bean, registeredTasks);\t\t\t\t}\t\t\t\tregisteredTasks.addAll(tasks);\t\t\t}\t\t}\t\tcatch (IllegalArgumentException ex) {\t\t\tthrow new IllegalStateException(\t\t\t\t\t\"Encountered invalid @Scheduled method '\" + method.getName() + \"': \" + ex.getMessage());\t\t}\t}\t@Override\tpublic void postProcessBeforeDestruction(Object bean, String beanName) {\t\tSet&lt;ScheduledTask&gt; tasks;\t\tsynchronized (this.scheduledTasks) {\t\t\ttasks = this.scheduledTasks.remove(bean);\t\t}\t\tif (tasks != null) {\t\t\tfor (ScheduledTask task : tasks) {\t\t\t\ttask.cancel();\t\t\t}\t\t}\t}\t@Override\tpublic boolean requiresDestruction(Object bean) {\t\tsynchronized (this.scheduledTasks) {\t\t\treturn this.scheduledTasks.containsKey(bean);\t\t}\t}\t@Override\tpublic void destroy() {\t\tsynchronized (this.scheduledTasks) {\t\t\tCollection&lt;Set&lt;ScheduledTask&gt;&gt; allTasks = this.scheduledTasks.values();\t\t\tfor (Set&lt;ScheduledTask&gt; tasks : allTasks) {\t\t\t\tfor (ScheduledTask task : tasks) {\t\t\t\t\ttask.cancel();\t\t\t\t}\t\t\t}\t\t\tthis.scheduledTasks.clear();\t\t}\t\tthis.registrar.destroy();\t}}ScheduledMethodRunnable任务执行方法,主要包括两个属性：  target–&gt; Spring 容器 bean实例  method –&gt; Bean对象方法源码：/* * Copyright 2002-2012 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * *      http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.springframework.scheduling.support;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import java.lang.reflect.UndeclaredThrowableException;import org.springframework.util.ReflectionUtils;/** * Variant of {@link MethodInvokingRunnable} meant to be used for processing * of no-arg scheduled methods. Propagates user exceptions to the caller, * assuming that an error strategy for Runnables is in place. * * @author Juergen Hoeller * @since 3.0.6 * @see org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor */public class ScheduledMethodRunnable implements Runnable {\tprivate final Object target;\tprivate final Method method;\tpublic ScheduledMethodRunnable(Object target, Method method) {\t\tthis.target = target;\t\tthis.method = method;\t}\tpublic ScheduledMethodRunnable(Object target, String methodName) throws NoSuchMethodException {\t\tthis.target = target;\t\tthis.method = target.getClass().getMethod(methodName);\t}\tpublic Object getTarget() {\t\treturn this.target;\t}\tpublic Method getMethod() {\t\treturn this.method;\t}\t@Override\tpublic void run() {\t\ttry {\t\t\tReflectionUtils.makeAccessible(this.method);\t\t\tthis.method.invoke(this.target);\t\t}\t\tcatch (InvocationTargetException ex) {\t\t\tReflectionUtils.rethrowRuntimeException(ex.getTargetException());\t\t}\t\tcatch (IllegalAccessException ex) {\t\t\tthrow new UndeclaredThrowableException(ex);\t\t}\t}}"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7.2 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7.2-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2018-01-20 00:00:00 +0800",
    





    
    "snippet": "主要包含文档说明、在线调试两大核心功能Swagger-Bootstrap-UI是Swagger的前端UI实现,采用jQuery+bootstrap实现,目的是替换Swagger默认的UI实现Swagger-UI,使文档更友好一点儿…1.fixed ISSUE responseBody是List时，Model结构无法显示，只有个Array2.fixed ISSUE @ApiResponse定义...",
    "content": "主要包含文档说明、在线调试两大核心功能Swagger-Bootstrap-UI是Swagger的前端UI实现,采用jQuery+bootstrap实现,目的是替换Swagger默认的UI实现Swagger-UI,使文档更友好一点儿…1.fixed ISSUE responseBody是List时，Model结构无法显示，只有个Array2.fixed ISSUE @ApiResponse定义的状态码无效3.去除默认响应状态码展示相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "工作流引擎技术选型",
    "url": "/posts/workflow-choose/",
    "categories": "工作流",
    "tags": "",
    "date": "2018-01-11 00:00:00 +0800",
    





    
    "snippet": "SnakerSnaker是一个基于Java的开源工作流引擎，适用于企业应用中常见的业务流程。本着轻量、简单、灵巧理念设计，定位于简单集成，多环境支持轻量:核心代码行数大约7000行，强大的扩展性，支持Spring、Jfinal、Nutz平台级框架；支持Jdbc、SpringJdbc、Hibernate3or4、Mybatis等orm框架简单:表设计简单，流程组件简单[start/end/ta...",
    "content": "SnakerSnaker是一个基于Java的开源工作流引擎，适用于企业应用中常见的业务流程。本着轻量、简单、灵巧理念设计，定位于简单集成，多环境支持轻量:核心代码行数大约7000行，强大的扩展性，支持Spring、Jfinal、Nutz平台级框架；支持Jdbc、SpringJdbc、Hibernate3or4、Mybatis等orm框架简单:表设计简单，流程组件简单[start/end/task/custom/subprocess/decision/fork/join]灵巧:暴露大量可扩展接口，支持流程设计器、流程引擎的组件模型自定义[节点自定义、属性自定义、表单自定义]Wiki:http://snakerflow.com/演示应用: http://git.oschina.net/yuqs/snaker-webGITHUB:https://github.com/snakerflow/snakerflowopenwebflowOpenWebFlow是基于Activiti（官方网站http://activiti.org/）扩展的工作流引擎（国人开发），它扩展的功能包括：  完全接管了Activiti对活动（activity）权限的管理。Activiti允许在设计model的时候指定每个活动的执行权限，但是，业务系统可能需要根据实际情况动态设置这些任务的执行权限（如：动态的Group）。OpenWebFlow完全实现了与流程定义时期的解耦，即用户对活动的访问控制信息单独管理（而不是在流程定义中预先写死），这样有利于动态调整权限，详见自定义活动权限管理；  完全接管了Activiti对用户表（IDENTITY_XXX表）的管理。在标准的工作流定义中，每个节点可以指定其候选人和候选用户组，但是比较惨的是，Activiti绑架了用户信息表的设计！这个是真正致命的，因为几乎每个业务系统都会属于自己的用户信息结构（包括User/Group/Membership），但不一定它存储在Activiti喜欢的那个库中，表的结构也不一定一样，有的时候，某些信息（如：动态的Group）压根儿就不采用表来存储。OpenWebFlow剥离了用户信息表的统一管理，客户程序可以忘掉Activiti的用户表、群组表、成员关系表，详见自定义用户成员关系管理；  允许运行时定义activity！彻底满足“中国特色”，并提供了安全的（同时也是优雅的）催办、代办、加签（包括前加签/后加签）、自由跳转（包括前进/后）、分裂节点等功能；支持与致谢  开发者使用帮助：https://github.com/bluejoe2008/openwebflow/wiki  使用手册与设计说明书（PDF格式）详细说明：https://my.oschina.net/bluejoe/blog/1552284#comment-listGITHUB地址：https://github.com/bluejoe2008/openwebflowJBPMjBpm是一个灵活可扩展的工作流管理系统。作为 jBpm运行时server输入的业务流程使用简单强大的语言表达并打包在流程档案中。jBpm将工作流应用开发的便利性和杰出的企业应用集成（EAI）能力结合了起来。jBpm包括一个Web应用程序和一个日程安排程序。jBpm是一组J2SE组件，可以作为J2EE应用集群部署。JBoss容器下的产品,可能存在兼容性问题，放弃Activiti的作者即是JBPM原作者官网：http://www.jbpm.org/ActivitiActiviti是一个业务流程管理(BPM)和工作流系统，适用于开发人员和系统管理员。其核心是超快速，稳定的BPMN2流程引擎。它易于与 Spring集成使用。用户指南：http://www.activiti.org/userguide/index.htmlGITHUB地址：https://github.com/Activiti/ActivitiGithub上更新频率最快：flowableflowable工作流是Activiti团队一个分支，从JBPM到Activiti到flowableflowable是一个用Java实现的轻量级业务工作流引擎，兼容activiti支持Spring 、Spring Boot可以部署到任意Java环境，如java SE、servlet容器、如Tomcat或jetty、Java EE 服务器 如JBoss容器等GITHUB地址：https://github.com/flowable/flowable-engineGITHUB更新频率官网：http://www.flowable.org/支持的数据：            Flowable 数据库类型      示例jdbc url      说明                  h2      jdbc:h2:tcp://localhost/flowable      默认配置数据库              mysql      jdbc:mysql://localhost:3306/flowable?autoReconnect=true      测试使用mysql-connector-java数据库驱动              oracle      jdbc:oracle:thin:@localhost:1521:xe                     postgres      jdbc:postgresql://localhost:5432/flowable                     db2      jdbc:db2://localhost:50000/flowable                     mssql      jdbc:sqlserver://localhost:1433;databaseName=flowable (jdbc.driver=com.microsoft.sqlserver.jdbc.SQLServerDriver) OR jdbc:jtds:sqlserver://localhost:1433/flowable (jdbc.driver=net.sourceforge.jtds.jdbc.Driver)      测试使用Microsoft JDBC Driver 4.0 (sqljdbc4.jar) 驱动      flowable的数据库名称都以act_开始。第二部分是对表格用例的两个字符的识别。这个用例也大致匹配服务API。act_re_ *：代表基础仓库。带有此前缀的表包含静态信息，如流程定义和流程资源（图像、规则等）。act_ru_ *：运行库。这些是运行时表，其中包含进程实例、用户任务、变量、作业等的运行时数据。流动只存储过程实例的执行过程中的运行时数据和删除记录时，一个流程实例结束。这样可以使运行时表小而快速。act_hi_ *：历史库，代表历史。这些表包含历史数据，如过去的流程实例、变量、任务等。act_ge_ *：常规库，这是用于各种使用案例。"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.7 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.7-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-12-18 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.7 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7更新如下：1、分组功能实现替换默认请求接口v2/api-docs,改为swagger的分组接口：swagger-res...",
    "content": "swagger-bootstrap-ui 1.7 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.7更新如下：1、分组功能实现替换默认请求接口v2/api-docs,改为swagger的分组接口：swagger-resources,左菜单分组下拉框可选在Spring Boot的swagger配置如：@Configuration@EnableSwagger2public class SwaggerConfiguration {    @Bean(value = \"defaultApi\")    public Docket defaultApi() {        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .groupName(\"默认接口\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.controller\"))                .paths(PathSelectors.any())                .build();    }    @Bean(value = \"groupRestApi\")    public Docket groupRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(groupApiInfo())                .groupName(\"分组接口\")                .select()                .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.group\"))                .paths(PathSelectors.any())                .build();    }    private ApiInfo groupApiInfo(){        return new ApiInfoBuilder()                .title(\"分组Api\")                .description(\"swagger-bootstrap-ui-demo RESTful APIs\")                .termsOfServiceUrl(\"http://www.group.com/\")                .contact(\"group@qq.com\")                .version(\"1.0\")                .build();    }    private ApiInfo apiInfo() {        return new ApiInfoBuilder()                .title(\"swagger-bootstrap-ui-demo RESTful APIs\")                .description(\"swagger-bootstrap-ui-demo RESTful APIs\")                .termsOfServiceUrl(\"http://www.xx.com/\")                .contact(\"xx@qq.com\")                .version(\"1.0\")                .build();    }}详细示例参考demo:swagger-bootstrap-ui-demo2、文件上传,form表单action地址取相对路径,截取掉首字符”/”Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.7&lt;/version&gt;&lt;/dependency&gt;相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "云数据中心sdk快速入门",
    "url": "/posts/cloud-sdk-get-started/",
    "categories": "Blog",
    "tags": "",
    "date": "2017-12-17 00:00:00 +0800",
    





    
    "snippet": "公司目前开发基础技术架构是：Spring、Spring Boot、lishicloud-sdk其中Spring、Spring Boot都是目前网上流行的开源框架lishicloud-sdk是公司针对云数据中心(cdc)开发工具包,封装了云数据中心所有的接口api操作架构说明spring、Spring Boot都是网上开源框架,自行搜索学习,这里不再叙述lishicloud-sdk是云数据中心...",
    "content": "公司目前开发基础技术架构是：Spring、Spring Boot、lishicloud-sdk其中Spring、Spring Boot都是目前网上流行的开源框架lishicloud-sdk是公司针对云数据中心(cdc)开发工具包,封装了云数据中心所有的接口api操作架构说明spring、Spring Boot都是网上开源框架,自行搜索学习,这里不再叙述lishicloud-sdk是云数据中心(cdc)提供数据CRUD操作,详细请参考《lishicloud-sdk开发指南v0.4.9.pdf》快速开始首先,我们基础架构是Spring,我们通常说的松耦合操作,需要使用到Spring的容器因为sdk是开发工具包,所以sdk提供给我们的工具类,我们需要通过Spring 的容器bean注入达到目的sdk提供的核心工具类com.lishiots.cloud.sdk.client.CloudQueryRunner在Spring Xml时代,需要通过在spring 的Xml配置文件中注入,例如：&lt;!--云数据中心基本信息--&gt; &lt;bean id=\"cloudConnection\" class=\"com.lishiots.cloud.sdk.basic.CloudBasicConnection\"&gt;     &lt;property name=\"url\" value=\"y.lishiots.com\" /&gt;     &lt;property name=\"port\" value=\"80\" /&gt;     &lt;property name=\"userName\" value=\"xx\" /&gt;     &lt;property name=\"password\" value=\"appsecret\" /&gt; &lt;/bean&gt; &lt;!--注入连接池管理类--&gt; &lt;bean id=\"cloudPoolingConnectionManager\" class=\"com.lishiots.cloud.sdk.basic.CloudPoolingConnectionManager\"&gt;     &lt;property name=\"connection\" ref=\"cloudConnection\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"cloudDataSource\" class=\"com.lishiots.cloud.sdk.basic.CloudBasicDataSource\"&gt;     &lt;property name=\"cloudPoolingConnectionManager\" ref=\"cloudPoolingConnectionManager\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--注入CloudQueryRunner实例--&gt; &lt;bean id=\"run\" class=\"com.lishiots.cloud.sdk.client.CloudQueryRunner\"&gt;     &lt;property name=\"dataSource\" ref=\"cloudDataSource\" /&gt; &lt;/bean&gt;在Spring Boot中会有所差别,@Configuration标注这是一个配置类,通过@Bean注解来达到注入bean的目的,如下:@Configurationpublic class CdcConfiguration {    @Value(value = \"${cdc.host}\")    private String host;    @Value(value = \"${cdc.port}\")    private Integer port;    @Value(value = \"${cdc.appid}\")    private String appid;    @Value(value = \"${cdc.appsecret}\")    private String appsecret;    @Bean(value = \"cloudQueryRunner\")    public CloudQueryRunner cloudQueryRunner(){        CloudBasicConnection cloudBasicConnection=new CloudBasicConnection();        LogbackLogger.info(\"host:\"+host+\",port:\"+port+\",appid:\"+appid+\",appsecret:\"+appsecret);        cloudBasicConnection.setUrl(host);        cloudBasicConnection.setPort(port);        //appid &amp; appsecret        cloudBasicConnection.setUserName(appid);        cloudBasicConnection.setPassword(appsecret);        //创建连接池管理类        LogbackLogger.info(\"create cloudPoolingConnectionManager...\");        CloudPoolingConnectionManager cloudPoolingConnectionManager=new CloudPoolingConnectionManager();        cloudPoolingConnectionManager.setConnection(cloudBasicConnection);        //创建数据源        LogbackLogger.info(\"create cloudBasicDataSource...\");        CloudBasicDataSource cloudBasicDataSource=new CloudBasicDataSource();        cloudBasicDataSource.setCloudPoolingConnectionManager(cloudPoolingConnectionManager);        //创建查询runner        LogbackLogger.info(\"create cloudQueryRunner...\");        CloudQueryRunner runner=new CloudQueryRunner();        runner.setDataSource(cloudBasicDataSource);        return runner;    }}通过以上操作,我们可以通过@Autowired自动注入实例,如下：@Servicepublic class CommonServiceImpl implements CommonService {    @Autowired    private CloudQueryRunner cloudQueryRunner;    @Override    public &lt;T&gt; List&lt;T&gt; queryAllData(Class&lt;T&gt; clzss,String resourceName, RequestExample requestExample) {        boolean flag=true;        int current_page=1;        int page_size=requestExample.getPageSize();        List&lt;T&gt; commonStats= Lists.newArrayList();        do {            Pagination&lt;T&gt; flowPagination=cloudQueryRunner.queryListByExample(clzss,resourceName,requestExample);            if (flowPagination!=null&amp;&amp;flowPagination.getCount()&gt;0){                //计算总页数                //部位                System.out.println(\"common。\");                int totalPage=(flowPagination.getCount()+page_size-1)/page_size;                if (current_page&lt;totalPage){                    current_page++;                }else{                    flag=false;                }                requestExample.setCurrentPage(current_page);                commonStats.addAll(flowPagination.getData());            }else{                flag=false;            }        }while (flag);        return commonStats;    }}  增加数据新增操作,提供对象即可,对象包含的字段必须是数据库表字段存在的字段，不能多、可以少(除必填字段)JSONObject jsonObject = new JSONObject();jsonObject.put(\"modu_rq_url\", rqUrl);jsonObject.put(\"modu_img_url\", imgUrl);jsonObject.put(\"modu_url\", moduUrl);jsonObject.put(\"modu_name\", moduName);jsonObject.put(\"modu_plate_id\", pid);//这里可以是jsonobject、也可以是对象实例RestMessage message = cloudQueryRunner.insert(\"modu\", jsonObject);//数据新增，返回新增记录主键id//通过对象.getId()获取System.out.println(message.getId())批量新增类似新增操作，只是把对象放入集合中List list=new ArrayList();JSONObject jsonObject = new JSONObject();jsonObject.put(\"modu_rq_url\", rqUrl);jsonObject.put(\"modu_img_url\", imgUrl);jsonObject.put(\"modu_url\", moduUrl);jsonObject.put(\"modu_name\", moduName);jsonObject.put(\"modu_plate_id\", pid);//加入结合数组list.add(jsonObject);//这里可以是jsonobject、也可以是对象实例,调用insertBatch方法RestMessage message = cloudQueryRunner.insertBatch(\"modu\", list);//数据批量新增，返回批量新增记录主键id，逗号分隔 ，多条记录,如：id1,id2,id3...//通过对象.getId()获取System.out.println(message.getId())###编辑数据编辑操作,除更新字段,需要添加pkid主键字段,非id,这是云数据中心规定字段JSONObject jsonObject = new JSONObject();jsonObject.put(\"modu_rq_url\", rqUrl);jsonObject.put(\"modu_img_url\", imgUrl);jsonObject.put(\"modu_url\", moduUrl);jsonObject.put(\"modu_name\", moduName);jsonObject.put(\"modu_plate_id\", pid);//更新idjsonObject.put(\"pkid\", pkid);//这里可以是jsonobject、也可以是对象实例RestMessage message = cloudQueryRunner.update(\"modu\", jsonObject);//数据编辑，返回编辑记录主键id//通过对象.getId()获取System.out.println(message.getId())批量编辑和编辑类似List list=new ArrayList();JSONObject jsonObject = new JSONObject();jsonObject.put(\"modu_rq_url\", rqUrl);jsonObject.put(\"modu_img_url\", imgUrl);jsonObject.put(\"modu_url\", moduUrl);jsonObject.put(\"modu_name\", moduName);jsonObject.put(\"modu_plate_id\", pid);//更新idjsonObject.put(\"pkid\", pkid);list.add(jsonObject);//这里可以是jsonobject、也可以是对象实例,调用updateBatch方法RestMessage message = cloudQueryRunner.updateBatch(\"modu\", list);//数据批量编辑，返回批量编辑记录主键id，逗号分隔 ，多条记录,如：id1,id2,id3...//通过对象.getId()获取System.out.println(message.getId())删除RestMessage message = cloudQueryRunner.delete(\"modu\", pkid);//数据删除，返回删除记录主键id//通过对象.getId()获取System.out.println(message.getId())批量删除//传入多个id数组RestMessage message = cloudQueryRunner.delete(\"modu\", pkid,pkid1,pkid3...);//数据删除，返回删除记录主键id//通过对象.getId()获取System.out.println(message.getId())查询除了云数据中心支持的nativeSQL查询数据，云数据中心还提供了多功能语法查询,同时也推荐开发者使用该方式查询数据，因为nativeSQL涉及到安全性等方面，云数据中心针对nativeSQL的接口以后可能会做调整，封闭也有可能.//requestExample对象RequestExample requestExample=new RequestExample(10,1);requestExample.addRelations(new Relation(\"scenic_info\",\"scenic_info\",\"id\",\"scenic_id\"));requestExample.addSort(\"create_time\",\"desc\");RequestExample.Criteria criteria=requestExample.create();criteria.getMust().add(requestExample.createParam().addFuzzy(\"title\",\"test\"));System.out.println(new Gson().toJson(requestExample));//使用queryBuilder查询表user_info数据Pagination&lt;Map&lt;String, Object&gt;&gt; pagination=cloudQueryRunner.queryListByExample(\"member_info\",requestExample);//遍历user_info数据for (Map&lt;String, Object&gt; map:pagination.getData()){    //do something}Sdk主要针对云数据中心给出的多功能查询结构体，封装了RequestExample对象，所有多功能查询，包括表关联查询，单表查询都可以使用该对象云数据中心查询结构体如下：{    \"page_size\": 10,    \"current_page\": 1,    \"display_fields\": \"id\",    \"query\": {        \"must_not\": [],        \"should\": [],        \"must\": [            {                \"prefix\": {},                \"term\": {},                \"fuzzy\": {                    \"title\": \"test\"                },                \"range\": {}            }        ]    },    \"sort\": {        \"create_time\": \"desc\"    },    \"rel\": [        {            \"rel_type\": \"o2o\",            \"rel_res_name\": \"scenic_info\",            \"rel_res_alias\": \"scenic_info\",            \"rel_res_field\": \"id\",            \"rel_symbol\": \"=\",            \"on_field\": \"scenic_id\",            \"where\": {                \"must\": [],                \"mustNot\": [],                \"should\": []            }        }    ]}主要包含以下属性：  query:该属性是条件查询属性，包含必须有、必须没有、应该三大子属性，同时每个子属性又包含模糊、匹配、前缀匹配、区间这四种匹配模式供开发者调用  sort:该属性是排序字段，是一个map对象，添加字段的排序属性，云数据中心会按排序好的字段顺序给出数据  rel：该属性是关联查询属性，详细介绍请参考关联查询章节      current_page:当前页面    page_size:页码大小  display_fields: 可选择的返回资源属性,不填则返回所有属性如上面的JSON体中，”fuzzy”:{“title”:”test”}就是一个判断式，它代表的是title的模糊匹配test值。除了fuzzy外，还有另外三个条件判断式的匹配方式(MATCH)，下面我们简单介绍一下。  term : 完全匹配;  prefix : 前缀匹配;  fuzzy : 模糊匹配;  range : 范围匹配。must/must_not/should为三个查询判断模式,  must: 必须满足的判断模式。must里面的条件判断式越多，结果越精确。  must_not：必须不包含(排除)的判断模式。只要满足must_not下的条件判断式的结果都不会被返回。  should：该模式的主要用途是查询满足多个条件的其中一个或多个的情况。所以，should下的条件判断式必须大于等于两个。如何需要输入多个相同键，不同值的参数？因为JSON主要是用键值对来绑定数据的，所以相同的键在同一个{body}里面是不能同时存在的，这和Java中的Map、C#中的Dictionary类似一样。所以需要在一个查询里面有多个相同键的情况，可以将相同键分装在两个不同的{body}中。例如： 我们要查询 所有不包含北京和上海的酒店，那可以使用{    \"must_not\": [        {            \"prefix\": {                \"hotel_cn_name\": \"北京\"            }        },        {            \"prefix\": {                \"hotel_cn_name\": \"上海\"            }        }    ]}should的注意点should表示的是满足多个条件里面的一个或多个即可，所以should的条件判断式至少要有两个。 但是这里需要特别主要的是，如果判断式的键是一样的，则必须这样写{    \"should\": [        {            \"prefix\": {                \"hotel_cn_name\": \"北京\"            }        },        {            \"prefix\": {                \"hotel_cn_name\": \"上海\"            }        }    ]}但是如果判断式键不一样，那么如下这样也算是两个判断式:{    \"should\": [        {            \"prefix\": {                \"hotel_cn_name\": \"北京\",                \"hotel_name\": \"h\"            }        }    ]}RequestExample在前面多功能查询三个章节中，都详细的阐述了云数据中心对于多功能查询的结构，那么我们要如何使用它呢？在我们sdk中，sdk提供了RequestExample对象，开发者可以轻松使用该对象构建查询结构体，查询我们想要的结果.//创建requestExample对象,传入页码,当前页RequestExample requestExample=new RequestExample(10,1);//如果有排序需求,desc,ascrequestExample.addSort(\"create_time\",\"desc\");//条件判断RequestExample.Criteria criteria=requestExample.create();//必须满足//完全匹配criteria.getMust().add(requestExample.createParam().addTerm(\"key\",\"value\"));//模糊匹配criteria.getMust().add(requestExample.createParam().addFuzzy(\"key\",\"value\"));//前缀匹配criteria.getMust().add(requestExample.createParam().addPrefix(\"key\",\"value\"));//范围//gt:大于//lt：小于//gte:大于等于//lte:小于等于//ne:不等于//eq:等于//例如查询create_time大于2017-01-01 00:00:00Map gt=new HashMap();gt.put(\"gt\",\"2017-01-01 00:00:00\");criteria.getMust().add(requestExample.createParam().addRange(\"create_time\",gt));//类似不满足、应该满足//criteria.getMustNot().add()//criteria.getShould().add()//如果有表关联查询,以下语句创建关联语句//创建表关联//例如查询门票信息表中,所属景点关联信息//门票表中存在景点id字段scenic_idRelation relation=new Relation(\"scenic_info\",\"scenic_info\",\"id\",\"scenic_id\");requestExample.addRelations(relation);//......"
  },
  
  {
    "title": "九一八国耻日：莫忘那些血不曾凉的英雄",
    "url": "/posts/918-hero/",
    "categories": "Blog",
    "tags": "",
    "date": "2017-09-18 00:00:00 +0800",
    





    
    "snippet": "君不见,汉终军,弱冠系虏请长缨君不见,班定远,绝域轻骑催战云!",
    "content": "君不见,汉终军,弱冠系虏请长缨君不见,班定远,绝域轻骑催战云!"
  },
  
  {
    "title": "PostgreSQL安装指南",
    "url": "/posts/postgresql-install-guide/",
    "categories": "数据库",
    "tags": "",
    "date": "2017-09-07 00:00:00 +0800",
    





    
    "snippet": "下载本次教程记录postgresql安装过程下载二进制文件：https://www.enterprisedb.com/download-postgresql-binaries下载版本：*Version 9.6.5*系统：win10 64位解压本次解压目录是D:\\Users\\xiaoymin\\Bin\\pgsql初始化开cmd管理员窗口执行命令：initdb --pgdata=D:\\Users\\...",
    "content": "下载本次教程记录postgresql安装过程下载二进制文件：https://www.enterprisedb.com/download-postgresql-binaries下载版本：*Version 9.6.5*系统：win10 64位解压本次解压目录是D:\\Users\\xiaoymin\\Bin\\pgsql初始化开cmd管理员窗口执行命令：initdb --pgdata=D:\\Users\\xiaoymin\\Bin\\pgsql\\data --encoding=UTF8 --locale=C输出：D:\\Users\\xiaoymin\\Bin\\pgsql\\bin&gt;initdb --pgdata=D:\\Users\\xiaoymin\\Bin\\pgsql\\data --encoding=UTF8 --locale=C属于此数据库系统的文件宿主为用户 \"xiaoymin\".此用户也必须为服务器进程的宿主.数据库簇将使用本地化语言 \"C\"进行初始化.缺省的文本搜索配置将会被设置到\"english\"禁止为数据页生成校验和.创建目录 D:/Users/xiaoymin/Bin/pgsql/data ... 成功正在创建子目录 ... 成功选择默认最大联接数 (max_connections) ... 100选择默认共享缓冲区大小 (shared_buffers) ... 128MB选择动态共享内存实现 ......windows创建配置文件 ... 成功正在运行自举脚本 ...成功正在执行自举后初始化 ...成功同步数据到磁盘...成功警告:为本地连接启动了 \"trust\" 认证.你可以通过编辑 pg_hba.conf 更改或你下次行 initdb 时使用 -A或者--auth-local和--auth-host选项.成功。您现在可以用下面的命令开启数据库服务器：    \"pg_ctl\" -D \"D:\\Users\\xiaoymin\\Bin\\pgsql\\data\" -l logfile start具体参数命令,可以使用–help展现：D:\\Users\\xiaoymin\\Bin\\pgsql\\bin&gt;initdb --helpinitdb 初始化一个 PostgreSQL 数据库簇.使用方法:  initdb [选项]... [DATADIR]选项:  -A, --auth=METHOD         本地连接的默认认证方法      --auth-host=METHOD   本地的TCP/IP连接的默认认证方法      --auth-local=METHOD   本地socket连接的默认认证方法  -D, --pgdata=DATADIR      当前数据库簇的位置  -E, --encoding=ENCODING   为新数据库设置默认编码      --locale=LOCALE      为新数据库设置默认语言环境  --lc-collate, --lc-ctype, --lc-messages=LOCALE  --lc-monetary, --lc-numeric, --lc-time=LOCALE                            为新的数据库簇在各自的目录中分别                   设定缺省语言环境（默认使用环境变                   量)  --no-locale               等同于 --locale=C  --pwfile=文件名           对于新的超级用户从文件读取口令  -T, --text-search-config=CFG                   缺省的文本搜索配置  -U, --username=NAME       数据库超级用户名  -W, --pwprompt            对于新的超级用户提示输入口令  -X, --xlogdir=XLOGDIR          当前事务日志目录的位置非普通使用选项:  -d, --debug               产生大量的除错信息 -k, --data-checksums    使用数据页产生效验和  -L DIRECTORY              输入文件的位置  -n, --noclean             出错后不清理  -N, --nosync             不用等待变化安全写入磁盘  -s, --show                显示内部设置  -S, --sync-only          只同步数据目录其它选项:  -V, --version             输出版本信息, 然后退出  -?, --help                显示此帮助, 然后退出如果没有指定数据目录, 将使用环境变量 PGDATA报告错误至 &lt;pgql-bugs@postgresql.org&gt;.注册windows服务执行命令:D:\\Users\\xiaoymin\\Bin\\pgsql\\bin&gt;pg_ctl.exe register -D D:\\Users\\xiaoymin\\Bin\\pgsql\\data -N PgSQL启动服务D:\\Users\\xiaoymin\\Bin\\pgsql\\bin&gt;net start PgSQLPgSQL 服务正在启动 .PgSQL 服务已经启动成功。"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.6 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.6-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-09-06 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.6 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.6更新如下：1、支持文件上传，需要指定dataType=MultipartFile,如下： @ApiOperation(...",
    "content": "swagger-bootstrap-ui 1.6 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿swagger-bootstrap-ui 1.6更新如下：1、支持文件上传，需要指定dataType=MultipartFile,如下： @ApiOperation(value = \"文件素材上传接口\") @ApiImplicitParams({@ApiImplicitParam(name = \"file\", value = \"文件流对象,接收数组格式\", required = true,dataType = \"MultipartFile\"),            @ApiImplicitParam(name = \"title\", value = \"title\", required = true)}    ) @RequestMapping(value=\"/uploadMaterial\",method = RequestMethod.POST) @ResponseBody public RestMessage uploadMaterial(@RequestParam(value=\"file\") MultipartFile[] files,@RequestParam(value = \"title\") String title, HttpServletRequest request) throws IOException {        //int mul=1*1024*1024;        String realPath=request.getSession().getServletContext().getRealPath(\"/upload\");  //......}2、ResponseBody类型的string展示3、布局溢出的问题.bycdao-main样式调整，修改margin-left:270px;4、ApiImplicitParam注解defaultValue属性支持5、菜单名称调整，展示接口方法类型、接口地址、接口说明三个参数Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.6&lt;/version&gt;&lt;/dependency&gt;相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.5 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.5-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-09-01 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.5 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、修改groupid为com.github.xiaoymin2、新增layer弹框,增加接口表单验证功能,针对required=true的字段3、修复实体...",
    "content": "swagger-bootstrap-ui 1.5 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、修改groupid为com.github.xiaoymin2、新增layer弹框,增加接口表单验证功能,针对required=true的字段3、修复实体类中包含自引用递归算法错误的bug4、类型dataType有ref类型显示为string的bug5、响应实体字段详细说明table添加6、针对RequestBody字段,如果是ref属性，详细列出每个字段的说明Maven坐标&lt;dependency&gt;   &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;   &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;   &lt;version&gt;1.5&lt;/version&gt;&lt;/dependency&gt;相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "confluence 安装指南(Linux)",
    "url": "/posts/confluence-linux-install-guide/",
    "categories": "Blog",
    "tags": "",
    "date": "2017-09-01 00:00:00 +0800",
    





    
    "snippet": "环境说明1.服务器为centos，windos端需要一个ftp工具，把需要的东西拿到Linux下。2.安装JDK1.8需要的文件  confluence的安装包官网下载地址：https://www.atlassian.com/software/confluence/download本次下载的版本是：atlassian-confluence-6.3.2-x64.bin  MySQL连接驱动程序...",
    "content": "环境说明1.服务器为centos，windos端需要一个ftp工具，把需要的东西拿到Linux下。2.安装JDK1.8需要的文件  confluence的安装包官网下载地址：https://www.atlassian.com/software/confluence/download本次下载的版本是：atlassian-confluence-6.3.2-x64.bin  MySQL连接驱动程序这个下载渠道很多，可以通过maven仓库去下载下载地址：mysql-connector-java-6.0.6.jar安装安装 JDK 1.8Linux jdk的安装这里不再说明安装mysql  下载下载地址：http://dev.mysql.com/downloads/mysql/5.6.html#downloads下载版本：我这里选择的5.6.33，通用版，linux下64位直接下载：wget  http://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.33-linux-glibc2.5-x86_64.tar.gz  解压#解压tar -zxvf mysql-5.6.33-linux-glibc2.5-x86_64.tar.gz#复制解压后的mysql目录cp -r mysql-5.6.33-linux-glibc2.5-x86_64 /usr/local/mysql  添加用户组和用户#添加用户组groupadd mysql#添加用户mysql 到用户组mysqluseradd -g mysql mysql  安装#切换到mysql主目录cd /usr/local/mysql/#创建mysql 数据文件夹mkdir ./data/mysql#授权chown -R mysql:mysql ././scripts/mysql_install_db --user=mysql --datadir=/usr/local/mysql/data/mysqlcp support-files/mysql.server /etc/init.d/mysqldchmod 755 /etc/init.d/mysqldcp support-files/my-default.cnf /etc/my.cnf#修改启动脚本vi /etc/init.d/mysqld #修改项：basedir=/usr/local/mysql/datadir=/usr/local/mysql/data/mysql #启动服务service mysqld start #测试连接./mysql/bin/mysql -uroot #加入环境变量，编辑 /etc/profile，这样可以在任何地方用mysql命令了export PATH=$PATH:/usr/local/mysql//bin&lt;br&gt;source /etc/profile  #启动mysqlservice mysqld start#关闭mysqlservice mysqld stop#查看运行状态service mysqld status  加入环境变量vim /etc/profileexport MYSQL_HOME=/usr/local/mysqlexport PATH=$MYSQL_HOME/bin:$PATH#执行profilesource /etc/profile  修改用户等选项#登录mysql -u rootuse mysql;select 'host' from user where user='root'; update user set host = '%' where user ='root';#修改密码update user set password=password('123456') where user='root';flush privileges; 创建数据库两种方式，通过命令行创建、或者通过navicat 等连接工具创建，我是通过navicat工具创建的，也验证mysql连接可用  创建数据库名：confluence#安装confluence5.8.10  修改增加可执行权限mv atlassian-confluence-6.3.2-x64.bin confluence.bin#增加可执行权限chown u+x confluence.bin  安装./confluence.bin#根据提示操作安装# 注意：在安装的过程中，如果你的默认目录被占用，端口8090被占用，会需要你自己设置端口号，这里安装是安装在/opt下，数据存放在/var目录下，用户目录在/home下，关于端口被占用的情况，一般是之前安装不成功，被无效的confluence用户占用了。可以使用lsof -i:8090查看是哪个进程占用了该端口，然后kill掉就OK了。如果不得不使用别的端口，记得在防火墙中开启该端口：iptables -I INPUT -p tcp -m state —state NEW -m tcp —dport xxxx -j ACCEPT  访问浏览器访问：http://ip:8090/回车后，进入安装界面，选择install production,然后直接跳过add ones，在出现serverID的时候，要保存复制  获取License Key1、访问网址：http://id.atlassian.com注册一个账号，也可以通过Google的Gmail账号登录（需要翻墙）2、访问网址：https://my.atlassian.com/登录我的页面，点击页面上的New Evaluation License  链接，填入刚才安装界面的serverID，新生成一个License Key3、上面获取的License Key 只有一个月免费  配置数据库1.选择mysql，点击external database2.选择上面的JDBC3.在出现的界面上url的最后加上解决中文乱码的&amp;useUnicode=true&amp;characterEncoding=utf84.输入用户名和密码，这里的数据库账户密码是之前创建的username和user code5.点击next如果出现已经存在xxxx的错误是因为之前安装过，直接overwrite就OK。关于破解confluencea.停止Confluence服务器/opt/atlassian/confluence/bin/stop-confluence.shb. 将数据库连接程序 mysql-connector-java-5.1.32-bin.jar 和汉化包：Confluence-5.8.10-language-pack-zh_CN.jar放在 atlassian\\confluence\\confluence\\WEB-INF\\lib 目录c. 将 atlassian\\confluence\\confluence\\WEB-INF\\lib\\atlassian-extras-decoder-v2-3.2.jar 拷贝到Windows上，重命名为atlassian-extras-2.4.jard. 执行confluence_keygen.jar，输入一些列账户名称邮箱这些信息，输入serverID,点击Patch，选择 atlassian-extras-2.4.jar，点击gene. 这时候就生成了需要的秘钥，复制下来保存。f.将atlassian-extras-2.4.jar重命名为原来的atlassian-extras-decoder-v2-3.2.jar，放回linux下的原位。f. 重新启动confluence/opt/atlassian/confluence/bin/start-confluence.shg. 刷新浏览器，输入密钥，进入下一步#恢复数据这里等待三分钟初始化结束后，如果想要新的界面，就点击empty site，如果要恢复，就选择最下面的导入backup文件，直接从windows下导入，导入结束后会自动import，当到100%的时候，就可以start up啦。说明：中间可能会有一些稀奇古怪的问题，可以将报错信息google，一般会找到解决办法。实在不行，建议全部卸载重来一遍。ps -ef|grep java 看看进程，可能是启动用户有问题kill 掉之前起来的/opt/atlassian/confluence/bin/startup.sh 用这个启动tail -f /var/atlassian/application-data/confluence/logs/atlassian-confluence.log看下日志"
  },
  
  {
    "title": "MariaDB 安装指南(windows)",
    "url": "/posts/mariadb-windows-install-guide/",
    "categories": "数据库",
    "tags": "",
    "date": "2017-07-31 00:00:00 +0800",
    





    
    "snippet": "下载首先去MariaDB官网下载,本次教程使用的版本是mariadb-10.2.7-winx64配置将下载好的mariadb解压到安装目录，例如我的目录是D:/Users/xiaoymin/Bin/mariadb  选择配置文件(例如my-large.ini)然后找到my-large，my-medium，my-small，三个文件，根据你的电脑的 配置进行选择，我这里选择的是my-large...",
    "content": "下载首先去MariaDB官网下载,本次教程使用的版本是mariadb-10.2.7-winx64配置将下载好的mariadb解压到安装目录，例如我的目录是D:/Users/xiaoymin/Bin/mariadb  选择配置文件(例如my-large.ini)然后找到my-large，my-medium，my-small，三个文件，根据你的电脑的 配置进行选择，我这里选择的是my-large文件。[client]port\t= 3306socket\t= /tmp/mysql.sock  添加basedir、datadir、charset：[mysqld]port\t= 3306socket\t= /tmp/mysql.sock## 添加basedir、datadir、charsetbasedir=D:/Users/xiaoymin/Bin/mariadbdatadir=D:/Users/xiaoymin/Bin/mariadb/datacharacter_set_server=utf8  加上WinMySQLAdmin：[mysqlhotcopy]interactive-timeout## 加上WinMySQLAdmin[WinMySQLAdmin]   Server=E:\\Softwear\\mariadb-10.0.10-winx64\\bin\\mysqld.exe  保存以上配置将以上配置文件另存保存至mariadb目录，如：D:/Users/xiaoymin/Bin/mariadb/my.ini安装配置完成后，安装mariadb服务，这里需要注意的是命令行需要以管理员方式运行# 首先cd到mariadb的bin目录cd D:/Users/xiaoymin/Bin/mariadb/bin#安装服务mysqld.exe --install MariaDB# 启动服务net start MariaDB登录启动mariadb后，可以登录系统，修改密码等操作mysql -u root -pentershow databases;#选择mysql数据库use mysql;#查询user表 select host ,user,password from user；#修改mysql 用户root的登录密码update user set password=password('新密码') where User=\"root\" ;#刷新flush privileges;其他一般安装不成功，多少与my.ini配置不对，可以通过SC命令删除服务，然后重复安装# 删除mariadb服务sc delete MariaDB"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.4 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.4-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-07-11 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.4 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、修改请求参数异常bug相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址...",
    "content": "swagger-bootstrap-ui 1.4 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、修改请求参数异常bug相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.3 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.3-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-07-05 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.3 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、修复application/json格式发送参数bug，文本框替换为textarea相关链接  swagger-bootstrap-ui 的详细介绍：点...",
    "content": "swagger-bootstrap-ui 1.3 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、修复application/json格式发送参数bug，文本框替换为textarea相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.2 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.2-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-05-14 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.2 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、添加PUT、DELETE方法支持相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui ...",
    "content": "swagger-bootstrap-ui 1.2 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、添加PUT、DELETE方法支持相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "技术架构整理",
    "url": "/posts/company-platform/",
    "categories": "Java",
    "tags": "",
    "date": "2017-05-08 00:00:00 +0800",
    





    
    "snippet": "简介基于Spring Boot+Cloud-SDK分布式敏捷开发系统架构，提供整套公共微服务服务模块：内容管理、支付中心、UC认证中心、用户管理、微信平台、存储系统、配置中心、日志分析、任务和通知等，打造全方位J2EE企业级开发解决方案开发语言JavaJDK 1.7+数据库云数据中心后端技术            技术      名称      官网                  Spr...",
    "content": "简介基于Spring Boot+Cloud-SDK分布式敏捷开发系统架构，提供整套公共微服务服务模块：内容管理、支付中心、UC认证中心、用户管理、微信平台、存储系统、配置中心、日志分析、任务和通知等，打造全方位J2EE企业级开发解决方案开发语言JavaJDK 1.7+数据库云数据中心后端技术            技术      名称      官网                  Spring  Framework      容器      http://projects.spring.io/spring-framework/              SpringMVC      MVC框架      http://docs.spring.io/spring/docs/current/spring-framework-reference/htmlsingle/#mvc              Spring Boot      微服务框架      http://projects.spring.io/spring-boot/              Apache Shiro      安全框架      http://shiro.apache.org/              Spring session      分布式Session管理      http://projects.spring.io/spring-session/              Cloud-sdk      云数据中心sdk工具包      http://www.lishiots.com/              Cloud-wx-kernel      微信核心工具包      http://www.lishiots.com/              Thymeleaf      模板引擎      http://www.thymeleaf.org/              Redis      分布式缓存数据库      https://redis.io/              Quartz      作业调度框架      http://www.quartz-scheduler.org/              Ehcache      进程内缓存框架      http://www.ehcache.org/              Log4J      日志组件      http://logging.apache.org/log4j/1.2/              Swagger2      接口测试框架      http://swagger.io/              Maven      项目构建管理      http://maven.apache.org/      前端技术            技术      名称      官网                  jQuery      函式库      http://jquery.com/              Bootstrap      前端框架      http://getbootstrap.com/              Bootstrap-table      Bootstrap数据表格      http://bootstrap-table.wenzhixin.net.cn/              Font-awesome      字体图标      http://fontawesome.io/              Waves      点击效果插件      https://github.com/fians/Waves              zTree      树插件      http://www.treejs.cn/v3/              Select2      选择框插件      https://github.com/select2/select2              Layer      弹出窗口插件      http://layer.layui.com/              Editor.md      Markdown编辑器      https://github.com/pandao/editor.md              Express      基于Node.js 平台,快速、开放、极简的 web 开发框架      http://www.expressjs.com.cn/      "
  },
  
  {
    "title": "Jformparser 开发指南",
    "url": "/posts/jformparser-guide/",
    "categories": "开源",
    "tags": "",
    "date": "2017-04-29 00:00:00 +0800",
    





    
    "snippet": "简介根据json结构,生成页面,达到解放后端开发人员的目的,降低后端对前端开发要求,后端专心开发后台接口等服务程序, 前期以表单元素为主,后期会增加更多页面元素的支持,敬请期待JFormParser依赖:目前主要依赖bootstrap css框架、jQuery两大流行核心组件,设计之初想法是降低对各个插件的依赖耦合度,构造的 页面元素使用其他插件也能达到多样化可替换,使得页面效果更加丰富码云...",
    "content": "简介根据json结构,生成页面,达到解放后端开发人员的目的,降低后端对前端开发要求,后端专心开发后台接口等服务程序, 前期以表单元素为主,后期会增加更多页面元素的支持,敬请期待JFormParser依赖:目前主要依赖bootstrap css框架、jQuery两大流行核心组件,设计之初想法是降低对各个插件的依赖耦合度,构造的 页面元素使用其他插件也能达到多样化可替换,使得页面效果更加丰富码云地址：JFormParserJFormParser元素  editor(富文本插件),富文本插件原打算使用百度的ueditor插件,因公司购买富文本插件强制需要使用,所以这里 使用ewebeditor插件,使用该插件需要依赖服务器环境,并且部署上线需要授权,否则无法使用.  text(基本文本框):文本域,文本域是很强大的一种表单元素,JFormParser目前只要支持以下几种数据类型的文本域          normal:常规文本域,无任务效果      email:只支持邮件形式的文本输入,会自检非其他格式数据      number:整数文本域,只支持输入整数,会自检非其他格式数据      decimal:小数文本域      datetime:日期类型,目前使用的插件是My97DatePicker日期插件,所以依赖WdatePicker.js文件        textarea(多行文本域):多行文本域  select(下拉框):下拉框元素,下拉框涉及数据初始化的原因,所以插件提供了remote_url属性通过后台加载数据初始化  panel(面板):面板组件,是一个容器组件  grid(表格):表格组件,这里的表格无任何特殊意义,仅仅只是为了页面布局,同panel一样,也是容器组件  checkboxGroup:复选框组组件  radioGroup:单选框组组件  button:按钮(普通按钮、提交按钮、返回按钮、、、、等)  buttonGroup:按钮组,是一个容器组件,包含按钮的组合,  datagrid:表格展示组件,依赖元数据查询组件  fileupload:文件上传  images:图集上传组件  bMap：地图拾取经纬度坐标组件，依赖于百度js地图(http://lbsyun.baidu.com/index.php?title=jspopular)页面template页面template主要是模板页，更多的是提供布局功能,现在主要包含两个模板列表页模板listlist模板页面主要是用于展现数据列表页模板结构{  \"component_name\":\"scenic_form\",  \"component_title\":\"景区form\",  \"template_type\":\"list\",  \"navs_title\":\"景区标准化管理 &gt; 景区管理 &gt; 景区列表\",  \"navs\":[{\"title\":\"景区标准化管理\",\"icon\":\"\",\"url\":\"\"},{\"title\":\"景区管理\",\"icon\":\"\"},{\"title\":\"景区列表\",\"icon\":\"\"}],  \"resource_name\":\"scenic_info\",  \"submit_url\":\"/cms/template/submit.htm\",  \"childrens\":[{    \"element_type\":\"panel\",    \"element_title\":\"景区查询\",    \"whether_header\":false,    \"whether_border\":false,    \"container\":true,    \"childrens\":[      {        \"element_type\":\"datagrid\",        \"element_title\":\"景区查询\",        \"is_remote\":true,        \"is_operate\":true,        \"operate_title\":\"操作\",        \"operate_buttons\":[          {\"element_type\":\"button\",\"type\":\"edit\",\"element_title\":\"编辑\",\"remote_url\":\"/cms/template/template_form.htm\",\"params\":{\"url\":\"/json/baotou/scenic/scenic_form.json\"}},          {\"element_type\":\"button\",\"type\":\"delete\",\"element_title\":\"图片\",\"remote_url\":\"/cms/template/delete.htm\"},          {\"element_type\":\"button\",\"type\":\"delete\",\"element_title\":\"视频\",\"remote_url\":\"/cms/template/delete.htm\"},          {\"element_type\":\"button\",\"type\":\"delete\",\"element_title\":\"音频\",\"remote_url\":\"/cms/template/delete.htm\"},          {\"element_type\":\"button\",\"type\":\"delete\",\"element_title\":\"删除\",\"remote_url\":\"/cms/template/delete.htm\"}],        \"pagination\":true,        \"remote_url\":\"/cms/template/get_remote_list.htm\",        \"columns\":[\t\t{\"field\":\"title\",\"title\":\"景区名称\"},\t\t{\"field\":\"level\",\"title\":\"景区等级\"},\t\t{\"field\":\"lawyer\",\"title\":\"法人代表\"},\t\t{\"field\":\"person_liable\",\"title\":\"负责人\"},\t\t{\"field\":\"phone\",\"title\":\"手机号码\"},\t\t{\"field\":\"tel\",\"title\":\"电话\"},\t\t{\"field\":\"fax\",\"title\":\"传真\"},\t\t{\"field\":\"approve_date\",\"title\":\"批准时间\"},\t\t{\"field\":\"approve_date\",\"title\":\"地理位置\"}],        \"childrens\":[          {            \"element_type\":\"text\",            \"element_title\":\"景区名称\",            \"meta_column\":\"title\",            \"is_query\":true,            \"direction\":\"left\",            \"width\":\"100%\"          },{            \"element_type\":\"text\",            \"element_title\":\"景区等级\",            \"meta_column\":\"level\",            \"is_query\":true,            \"direction\":\"left\",            \"width\":\"100%\"          },{            \"element_type\":\"button\",            \"element_title\":\"查询\",            \"type\":\"query\",            \"remote_url\":\"/cms/template/get_remote_list.htm\",            \"params\": {              \"params\": \"{resource_name: scenic_info}\"            }          },{            \"element_type\":\"buttonGroup\",            \"element_title\":\"操作按钮组\",            \"align\":\"left\",            \"childrens\":[              {\"element_type\":\"button\",\"type\":\"link\",\"element_title\":\"新增景区\",\"remote_url\":\"/cms/template/template_form.htm\",\"params\":{\"url\":\"/json/baotou/scenic/scenic_form.json\"}},              {\"element_type\":\"button\",\"type\":\"link\",\"element_title\":\"删除\",\"remote_url\":\"/cms/template/template_form.htm\",\"params\":{\"url\":\"/json/baotou/scenic/scenic_form.json\"}},              {\"element_type\":\"button\",\"type\":\"link\",\"element_title\":\"导入\",\"remote_url\":\"/cms/template/template_form.htm\",\"params\":{\"url\":\"/json/baotou/scenic/scenic_form.json\"}},              {\"element_type\":\"button\",\"type\":\"link\",\"element_title\":\"导出\",\"remote_url\":\"/cms/template/template_form.htm\",\"params\":{\"url\":\"/json/baotou/scenic/scenic_form.json\"}}            ]          }        ]      }    ]  }  ]}属性            字段      类型      说明      是否必填      默认值      其他                  component_name      string      temp页面组件名称      是      无                     component_title      string      temp页面组件title      是      无                     template_type      string      temp页面类型，目前2中，分别为：list、form      是      无                     navs_title      string      导航栏      是      无                     navs      Array      导航栏,属性见导航栏      是      无                     resource_name      string      展示元数据数据表名      是      无                     submit_url      string      根据template_type类型不同有不同的意义，list为获取数据地址，form为提交表单地址      是      无                     container      boolean      是否容器组件      否      true                     childrens      Array      地图子组件，这里必包含2个经纬度文本域组件      是      无             导航栏属性            字段      类型      说明      是否必填      默认值      其他                  title      string      导航栏名称      是      无                     icon      string      图标      否      无                     url      string      导航栏url      否      无             表单页模板formform模板页面主要是构建表单页面结构{  \"component_name\":\"trips_form\",  \"component_title\":\"行程form\",  \"template_type\":\"form\",  \"navs_title\":\"信息管理 &gt; 行程管理 &gt; 行程维护\",  \"navs\":[{\"title\":\"信息管理\",\"icon\":\"\",\"url\":\"\"},{\"title\":\"行程管理\",\"icon\":\"\"},{\"title\":\"行程维护\",\"icon\":\"\"}],  \"resource_name\":\"trips_info\",  \"submit_url\":\"/cms/template/submit.htm\",  \"init_url\":\"/cms/template/get_form_data.htm\",  \"childrens\":[    {      \"element_type\":\"panel\",      \"element_title\":\"基础信息\",      \"container\":true,      \"childrens\":[        {          \"element_type\":\"grid\",          \"cols\":3,          \"rows\":\"3\",          \"childrens\":[{            \"element_type\":\"text\",            \"element_title\":\"行程名称\",            \"meta_column\":\"title\",            \"is_required\":true          },{            \"element_type\":\"select\",            \"element_title\":\"行程类型\",            \"is_required\":true,            \"meta_column\":\"type\",            \"is_fk\":true,            \"fk_resource_name\":\"scenic_spot_info\",            \"fk_meta_column\":\"id\",            \"fk_meta_column_show\":\"title\",            \"data\":[              {\"text\":\"交通\",\"value\":\"jt\"},              {\"text\":\"会议\",\"value\":\"hy\"},              {\"text\":\"入住\",\"value\":\"rz\"},              {\"text\":\"用餐\",\"value\":\"yc\"},              {\"text\":\"考察\",\"value\":\"kc\"}            ],            \"is_remote\":false,            \"remote_url\":\"\"          },{            \"element_type\":\"text\",            \"element_title\":\"开始时间\",            \"meta_column\":\"start_time\",            \"is_required\":true          },{            \"element_type\":\"checkboxGroup\",            \"element_title\":\"参与小组\",            \"is_required\":true,            \"meta_column\":\"team_infos\",            \"fk_resource_name\":\"team_info\",            \"fk_meta_column\":\"id\",            \"fk_meta_column_show\":\"name\",            \"is_remote\":true,            \"width\":\"100%\",            \"remote_url\":\"/cms/template/get_remote_data.htm\"          }]        }      ]    },{      \"element_type\":\"panel\",      \"element_title\":\"详情\",      \"container\":true,      \"childrens\":[        {          \"element_type\":\"editor\",          \"meta_column\":\"intro\",          \"width\":\"400px\",          \"height\":\"300px\"        }      ]    },{      \"element_type\":\"buttonGroup\",      \"element_title\":\"\",      \"align\":\"center\",      \"childrens\":[        {\"element_type\":\"button\",\"type\":\"submit\",\"element_title\":\"提交\",\"remote_url\":\"/cms/template/submit.htm\",\"width\":\"80px\",\"action_url\":\"/cms/template/template_list.htm\",\"params\":{\"url\":\"/json/shengsi/trips/trips_list.json\"}},        {\"element_type\":\"button\",\"type\":\"link\",\"element_title\":\"返回\",\"remote_url\":\"/cms/template/template_list.htm\",\"params\":{\"url\":\"/json/shengsi/trips/trips_list.json\"},\"width\":\"80px\"}      ]    }  ]}属性            字段      类型      说明      是否必填      默认值      其他                  component_name      string      temp页面组件名称      是      无                     component_title      string      temp页面组件title      是      无                     template_type      string      temp页面类型，目前2中，分别为：list、form      是      无                     navs_title      string      导航栏      是      无                     navs      Array      导航栏,属性见导航栏      是      无                     resource_name      string      展示元数据数据表名      是      无                     submit_url      string      根据template_type类型不同有不同的意义，list为获取数据地址，form为提交表单地址      是      无                     container      boolean      是否容器组件      否      true                     childrens      Array      地图子组件，这里必包含2个经纬度文本域组件      是      无             导航栏属性            字段      类型      说明      是否必填      默认值      其他                  title      string      导航栏名称      是      无                     icon      string      图标      否      无                     url      string      导航栏url      否      无             容器组件容器组件，顾名思义面板panelPanel组件是一个bootstrap风格的panel容器组件,使用该插件主要是为了表单页面布局，页面看上去更像一个整体，有整体性，页面美观结构{\t\"element_type\":\"panel\",\t\"element_title\":\"资源信息\",\t\"container\":true,\t\"childrens\":[...]}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     whether_header      boolean      是否有header头      否      true                     whether_border      boolean      面板是否有边框      否      true                     width      string      地图初始宽度,可以是百分比，可以是像素值，例如：100% 或者400px;      否      无                     height      string      地图初始高度      否      无                     container      boolean      是否容器组件      否      true                     childrens      Array      容器子组件集合，可包含任何其他组件      否      无             表格gridGrid组件是一个类似表格组件，包含几行几列等属性，不过这里不同于表格table，这里只是一个页面展示组件，用于页面布局，没有任何实际作用，同panel一样，是容器组件结构{\t\"element_type\":\"grid\",\t\"element_title\":\"表格组件\",\t\"cols\":3,    \"rows\":\"4\",\t\"container\":true,\t\"childrens\":[...]}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     cols      number      表格列      是      1                     rows      number      表格行      是      1                     container      boolean      是否容器组件      否      true                     childrens      Array      容器子组件集合，可包含任何其他组件      否      无             地图组件bMapbmap组件是百度地图组件，地图组件必有两个子元素,都是文本域组件 经度、纬度两个字段结构{        \"element_type\":\"bMap\",        \"id\":\"bmap\",        \"center\":\"包头\",        \"dragging\":true,        \"scrollwheelzoom\":true,        \"doubleclickzoom\":true,        \"width\":\"100%\",        \"height\":\"450px\",        \"element_title\":\"位置信息\",        \"container\":true,        \"childrens\":[{          \"element_type\":\"text\",          \"element_title\":\"经度\",          \"meta_column\":\"baidu_x\",          \"map_element\":true,          \"point\":\"lng\",          \"width\":\"40%\",          \"float\":\"left\",          \"marginRight\":\"10px\",          \"is_required\":false        },{          \"element_type\":\"text\",          \"element_title\":\"纬度\",          \"meta_column\":\"baidu_y\",          \"map_element\":true,          \"point\":\"lat\",          \"width\":\"40%\",          \"float\":\"left\",          \"is_required\":false        }]}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     id      string      地图组件唯一id编号      是      无                     center      string      地图初始中央显示位置，eg:包头      是      无                     dragging      boolean      地图是否允许拖动      否      false                     scrollwheelzoom      boolean      地图是否允许缩放      否      false                     doubleclickzoom      boolean      地图是否允许鼠标双击缩放层级      否      true                     width      string      地图初始宽度,可以是百分比，可以是像素值，例如：100% 或者400px;      是      无                     height      string      地图初始高度      是      无                     container      boolean      是否容器组件      否      true                     childrens      Array      地图子组件，这里必包含2个经纬度文本域组件      是      无             数据表格datagridDatagrid组件是列表table展示数据组件结构{        \"element_type\":\"datagrid\",        \"element_title\":\"交通查询\",        \"is_remote\":true,        \"is_operate\":true,        \"operate_title\":\"操作\",        \"operate_buttons\":[          {\"type\":\"edit\",\"element_type\":\"button\",\"element_title\":\"编辑\",\"remote_url\":\"/cms/template/template_form.htm\",\"params\":{\"url\":\"/json/baotou/traffic/traffic_form.json\"}},          {\"type\":\"delete\",\"element_type\":\"button\",\"element_title\":\"删除\",\"remote_url\":\"/cms/template/delete.htm\"}],        \"pagination\":true,        \"remote_url\":\"/cms/template/get_remote_list.htm\",        \"columns\":[          {\"field\":\"start_name\",\"title\":\"出发城市\"},          {\"field\":\"end_name\",\"title\":\"到达城市\"},          {\"field\":\"name\",\"title\":\"航班号\"},          {\"field\":\"first_time\",\"title\":\"离港\"},          {\"field\":\"last_time\",\"title\":\"到港\"},          {\"field\":\"type\",\"title\":\"所属交通\",\"rel_column\":true,\"rel_resource_name\":\"traffic_type\"}],        \"childrens\":[          {            \"element_type\":\"text\",            \"element_title\":\"出发城市\",            \"meta_column\":\"start_name\",            \"is_query\":true,            \"direction\":\"left\",            \"width\":\"100%\"          }, {            \"element_type\":\"text\",            \"element_title\":\"到达城市\",            \"meta_column\":\"end_name\",            \"is_query\":true,            \"direction\":\"left\",            \"width\":\"100%\"          },{            \"element_type\":\"select\",            \"element_title\":\"所属交通\",            \"is_required\":true,            \"meta_column\":\"traffic_id\",            \"is_fk\":true,            \"fk_resource_name\":\"traffic_type\",            \"fk_meta_column\":\"id\",            \"fk_meta_column_show\":\"type\",            \"is_remote\":true,            \"rules\":\"is_email\",            \"message\":\"\",            \"remote_url\":\"/cms/template/get_remote_data.htm\"          },{            \"element_type\":\"button\",            \"element_title\":\"查询\",            \"type\":\"query\"          },{            \"element_type\":\"buttonGroup\",            \"element_title\":\"操作按钮组\",            \"align\":\"left\",            \"childrens\":[              {\"element_type\":\"button\",\"type\":\"link\",\"element_title\":\"添加班次\",\"remote_url\":\"/cms/template/template_form.htm\",\"params\":{\"url\":\"/json/baotou/traffic/traffic_form.json\"}}            ]          }        ]}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     is_remote      boolean      是否远程ajax加载数据,如果为false，data本地数据源字段必填，否则无数据展示      是      false                     remote_url      string      远程ajax加载数据url地址      是      无                     is_operate      boolean      是否包含操作栏      是      true                     operate_title      string      操作栏抬头title      是      true                     operate_buttons      Array      操作栏按钮集合，列如编辑、删除等等，具体按钮明细属性请参考button按钮      是      true                     pagination      boolean      是否分页      是      false                     data      Array      local数据源,和column列数据一一格式对应,例如：[{\"start_name\":\"北京\",\"end_name\":\"杭州\",\"name\":\"T2XDD\",\"first_time\":\"8:00\",\"last_time\":\"17:00\",\"type\":\"飞机\"}...]      否      true                     columns      Array      列集合明细,具体属性请参考column属性      是      无                     container      boolean      是否容器组件      否      true                     childrens      Array      容器子组件集合，可包含任何其他组件，这里datagrid包含的子组件仅仅是查询框组件      否      无             column属性            字段      类型      说明      是否必填      默认值      其他                  field      string      字段名称      是      无                     title      string      显示列title      是      无                     rel_column      boolean      是否多表关联查询，表关联查询情况，且列上需要展示关联表字段的时候，该字段为true，值为关联表字段      否      false                     rel_resource_name      string      外联表资源名称      否      无             基础表单组件富文本框editoreditor组件是一个富文本组件，这里使用的公司购买的ewebeditor插件，修改了ewebeditor部分源码，后台上传的资源全部上传到云数据中心结构{          \"element_type\":\"editor\",          \"element_title\":\"详情\",          \"meta_column\":\"detail_intro\",          \"width\":\"400px\",          \"is_required\":true,          \"height\":\"300px\"}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     meta_column      string      表单name字段，元数据字段      是      无                     is_required      boolean      是否必输项      否      false                     width      string      地图初始宽度,可以是百分比，可以是像素值，例如：100% 或者400px;      是      无                     height      string      地图初始高度      是      无             文本域texttext普通文本域组件，提供各种数据格式的支持，包括（整数、小数、身份证、时间）等等结构{            \"element_type\":\"text\",            \"element_title\":\"资讯时间\",            \"data_type\":\"datetime\",            \"formatter\":\"yyyy-MM-dd\",            \"is_required\":true,            \"meta_column\":\"scenic_time\"}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     meta_column      string      表单name字段，元数据字段      是      无                     is_required      boolean      是否必输项      否      false                     width      string      地图初始宽度,可以是百分比，可以是像素值，例如：100% 或者400px;      否      无                     defaultValue      string      默认值      否      无                     float      string      float位置：left、right      否      无                     marginRight      string      右间距，例如10px;      否      无                     data_type      string      数据类型，分为[“normal”,”email”,”number”,”decimal”,”datetime”,”card”..普通文本、邮箱、整数、小数、身份证]      否      normal                     formatter      string      数据类型为日期时，该值启用      否      yyyy-MM-dd                     map_element      boolean      是否是地图经纬度元素，配合父元素为bmap类型使用      否      false                     point      string      如果为地图经纬度元素，该值必填，值(lng、lat)经度、纬度，配合父元素为bmap类型使用      否      无                     is_query      boolean      是否为查询元素      否      false             多行文本textareatextarea多行文本域组件结构{            \"element_type\":\"textarea\",            \"element_title\":\"简介\",            \"is_required\":true,            \"meta_column\":\"intro\",            \"width\":\"100%\"}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     meta_column      string      表单name字段，元数据字段      是      无                     is_required      boolean      是否必输项      否      false                     width      string      地图初始宽度,可以是百分比，可以是像素值，例如：100% 或者400px;      否      无                     defaultValue      string      默认值      否      无             下拉框selectselect下拉框组件，可以根据url远程加载数据，也可以是local 数据结构{            \"element_type\":\"select\",            \"element_title\":\"所属景区\",            \"is_required\":true,            \"meta_column\":\"scenic_id\",            \"is_fk\":true,\t\t\t\"width\":\"100%\",            \"fk_resource_name\":\"scenic_info\",            \"fk_meta_column\":\"id\",            \"fk_meta_column_show\":\"title\",            \"is_remote\":true,            \"rules\":\"is_email\",            \"message\":\"\",            \"remote_url\":\"/cms/template/get_remote_data.htm\",\t\t\t\"data\":[            {\"text\":\"AAAAA\",\"value\":\"5A\"},            {\"text\":\"AAAA\",\"value\":\"4A\"},            {\"text\":\"AAA\",\"value\":\"3A\"},            {\"text\":\"AA\",\"value\":\"2A\"}          ]}属性                                                                  字段      类型      说明      是否必填      默认值      其他              element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     is_remote      boolean      是否远程ajax加载数据,如果为false，data本地数据源字段必填，否则无数据展示      是      false                     remote_url      string      远程ajax加载数据url地址      是      无                     is_fk      boolean      是否关联表查询获取数据      否      false                     fk_resource_name      string      关联表名      否      无                     fk_meta_column      string      关联列字段      否      无                     fk_meta_column_show      string      关联显示列字段      否      无                     data      Array      local数据源，text：文本、value：值[            {\"text\":\"AAAAA\",\"value\":\"5A\"},            {\"text\":\"AAAA\",\"value\":\"4A\"},            {\"text\":\"AAA\",\"value\":\"3A\"},            {\"text\":\"AA\",\"value\":\"2A\"}          ]       否      true             复选框checkboxGroupcheckboxGroup复选框组件，这里是复选框组，支持远程获取字典项结构{            \"element_type\":\"checkboxGroup\",            \"element_title\":\"参与小组\",            \"is_required\":true,            \"meta_column\":\"scenic_id\",            \"is_fk\":true,\t\t\t\"width\":\"100%\",            \"fk_resource_name\":\"scenic_info\",            \"fk_meta_column\":\"id\",            \"fk_meta_column_show\":\"title\",            \"is_remote\":true,            \"rules\":\"is_email\",            \"message\":\"\",            \"remote_url\":\"/cms/template/get_remote_data.htm\",\t\t\t\"data\":[            {\"text\":\"AAAAA\",\"value\":\"5A\"},            {\"text\":\"AAAA\",\"value\":\"4A\"},            {\"text\":\"AAA\",\"value\":\"3A\"},            {\"text\":\"AA\",\"value\":\"2A\"}          ]}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     meta_column      string      表单name字段，元数据字段      是      无                     is_required      boolean      是否必输项      否      false                     is_remote      boolean      是否远程ajax加载数据,如果为false，data本地数据源字段必填，否则无数据展示      是      false                     remote_url      string      远程ajax加载数据url地址      是      无                     is_fk      boolean      是否关联表查询获取数据      否      false                     fk_resource_name      string      关联表名      否      无                     fk_meta_column      string      关联列字段      否      无                     fk_meta_column_show      string      关联显示列字段      否      无                     data      Array      local数据源，text：文本、value：值[            {\"text\":\"AAAAA\",\"value\":\"5A\"},            {\"text\":\"AAAA\",\"value\":\"4A\"},            {\"text\":\"AAA\",\"value\":\"3A\"},            {\"text\":\"AA\",\"value\":\"2A\"}          ]      否      true             单选框radioGroupradioGroup下拉框组件，可以根据url远程加载数据，也可以是local 数据结构{            \"element_type\":\"radioGroup\",            \"element_title\":\"景区级别\",            \"is_required\":true,            \"meta_column\":\"scenic_id\",            \"is_fk\":true,\t\t\t\"width\":\"100%\",            \"fk_resource_name\":\"scenic_info\",            \"fk_meta_column\":\"id\",            \"fk_meta_column_show\":\"title\",            \"is_remote\":false,            \"rules\":\"is_email\",            \"message\":\"\",            \"remote_url\":\"/cms/template/get_remote_data.htm\",\t\t\t\"data\":[            {\"text\":\"AAAAA\",\"value\":\"5A\"},            {\"text\":\"AAAA\",\"value\":\"4A\"},            {\"text\":\"AAA\",\"value\":\"3A\"},            {\"text\":\"AA\",\"value\":\"2A\"}          ]}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     meta_column      string      表单name字段，元数据字段      是      无                     is_required      boolean      是否必输项      否      false                     is_remote      boolean      是否远程ajax加载数据,如果为false，data本地数据源字段必填，否则无数据展示      是      false                     remote_url      string      远程ajax加载数据url地址      是      无                     is_fk      boolean      是否关联表查询获取数据      否      false                     fk_resource_name      string      关联表名      否      无                     fk_meta_column      string      关联列字段      否      无                     fk_meta_column_show      string      关联显示列字段      否      无                     data      Array      local数据源，text：文本、value：值[            {\"text\":\"AAAAA\",\"value\":\"5A\"},            {\"text\":\"AAAA\",\"value\":\"4A\"},            {\"text\":\"AAA\",\"value\":\"3A\"},            {\"text\":\"AA\",\"value\":\"2A\"}          ]      否      true             自定义组件素材上传fileuploadfileupload上传组件，可以上传图片（可预览）、音频等素材结构{        \"element_type\":\"fileupload\",        \"element_title\":\"交通主图\",        \"meta_column\":\"logo_image\"}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     meta_column      string      表单name字段，元数据字段      是      无                     is_required      boolean      是否必输项      否      false             图集imagesImages图集组件，该组件和后台CMS绑定,需要一张素材表cms_material_info结构{          \"element_type\":\"images\",          \"id\":\"scenic_images\",          \"is_required\":true,          \"is_fk_resource\":true,          \"fk_resource_name\":\"cms_material_info\",          \"service\":\"materialService\",          \"remote_url\":\"/cms/images/get_remote_data.htm\",          \"width\":\"400px\",          \"height\":\"300px\"}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     meta_column      string      表单name字段，元数据字段      是      无                     id      string      图集id      是      无                     service      string      后台service业务名称      是      无                     remote_url      string      图集初始化url      是      无                     width      string      地图初始宽度,可以是百分比，可以是像素值，例如：100% 或者400px;      否      无                     height      string      图集高度      是      无                     is_required      boolean      是否必输项      否      false             其他按钮button结构{\t\"element_type\":\"button\",\t\"type\":\"submit\",\t\"element_title\":\"提交\",\t\"remote_url\":\"/cms/template/submit.htm\",\t\"width\":\"80px\",\t\"action_url\":\"/cms/template/template_list.htm\",\t\"params\":{\"url\":\"/json/shengsi/scenic/scenic_list.json\"}}属性            字段      类型      说明      是否必填      默认值      其他                  element_type      string      组件类型      是      无                     element_title      string      组件title      是      无                     type      string      按钮类型，目前有[submit、link、query、edit、delete]五种类型，提交、连接跳转、查询、编辑、删除      是      无                     remote_url      string      根据type类型，有不同的意义，例如是submit，这里则表示提交地址，如未link，这里则为跳转地址      否      无                     params      object      event点击事件，remote_url后面参数      否      无                     action_url      string      callback后执行地址      否      无                     width      string      地图初始宽度,可以是百分比，可以是像素值，例如：100% 或者400px;      否      无             "
  },
  
  {
    "title": "swagger-bootstrap-ui的使用说明",
    "url": "/posts/swagger-bootstrap-ui-introduce/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-04-27 00:00:00 +0800",
    





    
    "snippet": "很多朋友在使用这个jar包的时候会出现接口出不来的情况，或者只出现ui默认的几个接口，项目的api接口没有出来，这里有些注意点同大家说一下吧      依赖swagger(这点很重要),所以项目必须启用swagger,如果你的项目原来就是使用swagger的，仅仅只需要引入swagger-bootstrap-ui的jar包，然后访问/doc.html页面即可,类似于访问原生的/swagger...",
    "content": "很多朋友在使用这个jar包的时候会出现接口出不来的情况，或者只出现ui默认的几个接口，项目的api接口没有出来，这里有些注意点同大家说一下吧      依赖swagger(这点很重要),所以项目必须启用swagger,如果你的项目原来就是使用swagger的，仅仅只需要引入swagger-bootstrap-ui的jar包，然后访问/doc.html页面即可,类似于访问原生的/swagger-ui.html    swagger-bootstrap-ui仅仅只是ui包,没有特定的api语法，属于工具性质的，是完全依赖于swagger的,后端代码也需要使用swagger的java注解-来实现  swagger-bootstrap-ui做的工作就是解析swagger的接口/v2/api-docs，根据该接口做的界面呈现，因为作者喜欢左右风格的布局，原生的ui布局是上下结构的，对于作者来说不是很方便，所以就写了这个小工具,开源出来给大家使用，如果你也喜欢这种风格，你可以应用到你的项目中  git上也提供了一个demo，可以pull下来运行一下,地址:http://git.oschina.net/xiaoym/swagger-bootstrap-ui-demo如果出现js报错,接口出不来，欢迎提issue告知作者修正，非常乐意解决您遇到的bug新issue地址:http://git.oschina.net/xiaoym/swagger-bootstrap-ui/issues/new?issue%5Bassignee_id%5D=&amp;issue%5Bmilestone_id%5D=当然如果你也有更好的想法，欢迎沟通，一起来完善这个小工具~~~~~"
  },
  
  {
    "title": "swagger-bootstrap-ui 1.1 发布，前端 UI 实现",
    "url": "/posts/swagger-bootstrap-ui-1.1-issue/",
    "categories": "开源资讯",
    "tags": "",
    "date": "2017-04-27 00:00:00 +0800",
    





    
    "snippet": "swagger-bootstrap-ui 1.1 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、PathVariable类型的参数,在线调试bug2、绝对路径改成相对路径,适配带项目名称3、接口返回数据Model解析,文档说明中展示相关链接  sw...",
    "content": "swagger-bootstrap-ui 1.1 发布了。swagger-bootstrap-ui 是 Swagger 的前端 UI 实现，目的是替换 Swagger 默认的 UI 实现 Swagger-UI，使文档更友好一点儿本次更新：1、PathVariable类型的参数,在线调试bug2、绝对路径改成相对路径,适配带项目名称3、接口返回数据Model解析,文档说明中展示相关链接  swagger-bootstrap-ui 的详细介绍：点击查看  swagger-bootstrap-ui 的下载地址：点击下载"
  },
  
  {
    "title": "node.js应用Linux安装部署",
    "url": "/posts/nodejs-install-linux/",
    "categories": "NodeJs",
    "tags": "",
    "date": "2017-04-27 00:00:00 +0800",
    





    
    "snippet": "目的在Linux服务器部署node应用参考文档部署下载首先去node.js官网下载node的安装包，官网地址：https://nodejs.org/en/download/，下载tar.gz源码格式包环境node的安装需要依赖gcc、g++等底层命令,安装node.js的新版本对gcc等命令的版本要求也不一样，这里v6.10.2所依赖的gcc 需要v4.8以上，低于这个版本安装不成功安装执行...",
    "content": "目的在Linux服务器部署node应用参考文档部署下载首先去node.js官网下载node的安装包，官网地址：https://nodejs.org/en/download/，下载tar.gz源码格式包环境node的安装需要依赖gcc、g++等底层命令,安装node.js的新版本对gcc等命令的版本要求也不一样，这里v6.10.2所依赖的gcc 需要v4.8以上，低于这个版本安装不成功安装执行以下命令,如果出现命令不存在的错误,需要安装或更新相关系统命令，然后再执行.tar -xvf node-v6.10.1.tar.gz./configuremake &amp;&amp; make install配置环境变量按照上面默认安装,一般node.js会产生两个主要命令，命令默认在/usr/local/bin目录下，如果该目录配置在/etc/profile，则无需配置node：node.js的核心命令，运行js的node服务npm：node.js依赖包安装命令,node的第三方依赖都可以通过npm来安装配置方法：vim /etc/profile追加node的环境export PATH=/usr/local/bin:$PATHprofile生效source /etc/profile验证在终端指向命令,验证node是否安装成功,返回表示安装成功，提示node命令不存在则是环境变量配置不正确node -v安装淘宝镜像因为npm安装命令连接的是国外服务器，我们使用npm安装node的依赖时候速度可能会非常慢,所以使用国内淘宝提供的cnpm来代替参考文档：https://npm.taobao.org/安装命令：npm install -g cnpm--registry=https://registry.npm.taobao.org安装pm2PM2 是一个带有负载均衡功能的 Node 应用的进程管理器。当你要把你的独立代码利用全部的服务器上的所有 CPU，并保证进程永远都活着，0 秒的重载， PM2 是完美的。它非常适合 IaaS 结构，但不要把它用于 PaaS 方案（随后将开发 Paas 的解决方案）。备注：  SaaS、PaaS 和 IaaS 是云服务模式  SaaS 软件即服务，例如 Google 的 Gmail 邮箱服务，面向应用型用户  PaaS 平台即服务，例如 Google 的 GAE，面向开发型用户  IaaS 基础架构即服务，例如亚马逊的 AWS，IaaS 对于不知道新推出的应用程序/网站会有多成功的创业公司来说非常有用这里推荐使用pm2 启动node.js应用服务,相对于node本身命令,稳定,适合在服务器上部署参考文档：http://pm2.keymetrics.io/docs/usage/quick-start/安装cnpm install -g pm2启动服务一般node.js应用在Linux部署是不部署node_modules文件夹的，在线安装依赖，每个node.js应用都有package.json文件，该文件保存了node应用所依赖的各个组件，切到该目录执行命令cnpm install该命令执行后会自动安装依赖组件,并生成node_modules文件夹使用pm2来启动命令node的端口一般都会在启动js里面配置,可以使用vim命令对端口进行修改nginx配置node.js相当于java的服务，是类似于APP端的客户端程序，目前Java所承担的是接口服务的角色,所以不需要对外公开服务，只需要公开node的服务即可"
  },
  
  {
    "title": "swagger-bootstrap-ui发布到Maven中央仓库",
    "url": "/posts/swagger-bootstrap-ui-issue-maven-central/",
    "categories": "Blog",
    "tags": "",
    "date": "2017-04-25 00:00:00 +0800",
    





    
    "snippet": "准备工作注册Sonatype帐号地址：https://issues.sonatype.org/secure/Dashboard.jspa该账户是作为maven全局配置settings.xml文件中server节点需要使用到，账户名称不能是中文（我第一次注册就是注册了个中文，结果坑了好几天….）此外，Sonatype 还提供了一个名为 OSS 的系统：https://oss.sonatype....",
    "content": "准备工作注册Sonatype帐号地址：https://issues.sonatype.org/secure/Dashboard.jspa该账户是作为maven全局配置settings.xml文件中server节点需要使用到，账户名称不能是中文（我第一次注册就是注册了个中文，结果坑了好几天….）此外，Sonatype 还提供了一个名为 OSS 的系统：https://oss.sonatype.org我们上传成功后需要在该oss系统上close、发布组件创建一个JIRA ticket创建一个发布组件的请求issue,需要管理员审核通过该issue,你才有权限上传组件,如下图:这里注意点：  project选择：Community Support - Open Source Project Repository Hosting (OSSRH)  issue Type 选择：New Project  groupId:因为我的项目是托管在GITHUB上的，所以这里我的groupid是com.github.xiaoymin,如果你有自己的域名，可以填写你自己的groupid等待审批一般需要1~2天时间，需要耐心等待,审批通过后会发邮件通知，此外，在自己提交的 Issue 下面会看到 Sonatype 工作人员的回复。当看到如下回复时，表示已经审核通过,你可以上传组件了：使用GnuPG生成密钥如果是 Windows 操作系统，需要下载 Gpg4win 软件来生成密钥对安装 GPG 软件后，打开命令行窗口，依次做以下操作：1.查看是否安装成功gpg --version2.生成秘钥gpg --gen-key此时需要输入姓名、邮箱等字段，其它字段可使用默认值，此外，还需要输入一个 Passphase，相当于一个密钥库的密码，这个密码需要记住，因为后面会用到。3.查看密码gpg --list-keys输出如下信息：C:/Users/xiaoymin/AppData/Roaming/gnupg/pubring.gpg---------------------------------------------------pub   2048R/525E4513 2017-08-31uid       [ultimate] xiaoym &lt;xiaoymin@foxmail.com&gt;sub   2048R/3DC9A187 2017-08-31可见这里的公钥的 ID 是：525E4513，很明显是一个 16 进制的数字，马上就会用到。4.将公钥发布到 PGP 密钥服务器gpg --keyserver hkp://pool.sks-keyservers.net --send-keys 525E4513# 后面这个也需要执行,发布到ubuntu服务器上gpg --keyserver hkp://keyserver.ubuntu.com --send-keys 525E4513此后，可使用本地的私钥来对上传构件进行数字签名，而下载该构件的用户可通过上传的公钥来验证签名，也就是说，大家可以验证这个构件是否由本人上传的，因为有可能该构件被坏人给篡改了。5.查询公钥是否发布成功gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 525E4513实际上就是从 key server 上通过公钥 ID 来接收公钥，此外，也可以到 sks-keyservers.net 上通过公钥 ID 去查询。以上操作就算完成了密钥生成工作.修改maven配置文件需要修改的maven配置文件包括setting.xml和项目的pom.xml1.setting.xml&lt;!-- lang: xml --&gt;&lt;settings&gt;    ...    &lt;servers&gt;        &lt;server&gt;            &lt;id&gt;oss&lt;/id&gt;            &lt;username&gt;用户名&lt;/username&gt;            &lt;password&gt;密码&lt;/password&gt;        &lt;/server&gt;    &lt;/servers&gt;    ...&lt;/settings&gt;使用自己注册的 Sonatype 账号的用户名与密码来配置以上 server 信息。2.pom.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;  ...  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;  &lt;version&gt;1.5&lt;/version&gt;  &lt;name&gt;swagger-bootstrap-ui&lt;/name&gt;  &lt;description&gt;Swagger-Bootstrap-UI is the front of the UI Swagger implementation, using jQuery+bootstrap implementation, the purpose is to replace the default UI Swagger implementation of the Swagger-UI, so that the document is more friendly...&lt;/description&gt;  &lt;url&gt;https://git.oschina.net/xiaoym/swagger-bootstrap-ui&lt;/url&gt;  &lt;developers&gt;    &lt;developer&gt;      &lt;id&gt;xiaoym&lt;/id&gt;      &lt;name&gt;肖玉民&lt;/name&gt;      &lt;email&gt;xiaoymin@foxmail.com&lt;/email&gt;      &lt;roles&gt;        &lt;role&gt;Java Development Engineer&lt;/role&gt;      &lt;/roles&gt;      &lt;timezone&gt;2017-4-17 18:05:10&lt;/timezone&gt;    &lt;/developer&gt;  &lt;/developers&gt;  &lt;licenses&gt;    &lt;license&gt;      &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt;      &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt;    &lt;/license&gt;  &lt;/licenses&gt;  &lt;scm&gt;    &lt;connection&gt;scm:git@git.oschina.net:xiaoym/swagger-bootstrap-ui.git&lt;/connection&gt;    &lt;developerConnection&gt;scm:git@git.oschina.net:xiaoym/swagger-bootstrap-ui.git&lt;/developerConnection&gt;    &lt;url&gt;git@git.oschina.net:xiaoym/swagger-bootstrap-ui.git&lt;/url&gt;  &lt;/scm&gt;  &lt;distributionManagement&gt;    &lt;snapshotRepository&gt;      &lt;id&gt;oss&lt;/id&gt;      &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt;    &lt;/snapshotRepository&gt;    &lt;repository&gt;      &lt;id&gt;oss&lt;/id&gt;      &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;    &lt;/repository&gt;  &lt;/distributionManagement&gt;    &lt;profiles&gt;    &lt;profile&gt;      &lt;id&gt;release&lt;/id&gt;      &lt;build&gt;        &lt;plugins&gt;          &lt;!-- Source --&gt;          &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;            &lt;version&gt;2.2.1&lt;/version&gt;            &lt;executions&gt;              &lt;execution&gt;                &lt;phase&gt;package&lt;/phase&gt;                &lt;goals&gt;                  &lt;goal&gt;jar-no-fork&lt;/goal&gt;                &lt;/goals&gt;              &lt;/execution&gt;            &lt;/executions&gt;          &lt;/plugin&gt;          &lt;!-- Javadoc --&gt;          &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;            &lt;version&gt;2.9.1&lt;/version&gt;            &lt;executions&gt;              &lt;execution&gt;                &lt;phase&gt;package&lt;/phase&gt;                &lt;goals&gt;                  &lt;goal&gt;jar&lt;/goal&gt;                &lt;/goals&gt;              &lt;/execution&gt;            &lt;/executions&gt;          &lt;/plugin&gt;          &lt;!-- GPG --&gt;          &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt;            &lt;version&gt;1.6&lt;/version&gt;            &lt;executions&gt;              &lt;execution&gt;                &lt;phase&gt;verify&lt;/phase&gt;                &lt;goals&gt;                  &lt;goal&gt;sign&lt;/goal&gt;                &lt;/goals&gt;              &lt;/execution&gt;            &lt;/executions&gt;          &lt;/plugin&gt;        &lt;/plugins&gt;      &lt;/build&gt;      &lt;distributionManagement&gt;        &lt;!-- 这里的id oss需要和setting.xml里面server节点配置的id一致--&gt;        &lt;snapshotRepository&gt;          &lt;id&gt;oss&lt;/id&gt;          &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt;        &lt;/snapshotRepository&gt;        &lt;repository&gt;          &lt;id&gt;oss&lt;/id&gt;          &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;        &lt;/repository&gt;      &lt;/distributionManagement&gt;    &lt;/profile&gt;  &lt;/profiles&gt;  &lt;/project&gt;注意：以上 pom.xml 必须包括：name、description、url、licenses、developers、scm 等基本信息，此外，使用了 Maven 的 profile 功能，只有在 release 的时候，创建源码包、创建文档包、使用 GPG 进行数字签名。此外，snapshotRepository 与 repository 中的 id 一定要与 setting.xml 中 server 的 id 保持一致.上传构件到 OSS 中执行上传命令,这里我是新开cmd窗口执行mvn clean deploy -P release当执行以上 Maven 命令时，会自动弹出一个对话框，需要输入上面提到的 Passphase，它就是通过 GPG 密钥对的密码，只有自己才知道。随后会看到大量的 upload 信息，而且速度比较慢，经常会 timeout，需要反复尝试。注意：此时上传的构件并未正式发布到中央仓库中，只是部署到 OSS 中了，下面才是真正的发布。在执行这一步时可能碰到的错误：1、报401错误，如下：[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for https://oss.sonatype.org/service/local/staging/deploy/maven2/Uploading: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/github/xiaoymin/swagger-bootstrap-ui/1.5/swagger-bootstrap-ui-1.5.jarUploading: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/github/xiaoymin/swagger-bootstrap-ui/1.5/swagger-bootstrap-ui-1.5.pom[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 10.190 s[INFO] Finished at: 2017-08-31T17:17:58+08:00[INFO] Final Memory: 16M/155M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project swagger-bootstrap-ui: Failed to deploy artifacts: Could not transfer artifact com.github.xiaoymin:swagger-bootstrap-ui:jar:1.5 from/to oss (https://oss.sonatype.org/service/local/staging/deploy/maven2/): Failed to transfer file: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/github/xiaoymin/swagger-bootstrap-ui/1.5/swagger-bootstrap-ui-1.5.jar. Return code is: 401, ReasonPhrase: Unauthorized. -&gt; [Help 1]碰到这种情况有几种情况首先，确认使用的oss账号 、密码是否正确，这是最关键的其次，有可能使用该命令时，使用的全局配置setting.xml路径不对(比如我，因为我的配置文件是放在D盘目录下，结果在cmd窗口执行上传命令，命令中maven使用的却是默认配置，在C盘符下，所以修改c盘符下的setting.xml文件，添加server节点即可)可以使用-X命令调试执行,例如：mvn clean deploy -P release -X可以看到maven的详细打印日志,方便我们找出错误，当出现如下build success时，恭喜你,距离成功又进了一步Uploaded: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/github/xiaoymin/swagger-bootstrap-ui/1.5/swagger-bootstrap-ui-1.5-sources.jar.asc (484 B at 1.3 KB/sec)Uploading: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/github/xiaoymin/swagger-bootstrap-ui/1.5/swagger-bootstrap-ui-1.5-sources.jar.ascUploaded: https://oss.sonatype.org/service/local/staging/deploy/maven2/com/github/xiaoymin/swagger-bootstrap-ui/1.5/swagger-bootstrap-ui-1.5-sources.jar.asc (484 B at 1.4 KB/sec)[INFO] ------------------------------------------------------------------------                                         [INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 51.276 s[INFO] Finished at: 2017-09-01T10:17:38+08:00[INFO] Final Memory: 19M/156M[INFO] ------------------------------------------------------------------------在 OSS 中发布构件登录oss系统：https://oss.sonatype.org/在 OSS 中，使用自己的 Sonatype 账号登录后，可在 Staging Repositories 中查看刚才已上传的构件，这些构件目前是放在 Staging 仓库中，可进行模糊查询，快速定位到自己的构件。此时，该构件的状态为 Open，需要勾选它，然后点击 Close 按钮。接下来系统会自动验证该构件是否满足指定要求，当验证完毕后，状态会变为 Closed，最后，点击 Release 按钮来发布该构件。这里close最有可能碰到的错误就是签名错误:Failed: Signature Validation解决方法：1.首先保证自己的秘钥上传到服务器,可以在http://pool.sks-keyservers.net/查询自己上传的秘钥结果也可以再上传一次gpg --keyserver hkp://pool.sks-keyservers.net --send-keys 525E4513gpg --keyserver hkp://keyserver.ubuntu.com --send-keys 525E45132.在上传构建oss步骤中，没有使用 -P release参数，比如使用如下命令：mvn clean deploy 使用该命令可以上传成功,但是我们的文件没有签名,其实我们本地生成的文件也可以签名验证的例如：D:\\Users\\xiaoymin\\.m2\\repository\\com\\github\\xiaoymin\\swagger-bootstrap-ui\\1.5&gt;gpg2 --verify swagger-bootstrap-ui-1.5.jar.ascgpg: assuming signed data in 'swagger-bootstrap-ui-1.5.jar'gpg: Signature made 09/01/17 10:17:05 中国标准时间 using RSA key ID 525E4513gpg: Good signature from \"xiaoym &lt;xiaoymin@foxmail.com&gt;\" [ultimate]D:\\Users\\xiaoymin\\.m2\\repository\\com\\github\\xiaoymin\\swagger-bootstrap-ui\\1.5&gt;gpg2 --verify swagger-bootstrap-ui-1.5.pom.ascgpg: assuming signed data in 'swagger-bootstrap-ui-1.5.pom'gpg: Signature made 09/01/17 10:17:05 中国标准时间 using RSA key ID 525E4513gpg: Good signature from \"xiaoym &lt;xiaoymin@foxmail.com&gt;\" [ultimate]D:\\Users\\xiaoymin\\.m2\\repository\\com\\github\\xiaoymin\\swagger-bootstrap-ui\\1.5&gt;gpg2 --verify swagger-bootstrap-ui-1.5-sources.jar.ascgpg: assuming signed data in 'swagger-bootstrap-ui-1.5-sources.jar'gpg: Signature made 09/01/17 10:17:05 中国标准时间 using RSA key ID 525E4513gpg: Good signature from \"xiaoym &lt;xiaoymin@foxmail.com&gt;\" [ultimate]最后出现Good signature from ...这个信息的时候,那说明我们的文件是签名验证成功的，反之，会出现Bad signature from ...这点需要注意通知 Sonatype 构件已成功发布需要在曾经创建的 Issue 下面回复一条“构件已成功发布”的评论，这是为了通知 Sonatype 的工作人员为需要发布的构件做审批，发布后会关闭该 Issue。等待构件审批通过没错，还是要等，也许又是 1 ~ 2 天。同样，当审批通过后，将会收到邮件通知。从中央仓库中搜索构件最后，就可以到中央仓库中搜索到自己发布的构件了！  中央仓库搜索网站：http://search.maven.org/最后，想说一句：第一次都是很痛的，以后就舒服了。没错，只有第一次发布才如此痛苦，以后 deploy 的构件会自动部发布到中央仓库，无需再这样折腾了。参考文章      将 Smart 构件发布到 Maven 中央仓库    Working with PGP Signatures  No public key: Key with id: (XXXXX) was not able to be located (oss.sonatype.org)  Android Studio使用Gradle上传AAR至Maven  Maven Sonatype Nexus return 401"
  },
  
  {
    "title": "开源个人作品:swagger-bootstrap-ui",
    "url": "/posts/swagger-bootstrap-ui-open/",
    "categories": "开源",
    "tags": "",
    "date": "2017-04-22 00:00:00 +0800",
    





    
    "snippet": "简介swagger-bootstrap-ui是Swagger的前端UI实现,目的是替换Swagger默认的UI实现Swagger-UI,使文档更友好一点儿….swagger-bootstrap-ui 只是Swagger的UI实现,并不是替换Swagger功能,所以后端模块依然是依赖Swagger的,需要配合Swagger的注解达到效果,注解说明功能  接口文档说明,效果图如下：  在线调试功...",
    "content": "简介swagger-bootstrap-ui是Swagger的前端UI实现,目的是替换Swagger默认的UI实现Swagger-UI,使文档更友好一点儿….swagger-bootstrap-ui 只是Swagger的UI实现,并不是替换Swagger功能,所以后端模块依然是依赖Swagger的,需要配合Swagger的注解达到效果,注解说明功能  接口文档说明,效果图如下：  在线调试功能,效果图如下:demo演示swagger-bootstarp-ui-demo下载swagger-bootstrap-ui下载地址：下载使用说明  首先需要引入swagger的配置包信息,如下：&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 这里swagger-ui是swagger的默认实现,这个jar可以不用引入,使用下面的swagger-bootstrap-ui替代---&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;  maven项目中引用swagger-bootstrap-ui的jar包依赖,如下：&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;  &lt;version&gt;1.6&lt;/version&gt;&lt;/dependency&gt;  Spring项目中启用swagger,代码如下：1.注解方式@Configuration@EnableSwagger2public class SwaggerConfiguration { @Bean public Docket createRestApi() {     return new Docket(DocumentationType.SWAGGER_2)     .apiInfo(apiInfo())     .select()     .apis(RequestHandlerSelectors.basePackage(\"com.bycdao.cloud\"))     .paths(PathSelectors.any())     .build(); } private ApiInfo apiInfo() {     return new ApiInfoBuilder()     .title(\"swagger-bootstrap-ui RESTful APIs\")     .description(\"swagger-bootstrap-ui\")     .termsOfServiceUrl(\"http://localhost:8999/\")     .contact(\"developer@mail.com\")     .version(\"1.0\")     .build(); }}  swagger-bootstrap-ui默认访问地址是：http://${host}:${port}/doc.html注意事项  swagger封装给出的请求地址默认是/v2/api-docs,所以swagger-bootstrap-ui调用后台也是/v2/api-docs,不能带后缀,且需返回json格式数据,框架如果是spring boot的可以不用修改,直接使用,如果是Spring MVC在web.xml中配置了DispatcherServlet,则需要追加一个url匹配规则,如下：&lt;servlet&gt;   &lt;servlet-name&gt;cmsMvc&lt;/servlet-name&gt;   &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;   &lt;init-param&gt;   &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;   &lt;param-value&gt;classpath:config/spring.xml&lt;/param-value&gt;   &lt;/init-param&gt;   &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;!--默认配置,.htm|.do|.json等等配置--&gt;&lt;servlet-mapping&gt;\t&lt;servlet-name&gt;cmsMvc&lt;/servlet-name&gt; \t&lt;url-pattern&gt;*.htm&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;!-- 配置swagger-bootstrap-ui的url请求路径--&gt;&lt;servlet-mapping&gt;   &lt;servlet-name&gt;cmsMvc&lt;/servlet-name&gt;   &lt;url-pattern&gt;/v2/api-docs&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;鸣谢特别感谢以下大牛开发的js/css、html前端框架，美观、易用            框架      网站                  jquery      http://jquery.com/              bootstrap      http://getbootstrap.com              layer      http://layer.layui.com/              jsonview      https://github.com/yesmeck/jquery-jsonview      "
  },
  
  {
    "title": "个人开源作品：swagger-bootstrap-ui-demo",
    "url": "/posts/swagger-bootstrap-ui-demo-open/",
    "categories": "开源",
    "tags": "",
    "date": "2017-04-22 00:00:00 +0800",
    





    
    "snippet": "该项目是swagger-bootstrap-ui的演示项目,使用Spring boot1、该项目是Spring boot项目,直接main方法运行SwaggerBootstrapUiDemoApplication即可2、端口是application.properties中配置的8999server.port=89993、访问http://localhost:8999/doc.html相关链接...",
    "content": "该项目是swagger-bootstrap-ui的演示项目,使用Spring boot1、该项目是Spring boot项目,直接main方法运行SwaggerBootstrapUiDemoApplication即可2、端口是application.properties中配置的8999server.port=89993、访问http://localhost:8999/doc.html相关链接  swagger-bootstrap-ui-demo 的详细介绍：点击查看  swagger-bootstrap-ui-demo 的下载地址：点击下载"
  },
  
  {
    "title": "Java架构师之路",
    "url": "/posts/java-road-architect/",
    "categories": "Java",
    "tags": "",
    "date": "2017-03-30 00:00:00 +0800",
    





    
    "snippet": "Java架构师之路入门（1~3年）  目标：参与简单的项目开发。  技能：o   掌握 Java。经典的《Java核心技术：卷1 基础知识》(或者《Java 编程思想》)必看，跳过其中的图形和 applet 章节。习惯查阅 Java API Doc。为了保证代码的质量，《Effective Java》、《Clean Code》和《重构》也需要至少通读一遍。o   熟悉 Linux 开发环境和...",
    "content": "Java架构师之路入门（1~3年）  目标：参与简单的项目开发。  技能：o   掌握 Java。经典的《Java核心技术：卷1 基础知识》(或者《Java 编程思想》)必看，跳过其中的图形和 applet 章节。习惯查阅 Java API Doc。为了保证代码的质量，《Effective Java》、《Clean Code》和《重构》也需要至少通读一遍。o   熟悉 Linux 开发环境和bash shell。Linux 是我们的开发和部署环境，你最好尽快熟练它。Linux 的基本使用可以通过《鸟哥的Linux私房菜：基础学习篇（第三版）》学习，开发 bash shell 脚本可以参考《Linux Shell脚本攻略》。o   掌握开发工具§ 熟练使用一种 IDE。IntellijIDEA或者 Eclipse 都可以，推荐使用前者。至少熟悉常用的快捷键，会 debug(包括远程 debug)项目。§ 熟悉一种编辑器。比如 Vim/Emacs/Sublime Text，至少学会搜索/替换/代码补全。o   掌握 JDK 以外的常用类库和工具包。JDK 原生 API 在很多场景下使用并不方便。你需要掌握社区贡献的优秀类库和工具包，比如 apache commons、google guava 等，具体可以翻阅 服务端技术选型 的Utility篇。o   掌握 Web 开发框架。我们使用Spring(或Rose) + Ibatis(或Jade) 开发 web 服务，你需要熟练掌握它们。o   学习代码规范。我们大致上遵循 oracle 的 Java 语言编码规范，你可以先阅读并熟悉它。Code Formatting 文件在 git@xxx/coding-standard.git，在编写代码之前，请把它导入到IDE 中。另外，确认 IDE 已经安装 Findbugs 和 CheckStyle 插件。o   熟悉开发流程。我们的开发流程大致如下：功能开发-&gt;单元测试-&gt;功能测试-&gt;Code Review-&gt;集成测试-&gt;发布。确保你熟悉其中的每个环节。o   其他。需要熟练使用版本控制工具 Git（阅读：《Git 权威指南》），以及项目构建工具 Maven（阅读：《Maven 实战》）。另外，在这个阶段可以尝试 TDD 开发。进阶（3-5年）·目标：独立负责某个服务端项目。·技能：o   掌握 web 开发最佳实践，掌握Restful API 设计，理解 Spring 原理。推荐阅读《Spring揭秘》。掌握项目分层、子模块划分。推荐阅读：《J2EE 核心模式》。o   掌握 web 架构设计。包括Http 反向代理，数据缓存，负载均衡，水平扩展和垂直扩展。推荐阅读：《分布式 Java 应用：基础与实践》。o   掌握关系型数据库。包括设计 MySQL 表结构，根据业务特点分表分库，基于执行计划的 SQL 分析优化，以及数据库容量规划。推荐阅读：《MySQL 必知必会》、《高性能 MySQL》。o   了解 NoSQL。我们大规模使用Hadoop、HBase、Hive，同时部分项目使用 Redis、Storm。你需要学会这些工具最基本的使用。o   学习 web 安全知识。了解web 前端安全问题。设计安全 web 服务，包括加解密、防伪造、防重放攻击等。o   掌握 Http (推荐阅读：《图解Http》、《http权威指南》)、Thrift 等协议。o   掌握服务容量规划，性能调优，可靠性保证，以及故障处理。学习容量规划和性能调优知识，梳理业务监控点，熟练使用我们的监控报警系统。推荐阅读：《深入理解 Java 虚拟机》。o   其他。设计模式：从项目中学习，有时间可以看看《深入浅出设计模式》、《JDK 里的设计模式》。学习Java Socket 编程与多线程知识，可以看看《Java 并发编程实战》，并翻翻并发编程网的文章。深入（5年以后-）·目标：分布式系统和中间件开发。·构建知识体系：《大型网站系统与 Java 中间件实践》、《大型网站技术架构：核心原理与案例分析》。·原理与设计：《大规模存储式系统》、《UNIX 网络编程 卷1:套接字联网 API》、《HowTomcat Works》。·学习开源项目：Apache Thrift、Zipkin、Netty、Rose、Jade、淘宝 RPC 系统 Dubbo等。分析项目中的设计思路。比如，同样是RPC框架，Finagle和 Dubbo 有什么异同。·其他。根据参与的项目加深学习吧。比如，如果需要写 DSL，可以读一下《领域特定语言》，对 Redis 感兴趣推荐读一下：《Redis 设计与实现》。有两本书，无论做什么项目，都推荐读：《Unix 编程艺术》、《UNIX 环境高级编程(第3版)》。"
  },
  
  {
    "title": "Linux部署常用命令",
    "url": "/posts/common-command-linux/",
    "categories": "Linux",
    "tags": "",
    "date": "2017-03-30 00:00:00 +0800",
    





    
    "snippet": "目的该文档主要针对初次在Linux机器上部署应用，对Linux操作系统不熟悉的开发者用户，列举一些常用的命令集合以及部署步骤，供开发者对Linux系统有一个初步的了解和学习工具推荐部署工具：终端工具：XShell 5文件上传：XFtpLinux常用命令1、man:该命令是学习参数命令,任何linux终端命令都可以通过该命令查看参数学习，具体操作明细，命令如下：lishi@iZbp10yas4...",
    "content": "目的该文档主要针对初次在Linux机器上部署应用，对Linux操作系统不熟悉的开发者用户，列举一些常用的命令集合以及部署步骤，供开发者对Linux系统有一个初步的了解和学习工具推荐部署工具：终端工具：XShell 5文件上传：XFtpLinux常用命令1、man:该命令是学习参数命令,任何linux终端命令都可以通过该命令查看参数学习，具体操作明细，命令如下：lishi@iZbp10yas4kb5a9dudjbw2Z:~&gt; man vim回车后会详细显示vim命令的具体参数及用法2、cd:切换文件夹命令，例如从当前/home目录切换到/mnt目录，命令如下：lishi@iZbp10yas4kb5a9dudjbw2Z:~&gt; cd /lishi@iZbp10yas4kb5a9dudjbw2Z:/&gt; cd /mntlishi@iZbp10yas4kb5a9dudjbw2Z:/mnt&gt; pwd/mntlishi@iZbp10yas4kb5a9dudjbw2Z:/mnt&gt; 3、pwd:显示当前用户所在文件夹位置，命令如下：lishi@iZbp10yas4kb5a9dudjbw2Z:/mnt&gt; pwd/mntlishi@iZbp10yas4kb5a9dudjbw2Z:/mnt&gt; 4、ps:展示当前进程详情，一般用于查找例如我想知道当前linux系统运行了多少java相关的进程，命令如下：ps-ef|grep java5、netstat: 打印网络连接、路由表、接口统计、伪装连接和多播成员该命令一般用于通过端口号查找进程，命令如下：lishi@iZbp10yas4kb5a9dudjbw2Z:/mnt&gt; netstat -anp|grep 8080(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN      -                   lishi@iZbp10yas4kb5a9dudjbw2Z:/mnt&gt; 6、kill:终止进程服务命令：kill -9 pidPid是进程号7、mv:移动文件该命令可以作为移动文件命令，也可以作为更名命令使用；8、mkdir：创建文件夹9、ls:展示文件夹目录列表信息命令如下：10、vim:编辑器vim是linux 一个编辑器软件，详细参数请通过man命令或网上资料学习使用，这里不一一列举字母i进入编辑状态按钮esc退出编辑状态:wq保存当前文件并退出:wq!强制保存并退出:q!不保存退出tomcat命令首先cd到tomcat主目录，然后执行下面命令bin/startup.sh:启动当前tomcat服务bin/shutdown.sh:关闭当前tomcat服务nginx命令首先cd到nginx主目录，然后执行下面命令sbin/nginx:启动nginxsbin/nginx -s reload:重启nginxsbin/nginx -t:测试nginx配置是否正确，是否可启动pm2命令pm2是nodejs的进程管理器，角色类似于Java应用中的tomcat，一般我们的nodejs应用都是通过node命令来启动例如：这种方式服务端部署的时候不是很稳定及规范,所以nodejs应用部署使用pm2通过pm2 help可以查看明细参数主要命令如下："
  },
  
  {
    "title": "前后端分离方案探索",
    "url": "/posts/back-front-explore/",
    "categories": "Blog",
    "tags": "",
    "date": "2017-03-30 00:00:00 +0800",
    





    
    "snippet": "背景目前我们组开发的所有官网咨询类项目，开发方式全部是采用调用后端Java RestfulApi接口，然后ajax渲染页面,这种开发方式就功能而言，是没有任何问题的，但在SEO这方面，ajax不是很友好，又因为是官网这种性质的网站，SEO无可避免的会被提及，所以目前考虑的技术方案是既要保证在满足解决SEO的大前提下，又不会破坏我们目前的开发方式，对我们开发模式影响降到最低,发挥前后端开发人员...",
    "content": "背景目前我们组开发的所有官网咨询类项目，开发方式全部是采用调用后端Java RestfulApi接口，然后ajax渲染页面,这种开发方式就功能而言，是没有任何问题的，但在SEO这方面，ajax不是很友好，又因为是官网这种性质的网站，SEO无可避免的会被提及，所以目前考虑的技术方案是既要保证在满足解决SEO的大前提下，又不会破坏我们目前的开发方式，对我们开发模式影响降到最低,发挥前后端开发人员的开发效率解决方案在希望前后端开发模式变动很小的前提下，引入nodejs技术，前端负责URL Design，并写路由控制，原来ajax异步调用的方式，多加一层MVC层中的C层代码，访问方式变成同步访问前端的同学们现在要开始学习nodejs了！！！以后官网的开发基本都会走这种开发模式，wap、微信类还是可以继续保留老的方式，不走nodejs示例技术架构设计架构图如下：Nginx：web服务器Node1: 前端nodejs应用服务器，通过nginx负载均衡，可以代理多台nodejs应用Java Restful Api:Java后端接口服务器，前端nodejs调用接口获取数据Redis：后期用到，所有session会话存入session，前端获取用户资料不在从Java接口获取，而是直接调用Redis获取当前会话值，Java后端提供接口供node接口调用将用户session值存入Redis数据库中技术参考下面几篇博客很有参考意义,大家可以看下1.图解基于Node.js实现前后端分离2.前后端分离的思考与实践（一）3.前后端分离的思考与实践（二）4.前后端分离的思考与实践（三）5.前后端分离的思考与实践（四）6.前后端分离的思考与实践（五）7.关于大型网站技术演进的思考（十四）–网站静态化处理—前后端分离—上（6）8.关于大型网站技术演进的思考（十五）–网站静态化处理—前后端分离—中（7）9.关于大型网站技术演进的思考（十六）–网站静态化处理—前后端分离—下（8）10.关于大型网站技术演进的思考（十七）–网站静态化处理—满足静态化的前后端分离（9）"
  },
  
  {
    "title": "开源个人作品:JFormParser",
    "url": "/posts/jformparser-open/",
    "categories": "开源",
    "tags": "",
    "date": "2017-01-20 00:00:00 +0800",
    





    
    "snippet": "JFormParser插件:根据json结构,生成页面,达到解放后端开发人员的目的,降低后端对前端开发要求,后端专心开发后台接口等服务程序,前期以表单元素为主,后期会增加更多页面元素的支持码云地址：https://gitee.com/xiaoym/JFormParser",
    "content": "JFormParser插件:根据json结构,生成页面,达到解放后端开发人员的目的,降低后端对前端开发要求,后端专心开发后台接口等服务程序,前期以表单元素为主,后期会增加更多页面元素的支持码云地址：https://gitee.com/xiaoym/JFormParser"
  },
  
  {
    "title": "跨域请求,关于后端session会话丢失的解决办法",
    "url": "/posts/back-session-jsonp/",
    "categories": "Blog",
    "tags": "",
    "date": "2016-11-26 00:00:00 +0800",
    





    
    "snippet": "目前使用前后端分离的模式开发，后端提供跨域接口、前端jsonp调用，绑定数据，但是在该站点下有个人中心模块存在的情况下，服务端的session会话会被跨域请求覆盖改掉大家都知道tomcat使用cookie中jsessionid来区分客户端session会话跨域请求接口恰恰有时候响应回来回改变该站点下的jsessionid值，导致服务器每次判断都是一个新的会话以网站个人中心模块来说，每一个跨域...",
    "content": "目前使用前后端分离的模式开发，后端提供跨域接口、前端jsonp调用，绑定数据，但是在该站点下有个人中心模块存在的情况下，服务端的session会话会被跨域请求覆盖改掉大家都知道tomcat使用cookie中jsessionid来区分客户端session会话跨域请求接口恰恰有时候响应回来回改变该站点下的jsessionid值，导致服务器每次判断都是一个新的会话以网站个人中心模块来说，每一个跨域jsonp请求，都会Response 一个cookie值，SET-COOKIE:JSESSIONID=XXXX,如下图：再看服务端，前端刷新一次也没，后端服务会话id都不是同一个sessionid，所有后端所有的请求都是未登录，这就导致前端发送的请求，后端无法拿到当前个人用户信息目前服务端部署都采用tomcat，所以修改办法是在conf/context.xml文件中，设置sessionId的cookieName别名，不和默认的jsessionid一直，如下：最终修改好后，再看服务器的cookie值，服务端使用session取的cookie值是刚刚设置的别名cookie值SHGJSESSIONID,所以不受跨域接口影响最终服务端请求的session会话能保证是同一个，所以也能取到当前登录的个人信息更多tomcat参数设置值请参考  tomcat-context参数值"
  },
  
  {
    "title": "前端本地nginx反向代理说明",
    "url": "/posts/nginx-front-intruduce/",
    "categories": "Blog",
    "tags": "",
    "date": "2016-11-15 00:00:00 +0800",
    





    
    "snippet": "背景目前前端在和后端对接接口的时候，有2种方式，都是根据接口类型来分，第一种是后端是jsonp接口，前端在本地调试时直接能访问到,这种是方便前端开发的，但是对后端接口类型有要求,第二种是非jsonp接口，针对这种接口，对于前端来说就非常痛苦，前端需要在本地修改好代码后,上传到测试服务器，然后通过访问测试服务器地址来确定代码正确性，反复重复修改、上传、测试动作，开发效率不高，另外一个弊端就是前...",
    "content": "背景目前前端在和后端对接接口的时候，有2种方式，都是根据接口类型来分，第一种是后端是jsonp接口，前端在本地调试时直接能访问到,这种是方便前端开发的，但是对后端接口类型有要求,第二种是非jsonp接口，针对这种接口，对于前端来说就非常痛苦，前端需要在本地修改好代码后,上传到测试服务器，然后通过访问测试服务器地址来确定代码正确性，反复重复修改、上传、测试动作，开发效率不高，另外一个弊端就是前端需要些config文件，来配置我们后端的接口请求地址，如果前端工程师规范意识强一点，会通用到一个配置文件里，但是如果没有这方面的意识的话，就会出现代码里硬编码的情况，不利于服务器迁移，代码更新，接口变动等操作目的提高团队开发效率,并且防止硬编码的情况出现，方便以后服务器迁移，真正达到前后端分离，动静分开组件nginx-1.10.2配置步骤安装nginx1、 nginx官网(http://nginx.org/en/download.html)下载nginx的windows安装包，这里下载的是zip压缩包，解压即可，解压目录父目录不要放在中文目录下，防止出现不必要的麻烦，不需要安装,解压之后，如下目录：2、 修改nginx.conf配置文件，使用include命令引入项目配置conf文件，在conf文件夹下引入vhost中的配置文件在vhost中添加每个项目的配置文件，以.conf文件名结尾3、 配置自己项目环境，代理端口、前端静态文件路径4、 启动nginx双击nginx.exe文件，这里主要注意点是添加配置，或者修改端口后，nginx重新运行也不起作用，这时候先停掉nginx程序，然后在启动，步骤：1、 启动cmd窗口程序，停止a)     2、 启动nginx，直接运行或命令终端指向exe都可以的5、 访问项目前端代码不需要使用jsonp模式，根据服务端接口给出的类型get or post 酌情使用配置demoserver{       listen       8089;       server_name  127.0.0.1 localhost;       access_log logs/baotou_website.log;       charset utf-8;              location / {                proxy_passhttp://192.168.11.111:58080/;                            proxy_redirectdefault;        }        location ~* ^.+.(ico|gif|jpg|jpeg|png|html)$ {           root        D:/java/git/xinghc_wx/front/;       }        location ~* ^.+.(css|js|txt|xml|swf|wav)$ {           root       D:/java/git/xinghc_wx/front/;       }}"
  },
  
  {
    "title": "Linux部署规范",
    "url": "/posts/deploy-standard-linux/",
    "categories": "Linux",
    "tags": "",
    "date": "2016-11-08 00:00:00 +0800",
    





    
    "snippet": "前言目前我们组主要以官网、微信、wap、app居多，目前前端大多使用路由相关的技术框架，例如backbone、vue等，通过ajax调用后端接口，实现页面交互，所以所有的访问url连接都是前端的规范地址，开发阶段已经实现了前后端分离，但目前在部署方面，还没有真正实现，以前的部署都是只部署一台tomcat，前端html页面后端接口部署在一起，这样会存在多种弊端，在后期如果要做负载的情况下，不易...",
    "content": "前言目前我们组主要以官网、微信、wap、app居多，目前前端大多使用路由相关的技术框架，例如backbone、vue等，通过ajax调用后端接口，实现页面交互，所以所有的访问url连接都是前端的规范地址，开发阶段已经实现了前后端分离，但目前在部署方面，还没有真正实现，以前的部署都是只部署一台tomcat，前端html页面后端接口部署在一起，这样会存在多种弊端，在后期如果要做负载的情况下，不易扩展，后端更新接口不方便，有可能会对前端的代码有影响目的真正实现前后端分离，前端界面、后端接口通过该套程序规范，达到分离效果结构图访问者访问前端提供的url，所有的静态（html、css、jpg等）文件通过nginx直接处理，响应给用户，调用接口部分，通过nginx配置接口反向代理地址，后端接口可以做负载，缓解一台服务器压力，提高程序响应速度，这样做的好处：1、 nginx在静态文件的处理能力上和tomcat不是同一个级别的，1000个并发完全不是问题，tomcat默认使用socket处理，高并发的情况下会造成io阻塞，线程一直等待2、 方便后端接口做负载，提高程序并发、吞吐量部署组件1.Nginx1.9.5 以上2.Tomcat8以上nginx说明Nginx主要是提供给前端部署静态文件使用，前端以后所有的访问路径不在部署在tomcat服务器里面，通过静态目录的方式直接访问html，附上nginx服务器配置上图中细红线框部分是linux上静态目录，前端所有文件全部放在该目录下，命名规则/home/drore/kaifayizu/${project_name}这里首先要查看服务器硬盘情况，有时候可能不是home目录，在linxu使用dh -f命令查看服务器硬盘情况，如下图：根据avail空闲硬盘情况，决定在哪个目录建立drore/kaifayizu/${project_name}目录在nginx配置那种图中，粗红框部分是我们后端的接口反向代理地址，该接口可以部署在和nginx同一台机器，也可以是别个机器所以最终我们所有的接口访问地址是和前端的访问url保持一致的，都是通过nginx反向代理的，这点非常重要，这种模式可以让我们抛弃jsonp跨域模式更多的nginx配置参数情况请自己百度学习Tomcat8​       为什么使用tomcat8？主要是考虑tomcat8是支持nio的方式的，是一种io非阻塞的处理方式，能提高接口性能，只是需要我们修改tomcat中的server.xml配置文件，以后所有的部署配置文件都必须修改如下方式：1、 修改默认方式，改成nio（org.apache.coyote.http11.Http11Nio2Protocol）的方式，并且加encoding参数为utf-82、 修改自动解压包文件等参数为false目前主要是以上这2点，以后有新的参数配置提升程序性能等会后续补上"
  },
  
  {
    "title": "MariaDB Galera集群启动",
    "url": "/posts/mariadb-galera-startup/",
    "categories": "数据库",
    "tags": "",
    "date": "2016-10-12 00:00:00 +0800",
    





    
    "snippet": "系统：CentOS7_x86_641.安装安装可以遵循官网的方法，在/etc/yum.repos.d写一个MariaDB.repo.repo的内容如下：# MariaDB 10.1 CentOSrepository list - created 2016-05-06 05:30 UTC #http://mariadb.org/mariadb/repositories/ [mariadb] n...",
    "content": "系统：CentOS7_x86_641.安装安装可以遵循官网的方法，在/etc/yum.repos.d写一个MariaDB.repo.repo的内容如下：# MariaDB 10.1 CentOSrepository list - created 2016-05-06 05:30 UTC #http://mariadb.org/mariadb/repositories/ [mariadb] name = MariaDB baseurl =http://yum.mariadb.org/10.1/centos7-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=1 具体可以到这里获得：https://downloads.mariadb.org/mariadb/repositories/#mirror=neusoft然后执行：sudo yum install MariaDB-server MariaDB-client这里说明一点，因为我使用的是10.1的版本，从这个版本开始，mariadb已经默认自带galera了，所以无需另外安装。2.系统和网络配置配置主要分为：selinux设置：修改/etc/selinux/config，改成disabled;iptables设置：如果嫌麻烦就直接关闭防火墙，不然那要开放 3306，4567，4568，4444四个端口。3.配置文件主要是配置/etc/my.cnf.d/server.cnf[galera]# Mandatory settingswsrep_on=ONwsrep_provider=/usr/lib64/galera/libgalera_smm.sowsrep_cluster_address=gcomm://open11,open134,open246binlog_format=rowdefault_storage_engine=InnoDBinnodb_autoinc_lock_mode=2还有就是配置用户和组，然后chown相应的文件groupadd mariadbuseradd -g mariadb mariadbchown -R  mariadb:mariadb  /var/data/mysql4.启动第一台启动的时候：mysqld --wsrep-new-cluster其他机器启动：mysqld --wsrep_cluster_address=gcomm://s91,s71,s240mysqld --wsrep_cluster_address=gcomm://sv203,sv204,sv2055.MariaDB Galera Cluster 参数使用SHOW VARIABLES LIKE 'wsrep%'以下是特别的几个：SHOW GLOBAL STATUS LIKE ‘wsrep_cluster_state_uuid’;查看集群的UUIDshow global status like 'wsrep_cluster_status';primary-non-Primary"
  },
  
  {
    "title": "个人开源作品：Spring MVC 关于jsonp跨域处理",
    "url": "/posts/spring-mvc-jsonp-open/",
    "categories": "开源",
    "tags": "",
    "date": "2015-09-13 00:00:00 +0800",
    





    
    "snippet": "1、新建JsonpAdvice控制器增强继承org.springframework.web.servlet.mvc.method.annotation.AbstractJsonpResponseBodyAdvice类 package com.drore.jsonp.advice;  import org.springframework.web.bind.annotation.Controll...",
    "content": "1、新建JsonpAdvice控制器增强继承org.springframework.web.servlet.mvc.method.annotation.AbstractJsonpResponseBodyAdvice类 package com.drore.jsonp.advice;  import org.springframework.web.bind.annotation.ControllerAdvice;  import org.springframework.web.servlet.mvc.method.annotation.AbstractJsonpResponseBodyAdvice;  @ControllerAdvice  public class JsonpAdvice extends AbstractJsonpResponseBodyAdvice{  \tpublic JsonpAdvice() {  \t\tsuper(\"callback\",\"jsonp\");  \t}  }2、所有controller类使用@RestController注解package com.drore.jsonp.controller;    import java.util.ArrayList;  import java.util.HashMap;  import java.util.List;  import java.util.Map;    import org.springframework.web.bind.annotation.RequestMapping;  import org.springframework.web.bind.annotation.RestController;    @RestController  public class HomeController {    \t@RequestMapping(value=\"/render.json\")  \tpublic List&lt;Map&lt;String, Object&gt;&gt; render(){  \t\tList&lt;Map&lt;String, Object&gt;&gt; list=new ArrayList&lt;Map&lt;String,Object&gt;&gt;();  \t\tfor (int i = 0; i &lt; 10; i++) {  \t\t\tMap&lt;String, Object&gt; map=new HashMap&lt;String, Object&gt;();  \t\t\tmap.put(\"userName\", \"张三\"+i);  \t\t\tmap.put(\"sex\", \"男\");  \t\t\tmap.put(\"phone\", \"1598723212\"+i);  \t\t\tlist.add(map);  \t\t}  \t\treturn list;  \t}  }3、jQuery跨域调用： $.ajax({  \turl:'http://localhost:9090/render.json',  \tdataType:'jsonp',  \tsuccess:function(data){  \t\tconsole.log(data)  \t}  })  //返回json数据  jQuery162036356921307742596_1442105501105([      {          \"phone\": \"15987232120\",          \"sex\": \"男\",          \"userName\": \"张三0\"      },     //......  ]);相关链接  jsonp 的详细介绍：点击查看  jsonp 的下载地址：点击下载"
  },
  
  {
    "title": "论js闭包的重要性",
    "url": "/posts/js-closure/",
    "categories": "JavaScript",
    "tags": "",
    "date": "2015-01-07 00:00:00 +0800",
    





    
    "snippet": "很久没写博客了,今天发现了一个很有意思的问题,写下来分享一下话不多说,贴前端代码:前端一个很简单的ajax提交代码,对不对?通过getMoney()函数 得到一个值,然后发送给后台,注意,该函数是不包含在$()代码块里面的后台代码：也是很简单的,只是响应用户的发送数据,代码如下：OK,万事具备,页面走起!!页面点击发送看后台：貌似没错,后台如愿得到我们要的数据只是,如果有些捣蛋鬼喜欢捣蛋呢?...",
    "content": "很久没写博客了,今天发现了一个很有意思的问题,写下来分享一下话不多说,贴前端代码:前端一个很简单的ajax提交代码,对不对?通过getMoney()函数 得到一个值,然后发送给后台,注意,该函数是不包含在$()代码块里面的后台代码：也是很简单的,只是响应用户的发送数据,代码如下：OK,万事具备,页面走起!!页面点击发送看后台：貌似没错,后台如愿得到我们要的数据只是,如果有些捣蛋鬼喜欢捣蛋呢?比如我用火狐的firefox注入一个getMoney()方法好吧,我注入了一个和页面上相同的函数getMoney(),居然返回100000.太坏了..OK,让我们在点击发送后台按钮,看看是什么情况呢?天呐…….居然真给变了…好吧,再看看我们的服务端,是不是也会随波逐流呢?我已经无语了,这别个捣蛋鬼岂不是能随便传送数据…不然,如果页面修改一下呢?代码如下：注意,这次我的getMoney()函数写在$()这个里面去了OK,我们在刷新页面,做相同的操作,注入一个getMoney很奇怪呢,居然没有变化,不放心,再看看后台：也没有变化,是不是很有意思呢?呵呵,各位有什么看法呢?畅所欲言哦"
  }
  
]

